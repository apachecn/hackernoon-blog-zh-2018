<html>
<head>
<title>Transfer learning with MXNet Gluon</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">MXNet胶子迁移学习</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/transfer-learning-with-mxnet-gluon-8203005afafe?source=collection_archive---------11-----------------------#2018-01-07">https://medium.com/hackernoon/transfer-learning-with-mxnet-gluon-8203005afafe?source=collection_archive---------11-----------------------#2018-01-07</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="81a5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">一年前，我开始用Tensorflow学习神经网络。旅途并不像我想象的那么顺利。感谢<a class="jp jq gr" href="https://medium.com/u/592ce2a67248?source=post_page-----8203005afafe--------------------------------" rel="noopener" target="_blank">吴恩达</a>的在线课程和几本书，我对这个理论有了一个基本的了解，然而，当我试图将它应用到现实生活的项目中时，Tensorflow的语法和api有时会让我困惑(也许我没有花足够的时间在它上面)。</p><p id="f35d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为了获得项目的早期结果，我直接应用了Tensorflow计算机视觉api。然而，当谈到定制模型时，我花了很长时间来整理一切。</p><p id="4e62" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">直到有一天，我发现了<a class="ae jr" href="https://mxnet.incubator.apache.org/api/python/gluon.html" rel="noopener ugc nofollow" target="_blank"> MXNet胶子</a>。</p><h1 id="2e9a" class="js jt hu bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dt translated">什么是MXNet胶子</h1><p id="f80d" class="pw-post-body-paragraph ir is hu it b iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo hn dt translated">Gluon是MXNet的接口——亚马逊支持的深度学习框架。Gluon类似于其他高级api，如Keras、Pytorch和Chainer。但它有其独特的可爱之处:</p><ol class=""><li id="80c2" class="kv kw hu it b iu iv iy iz jc kx jg ky jk kz jo la lb lc ld dt translated">命令式和符号式:胶子通过它的<code class="eh le lf lg lh b"><a class="ae jr" href="https://mxnet.incubator.apache.org/api/python/gluon.html#mxnet.gluon.HybridBlock" rel="noopener ugc nofollow" target="_blank">HybridBlock</a></code>让你享受命令式框架和符号式框架的优点。因此，您可以轻松地使用jupyter笔记本进行开发和调试，并在将其转换为symbolic时享受性能优化。</li><li id="89eb" class="kv kw hu it b iu li iy lj jc lk jg ll jk lm jo la lb lc ld dt translated">简单的API而不牺牲灵活性:与Pytorch或Chainer不同，您不需要记住每一层的输出大小。API定义与Keras非常相似。您可以轻松扩展和构建自己的<code class="eh le lf lg lh b">block</code>。</li></ol><h1 id="0b91" class="js jt hu bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dt translated">什么是迁移学习</h1><p id="1ead" class="pw-post-body-paragraph ir is hu it b iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo hn dt translated">迁移学习是一种重用现有模型的学习表示并将其应用于不同但相关的领域的技术。</p><p id="6727" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">之所以要用迁移学习，是因为从零开始训练一个神经网络需要很长的时间和大量的资源。通常我们以两种方式使用迁移学习:</p><ol class=""><li id="8415" class="kv kw hu it b iu iv iy iz jc kx jg ky jk kz jo la lb lc ld dt translated">用预训练模型初始化参数</li><li id="37c2" class="kv kw hu it b iu li iy lj jc lk jg ll jk lm jo la lb lc ld dt translated">使用预训练模型作为固定特征提取器，建立基于特征的模型</li></ol><p id="3dab" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">迁移学习作为一个话题本身就可以涉及到很长的讨论。在这篇文章中，我们将主要看使用它来初始化参数。</p><h1 id="b698" class="js jt hu bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dt translated">我们开始吧</h1><h2 id="08a9" class="ln jt hu bd ju lo lp lq jy lr ls lt kc jc lu lv kg jg lw lx kk jk ly lz ko ma dt translated">问题定义</h2><figure class="mc md me mf fq mg fe ff paragraph-image"><div class="fe ff mb"><img src="../Images/05c1f70d42ec0d37f1bfcf093b242721.png" data-original-src="https://miro.medium.com/v2/resize:fit:1120/format:webp/1*9JKUeiZP2BLP0L9u-qb3Gw.jpeg"/></div><figcaption class="mj mk fg fe ff ml mm bd b be z ek">husky or akita</figcaption></figure><p id="863e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">给一张我们最喜欢的宠物狗的照片，它是哈士奇还是秋田犬？</p><p id="f358" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为什么会有这个问题？最好研究你感兴趣的问题，数据集应该很容易找到。(他们很可爱，很容易找到他们的照片)</p><h2 id="fc35" class="ln jt hu bd ju lo lp lq jy lr ls lt kc jc lu lv kg jg lw lx kk jk ly lz ko ma dt translated">先决条件</h2><ol class=""><li id="dab2" class="kv kw hu it b iu kq iy kr jc mn jg mo jk mp jo la lb lc ld dt translated">安装MXNet: <code class="eh le lf lg lh b">pip install mxnet</code></li><li id="6166" class="kv kw hu it b iu li iy lj jc lk jg ll jk lm jo la lb lc ld dt translated">安装Jupyter笔记本:<code class="eh le lf lg lh b">pip install jupyter</code></li></ol><h2 id="2e8b" class="ln jt hu bd ju lo lp lq jy lr ls lt kc jc lu lv kg jg lw lx kk jk ly lz ko ma dt translated">准备数据集</h2><p id="0248" class="pw-post-body-paragraph ir is hu it b iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo hn dt translated">数据来源:关键字哈士奇和秋田的谷歌图片。</p><p id="3368" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">数据集将分为4个部分:</p><ol class=""><li id="d4a1" class="kv kw hu it b iu iv iy iz jc kx jg ky jk kz jo la lb lc ld dt translated"><code class="eh le lf lg lh b">sample</code> : 16张开发调试图像</li><li id="092c" class="kv kw hu it b iu li iy lj jc lk jg ll jk lm jo la lb lc ld dt translated"><code class="eh le lf lg lh b">train</code> : 70%，针对列车模型</li><li id="676f" class="kv kw hu it b iu li iy lj jc lk jg ll jk lm jo la lb lc ld dt translated"><code class="eh le lf lg lh b">validation</code> : 15%，用于诊断模型，检测过拟合/欠拟合，如果有多个版本，则选择模型</li><li id="1b7f" class="kv kw hu it b iu li iy lj jc lk jg ll jk lm jo la lb lc ld dt translated"><code class="eh le lf lg lh b">test</code> : 15%，用于评估模型的准确性</li></ol><p id="1b46" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">MXNet提供了一个<code class="eh le lf lg lh b"><a class="ae jr" href="https://github.com/apache/incubator-mxnet/blob/master/tools/im2rec.py" rel="noopener ugc nofollow" target="_blank">im2rec.py</a></code>脚本来生成<code class="eh le lf lg lh b">rec</code>文件，它需要一个<code class="eh le lf lg lh b">lst</code>文件来指定文件位置和标签。生成lst文件和rec文件的笔记本可以在<a class="ae jr" href="https://github.com/MrXu/transfer-learning-with-gluon/blob/master/prepare-dataset.ipynb" rel="noopener ugc nofollow" target="_blank">这里</a>找到。</p><p id="4351" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">生成数据集后，您的目录结构将如下所示:</p><figure class="mc md me mf fq mg fe ff paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="fe ff mq"><img src="../Images/9a94ad92261c50ad61aa5b9b20632990.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lN_F32pg3h11gjUrjEB0SQ.png"/></div></div></figure><h2 id="2a08" class="ln jt hu bd ju lo lp lq jy lr ls lt kc jc lu lv kg jg lw lx kk jk ly lz ko ma dt translated">建立模型</h2><p id="df2e" class="pw-post-body-paragraph ir is hu it b iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo hn dt translated">我们将使用<a class="ae jr" href="https://arxiv.org/abs/1704.04861" rel="noopener ugc nofollow" target="_blank"> MobileNet </a>完成迁移学习任务。MobileNet是一种高效的卷积神经网络架构。它采用3×3深度方向conv和1×1点方向conv代替常规卷积层，降低了计算复杂度。</p><figure class="mc md me mf fq mg fe ff paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="fe ff mv"><img src="../Images/81ef32b7e36c1e95ad846188ea4bee96.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7XhU6VXW9mq9uaWYsk5BAw.png"/></div></div><figcaption class="mj mk fg fe ff ml mm bd b be z ek">regular convolution vs depthwise separable convolution (<a class="ae jr" href="http://machinethink.net/blog/googles-mobile-net-architecture-on-iphone/" rel="noopener ugc nofollow" target="_blank">reference</a>)</figcaption></figure><p id="2a4e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">多亏了胶子社区，我们已经在ImageNet上对MobileNets进行了预训练。让我们用Jupyter笔记本来探索一下吧。</p><pre class="mc md me mf fq mw lh mx my aw mz dt"><span id="dc06" class="ln jt hu lh b fv na nb l nc nd">from mxnet.gluon.model_zoo.vision import mobilenet1_0<br/>pretrained_net = mobilenet1_0(pretrained=True)<br/>print(pretrained_net)</span></pre><p id="25c3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">一旦你运行它，你会发现这个模型由两个高层模块组成:<code class="eh le lf lg lh b">features</code>和<code class="eh le lf lg lh b">output</code>。由于ImageNet版本的输出形状是1000，我们需要创建一个输出形状为2的模型。</p><pre class="mc md me mf fq mw lh mx my aw mz dt"><span id="e74c" class="ln jt hu lh b fv na nb l nc nd">net = mobilenet1_0(classes=2)</span></pre><p id="57b6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为了重用预训练模型的权重，我们可以直接将其分配给新模型的<code class="eh le lf lg lh b">features</code>模块。</p><pre class="mc md me mf fq mw lh mx my aw mz dt"><span id="c56a" class="ln jt hu lh b fv na nb l nc nd">from mxnet import init<br/>net.features = pretrained_net.features<br/>net.output.initialize(init.Xavier())</span></pre><p id="0060" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">就是这样~</p><h2 id="aa1f" class="ln jt hu bd ju lo lp lq jy lr ls lt kc jc lu lv kg jg lw lx kk jk ly lz ko ma dt translated">训练模型</h2><p id="8110" class="pw-post-body-paragraph ir is hu it b iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo hn dt translated">在训练模型之前，让我们为husky &amp; akita数据集创建数据加载器。我们将使用MXNet提供的<a class="ae jr" href="https://mxnet.incubator.apache.org/api/python/image.html" rel="noopener ugc nofollow" target="_blank">图像增强功能</a>来生成新样本，并帮助避免过拟合。</p><pre class="mc md me mf fq mw lh mx my aw mz dt"><span id="6c09" class="ln jt hu lh b fv na nb l nc nd">from mxnet.image import color_normalize<br/>from mxnet import image</span><span id="e723" class="ln jt hu lh b fv ne nb l nc nd">train_augs = [<br/>    image.ResizeAug(224),<br/>    image.HorizontalFlipAug(0.5),  # flip the image horizontally<br/>    image.BrightnessJitterAug(.3), # randomly change the brightness<br/>    image.HueJitterAug(.1)         # randomly change hue<br/>]<br/>test_augs = [<br/>    image.ResizeAug(224)<br/>]</span><span id="084e" class="ln jt hu lh b fv ne nb l nc nd">def transform(data, label, augs):<br/>    data = data.astype('float32')<br/>    for aug in augs:<br/>        data = aug(data)<br/>    data = nd.transpose(data, (2,0,1))<br/>    return data, nd.array([label]).asscalar().astype('float32')</span></pre><p id="b225" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在我们可以用我们定义的扩充创建一个数据迭代器。</p><pre class="mc md me mf fq mw lh mx my aw mz dt"><span id="aec5" class="ln jt hu lh b fv na nb l nc nd">from mxnet.gluon.data.vision import ImageRecordDataset</span><span id="be14" class="ln jt hu lh b fv ne nb l nc nd">train_rec = './data/train/dog.rec'<br/>validation_rec = './data/validation/dog.rec'</span><span id="ea30" class="ln jt hu lh b fv ne nb l nc nd">trainIterator = ImageRecordDataset(<br/>    filename=train_rec, <br/>    transform=lambda X, y: transform(X, y, train_augs)<br/>)<br/>validationIterator = ImageRecordDataset(<br/>    filename=validation_rec,<br/>    transform=lambda X, y: transform(X, y, test_augs)<br/>)</span></pre><p id="71dd" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">让我们定义我们的训练函数。</p><pre class="mc md me mf fq mw lh mx my aw mz dt"><span id="1056" class="ln jt hu lh b fv na nb l nc nd">def train(net, ctx, <br/>          batch_size=64, epochs=10, learning_rate=0.01, wd=0.001):</span><span id="55df" class="ln jt hu lh b fv ne nb l nc nd">    train_data = gluon.data.DataLoader(<br/>        trainIterator, batch_size, shuffle=True)<br/>    validation_data = gluon.data.DataLoader(<br/>        validationIterator, batch_size)</span><span id="36ed" class="ln jt hu lh b fv ne nb l nc nd">    net.collect_params().reset_ctx(ctx)<br/>    net.hybridize()<br/>    <br/>    loss = gluon.loss.SoftmaxCrossEntropyLoss()<br/>    trainer = gluon.Trainer(net.collect_params(), 'sgd', {<br/>        'learning_rate': learning_rate, 'wd': wd})<br/>    <br/>    train_util(net, train_data, validation_data, <br/>               loss, trainer, ctx, epochs, batch_size)</span></pre><p id="df5e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><code class="eh le lf lg lh b">train_util</code>功能可以在这里找到<a class="ae jr" href="https://github.com/MrXu/transfer-learning-with-gluon/blob/master/train.ipynb" rel="noopener ugc nofollow" target="_blank">。一般都是复用的，这里就不贴了。</a></p><p id="c7ca" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">有一些要点需要强调:</p><ol class=""><li id="ad77" class="kv kw hu it b iu iv iy iz jc kx jg ky jk kz jo la lb lc ld dt translated"><code class="eh le lf lg lh b">hybridize</code>:将你的命令模型转换成符号模型的函数，计算图为更快的训练而优化。</li><li id="72cd" class="kv kw hu it b iu li iy lj jc lk jg ll jk lm jo la lb lc ld dt translated">在这里，我们定义我们的学习率、优化函数和权重衰减</li></ol><p id="5cf4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">一切就绪后，我们可以开始训练了！</p><p id="4569" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在5个时期之后，我们可以看到训练准确度和验证准确度都上升了。</p><figure class="mc md me mf fq mg fe ff paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="fe ff nf"><img src="../Images/3976a9a0232e7f1a7f95ef6ef548e8c8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*sXQZWPAbhP9pvNu0BMlFEg.png"/></div></div><figcaption class="mj mk fg fe ff ml mm bd b be z ek">training process</figcaption></figure><h2 id="2729" class="ln jt hu bd ju lo lp lq jy lr ls lt kc jc lu lv kg jg lw lx kk jk ly lz ko ma dt translated">试验</h2><p id="71a9" class="pw-post-body-paragraph ir is hu it b iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo hn dt translated">所以我们在训练集中达到了<code class="eh le lf lg lh b">0.97</code>的精度，但是，我们不能用训练精度来评价一个模型。原因是这个模型可能只是过度拟合了训练数据的分布(有一次我故意过度拟合了训练集，它达到了99.9%，但它在真实数据集上表现很差)。</p><p id="d274" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为了评估我们模型的性能，我们需要使用我们从未在训练、模型选择或参数微调中使用过的<code class="eh le lf lg lh b">test dataset</code>。</p><pre class="mc md me mf fq mw lh mx my aw mz dt"><span id="b838" class="ln jt hu lh b fv na nb l nc nd">test_data_loader = gluon.data.DataLoader(testIterator, 64)<br/>test_acc = evaluate_accuracy(test_data_loader, net)</span></pre><p id="a991" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">测试精度是<code class="eh le lf lg lh b">0.93</code>，所以我们的模型没有我们想象的那么好。</p><figure class="mc md me mf fq mg fe ff paragraph-image"><div role="button" tabindex="0" class="mr ms di mt bf mu"><div class="fe ff ng"><img src="../Images/7809cd7233848bfea1235e2e50d83cd6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jjhhF9MpBMD04p3z4cXH7Q.png"/></div></div></figure><h1 id="0ac6" class="js jt hu bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dt translated">讨论</h1><blockquote class="nh ni nj"><p id="d97f" class="ir is nk it b iu iv iw ix iy iz ja jb nl jd je jf nm jh ji jj nn jl jm jn jo hn dt translated">第一次验证精度达到0.88，感觉不真实</p></blockquote><p id="36ef" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">是的，原因是<code class="eh le lf lg lh b">husky</code>是ImageNet中的一个现有标签，我们的数据集不是很大</p><blockquote class="nh ni nj"><p id="aa9d" class="ir is nk it b iu iv iw ix iy iz ja jb nl jd je jf nm jh ji jj nn jl jm jn jo hn dt translated">训练准确性和验证准确性之间总是有差距</p></blockquote><p id="523f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这表明我们过度拟合了我们的模型。我们可以通过增加<code class="eh le lf lg lh b">weight_decay</code>来应用更多的正则化，或者我们应该尝试获得更多的训练数据。</p><h1 id="4267" class="js jt hu bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dt translated">结论</h1><p id="ed10" class="pw-post-body-paragraph ir is hu it b iu kq iw ix iy kr ja jb jc ks je jf jg kt ji jj jk ku jm jn jo hn dt translated">这篇文章向你展示了使用MXNet胶子进行迁移学习是多么简单。当您尝试将这种技术应用到您自己的问题时，它也是一个指南。</p><p id="a680" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">还有很多有趣的话题我没有涉及，比如定制block、构建自己的架构以及在不同的环境中部署模型。我会在以后的文章中尽量涵盖它们。</p><p id="82ff" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">源代码:<a class="ae jr" href="https://github.com/MrXu/transfer-learning-with-gluon" rel="noopener ugc nofollow" target="_blank">https://github.com/MrXu/transfer-learning-with-gluon</a></p><h1 id="80ba" class="js jt hu bd ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp dt translated">参考</h1><ol class=""><li id="d9b7" class="kv kw hu it b iu kq iy kr jc mn jg mo jk mp jo la lb lc ld dt translated"><a class="ae jr" href="https://blog.keras.io/on-the-importance-of-democratizing-artificial-intelligence.html" rel="noopener ugc nofollow" target="_blank">关于人工智能民主化的重要性</a></li><li id="67d9" class="kv kw hu it b iu li iy lj jc lk jg ll jk lm jo la lb lc ld dt translated"><a class="ae jr" href="http://cs231n.github.io/transfer-learning/" rel="noopener ugc nofollow" target="_blank">用于视觉识别的CS231n卷积神经网络</a></li><li id="86ea" class="kv kw hu it b iu li iy lj jc lk jg ll jk lm jo la lb lc ld dt translated"><a class="ae jr" href="https://mxnet.incubator.apache.org/api/python/gluon.html" rel="noopener ugc nofollow" target="_blank"> MXNet胶子文档</a></li><li id="57ce" class="kv kw hu it b iu li iy lj jc lk jg ll jk lm jo la lb lc ld dt translated"><a class="ae jr" href="https://zhuanlan.zhihu.com/p/28648399" rel="noopener ugc nofollow" target="_blank">https://zhuanlan.zhihu.com/p/28648399</a></li><li id="e771" class="kv kw hu it b iu li iy lj jc lk jg ll jk lm jo la lb lc ld dt translated"><a class="ae jr" href="https://arxiv.org/abs/1704.04861" rel="noopener ugc nofollow" target="_blank">移动网络</a></li><li id="b0d5" class="kv kw hu it b iu li iy lj jc lk jg ll jk lm jo la lb lc ld dt translated"><a class="ae jr" href="http://machinethink.net/blog/googles-mobile-net-architecture-on-iphone/" rel="noopener ugc nofollow" target="_blank">苹果手机上的谷歌手机</a></li></ol></div></div>    
</body>
</html>