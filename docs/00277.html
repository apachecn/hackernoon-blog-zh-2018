<html>
<head>
<title>Exploiting Spectre with Deep Learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">利用深度学习开发Spectre</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/exploiting-spectre-with-deep-learning-d8ec2ba4c8ca?source=collection_archive---------19-----------------------#2018-01-09">https://medium.com/hackernoon/exploiting-spectre-with-deep-learning-d8ec2ba4c8ca?source=collection_archive---------19-----------------------#2018-01-09</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/a8f8671a57ce7350ddf3f0e33a27eacb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PflM4OAaya6mBK3dDQEmlA.jpeg"/></div></div></figure><p id="bbb8" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">上周，谷歌的Project Zero 向安全社区抛出了一个<a class="ae ka" href="https://googleprojectzero.blogspot.com/2018/01/reading-privileged-memory-with-side.html" rel="noopener ugc nofollow" target="_blank">的重磅炸弹</a>，详细描述了影响<a class="ae ka" href="https://newsroom.intel.com/wp-content/uploads/sites/11/2018/01/Intel-Analysis-of-Speculative-Execution-Side-Channels.pdf" rel="noopener ugc nofollow" target="_blank">英特尔</a>、<a class="ae ka" href="https://www.amd.com/en/corporate/speculative-execution" rel="noopener ugc nofollow" target="_blank"> AMD </a>和<a class="ae ka" href="https://developer.arm.com/support/security-update" rel="noopener ugc nofollow" target="_blank"> ARM </a>架构的CPU缺陷，这些架构可以追溯到奔腾pro。是的，芯片有一座山的缓存和不死的怪异铝。</p><figure class="kb kc kd ke fq iv"><div class="bz el l di"><div class="kf kg l"/></div></figure><p id="2ba4" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这些bug实际上有几个变种，统称为<a class="ae ka" href="https://meltdownattack.com/" rel="noopener ugc nofollow" target="_blank"> Meltdown </a>和<a class="ae ka" href="https://spectreattack.com/" rel="noopener ugc nofollow" target="_blank"> Spectre </a>，在<a class="ae ka" href="https://bugs.chromium.org/p/project-zero/issues/detail?id=1272" rel="noopener ugc nofollow" target="_blank">官方bug报告</a>中有详细描述。有趣的是，错误总结的最后一行写道:</p><blockquote class="kh ki kj"><p id="d014" class="jc jd kk je b jf jg jh ji jj jk jl jm kl jo jp jq km js jt ju kn jw jx jy jz hn dt translated">所有POC都是针对特定处理器编写的，可能至少需要一些调整才能在其他环境中运行，例如，由于硬编码的计时阈值[原文如此]。</p></blockquote><p id="c342" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">事实上，硬编码值从来都不是一个好主意，因为它经常导致代码不灵活。这篇文章探讨了我们如何在深度学习的帮助下学习这些阈值。但首先，让我们回顾一下Spectre是如何工作的。</p><h1 id="21e2" class="ko kp hu bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll dt translated">spectre——或者如何利用CPU优化</h1><p id="8fe5" class="pw-post-body-paragraph jc jd hu je b jf lm jh ji jj ln jl jm jn lo jp jq jr lp jt ju jv lq jx jy jz hn dt translated">如果你在寻找这个巧妙利用的完整解释，你可以在这里找到论文<a class="ae ka" href="https://spectreattack.com/spectre.pdf" rel="noopener ugc nofollow" target="_blank">。总之，Spectre利用了两个非常流行的CPU优化:</a><a class="ae ka" href="https://en.wikipedia.org/wiki/Branch_predictor" rel="noopener ugc nofollow" target="_blank">分支预测</a>和<a class="ae ka" href="https://en.wikipedia.org/wiki/Speculative_execution" rel="noopener ugc nofollow" target="_blank">推测执行</a>。当CPU执行包含附加到内存值的分支的一段代码时，由于从RAM中检索该值可能需要一些时间，因此CPU可以选择越过该分支执行。在高级编程语言中，分支通常是条件语句的结果，比如<code class="eh lr ls lt lu b">if … then …</code>。当RAM中的值最终到达时，如果它的预测碰巧是错误的，CPU将丢弃执行的代码。</p><p id="1c20" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这种推测性执行的副作用是将CPU读取的RAM复制到缓存中，如果该内存属于另一个进程，或者更糟的是，属于内核，那么在现代安全系统意识到内存访问被禁止之前，它将被缓存。因此，恶意代码可以欺骗CPU缓存特权内存，然后通过<a class="ae ka" href="https://en.wikipedia.org/wiki/Side-channel_attack" rel="noopener ugc nofollow" target="_blank">侧通道</a> <a class="ae ka" href="https://en.wikipedia.org/wiki/Timing_attack" rel="noopener ugc nofollow" target="_blank">定时攻击</a>读出缓存的值。这种攻击利用了CPU从RAM(慢速)和片上CPU缓存(快速)获取值所需时间的差异。正如bug总结中提到的，每个CPU都会表现出不同的计时行为。这就是深度学习的用武之地。</p><h1 id="2585" class="ko kp hu bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll dt translated">深度学习CPU缓存计时</h1><p id="0fd0" class="pw-post-body-paragraph jc jd hu je b jf lm jh ji jj ln jl jm jn lo jp jq jr lp jt ju jv lq jx jy jz hn dt translated">为了读取特权内存地址的字节值，我们的<a class="ae ka" href="https://github.com/asm/deep_spectre/blob/master/deep_spectre.c#L81-L89" rel="noopener ugc nofollow" target="_blank">概念验证代码</a>试图读取给定内存地址的每个可能的8位值——总共256个。我们不能直接读取值，因为内核不允许，但是我们可以观察每次读取花费了多长时间。如果读得很快，我们就有机会找到正确的值。不幸的是，这并不总是正确的，因为有些值读取起来总是有点快(例如，0和1)，所以假设最快可能会导致误读值。让我们看看如何使用深度学习模型来提高阅读准确性。</p><p id="e670" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">概念代码的完整证明可以在<a class="ae ka" href="https://github.com/asm/deep_spectre" rel="noopener ugc nofollow" target="_blank">这里</a>找到，从这里开始我将只包括最相关的部分。首先，我们将使用一串可能的字节值及其观察到的缓存计时来构建我们的训练数据:</p><pre class="kb kc kd ke fq lv lu lw lx aw ly dt"><span id="a075" class="lz kp hu lu b fv ma mb l mc md">data_x = np.zeros([n_samples, 256])<br/>data_y = np.zeros([n_samples, len(unique_chars)])<br/>for i in range(n_iterations):<br/>    for j, val in enumerate(secret_chars):<br/>        data_x[i * n_chars + j, :] = deep_spectre.train(j)<br/>        data_y[i * n_chars + j, char_to_idx_map[val]] = 1</span></pre><p id="1f62" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><code class="eh lr ls lt lu b">data_x</code>包含我们的训练数据，<code class="eh lr ls lt lu b">data_y</code>包含我们的目标数据。<code class="eh lr ls lt lu b">data_x</code>的每一行代表对单个字节值的所有256个缓存读取时间的观察。<code class="eh lr ls lt lu b">data_y</code>的每一行包含字节值，<a class="ae ka" href="https://en.wikipedia.org/wiki/One-hot" rel="noopener ugc nofollow" target="_blank">一个热编码</a>。神经网络通常对大值敏感，因此我们将使用<a class="ae ka" href="http://scikit-learn.org/stable/" rel="noopener ugc nofollow" target="_blank"> Scikit Learn的</a>便捷缩放器来归一化(0均值，单位方差)时序。我们还将把训练和目标数据分成训练集和验证集。验证集包含模型在训练时从未见过的数据，并提供了模型在野外表现如何的合理度量:</p><pre class="kb kc kd ke fq lv lu lw lx aw ly dt"><span id="00aa" class="lz kp hu lu b fv ma mb l mc md">scaler = StandardScaler()<br/>data_x = scaler.fit_transform(data_x)<br/>x_train, x_test, y_train, y_test = train_test_split(data_x, data_y)</span></pre><p id="a735" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在是激动人心的部分——让我们建立一个简单的深度模型。我们将使用<a class="ae ka" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras API </a>来包装<a class="ae ka" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>并构建一个四层密集连接的神经网络。如果你对神经架构感兴趣，我鼓励你去看看Keras提供的其他层类型。</p><pre class="kb kc kd ke fq lv lu lw lx aw ly dt"><span id="73b1" class="lz kp hu lu b fv ma mb l mc md">model = Sequential()<br/>model.add(Dense(200, input_shape = (256,), activation = ‘relu’))<br/>model.add(Dense(150, activation = ‘relu’))<br/>model.add(Dense(100, activation = ‘relu’))<br/>model.add(Dense(len(unique_chars), activation = ‘softmax’))</span><span id="d778" class="lz kp hu lu b fv me mb l mc md">model.compile(loss = ‘categorical_crossentropy’,<br/>              optimizer = ‘adam’,<br/>              metrics = [‘accuracy’])</span><span id="4ce7" class="lz kp hu lu b fv me mb l mc md">model.fit(x_train, y_train, <br/>          batch_size = 32,<br/>          epochs = 10,<br/>          validation_data = (x_test, y_test))</span></pre><p id="6587" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">呼叫<code class="eh lr ls lt lu b">model.fit()</code>将开始训练过程。如果一切顺利，我们的模型应该达到90%以上的准确率。在我的机器上运行这个程序会产生:</p><pre class="kb kc kd ke fq lv lu lw lx aw ly dt"><span id="4609" class="lz kp hu lu b fv ma mb l mc md">Train on 48000 samples, validate on 16000 samples<br/>Epoch 1/10<br/>48000/48000 [==============================] — 4s 83us/step — loss: 2.9168 — acc: 0.3363 — val_loss: 0.7985 — val_acc: 0.8276<br/>Epoch 2/10<br/>48000/48000 [==============================] — 4s 73us/step — loss: 0.4543 — acc: 0.9007 — val_loss: 0.3505 — val_acc: 0.9204<br/>Epoch 3/10<br/>48000/48000 [==============================] — 4s 75us/step — loss: 0.2802 — acc: 0.9367 — val_loss: 0.2825 — val_acc: 0.9335<br/>Epoch 4/10<br/>48000/48000 [==============================] — 3s 73us/step — loss: 0.2516 — acc: 0.9441 — val_loss: 0.2948 — val_acc: 0.9293<br/>Epoch 5/10<br/>48000/48000 [==============================] — 4s 73us/step — loss: 0.2368 — acc: 0.9451 — val_loss: 0.2640 — val_acc: 0.9361<br/>Epoch 6/10<br/>48000/48000 [==============================] — 4s 73us/step — loss: 0.2320 — acc: 0.9460 — val_loss: 0.2765 — val_acc: 0.9360<br/>Epoch 7/10<br/>48000/48000 [==============================] — 3s 73us/step — loss: 0.2405 — acc: 0.9458 — val_loss: 0.2588 — val_acc: 0.9376<br/>Epoch 8/10<br/>48000/48000 [==============================] — 4s 74us/step — loss: 0.2324 — acc: 0.9468 — val_loss: 0.2502 — val_acc: 0.9403<br/>Epoch 9/10<br/>48000/48000 [==============================] — 4s 73us/step — loss: 0.2269 — acc: 0.9474 — val_loss: 0.2452 — val_acc: 0.9408<br/>Epoch 10/10<br/>48000/48000 [==============================] — 3s 72us/step — loss: 0.2277 — acc: 0.9467 — val_loss: 0.2663 — val_acc: 0.9392</span></pre><p id="e42d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在我们有了一个训练好的模型，我们可以用它来预测未知的字节值，只给定缓存计时。例如，让我们读取一个40字节的秘密字符串:</p><pre class="kb kc kd ke fq lv lu lw lx aw ly dt"><span id="bc4d" class="lz kp hu lu b fv ma mb l mc md">secret_len = 40<br/>x_message = np.zeros([secret_len, 256])<br/>for i in range(secret_len):<br/>    x_message[i, :] = deep_spectre.read(i)</span></pre><p id="531e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在将<code class="eh lr ls lt lu b">x_message</code>传递到<code class="eh lr ls lt lu b">model.predict()</code>之后，我们简单地通过<code class="eh lr ls lt lu b">np.argmax()</code>获取概率最高的输出神经元，并将其映射回一个字节值:</p><pre class="kb kc kd ke fq lv lu lw lx aw ly dt"><span id="d927" class="lz kp hu lu b fv ma mb l mc md">y_pred = model.predict(scaler.transform(x_message))<br/>pred_chars = np.argmax(y_pred, axis=1)<br/>message = ‘’.join(list(map(lambda x: chr(idx_to_char_map[x]), pred_chars)))<br/>print(“The secret message is:”, message)</span></pre><p id="7bf2" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果一切按计划进行，我们应该看到:</p><pre class="kb kc kd ke fq lv lu lw lx aw ly dt"><span id="ac0b" class="lz kp hu lu b fv ma mb l mc md">The secret message is: The Magic Words are Squeamish Ossifrage.</span></pre><p id="28b0" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">将这些深度学习框架与漏洞打包在一起将会产生非常大的有效载荷。然而，可以使用<a class="ae ka" href="https://www.tensorflow.org/mobile/tflite/" rel="noopener ugc nofollow" target="_blank"> TensorFlow Lite </a>来减小模型的尺寸。毫无疑问，不难想象一种新的神经利用技术，用深度学习模型来克服跨CPU架构和软件版本的特质。</p><p id="1dae" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">当然，这仍然是纯粹的推测；)</p></div></div>    
</body>
</html>