<html>
<head>
<title>One Class Classification for Images with Deep features</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">具有深层特征的图像的一类分类</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/one-class-classification-for-images-with-deep-features-be890c43455d?source=collection_archive---------2-----------------------#2018-01-18">https://medium.com/hackernoon/one-class-classification-for-images-with-deep-features-be890c43455d?source=collection_archive---------2-----------------------#2018-01-18</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="65a2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">作为程序员，我们经常会遇到需要构建A vs ~A类型的二进制分类器的项目，其中当分类器被给予一个新的数据样本时，它能够预测该样本是属于A类还是离群值。解决这个问题的一个可靠但困难的方法是使用一类学习模式。</p><p id="0d8a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在一类学习中，我们只在正类数据集上训练模型，并自发地从中对宇宙[A union ~A]做出判断。这是一个热门的研究课题，有多种工具可以实现这一任务，如<a class="ae jp" href="http://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html" rel="noopener ugc nofollow" target="_blank">一级SVM </a>和<a class="ae jp" href="http://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html" rel="noopener ugc nofollow" target="_blank">隔离林</a>。在由~A样本组成的数据可以采用任何分布，并且不可能学习~A类的模式的情况下，单类学习可以被证明是至关重要的。</p><p id="f499" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">但是当样本点的维数增加时，单类学习变得更具挑战性。例如，考虑224x224px的图像大小-由于每个样本点包含大量的特征(在本例中为50，176个特征)，因此在这里直接应用任何一种开箱即用的学习算法都是致命的。因此，通常需要有效且有区别的特征表示来为图像或高维数据建立单类分类器。</p><p id="de75" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jq">这篇文章介绍了使用深度神经网络功能实现单类学习，并比较了基于OC- SVM、隔离森林和高斯混合方法的分类器性能。</em></p><p id="2509" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">作为特征提取器的CNNs】</strong></p><p id="1e8f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">当涉及到图像中的对象识别时，卷积神经网络已经被证明是最先进的。CNN已经取代了传统的<a class="ae jp" href="https://hackernoon.com/tagged/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>管道，其中特征提取和用于从这些特征中学习的模型是两个独立的实体。此外，CNN还可以帮助提取图像的有意义的特征，因为深度神经网络也可以学习哪些特征是重要的，哪些是不重要的，以便区分一个类别。这允许我们简单地<a class="ae jp" href="https://blog.keras.io/building-powerful-image-classification-models-using-very-little-data.html" rel="noopener ugc nofollow" target="_blank">使用从这些准备就绪的深度CNN返回的特征</a>，并构建我们的分类器。</p><p id="0384" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">此外，ImageNet数据上预训练CNN的可用性(超过1，000个类别和超过1，400万张图像)使图像分类变得更加简单，因为预训练CNN通常会返回足够令人满意的特征<em class="jq"/>来使用它们训练轻量级模型。</p><p id="2088" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">正如我前面提到的——由于CNN返回的特征向量给出了生成它们的图像的强大表示，我们使用这些特征来训练我们的单类分类器。出于本文的目的，我们使用ResNet-50作为模型的特征提取器。<em class="jq">为什么？</em>因为它快速、准确、可信，因为<a class="ae jp" href="https://blogs.microsoft.com/ai/microsoft-researchers-win-imagenet-computer-vision-challenge/" rel="noopener ugc nofollow" target="_blank">赢得了2015年的ImageNet挑战赛</a>。</p><p id="cfb0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> <em class="jq">用于这个问题的数据集— </em> </strong>我们使用的是<a class="ae jp" href="https://mmspg.epfl.ch/food-image-datasets" rel="noopener ugc nofollow" target="_blank"> Food5k </a>数据集，其中包含了Food和~Food两种图像(各2500张)。样本图像如下所示-</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff jr"><img src="../Images/0e43c3ba78ecf433c7004efc5bb9512c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SL6h3aP-lsuk5biyAJoLvw.png"/></div></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek">Sample food vs ~food images</figcaption></figure><p id="9312" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">一类SVM和隔离林模型的实现细节:</strong></p><p id="329e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们首先为图像数据集计算ResNet-50特征。其代码如下所示-</p><pre class="js jt ju jv fq kh ki kj kk aw kl dt"><span id="c97f" class="km kn hu ki b fv ko kp l kq kr">from keras.applications.resnet50 import ResNet50<br/>def extract_resnet(X):  <br/>    # X : images numpy array<br/>    resnet_model = ResNet50(input_shape=(image_h, image_w, 3), weights='imagenet', include_top=False)  # Since top layer is the fc layer used for predictions<br/>    features_array = resnet_model.predict(X)<br/>    return features_array</span></pre><p id="9f52" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们可以相应地计算数据集中所有图像的ResNet特征。下一步，沿着管道-</p><ol class=""><li id="c52f" class="ks kt hu it b iu iv iy iz jc ku jg kv jk kw jo kx ky kz la dt translated">对获得的特征应用标准缩放器。</li><li id="6134" class="ks kt hu it b iu lb iy lc jc ld jg le jk lf jo kx ky kz la dt translated">n_components = 512的主成分分析。</li><li id="a71e" class="ks kt hu it b iu lb iy lc jc ld jg le jk lf jo kx ky kz la dt translated">将剩余的功能传递给一个类SVM模型或隔离林</li></ol><p id="51b4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在下面的代码中，X_train和X_test是训练和测试图像的resnet特性。</p><pre class="js jt ju jv fq kh ki kj kk aw kl dt"><span id="dcf3" class="km kn hu ki b fv ko kp l kq kr">from sklearn.preprocessing import StandardScaler<br/>from sklearn.decomposition import PCA<br/>from sklearn.ensemble import IsolationForest<br/>from sklearn import svm<br/><br/># Apply standard scaler to output from resnet50<br/>ss = StandardScaler()<br/>ss.fit(X_train)<br/>X_train = ss.transform(X_train)<br/>X_test = ss.transform(X_test)<br/><br/># Take PCA to reduce feature space dimensionality<br/>pca = PCA(n_components=512, whiten=True)<br/>pca = pca.fit(X_train)<br/>print('Explained variance percentage = %0.2f' % sum(pca.explained_variance_ratio_))<br/>X_train = pca.transform(X_train)<br/>X_test = pca.transform(X_test)<br/><br/># Train classifier and obtain predictions for OC-SVM<br/>oc_svm_clf = svm.OneClassSVM(gamma=0.001, kernel='rbf', nu=0.08)  # Obtained using grid search<br/>if_clf = IsolationForest(contamination=0.08, max_features=1.0, max_samples=1.0, n_estimators=40)  # Obtained using grid search<br/><br/>oc_svm_clf.fit(X_train)<br/>if_clf.fit(X_train)<br/><br/>oc_svm_preds = oc_svm_clf.predict(X_test)<br/>if_preds = if_clf.predict(X_test)<br/><br/># Further compute accuracy, precision and recall for the two predictions sets obtained</span></pre><p id="5fa7" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> PS </strong>:隔离林和一类SVM返回的预测都是{-1，1}的形式。-1表示“非食物”，1表示“食物”。</p><p id="b2ec" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">使用高斯混合和保序回归的一类分类</strong></p><p id="2916" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">直观地说，食物可以属于不同的类别，如谷类、蛋类、面包等。，并且一些食物也可以同时属于多个簇。因此，我们可以在正类数据点(ResNet特征)上拟合高斯混合。<a class="ae jp" href="https://brilliant.org/wiki/gaussian-mixture-model/" rel="noopener ugc nofollow" target="_blank">高斯混合模型</a><em class="jq">是一种概率模型，用于表示总体人口中的正态分布子人口</em>。可以推测，混合模型代表了正态分布亚总体的聚类。一个高斯混合模型，一旦与数据拟合，就可以给我们关于是否有任何新点从该分布中产生的概率的信息。</p><p id="86e2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">但是要注意— <strong class="it hv"> <em class="jq">高斯混合模型返回给定样本</em> </strong>的概率密度函数值的对数(而不是实际概率)。因此，有必要将这些概率密度函数值转换为“概率得分”，这可以表明新样本将属于置信度为“x”的高斯分布。</p><p id="397c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">实现这一点的简单而有效的方法是通过对验证集数据点的对数概率密度分数w.r.t .标签拟合保序回归模型。<a class="ae jp" href="http://www.research.ibm.com/people/z/zadrozny/kdd2002-Transf.pdf" rel="noopener ugc nofollow" target="_blank">保序回归</a>是一种概率校准技术，它可以通过沿着分类器返回的分数拟合一个逐步非递减函数，将分类器分数校准到近似概率值。</p><p id="d8c2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">使用GMMs进行一堂课学习的实施细节</strong></p><pre class="js jt ju jv fq kh ki kj kk aw kl dt"><span id="bdc0" class="km kn hu ki b fv ko kp l kq kr"># The standard scaler and PCA part remain same. Just that we will also require a validation set to fit<br/># isotonic regressor on the probability density scores returned by GMM<br/><br/># Also assuming that resnet feature generation is done<br/>from sklearn.mixture import GaussianMixture<br/>from sklearn.isotonic import IsotonicRegression</span><span id="3dfb" class="km kn hu ki b fv lg kp l kq kr">gmm_clf = GaussianMixture(covariance_type='spherical', n_components=18, max_iter=int(1e7))  # Obtained via grid search</span><span id="8e65" class="km kn hu ki b fv lg kp l kq kr">gmm_clf.fit(X_train)</span><span id="8819" class="km kn hu ki b fv lg kp l kq kr">log_probs_val = gmm_clf.score_samples(X_val)</span><span id="872f" class="km kn hu ki b fv lg kp l kq kr">isotonic_regressor = IsotonicRegression(out_of_bounds='clip')<br/>isotonic_regressor.fit(log_probs_val, y_val)  # y_val is for labels 0 - not food 1 - food (validation set)<br/><br/># Obtaining results on the test set<br/>log_probs_test = gmm_clf.score_samples(X_test)<br/>test_probabilities = isotonic_regressor.predict(log_probs_test)<br/>test_predictions = [1 if prob &gt;= 0.5 else 0 for prob in test_probabilities]<br/><br/># Calculate accuracy metrics</span></pre><h1 id="4091" class="lh kn hu bd li lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md dt translated"><strong class="ak">结果和讨论</strong></h1><p id="921e" class="pw-post-body-paragraph ir is hu it b iu me iw ix iy mf ja jb jc mg je jf jg mh ji jj jk mi jm jn jo hn dt translated">以下是使用三个一类学习技巧获得的结果</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff mj"><img src="../Images/8fc5b36a3b19175f3b0940a4670cd000.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*jNffiubY7w1-8TGl5dIzFA.png"/></div></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek">Results table comparing all three algorithms over food vs ~food data</figcaption></figure><p id="fe73" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">因此，GMM模型(使用保序回归校准)优于其他两种单类学习模型，并且与在训练神经网络700次迭代后获得的“最先进的<a class="ae jp" href="https://infoscience.epfl.ch/record/221610/files/madima2016_food_recognition.pdf" rel="noopener ugc nofollow" target="_blank"/>”相差不远。此外，在最先进的方法中，该模型是在正负数据样本上训练的，而在我们的方法中，该模型<strong class="it hv">只是在正类样本上训练的，</strong>因此使其在处理~A样本中的任何类型的分布时更加稳健。</p><p id="9afc" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">与一级SVM相比，GMM通过正确预测更多“非食物”图像来帮助提高模型的精度。这导致相当少的假阳性。例如，一些被GMM正确预测为“不是食物”(与OC-SVM相对)的图片是-</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff mk"><img src="../Images/c425305d9d4050978407cba75c988085.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*AZn1K8xbJuKfcGMyI-tp0g.png"/></div></div><figcaption class="kd ke fg fe ff kf kg bd b be z ek">Not food correctly predicted by GMM as opposed to OC-SVM</figcaption></figure><p id="d795" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">最后补充一点——我没有深入研究如何对高斯混合模型进行网格搜索，但任何希望了解更多信息的人都可以查看这个<a class="ae jp" href="http://scikit-learn.org/stable/auto_examples/mixture/plot_gmm_selection.html#sphx-glr-auto-examples-mixture-plot-gmm-selection-py" rel="noopener ugc nofollow" target="_blank"> sklearn教程</a>。</p><p id="52ae" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果你喜欢这篇文章，你可以在https://medium.com/squad-engineering<a class="ae jp" href="https://medium.com/squad-engineering" rel="noopener">查看更多关于小队工程的故事。</a></p><figure class="js jt ju jv fq jw"><div class="bz el l di"><div class="ml mm l"/></div></figure></div></div>    
</body>
</html>