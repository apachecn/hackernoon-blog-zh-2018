<html>
<head>
<title>Only Numpy: Dilated Back Propagation and Google Brain’s Gradient Noise with Interactive Code</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">只有Numpy:扩张反向传播和谷歌大脑的梯度噪声与互动代码</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/only-numpy-dilated-back-propagation-and-google-brains-gradient-noise-with-interactive-code-3a527fc8003c?source=collection_archive---------12-----------------------#2018-02-16">https://medium.com/hackernoon/only-numpy-dilated-back-propagation-and-google-brains-gradient-noise-with-interactive-code-3a527fc8003c?source=collection_archive---------12-----------------------#2018-02-16</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/a9a4d22ebacf0cad8e1b9df321f86a8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OGl1UwRSW5ItC4x98UXAvg.jpeg"/></div></div><figcaption class="jc jd fg fe ff je jf bd b be z ek">Photo of <a class="ae jg" href="https://en.wikipedia.org/wiki/Gwanghwamun" rel="noopener ugc nofollow" target="_blank">gwanghwamu </a>from <a class="ae jg" href="https://pixabay.com/" rel="noopener ugc nofollow" target="_blank">pixelbay</a></figcaption></figure><p id="7546" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">所以昨天我从<a class="ae jg" href="https://papers.nips.cc/book/advances-in-neural-information-processing-systems-30-2017?utm_campaign=Revue%20newsletter&amp;utm_medium=Newsletter&amp;utm_source=Deep%20Learning%20Weekly" rel="noopener ugc nofollow" target="_blank"> NIPS 2017 </a>找到这篇论文<a class="ae jg" href="https://papers.nips.cc/paper/6613-dilated-recurrent-neural-networks" rel="noopener ugc nofollow" target="_blank">扩张型递归神经网络</a>，在这里实现了<a class="ae jg" href="https://towardsdatascience.com/only-numpy-nips-2017-implementing-dilated-recurrent-neural-networks-with-interactive-code-e83abe8c9b27" rel="noopener" target="_blank">。但是我突然想到，Res Net和High Way net是以一种允许输入数据X和转换数据X’之间直接连接的方式构建的。</a></p><p id="221c" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">为什么我们不能对反向传播做同样的事情呢？将之前图层的渐变连接到更深的图层…..T9】</p><p id="555f" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">我的意思是，如果你不使用框架来执行自动微分，为什么我们不把梯度从最新的层连接到更深的层，看看会怎么样？在这篇文章中，我们会这样做，也让我们更进一步，并与应用<a class="ae jg" href="https://arxiv.org/abs/1511.06807" rel="noopener ugc nofollow" target="_blank">谷歌大脑的梯度噪声</a>的模型进行比较。</p><p id="516b" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">由于我是在阅读了扩张的RNN后获得灵感的，我就称之为扩张的反向传播，<strong class="jj hv">然而，如果有人知道其他论文以这种方式进行了反向传播，请在评论部分告诉我。另外，我假设你已经阅读了我关于实施扩张RNN的博文，</strong> <a class="ae jg" href="https://towardsdatascience.com/only-numpy-nips-2017-implementing-dilated-recurrent-neural-networks-with-interactive-code-e83abe8c9b27" rel="noopener" target="_blank"> <strong class="jj hv">如果没有，请点击这里。</strong> </a></p></div><div class="ab cl kg kh hc ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hn ho hp hq hr"><p id="8a99" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">网络架构(前馈方向)</strong></p><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff kn"><img src="../Images/839f2d72d0da5f4e3beba3613bd93f79.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UHYxN6WLnStXUAl9sT80aQ.png"/></div></div><figcaption class="jc jd fg fe ff je jf bd b be z ek">Side View</figcaption></figure><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ks"><img src="../Images/3881495e0503c6630841d9ba1b08b812.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*w8gkawG_AHFg5wX6bBNTbA.png"/></div></div><figcaption class="jc jd fg fe ff je jf bd b be z ek">Front View</figcaption></figure><p id="220a" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">红圈</strong> →网络的最终输出，预测数的一个热编码的(1*10)向量</p><p id="99d1" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">棕色圆圈</strong> →第2层隐藏状态0<br/><strong class="jj hv">石灰圆圈</strong> →第2层隐藏状态</p><p id="fabb" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">粉色圆圈</strong> →层1的隐藏状态0<br/><strong class="jj hv">黑色圆圈</strong> →层1的隐藏状态</p><p id="ed2e" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">蓝色数字1、2、3、4、5 </strong> →每个时间戳的输入(请<em class="kf">注意这一点</em>，因为我将使用这些知识来解释训练/测试数据)</p><p id="7d34" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">略带桃色？箭头</strong> →前馈运行方向，</p><p id="d386" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">如上图所示，网络架构与上一篇帖子完全相同。然而，有一件事我改变了，那就是每个时间戳的输入数据。</p></div><div class="ab cl kg kh hc ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hn ho hp hq hr"><p id="2c67" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">训练数据/测试数据</strong></p><div class="ko kp kq kr fq ab cb"><figure class="kt iv ku kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/e68d4ad28e9fbdb63f47a4f495712fa0.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*5cq9zHTNVhg4r4XTRWKnpQ.png"/></div></figure><figure class="kt iv ku kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/4c8c82c9caa2ea10d48e892cbf88491e.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*vggl8yO99dJKSykkRRs4LQ.png"/></div></figure><figure class="kt iv ku kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/3b4478c169a2c31e9d5a1210da020111.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*iEJI0SBVAeLXlS8MudeJzA.png"/></div></figure></div><div class="ab cb"><figure class="kt iv kz kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/7a9bcecdff32a1299404a5b13696ee57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*SUbAHR4dFyU92lfSYBEucg.png"/></div></figure><figure class="kt iv kz kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/82d1576560a9a425aa512221f4841b52.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*1hj_IW01b8Zae8X5eWinew.png"/></div></figure></div><p id="1ae0" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">粉色框</strong> →时间戳1处输入(矢量化14*14像素图像)<br/> <strong class="jj hv">黄色框</strong> →时间戳2处输入(矢量化14*14像素图像)<br/> <strong class="jj hv">蓝色框</strong> →时间戳3处输入(矢量化14*14像素图像)<br/> <strong class="jj hv">紫色框</strong> →时间戳4处输入(矢量化14*14像素图像)<br/> <strong class="jj hv">绿色框</strong> →输入</p><p id="39e5" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">尽管有些图像看起来比其他图像大，但它们都是(14*14)像素的图像。并且每个图像都是通过对原始图像(28*28像素图像)应用不同种类的合并操作而制成的。下面描述了每个池操作。</p><p id="854c" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">粉色方框</strong> →均值池使用<a class="ae jg" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.mean.html" rel="noopener ugc nofollow" target="_blank"> np.mean </a>函数<br/> <strong class="jj hv">黄色方框</strong> →方差池使用<a class="ae jg" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.var.html" rel="noopener ugc nofollow" target="_blank"> np.var </a>函数<br/> <strong class="jj hv">蓝色方框</strong> →最大池使用<a class="ae jg" href="https://docs.scipy.org/doc/numpy-1.13.0/reference/generated/numpy.maximum.html" rel="noopener ugc nofollow" target="_blank"> np.max </a>函数<br/> <strong class="jj hv">紫色方框</strong> →标准差池使用<a class="ae jg" href="https://docs.scipy.org/doc/numpy/reference/generated/numpy.std.html" rel="noopener ugc nofollow" target="_blank"> np.std </a>函数<br/> <strong class="jj hv">绿色方框</strong></p><p id="2589" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">下面是实现这一点的代码。</p><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff la"><img src="../Images/2bd6cb212b245dee05b551fc257bf00c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*W8TeuBWg21W3JnYvN23hnw.png"/></div></div></figure><p id="3d12" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">记住这一点，让我们看看其他的训练数据。最后，我这样做的原因很简单，我想。</p><div class="ko kp kq kr fq ab cb"><figure class="kt iv ku kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/996db270b3b7c025ef43f7e171e62180.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*GOpePyTVipo1-LMv33KW1w.png"/></div></figure><figure class="kt iv ku kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/b605c85735d609e2c4deeade43800600.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*dBZlSTPf7AqkwMD8yWpzKA.png"/></div></figure><figure class="kt iv ku kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/412a316c2cf00b473de20e4c960c9d51.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*VN2wQT7ozsBxbbext66Y5g.png"/></div></figure></div><div class="ab cb"><figure class="kt iv kz kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/0a59042b8df7d516841b777c2060b150.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*j4FX1kIzldkqaphwOjD5zA.png"/></div></figure><figure class="kt iv kz kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/e3d389350f835dcf7156ffe4414bf9b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*tbDzeXSstDAZ3-iZnHw9cg.png"/></div><figcaption class="jc jd fg fe ff je jf bd b be z ek lb di lc ld">Image of 0</figcaption></figure></div><div class="ab cb"><figure class="kt iv ku kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/3850512f440525a807174743288f961a.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*5O3-eP1xlrl2SruEPd8ToQ.png"/></div></figure><figure class="kt iv ku kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/8f6a983e735c290e0f00db53c216a4e1.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*XQfaijMN6YSLSqkrcptFyw.png"/></div></figure><figure class="kt iv ku kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/0defeb9b1ef010bf5e8d3ce1ce2a8ff8.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*lwErmt8g72fRuoSO0N9O-w.png"/></div></figure></div><div class="ab cb"><figure class="kt iv kz kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/fa671bb20d0176a0019c60468e4501be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*-NHSnAeR1zQmlaGGMLsJsA.png"/></div></figure><figure class="kt iv kz kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/80ea3086f995649200fca51d3c9f48da.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*qYrUrYyZckCD2nXKVScvkA.png"/></div><figcaption class="jc jd fg fe ff je jf bd b be z ek lb di lc ld">Image of 3</figcaption></figure></div></div><div class="ab cl kg kh hc ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hn ho hp hq hr"><p id="c08b" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">情况1:正常反向传播</strong></p><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff le"><img src="../Images/fd4f3ddde7112335098d762af6afdfb1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OkaYi4l_q7wZjLVrAytriQ.png"/></div></div></figure><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lf"><img src="../Images/8f16fb2d960b678b6644aa8f424d09bc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k3dYa6IMKzKigT_dDv0SpA.png"/></div></div></figure><p id="5d5b" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">紫色箭头</strong> →梯度流的标准方向</p><p id="b98c" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">上面是正常的(或标准的)反向传播，我们计算每一层的梯度，将它们传递给下一层。并且不同时间戳的每个权重使用它们来更新它们的权重，并且梯度流继续进行。</p></div><div class="ab cl kg kh hc ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hn ho hp hq hr"><p id="5369" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">案例二:谷歌大脑梯度噪声</strong></p><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lg"><img src="../Images/ed317797c3d60dd00d1cbc1a04cc9b21.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WMHW0ms7W8Lb9y9yt3yZgQ.png"/></div></div></figure><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lh"><img src="../Images/91aa0fecc5776925ecd9a6a0383b30f5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Gf6tdA1nEXsAQvYJR0pzoQ.png"/></div></div></figure><p id="be37" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">紫色箭头</strong> →梯度流的标准方向<br/> <strong class="jj hv">黄色箭头</strong> →添加梯度噪声</p><p id="f2b2" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">同样，紫色的箭头代表标准的梯度流，但是这次在更新每个权重之前，我们要给梯度添加一些噪声。下面是我们如何实现这一目标的屏幕截图。</p><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff li"><img src="../Images/b9dee7f00fa4beae80d5a068703c615b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6Medu49cq8jqTrxoVkvioA.png"/></div></div></figure></div><div class="ab cl kg kh hc ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hn ho hp hq hr"><p id="94b9" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">情况3:扩张的反向传播</strong></p><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lj"><img src="../Images/8dbfbfe3ec3ea63e2c5ffe0a238bfd30.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GquAYDj6T4ceL9bUkKUV0Q.png"/></div></div></figure><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lk"><img src="../Images/1de9cf8fbd56fb90f4ceb78e9f46ba54.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*d2l2VQUD105TlGmm_2DMFQ.png"/></div></div></figure><p id="2ea2" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">紫色箭头</strong> →梯度流的标准方向<br/> <strong class="jj hv">黑色箭头</strong> →扩张反向传播，将梯度的一部分传递给之前的层，这些层并不直接相连。</p><p id="706b" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">现在，我们在这里介绍我们的新理论，希望能提高模型的准确性。这里有两点需要注意。</p><ol class=""><li id="4ed9" class="ll lm hu jj b jk jl jo jp js ln jw lo ka lp ke lq lr ls lt dt translated">我们只是将渐变的一部分传递给前面的图层。</li></ol><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lu"><img src="../Images/f7f6502e9e1b7c1f53d2428903fb97ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pbU9wEXnOh-gfSaXcOUTyQ.png"/></div></div></figure><p id="b0b5" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">如上所述，我们有一些称为“衰减比例率”的变量，我们将使用<a class="ae jg" href="https://www.tensorflow.org/api_docs/python/tf/train/inverse_time_decay" rel="noopener ugc nofollow" target="_blank">逆时间衰减率</a>来减少随着时间的推移它可以传递到前面层的梯度量。如绿色框中所示，由于我们将来自未来层的梯度乘以衰减比例率，随着训练的持续，扩张的梯度流量的量减少。</p><p id="e9f1" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">2.扩张的梯度流每2层跳过一次。</p><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ks"><img src="../Images/475a9aee5feb7c3cda6411cf6a5e4b3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*JwieLnhivele1PTbH_OgjA.png"/></div></div></figure><p id="fe3a" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">如上面的红框所示，时间戳5处的渐变仅适用于时间戳3处的渐变。然而，这种结构可以进一步探索，使梯度流更加密集。</p></div><div class="ab cl kg kh hc ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hn ho hp hq hr"><p id="ac3e" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">案例4:扩张型反向传播+谷歌大脑梯度噪声</strong></p><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lv"><img src="../Images/b1dac863d21d16da5bbc5728757684ff.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Ab6lsXn27nyfVekRX3esSw.png"/></div></div></figure><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lw"><img src="../Images/126dbab1350caf7309de8474e79c4cb9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZCwKmI0YCtysqMJDY55oJQ.png"/></div></div></figure><p id="4c55" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">紫色箭头</strong> →梯度流的标准方向<br/> <strong class="jj hv">黑色箭头</strong> →扩张反向传播，将梯度的一部分传递给之前的层，这些层不直接相连。<br/> <strong class="jj hv">黄色箭头</strong> →添加渐变噪点</p><p id="c22b" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">这里，我们不仅在每次权重更新中添加了渐变噪声，还使渐变流更好。</p></div><div class="ab cl kg kh hc ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hn ho hp hq hr"><p id="2faf" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">训练和结果(Google Colab，本地设置)</strong></p><div class="ko kp kq kr fq ab cb"><figure class="kt iv lx kv kw kx ky paragraph-image"><img src="../Images/9a91a2669713fca5fdc603baad485e25.png" data-original-src="https://miro.medium.com/v2/resize:fit:958/format:webp/1*s4VA0PUU3BqVI1yR-K_zcQ.png"/></figure><figure class="kt iv ly kv kw kx ky paragraph-image"><img src="../Images/829f15b31fc958437b5c72deeb875ed5.png" data-original-src="https://miro.medium.com/v2/resize:fit:962/format:webp/1*yF-EMErif3Vw1QXzPjtFUA.png"/></figure></div><p id="28ed" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">以上是在Google Colab上运行代码的结果。准确度栏代表模型对100幅测试图像的正确猜测。不幸的是，我忘记打印出准确的准确率，但我们可以看到情况2(谷歌大脑梯度噪声)具有最高的准确性。此外，非标准反向传播的情况比标准反向传播更好。在时间成本函数中，我们可以看到标准反向传播具有最高的成本率。</p><div class="ko kp kq kr fq ab cb"><figure class="kt iv lz kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/9b1f7de81694d4398e0df3f972990147.png" data-original-src="https://miro.medium.com/v2/resize:fit:972/format:webp/1*OhW5WWgM6eQxWH9etHTOzg.png"/></div></figure><figure class="kt iv ma kv kw kx ky paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><img src="../Images/8ede536f4d04a18a131fc760727d2e95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1030/format:webp/1*A_GpNfPIqNbxX0M4qCJl4Q.png"/></div></figure></div><p id="f29e" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">以上是在我的本地笔记本电脑上运行代码的结果。准确度栏代表模型对100幅测试图像的正确猜测。有趣的是，与标准反向传播相比，情况3(扩张反向传播)表现不佳。然而，扩张的反向传播和谷歌大脑的梯度噪声的结合已经超越了每个模型。</p></div><div class="ab cl kg kh hc ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hn ho hp hq hr"><p id="3acf" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">互动码</strong></p><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mb"><img src="../Images/f81708ab07b98c40e249e039699ed812.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nTkJptUtCDeBm6CBibqUZA.png"/></div></div></figure><p id="7515" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">我搬到了Google Colab来获取交互代码！所以你需要一个谷歌帐户来查看代码，你也不能在谷歌实验室运行只读脚本，所以在你的操场上做一个副本。最后，我永远不会请求允许访问你在Google Drive上的文件，仅供参考。编码快乐！</p><p id="706a" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">请点击此处<a class="ae jg" href="https://colab.research.google.com/drive/18F9dFn7ZejVg0ei5gh5SGi-aF6rN6Mj6" rel="noopener ugc nofollow" target="_blank">访问互动代码。</a></p></div><div class="ab cl kg kh hc ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hn ho hp hq hr"><p id="5c39" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">遗言</strong></p><p id="ceaf" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">我喜欢Tensorflow和Keras之类的框架。然而，我坚信我们需要探索更多不同的方法来执行反向传播。</p><p id="510b" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">如果发现任何错误，请发电子邮件到jae.duk.seo@gmail.com给我，如果你想看我所有写作的列表，请<a class="ae jg" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">在这里查看我的网站</a>。</p><p id="ccc9" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">同时，在我的twitter <a class="ae jg" href="https://twitter.com/JaeDukSeo" rel="noopener ugc nofollow" target="_blank">这里</a>关注我，并访问<a class="ae jg" href="https://jaedukseo.me/" rel="noopener ugc nofollow" target="_blank">我的网站</a>，或我的<a class="ae jg" href="https://www.youtube.com/c/JaeDukSeo" rel="noopener ugc nofollow" target="_blank"> Youtube频道</a>了解更多内容。如果你感兴趣的话，我还做了解耦神经网络的比较。</p></div><div class="ab cl kg kh hc ki" role="separator"><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl km"/><span class="kj bw bk kk kl"/></div><div class="hn ho hp hq hr"><p id="2b1f" class="pw-post-body-paragraph jh ji hu jj b jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jj hv">参考</strong></p><ol class=""><li id="d2b4" class="ll lm hu jj b jk jl jo jp js ln jw lo ka lp ke lq lr ls lt dt translated">常，张，杨，韩，魏，余，米，郭，陈，谭，黄，黄铁生(2017)。扩张的循环神经网络。在<em class="kf">神经信息处理系统的进展</em>(第76–86页)。</li><li id="c2c9" class="ll lm hu jj b jk mc jo md js me jw mf ka mg ke lq lr ls lt dt translated">Neelakantan，a .，Vilnis，l .，Le，Q. V .，Sutskever，I .，Kaiser，l .，Kurach，k .，和Martens，J. (2015年)。添加梯度噪声改善了对非常深的网络的学习。arXiv预印本arXiv:1511.06807 。</li><li id="e134" class="ll lm hu jj b jk mc jo md js me jw mf ka mg ke lq lr ls lt dt translated">Seo，J. D. (2018年2月14日)。only Numpy:NIPS 2017——用交互式代码实现扩张型递归神经网络。检索于2018年2月15日，来自<a class="ae jg" href="https://towardsdatascience.com/only-numpy-nips-2017-implementing-dilated-recurrent-neural-networks-with-interactive-code-e83abe8c9b27" rel="noopener" target="_blank">https://towards data science . com/only-numpy-nips-2017-implementing-expanded-recurrent-neural-networks-with-interactive-code-e 83 Abe 8 C9 b 27</a></li><li id="565f" class="ll lm hu jj b jk mc jo md js me jw mf ka mg ke lq lr ls lt dt translated">索引。(未注明)。检索于2018年2月15日，来自<a class="ae jg" href="https://docs.scipy.org/doc/numpy/genindex.html" rel="noopener ugc nofollow" target="_blank">https://docs.scipy.org/doc/numpy/genindex.html</a></li><li id="d65d" class="ll lm hu jj b jk mc jo md js me jw mf ka mg ke lq lr ls lt dt translated">[1]" TF . train . inverse _ time _ decay | tensor flow "，<em class="kf"> TensorFlow </em>，2018。【在线】。可用:<a class="ae jg" href="https://www.tensorflow.org/api_docs/python/tf/train/inverse_time_decay." rel="noopener ugc nofollow" target="_blank">https://www . tensor flow . org/API _ docs/python/TF/train/inverse _ time _ decay。</a>【访问时间:2018年2月16日】。</li></ol></div></div>    
</body>
</html>