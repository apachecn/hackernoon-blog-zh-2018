<html>
<head>
<title>How To Build An Audio Processor In Your Browser</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何在浏览器中构建音频处理器</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/how-to-build-an-audio-processor-in-your-browser-302cb7aa502a?source=collection_archive---------4-----------------------#2018-02-18">https://medium.com/hackernoon/how-to-build-an-audio-processor-in-your-browser-302cb7aa502a?source=collection_archive---------4-----------------------#2018-02-18</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/d398e33b25609c1be59e37203cc9b34f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*f2JID-3wDkyn0rMNV7qoYA.png"/></div></div><figcaption class="jc jd fg fe ff je jf bd b be z ek"><a class="ae jg" href="https://github.com/omgimanerd/audio-spatializer" rel="noopener ugc nofollow" target="_blank">Audio Spatializer</a>, submission for BrickHack4</figcaption></figure></div><div class="ab cl jh ji hc jj" role="separator"><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm"/></div><div class="hn ho hp hq hr"><h1 id="ff24" class="jo jp hu bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl dt translated">一些背景信息</h1><p id="8e47" class="pw-post-body-paragraph km kn hu ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj hn dt translated">我上周末在RIT的brick hack 4做黑客。通常，我喜欢用我的黑客马拉松来构建多人游戏，但这一次，我想尝试实现一个我已经在待办事项列表后面有一段时间的想法。这个想法是在我听了一些<a class="ae jg" href="https://www.urbandictionary.com/define.php?term=nightcore" rel="noopener ugc nofollow" target="_blank"> nightcore </a>(一首歌曲的混音曲目，加快了速度，提高了音高，更强调了强有力的节拍)后产生的。具体来说，我在YouTube上听了这个:</p><figure class="lk ll lm ln fq iv"><div class="bz el l di"><div class="lo lp l"/></div></figure><p id="a12e" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">如果你跳到0:36标记，你可以听到一个有趣的音频效果，如果你戴着耳机。节拍在左耳和右耳之间跳跃(这个视频中的其他几个点也会发生这种情况)。这是一个如此有趣的效果，我想知道是否有可能通过算法为其他歌曲创造这种效果。我对这个项目的最终目标是能够采取一些dubstep和使用立体声效果来切换左右耳之间的节拍，并创建一个身临其境的听觉体验。在黑客马拉松期间，我和我的朋友<a class="ae jg" href="https://github.com/Searnsy" rel="noopener ugc nofollow" target="_blank">安德鲁·瑟恩斯</a>一起工作，尝试创建一个网络应用程序来完成这项工作(安德鲁还向我展示了<a class="ae jg" href="https://www.youtube.com/watch?v=L8RT9yAzYXE" rel="noopener ugc nofollow" target="_blank">其他有趣的歌曲，艺术家在这些歌曲中播放了立体声效果</a>)。</p><p id="c898" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">虽然它不像我们预期的那样成功，但我们用一个架构来做这件事是很有趣的，而且我个人在设计应用程序界面时学习了相当多的CSS Flexbox。在本次技术发布中，<strong class="ko hv">我将带您了解我的思考过程，并向您展示如何概括我们编写的代码，以在浏览器中构建音频处理框架。</strong></p></div><div class="ab cl jh ji hc jj" role="separator"><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm"/></div><div class="hn ho hp hq hr"><h1 id="3cb7" class="jo jp hu bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl dt translated">音频流架构</h1><p id="a88b" class="pw-post-body-paragraph km kn hu ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj hn dt translated">好吧，让我们想想我们需要什么来完成这个。理想情况下，我们希望用户只需将一个YouTube链接粘贴到我们的应用程序中，它将处理音频流，将其空间化，然后播放它。</p><p id="9cd4" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">显然，我们需要的第一件事是一些方法来做音频流。我将在本节中讨论我们如何设置它，稍后我们将讨论音频空间化部分。</p><p id="1a1a" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">因为我们想快速开发和迭代，我们使用了</p><figure class="lk ll lm ln fq iv fe ff paragraph-image"><div class="fe ff lv"><img src="../Images/c1206ff6c2d02e9547deb5d7e29d7a21.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*rc04Rl7SZ8iEZSp9UVCWag.jpeg"/></div></figure><p id="8a66" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">(也是因为我刚好很喜欢node.js)。在黑客马拉松期间，我们发现了两种有据可查的从YouTube进行音频流传输的方法。</p><p id="21ce" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">o̶n̶e̶̶o̶p̶t̶i̶o̶n̶̶w̶a̶s̶̶t̶h̶e̶̶p̶a̶c̶k̶a̶g̶e̶̶<a class="ae jg" href="https://github.com/JamesKyburz/youtube-audio-stream" rel="noopener ugc nofollow" target="_blank">y̶o̶u̶t̶u̶b̶e̶-̶a̶u̶d̶i̶o̶-̶s̶t̶r̶e̶a̶m̶</a>,̶̶a̶n̶d̶̶t̶h̶e̶̶o̶t̶h̶e̶r̶̶o̶p̶t̶i̶o̶n̶̶w̶a̶s̶̶t̶h̶e̶̶p̶a̶c̶k̶a̶g̶e̶̶<a class="ae jg" href="https://www.npmjs.com/package/ytdl-core" rel="noopener ugc nofollow" target="_blank">y̶t̶d̶l̶-̶c̶o̶r̶e̶</a>̶(̶w̶h̶i̶c̶h̶̶y̶o̶u̶t̶u̶b̶e̶-̶a̶u̶d̶i̶o̶-̶s̶t̶r̶e̶a̶m̶̶a̶c̶t̶u̶a̶l̶l̶y̶̶d̶e̶p̶e̶n̶d̶s̶̶o̶n̶)̶.̶̶a̶f̶t̶e̶r̶̶a̶̶l̶o̶t̶̶o̶f̶̶i̶t̶e̶r̶a̶t̶i̶o̶n̶̶a̶n̶d̶̶t̶e̶s̶t̶i̶n̶g̶,̶̶w̶e̶̶s̶e̶t̶t̶l̶e̶d̶̶o̶n̶̶u̶s̶i̶n̶g̶̶y̶o̶u̶t̶u̶b̶e̶-̶a̶u̶d̶i̶o̶-̶s̶t̶r̶e̶a̶m̶̶t̶o̶̶p̶i̶p̶e̶̶t̶h̶e̶̶a̶u̶d̶i̶o̶̶s̶t̶r̶e̶a̶m̶̶d̶i̶r̶e̶c̶t̶l̶y̶̶t̶o̶̶t̶h̶e̶̶c̶l̶i̶e̶n̶t̶.̶</p><p id="8adc" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated"><strong class="ko hv">编辑:我重新审视了这个项目，youtube-audio-stream包有时有点古怪，不像</strong><a class="ae jg" href="https://www.npmjs.com/package/ytdl-core" rel="noopener ugc nofollow" target="_blank"><strong class="ko hv">ytdl-core</strong></a><strong class="ko hv">那样积极维护。我已经重写了项目以使用ytdl-core，但是由于遗留的原因，我不会修改这篇博文。不要担心，这个变化几乎是一个下降的替代，只影响大约5行代码。</strong></p><p id="5647" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">为此，客户端将youtube视频ID发送到我们的服务器，服务器使用<a class="ae jg" href="https://github.com/JamesKyburz/youtube-audio-stream" rel="noopener ugc nofollow" target="_blank"> youtube-audio-stream </a>从YouTube获取视频ID，然后通过管道将其发送回客户端。</p><figure class="lk ll lm ln fq iv fe ff paragraph-image"><div class="fe ff lw"><img src="../Images/4a3a6619b0867595ab266d3cffb99dd1.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*-SlHu2V-lxOgjpardc6LxA.png"/></div><figcaption class="jc jd fg fe ff je jf bd b be z ek">Diagram created using <a class="ae jg" href="http://www.websequencediagrams.com" rel="noopener ugc nofollow" target="_blank">websequencediagrams.com</a></figcaption></figure><p id="90e8" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">我们决定将音频处理卸载到客户端，以减少服务器的负载。对于我们的目的来说，这是最实用的解决方案，并且易于编码和组装。</p><p id="c742" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">现在你可能会看到这个，并问为什么我们没有跳过中间人，让网络浏览器直接从YouTube请求音频流。<a class="ae jg" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS" rel="noopener ugc nofollow" target="_blank">跨来源资源共享(CORS) </a>阻止我们从客户端直接向YouTube发出请求。此外，我们希望我们的服务器在所有客户机之间提供一个通信通道(原因我们将在后面的部分讨论)。</p><p id="b54a" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">下面是上述架构的一个最小工作示例:</p><figure class="lk ll lm ln fq iv"><div class="bz el l di"><div class="lx lp l"/></div><figcaption class="jc jd fg fe ff je jf bd b be z ek"><a class="ae jg" href="https://github.com/omgimanerd/audio-spatializer/tree/blog-min-example" rel="noopener ugc nofollow" target="_blank">Here’s a link to a git repository you can clone to get this sample code</a></figcaption></figure><p id="8125" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">这看起来可能需要消化很多代码，但实际上非常简单，大部分代码都是样板文件。让我们浏览一遍。</p><p id="9b21" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated"><code class="eh ly lz ma mb b">audio-processor-server.js</code>是一个非常标准的<a class="ae jg" href="https://expressjs.com/" rel="noopener ugc nofollow" target="_blank"> boilerplate express.js服务器</a>，它定义了两条路径:一条用于向客户端提供HTML页面，另一条用于向客户端提供音频流。服务器还将静态地提供<code class="eh ly lz ma mb b">/client</code>文件夹中的文件，这是我们存储<code class="eh ly lz ma mb b">audio-processor.js</code>的地方。</p><p id="e590" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated"><code class="eh ly lz ma mb b">audio-processor.html</code>是一个普通的HTML页面，除了一个YouTube视频ID的输入字段和一个提交按钮之外什么都没有。</p><p id="9843" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated"><code class="eh ly lz ma mb b">audio-processor.js</code>是加载到HTML页面中的客户端脚本，用于向服务器发送音频流请求。我们使用一个<a class="ae jg" href="https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest" rel="noopener ugc nofollow" target="_blank"> XHR请求</a>来请求音频流，这样我们就可以指定arraybuffer的返回类型。使用<a class="ae jg" href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API" rel="noopener ugc nofollow" target="_blank"> Web Audio API </a>的<a class="ae jg" href="https://developer.mozilla.org/en-US/docs/Web/API/AudioContext" rel="noopener ugc nofollow" target="_blank"> AudioContext </a>对象，我们可以<a class="ae jg" href="https://developer.mozilla.org/en-US/docs/Web/API/BaseAudioContext/decodeAudioData" rel="noopener ugc nofollow" target="_blank">将arraybuffer解码为包含解码后的PCM音频数据的AudioBuffer对象</a>。这个缓冲区被传递给<code class="eh ly lz ma mb b">processAudio()</code>方法(在上面的示例存根中没有定义),您可以用任何想要的函数替换它。</p><p id="8eb0" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">这里有一个例子<code class="eh ly lz ma mb b">processAudio()</code>函数，我们用来做一些天真的节拍检测。我们让音频数据通过一个低通滤波器，并隔离高于某个相对值的所有点。<a class="ae jg" href="http://joesul.li/van/beat-detection-using-web-audio/" rel="noopener ugc nofollow" target="_blank">我们要感谢Joe Sullivan精彩的文章，他解释并提供了下面的低通滤波器代码。</a></p><figure class="lk ll lm ln fq iv"><div class="bz el l di"><div class="lx lp l"/></div><figcaption class="jc jd fg fe ff je jf bd b be z ek"><a class="ae jg" href="https://github.com/omgimanerd/audio-spatializer/tree/blog-min-example" rel="noopener ugc nofollow" target="_blank">Here’s a link to a git repository you can clone to get this sample code</a></figcaption></figure><p id="e0ef" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">这里有一个<a class="ae jg" href="https://github.com/omgimanerd/audio-spatializer/tree/blog-min-example" rel="noopener ugc nofollow" target="_blank">链接，链接到我们项目的一个分支，包含上面</a>的示例代码。您可以使用<a class="ae jg" href="https://developer.mozilla.org/en-US/docs/Web/API/AudioBuffer" rel="noopener ugc nofollow" target="_blank">音频缓冲区</a>中的PCM音频数据做各种有趣的事情。</p><p id="a2df" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">注意，<code class="eh ly lz ma mb b">audio-processor.js</code>中的代码仍然相关，即使你不想从YouTube加载音频。您可以将它应用到静态载入的音频文件或您想要使用的任何其他音频源。我建议浏览一下<a class="ae jg" href="https://developer.mozilla.org/en-US/docs/Web/API/Web_Audio_API" rel="noopener ugc nofollow" target="_blank"> Web Audio API文档</a>,看看你能用音频缓冲区做些什么。</p></div><div class="ab cl jh ji hc jj" role="separator"><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm"/></div><div class="hn ho hp hq hr"><h1 id="97df" class="jo jp hu bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl dt translated">另一种音频流架构</h1><p id="df3a" class="pw-post-body-paragraph km kn hu ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj hn dt translated">然而，假设您想要在服务器上执行音频处理部分。这对于在客户端进行处理有几个好处:服务器端缓存、特定于架构的处理库，或者只是方便。然而，缺点是许多并发请求会给服务器带来很大的负载。</p><p id="e906" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">我们还尝试在黑客马拉松期间使用这样的架构在服务器端进行处理:</p><figure class="lk ll lm ln fq iv fe ff paragraph-image"><div class="fe ff mc"><img src="../Images/d96a99757bb3e957ff5f2243fa3dc750.png" data-original-src="https://miro.medium.com/v2/resize:fit:918/format:webp/1*oH4P1ZIhpFbwhVc-d6_vbg.png"/></div><figcaption class="jc jd fg fe ff je jf bd b be z ek">Diagram created using <a class="ae jg" href="http://www.websequencediagrams.com" rel="noopener ugc nofollow" target="_blank">websequencediagrams.com</a></figcaption></figure><p id="bc2e" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">我们选择不这样做是为了减少服务器负载，但是如果您想在自己的项目中复制这一点，我也会给出这个架构的示例代码。</p><figure class="lk ll lm ln fq iv"><div class="bz el l di"><div class="lx lp l"/></div><figcaption class="jc jd fg fe ff je jf bd b be z ek"><a class="ae jg" href="https://github.com/omgimanerd/audio-spatializer/tree/blog-min-example-2" rel="noopener ugc nofollow" target="_blank">Here’s a link to a git repository you can clone to get this sample code</a></figcaption></figure><p id="f57a" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated"><code class="eh ly lz ma mb b">audio-processor-server.js</code>还是一个简单的<a class="ae jg" href="http://expressjs.com" rel="noopener ugc nofollow" target="_blank"> express.js样板服务器</a>，但是这次增加了一些额外的部分。在这个版本中，我们将音频流作为. flv文件保存到文件系统中。如果您只想将音频流传输到您的定制音频处理器，这是不必要的，但我们发现这允许更多的灵活性和控制。像以前一样，这个服务器定义了两条路由:一条用于服务HTML页面，另一条用于服务音频流。同样，服务器也将静态地服务于<code class="eh ly lz ma mb b">/client</code>文件夹中的文件。</p><p id="37f2" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated"><code class="eh ly lz ma mb b">audio-processor.html</code>是相同的普通HTML页面，带有YouTube视频ID的输入字段和提交按钮。</p><p id="8060" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated"><code class="eh ly lz ma mb b">audio-processor.js</code>是一个加载到HTML页面的客户端脚本，它使用<a class="ae jg" href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLAudioElement" rel="noopener ugc nofollow" target="_blank"> HTMLAudioElement </a>请求一个音频文件并播放它。</p><p id="171b" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">如果你选择做服务器端的处理，<a class="ae jg" href="https://stackoverflow.com/questions/33725402/why-web-audio-api-isnt-supported-in-nodejs" rel="noopener ugc nofollow" target="_blank">要注意Web Audio API是一个web JavaScript API，它不是JavaScript语言的一部分</a>。因此，它对于运行在服务器端的node.js服务器是不可用的。</p><p id="c8a5" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">如果你想要更多的粒度，<strong class="ko hv">你实际上可以结合上述两种方法在服务器上进行处理，在客户端进行额外的后处理</strong>。我们没有尝试这样做，但是通过将后端特定的库与Web Audio API的强大功能相结合，您可能会做很多很酷的事情。</p><p id="b046" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated"><strong class="ko hv">如果您只对构建浏览器内音频处理架构感兴趣，那么您可以在此停止阅读或跳到最后。</strong>技术发布的其余部分将是关于我们如何将这个音频流架构连接到<a class="ae jg" href="https://developers.google.com/resonance-audio/" rel="noopener ugc nofollow" target="_blank"> Resonance Audio API </a>进行我们的黑客攻击。</p></div><div class="ab cl jh ji hc jj" role="separator"><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm"/></div><div class="hn ho hp hq hr"><h1 id="1d34" class="jo jp hu bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl dt translated">将音频流空间化</h1><p id="3999" class="pw-post-body-paragraph km kn hu ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj hn dt translated">一旦我们克服了找出处理音频流的最佳方式的挑战，我们就需要找出如何在立体声中移动音频来创建我们想要的效果。我们使用了<a class="ae jg" href="https://developers.google.com/resonance-audio/" rel="noopener ugc nofollow" target="_blank"> Google Resonance Audio API </a>来做到这一点。给定一个音频源和一个矢量位置，这个API允许我们在3D空间中围绕听众定位音频源。你可以在他们的<a class="ae jg" href="https://cdn.rawgit.com/resonance-audio/resonance-audio-web-sdk/master/examples/hello-world.html" rel="noopener ugc nofollow" target="_blank">演示</a>中探索这种效果(最好用耳机体验)。</p><p id="440b" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">我们的计划是基于音频数据生成一个向量值列表，并在播放音频时使用Resonance Audio API移动声源。使用<code class="eh ly lz ma mb b">setInterval()</code>并使用音频中的当前帧来同步向量位置列表是非常简单的。由于音频缓冲器的采样速率是已知的，所以我们可以精确地计算出将音频源定位在哪个矢量位置。</p><p id="b1e6" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">困难的部分(也是最酷的部分)是弄清楚如何正确地生成向量位置列表，以便立体声平移与节拍同步。我们不希望只是在左右摇摆，也不希望运动模式重复而乏味。安德鲁和我试验了各种运动模式，并开发了一种编码方案。</p><figure class="lk ll lm ln fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff md"><img src="../Images/e7bb2ce5543714a58990e5a0cfa389cd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fh_RqbBzlFW1NF5M.jpg"/></div></div><figcaption class="jc jd fg fe ff je jf bd b be z ek">Locations around the head which we can place the audio source. <a class="ae jg" href="https://imgur.com/gallery/gXIDw4j" rel="noopener ugc nofollow" target="_blank">Image from <strong class="bd me"><em class="mf">3D audio experience</em></strong> — Imgur.</a></figcaption></figure><p id="455f" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">我们将移动模式命名为变换，并决定了围绕听众移动音频的5种不同方式:跳跃(将音频源移动到听众周围的随机位置)、翻转(将音频源移动到听众的正对面)、旋转(围绕听众缓慢旋转音频源)、延迟(将音频源保持在原位)和重置(将音频源重置到原点)。使用之前描述的简单节拍检测算法，我们在每个节拍上从一个变换过渡到另一个变换。</p><p id="6911" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">为了生成转换序列，我们使用马尔可夫链，最初以相等的概率播种每个转换。在这里，我们实际上利用服务器作为连接的客户端之间的中继点。我们试图通过在界面上添加一个按钮，允许用户投票赞成或投票反对当前的音频空间化模式，使序列生成变得有些智能。然后，服务器将通过增加或减少用户正在收听的歌曲中使用的序列的概率来考虑这一点。</p><figure class="lk ll lm ln fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mg"><img src="../Images/7117ede5022dc183e5c60f4cd52d2866.png" data-original-src="https://miro.medium.com/v2/resize:fit:1154/format:webp/1*MU8fcev593HKxiIsu0Cxmw.png"/></div></div><figcaption class="jc jd fg fe ff je jf bd b be z ek">Diagram made with <a class="ae jg" href="http://draw.io" rel="noopener ugc nofollow" target="_blank">draw.io</a></figcaption></figure><p id="6bc1" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">新的马尔可夫链将被传播到所有客户端，并且访问该站点的任何新客户端将使用新的概率来生成它们的空间化。尽管我们充分讨论了这个想法，但是JavaScript对象的各种错误和问题阻止了我们在提交hackathon之前完全实现它。</p></div><div class="ab cl jh ji hc jj" role="separator"><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm jn"/><span class="jk bw bk jl jm"/></div><div class="hn ho hp hq hr"><h1 id="339c" class="jo jp hu bd jq jr js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl dt translated">事后思考</h1><p id="3920" class="pw-post-body-paragraph km kn hu ko b kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj hn dt translated">这是一个非常棒的设计和游戏项目。在网络音频API中有很多有趣的东西可以探索。我不太了解音频编码，但我想如果我对音频编解码器和PCM数据有更多的背景知识，那里的资源会有用得多。</p><p id="fa7a" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">如果你想查看我们的整个项目，<a class="ae jg" href="https://github.com/omgimanerd/audio-spatializer" rel="noopener ugc nofollow" target="_blank">这里有一个到git库</a>的链接。有三个显著的分支。<a class="ae jg" href="https://github.com/omgimanerd/audio-spatializer" rel="noopener ugc nofollow" target="_blank">主分支</a>包含我们对音频空间化项目的实施。<a class="ae jg" href="https://github.com/omgimanerd/audio-spatializer/tree/blog-min-example" rel="noopener ugc nofollow" target="_blank"> blog-min-example分支</a>包含第一部分中描述的客户端处理示例，而<a class="ae jg" href="https://github.com/omgimanerd/audio-spatializer/tree/blog-min-example-2" rel="noopener ugc nofollow" target="_blank"> blog-min-example-2分支</a>包含第二部分中描述的服务器端处理示例。</p><p id="9e1c" class="pw-post-body-paragraph km kn hu ko b kp lq kr ks kt lr kv kw kx ls kz la lb lt ld le lf lu lh li lj hn dt translated">如果你喜欢这个技术演讲，可以考虑点击拍手图标或者在Twitter上关注我以获得更多类似的内容。非常感谢您的阅读！</p></div></div>    
</body>
</html>