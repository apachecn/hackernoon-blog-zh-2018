<html>
<head>
<title>Tensor &amp; Flow: Part 1, TensorFlow &amp; Machine Learning on Android</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">张量和流:第1部分，Android上的张量流和机器学习</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/tensor-flow-part-1-tensorflow-machine-learning-on-android-73fd536a1a7c?source=collection_archive---------28-----------------------#2018-03-08">https://medium.com/hackernoon/tensor-flow-part-1-tensorflow-machine-learning-on-android-73fd536a1a7c?source=collection_archive---------28-----------------------#2018-03-08</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="9427" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Android和iOS上的许多流行应用广泛使用了设备上的T2机器学习。Gmail或Siri的Inbox等应用程序利用了设备上的机器学习，因为它速度更快，在保护用户隐私方面做得更好。<a class="ae jp" href="https://developer.apple.com/machine-learning/" rel="noopener ugc nofollow" target="_blank"> iOS </a>和<a class="ae jp" href="https://developer.android.com/ndk/guides/neuralnetworks/index.html" rel="noopener ugc nofollow" target="_blank"> Android </a>都有适当的API支持在设备上使用，神经网络用于预测目的。在这两个平台上，您可以连接自己的神经网络，或者使用TensorFlow这样的高级框架来为您完成繁重的工作。</p><p id="4d13" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Tensor &amp; Flow是一个由两部分组成的系列，其中我们将探索将机器学习模型部署到Android应用程序所需做的细节。我将在第1部分使用TensorFlow Mobile，在第2部分使用TensorFlow Lite。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff jq"><img src="../Images/639a5873baec00fbcd26b9af857947e3.png" data-original-src="https://miro.medium.com/v2/resize:fit:854/0*SGgNKrV9P7GydpQK.gif"/></div><figcaption class="jy jz fg fe ff ka kb bd b be z ek">Tensor &amp; Flow demo app on Android</figcaption></figure><h1 id="de78" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">训练神经网络</h1><p id="656e" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">这个旅程的第一步是训练一个我可以部署的神经网络。有大量的教程指导有抱负的机器学习工程师构建模型，这些模型可以对花朵进行分类，识别图片中的对象，检测垃圾邮件，甚至对图片应用过滤器。我选择了一个相当容易理解的教程，建立一个识别手写数字的模型。</p><p id="90d5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><a class="ae jp" href="https://www.tensorflow.org/tutorials/layers" rel="noopener ugc nofollow" target="_blank">TF层指南:构建卷积神经网络</a>向我们展示了配置和训练神经网络以识别手写字符的整个过程。本指南向我们介绍神经网络配置、下载用于训练的数据集以及训练过程。</p><p id="96c5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">第一步是配置我们的神经网络。</p><h1 id="66df" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">神经网络</h1><p id="5d07" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">MNIST教程训练了一个卷积神经网络(CNN)来识别手写数字。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff lf"><img src="../Images/b25d03b520af9e664401e536f76815c3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1052/0*ay0RD9Y5pombwVGe.gif"/></div><figcaption class="jy jz fg fe ff ka kb bd b be z ek">Feature extraction using convolution — <a class="ae jp" href="http://deeplearning.stanford.edu/wiki/index.php/Feature_extraction_using_convolution" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="f024" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">CNN由几个不同的层组成:</p><ul class=""><li id="3052" class="lg lh hu it b iu iv iy iz jc li jg lj jk lk jo ll lm ln lo dt translated">卷积层，使用卷积运算从图像中提取特征。</li><li id="9ead" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo ll lm ln lo dt translated">合并图层，对图像进行下采样，这减少了处理时间，提高了训练和推理性能。</li><li id="4306" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo ll lm ln lo dt translated">密集层，使用卷积层中提取的特征预测类别。</li></ul><p id="68b4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在继续之前，我鼓励你访问一下<a class="ae jp" href="https://ujjwalkarn.me/" rel="noopener ugc nofollow" target="_blank">数据科学博客</a>，在那里，Ujjwal Karn写了一篇非常直观的博文，名为<a class="ae jp" href="https://ujjwalkarn.me/2016/08/11/intuitive-explanation-convnets/" rel="noopener ugc nofollow" target="_blank">“卷积神经网络的直观解释”</a>。一旦你写完博文，请访问<a class="ae jp" href="http://scs.ryerson.ca/~aharley/vis/conv/flat.html" rel="noopener ugc nofollow" target="_blank"> 2D卷积神经网络可视化</a>，观看CNN的精彩演示。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="fe ff lu"><img src="../Images/53e82cc0b7b95af75f529efc697917a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fMvSpYTBfw00UaAA.png"/></div></div><figcaption class="jy jz fg fe ff ka kb bd b be z ek">2D Visualization of a CNN</figcaption></figure><p id="6920" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">关于神经网络的更多细节在此示例中，输入层是输入数据大小的一对一映射。MNIST数据集包含数万个手写数字样本和标签。每个样本都是手写数字的单色图像，28像素x 28像素。图像是一个二维数组，包含像素数据，这意味着我们的输入层有784个输入节点(28 x 28 = 784)。</p><p id="2825" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">输出层是一个<a class="ae jp" href="https://en.wikipedia.org/wiki/Logit" rel="noopener ugc nofollow" target="_blank"> Logits </a>层，它将我们的预测作为原始值发出。网络使用几个附加函数将原始数据转换成预测和概率(用于训练)。</p><h1 id="bdf2" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">集成的培训和准备</h1><p id="0b5d" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">训练神经网络模型并将其集成到Android应用程序中的过程类似于:</p><ol class=""><li id="ddb2" class="lg lh hu it b iu iv iy iz jc li jg lj jk lk jo lz lm ln lo dt translated">训练神经网络。</li><li id="9620" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo lz lm ln lo dt translated">冻结和优化用于推理的张量流图。</li><li id="1c97" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo lz lm ln lo dt translated">在TensorBoard中查看神经网络模型。(可选)</li><li id="c3d8" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo lz lm ln lo dt translated">将优化的图形导入我们的Android项目。</li></ol><p id="0eb3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">根据您的计算平台，为培训做好一切准备可能比实际培训更困难。我的设置:</p><ul class=""><li id="82b2" class="lg lh hu it b iu iv iy iz jc li jg lj jk lk jo ll lm ln lo dt translated">运行MacOS 10.13的MacBook Pro (2015)</li><li id="b738" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo ll lm ln lo dt translated">IDE: PyCharm，通过自动导入Python依赖项和提供代码调试功能使这变得更加容易</li><li id="e60d" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo ll lm ln lo dt translated">Python 2.7.13</li><li id="8a15" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo ll lm ln lo dt translated">张量流1.5</li><li id="8b81" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo ll lm ln lo dt translated">安卓工作室3.0.1</li></ul><p id="b71f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们的指南“TF层指南”引导我们建立我们的神经网络和训练。在浏览了几遍指南后，我做了一个调整，使集成到Android应用程序变得更加容易，我给我的输入和输出层分别起了明确的名字，“输入”和“输出”。我在花了几个小时试图自己找出答案后这样做了。如果不命名神经网络中的层，它们将被赋予默认名称。您需要在TensorBoard中打开您的训练图，以确定您的图层的名称。</p><p id="1fbf" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们将以这个Python脚本结束:</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="00ac" class="mf kd hu mb b fv mg mh l mi mj">from __future__ import absolute_import<br/>from __future__ import division<br/>from __future__ import print_function</span><span id="ca15" class="mf kd hu mb b fv mk mh l mi mj"># Imports<br/>import numpy as np<br/>import tensorflow as tf</span><span id="a707" class="mf kd hu mb b fv mk mh l mi mj">tf.logging.set_verbosity(tf.logging.INFO)</span><span id="6a2e" class="mf kd hu mb b fv mk mh l mi mj">def cnn_model_fn(features, labels, mode):<br/>    """Model function for CNN."""<br/>    # Input Layer<br/>    input_layer = tf.reshape(features["x"], [-1, 28, 28, 1], name="input")</span><span id="d37d" class="mf kd hu mb b fv mk mh l mi mj"># Convolutional Layer #1<br/>    conv1 = tf.layers.conv2d(<br/>      inputs=input_layer,<br/>      filters=32,<br/>      kernel_size=[5, 5],<br/>      padding="same",<br/>      activation=tf.nn.relu)</span><span id="abeb" class="mf kd hu mb b fv mk mh l mi mj"># Pooling Layer #1<br/>    pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)</span><span id="6c2f" class="mf kd hu mb b fv mk mh l mi mj"># Convolutional Layer #2 and Pooling Layer #2<br/>    conv2 = tf.layers.conv2d(<br/>      inputs=pool1,<br/>      filters=64,<br/>      kernel_size=[5, 5],<br/>      padding="same",<br/>      activation=tf.nn.relu)<br/>    pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)</span><span id="2f92" class="mf kd hu mb b fv mk mh l mi mj"># Dense Layer<br/>    pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])<br/>    dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)<br/>    dropout = tf.layers.dropout(<br/>      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)</span><span id="2f03" class="mf kd hu mb b fv mk mh l mi mj"># Logits Layer<br/>    logits = tf.layers.dense(inputs=dropout, units=10)</span><span id="c42d" class="mf kd hu mb b fv mk mh l mi mj">predictions = {<br/>      # Generate predictions (for PREDICT and EVAL mode)<br/>      "classes": tf.argmax(input=logits, axis=1, name="output"),<br/>      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the<br/>      # `logging_hook`.<br/>      "probabilities": tf.nn.softmax(logits, name="softmax_tensor")<br/>    }</span><span id="0029" class="mf kd hu mb b fv mk mh l mi mj">if mode == tf.estimator.ModeKeys.PREDICT:<br/>        return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)</span><span id="9706" class="mf kd hu mb b fv mk mh l mi mj"># Calculate Loss (for both TRAIN and EVAL modes)<br/>    loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)</span><span id="f607" class="mf kd hu mb b fv mk mh l mi mj"># Configure the Training Op (for TRAIN mode)<br/>    if mode == tf.estimator.ModeKeys.TRAIN:<br/>        optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)<br/>        train_op = optimizer.minimize(<br/>            loss=loss,<br/>            global_step=tf.train.get_global_step())<br/>        return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)</span><span id="9526" class="mf kd hu mb b fv mk mh l mi mj"># Add evaluation metrics (for EVAL mode)<br/>    eval_metric_ops = {<br/>      "accuracy": tf.metrics.accuracy(<br/>          labels=labels, predictions=predictions["classes"])}<br/>    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)</span><span id="dbe9" class="mf kd hu mb b fv mk mh l mi mj">def main(unused_argv):<br/>    # Load training and eval data<br/>    mnist = tf.contrib.learn.datasets.load_dataset("mnist")<br/>    train_data = mnist.train.images  # Returns np.array<br/>    train_labels = np.asarray(mnist.train.labels, dtype=np.int32)<br/>    eval_data = mnist.test.images  # Returns np.array<br/>    eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)</span><span id="caaf" class="mf kd hu mb b fv mk mh l mi mj"># Create the Estimator<br/>    mnist_classifier = tf.estimator.Estimator(model_fn=cnn_model_fn, model_dir="/tmp/mnist_convnet_model")</span><span id="1386" class="mf kd hu mb b fv mk mh l mi mj"># Set up logging for predictions<br/>    tensors_to_log = {"probabilities": "softmax_tensor"}<br/>    logging_hook = tf.train.LoggingTensorHook(tensors=tensors_to_log, every_n_iter=50)</span><span id="f006" class="mf kd hu mb b fv mk mh l mi mj"># Train the model<br/>    train_input_fn = tf.estimator.inputs.numpy_input_fn(<br/>        x={"x": train_data},<br/>        y=train_labels,<br/>        batch_size=100,<br/>        num_epochs=None,<br/>        shuffle=True)<br/>    mnist_classifier.train(<br/>        input_fn=train_input_fn,<br/>        steps=20000,<br/>        hooks=[logging_hook])</span><span id="7492" class="mf kd hu mb b fv mk mh l mi mj"># Evaluate the model and print results<br/>    eval_input_fn = tf.estimator.inputs.numpy_input_fn(<br/>        x={"x": eval_data},<br/>        y=eval_labels,<br/>        num_epochs=1,<br/>        shuffle=False)<br/>    eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)<br/>    print(eval_results)</span><span id="a90f" class="mf kd hu mb b fv mk mh l mi mj">if __name__ == "__main__":<br/>    tf.app.run()</span></pre><p id="ace0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">它在<code class="eh ml mm mn mb b">cnn_model_fn</code>中配置我们的神经网络。培训在<code class="eh ml mm mn mb b">main</code>进行。在我们的训练步骤中，我们下载MNIST数据集，它已经被分解成训练和评估块。在训练神经网络时，您希望确保训练数据的子集可用于评估目的。这允许你在训练过程中测试你的神经网络的准确性。这也可以防止你的神经网络过度适应训练数据。</p><p id="8de0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">使用<code class="eh ml mm mn mb b">python train_cnn.py</code>命令开始训练也很简单。根据计算机的硬件配置，培训可能需要几分钟到几小时不等。这个脚本被配置为训练网络20，000次迭代。当您的训练脚本运行时，您将定期看到显示训练过程进度的输出。</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="6d6f" class="mf kd hu mb b fv mg mh l mi mj">INFO:tensorflow:global_step/sec: 2.75874<br/>    INFO:tensorflow:probabilities = [[ 0.10167542  0.10189584  0.10309957  0.11525927  0.09659223  0.08847987<br/>       0.09406721  0.10499229  0.093654    0.10028425]<br/>     [ 0.10425898  0.11098097  0.10286383  0.09657481  0.10871311  0.08486023 0.09235432  0.09499202  0.10640075  0.09800103]<br/>     [ 0.1033088   0.11629853  0.11034065  0.0981971   0.08924178  0.09668511 0.10001212  0.09568888  0.08589367  0.10433336]<br/>     [ 0.10667751  0.10386481  0.09242702  0.11075728  0.08897669  0.09205832 0.10070907  0.10779921  0.08927511  0.10745502]<br/>    ...</span></pre><p id="034b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">它显示了训练的速率和样本图像成为一个数字的概率数组。例如:</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="5fd4" class="mf kd hu mb b fv mg mh l mi mj">[ 0.00001972  0.00000233  0.00022174  0.00427989  0.00001842  0.97293282 0.00000114  0.00013626  0.00584014  0.01654756]</span></pre><p id="aebb" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">看起来有97.3%的可能性该样本图像是由该索引表示的数字(5或6，取决于起始索引)。随着训练的继续，这些值变得更加确定。神经网络正在提高其识别手写数字的能力。</p><p id="0dbe" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在训练开始时比较这些概率:</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="ce38" class="mf kd hu mb b fv mg mh l mi mj">[ 0.1033088 0.11629853 0.11034065 0.0981971 0.08924178 0.09668511 0.10001212 0.09568888 0.08589367 0.10433336]</span></pre><p id="68c1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">有了这些，接近尾声:</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="222a" class="mf kd hu mb b fv mg mh l mi mj">[ 0.00000006 0.0000001 0.00000017 0.00000019 0.99616736 0.00000038, 0.00000154 0.00000558 0.00001187 0.00381267]</span></pre><p id="f2b1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">你会注意到网络的预测越来越准确。</p><p id="3865" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">一旦训练完成，它将根据标记图像的第二个数据集测试神经网络。这用于计算训练网络的准确度。</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="c18e" class="mf kd hu mb b fv mg mh l mi mj">INFO:tensorflow:Saving dict for global step 20000: accuracy = 0.9708, global_step = 20000, loss = 0.0991706</span></pre><p id="3413" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">截止到第20000步，我们的神经网络的预测准确率达到了97.8%！稍微讲一下<code class="eh ml mm mn mb b">loss</code>值。训练神经网络的目标是最小化损失，或者最小化预测值和实际值之间的差异。一般来说，<code class="eh ml mm mn mb b">loss</code>量较低的神经网络会给出更准确的预测。</p><p id="c4ae" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在培训已经完成，我们在<code class="eh ml mm mn mb b">/tmp/mnist_convnet_model</code>中结束了一堆文件:</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="668f" class="mf kd hu mb b fv mg mh l mi mj">checkpoint<br/>eval<br/>events.out<br/>graph.pbtxt<br/>model.ckpt-15199.data-00000-of-00001<br/>model.ckpt-15199.index<br/>model.ckpt-15199.meta<br/>model.ckpt-20000.data-00000-of-00001<br/>model.ckpt-20000.index<br/>model.ckpt-20000.meta</span></pre><p id="f50b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们在接下来的步骤中关注的文件是:</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="e00f" class="mf kd hu mb b fv mg mh l mi mj">graph.pbtxt // graph definition file, human readable protobuf format<br/>model.ckpt-20000.data-00000-of-00001  //  variables from our graph model.ckpt-20000.index // identifies the checkpoint / training step<br/>model.ckpt-20000.meta  // stores the structure of the graph</span></pre><p id="c52a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在将它们集成到Android应用程序之前，我们需要做一些调整。我们将:</p><ol class=""><li id="a250" class="lg lh hu it b iu iv iy iz jc li jg lj jk lk jo lz lm ln lo dt translated">冻结我们的图表和值。这将神经网络和张量值存储在一个二进制图形定义文件(.pb)，而不是单独的文件。</li><li id="f2be" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo lz lm ln lo dt translated">优化我们的图表进行推理。训练步骤完成后，我们的图包含了在训练过程中使用的节点。进行推理时不需要这些节点。这种优化将删除这些额外的节点和张量。这减小了图表的大小，也降低了我们在图表中遇到TensorFlow Mobile不支持的操作的可能性。</li></ol><h2 id="161f" class="mf kd hu bd ke mo mp mq ki mr ms mt km jc mu mv kq jg mw mx ku jk my mz ky na dt translated">极冷的</h2><p id="1e10" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">冻结我们的图表就像执行在<a class="ae jp" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/freeze_graph.py" rel="noopener ugc nofollow" target="_blank"> TensorFlow存储库</a>中可用的Python脚本一样简单。</p><p id="0299" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">执行看起来像:</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="1541" class="mf kd hu mb b fv mg mh l mi mj">python freeze_graph.py \<br/>   --input_graph=/tmp/mnist_convnet_model/graph.pbtxt \<br/>   --input_binary=false \<br/>   --input_checkpoint=/tmp/mnist_convnet_model/model.ckpt-20000 \<br/>   --output_graph=/tmp/mnist_convnet_model/frozen_graph.pb \<br/>   --output_node_names=output \</span></pre><p id="8b9a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">当这个脚本完成时，您将在<code class="eh ml mm mn mb b">/tmp/mnist_convnet_model</code>中看到一个新文件<code class="eh ml mm mn mb b">frozen_graph.db</code>。它包含我们的图形定义和网络值。</p><h2 id="05f4" class="mf kd hu bd ke mo mp mq ki mr ms mt km jc mu mv kq jg mw mx ku jk my mz ky na dt translated">推理优化</h2><p id="f596" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">现在，我们优化我们的神经网络进行推理。在<a class="ae jp" href="https://github.com/tensorflow/tensorflow/blob/master/tensorflow/python/tools/optimize_for_inference.py" rel="noopener ugc nofollow" target="_blank"> TensorFlow资源库</a>中也有一个可用的脚本。针对推理的优化移除了图形中仅用于训练的部分。</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="023d" class="mf kd hu mb b fv mg mh l mi mj">python optimize_for_inference.py \<br/>   --input=/tmp/mnist_convnet_model/frozen_graph.pb \<br/>   --output=/tmp/mnist_convnet_model/optimized_graph.pb \<br/>   --input_names=input \<br/>   --output_names=output</span></pre><p id="16f4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">当这个脚本完成时，你会在<code class="eh ml mm mn mb b">/tmp/mnist_convnet_model</code>中看到一个新文件<code class="eh ml mm mn mb b">optimized_graph.db</code>。这是我们神经网络模型的最终状态。</p><p id="02e8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这是我们的冻结和优化图形的张量视图。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="lv lw di lx bf ly"><div class="fe ff nb"><img src="../Images/b86164fccccc154f424b44a0e81e3656.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*BD-U8_P3xSfdd6DJ.png"/></div></div></figure><p id="1fb8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果您想用TensorBoard可视化您的优化图形，请查看<a class="ae jp" rel="noopener" href="/@daj/how-to-inspect-a-pre-trained-tensorflow-model-5fd2ee79ced0">如何检查预训练的TF模型</a>。</p><p id="c529" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们现在准备开始在一个Android项目中使用它。</p><h1 id="5156" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">集成到Android应用程序中</h1><p id="fa66" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">部署经过训练的张量流神经网络模型是一项相对较难的任务。</p><h2 id="ff34" class="mf kd hu bd ke mo mp mq ki mr ms mt km jc mu mv kq jg mw mx ku jk my mz ky na dt translated">添加TensorFlow移动依赖项</h2><p id="29d5" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">将TensorFlow移动依赖项添加到<code class="eh ml mm mn mb b">app/</code>文件夹中的<code class="eh ml mm mn mb b">build.gradle</code>，然后同步项目的Gradle依赖项。</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="2cea" class="mf kd hu mb b fv mg mh l mi mj">implementation "org.tensorflow:tensorflow-android:1.5.0"</span></pre><p id="ea18" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们将使用TensorFlow Mobile提供的类<code class="eh ml mm mn mb b">TensorFlowInferenceInterface</code>与我们的模型进行交互。它提供了几种加载模型、向网络提供新数据、运行推理和提取预测的方法。</p><h2 id="c3a6" class="mf kd hu bd ke mo mp mq ki mr ms mt km jc mu mv kq jg mw mx ku jk my mz ky na dt translated">添加模型</h2><p id="6e99" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">将优化后的图形复制到您的Android项目中。应该是复制到了<code class="eh ml mm mn mb b">src/main/assets</code>。<code class="eh ml mm mn mb b">TensorFlowInferenceInterface</code>将从这个文件夹加载模型到它的构造函数中。</p><h2 id="7f48" class="mf kd hu bd ke mo mp mq ki mr ms mt km jc mu mv kq jg mw mx ku jk my mz ky na dt translated">一些建筑</h2><p id="b833" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">我们的应用程序将允许用户用手指画一个数字。我们会将他们的图画转换成位图，并将其传递给我们的神经网络进行预测。认识到这一点，我要做的第一件事就是创建一个<code class="eh ml mm mn mb b">Classifier</code>界面。</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="db54" class="mf kd hu mb b fv mg mh l mi mj">interface Classifier { <br/>   fun predict(input: IntArray): <br/>   Int fun close() <br/>}</span></pre><p id="4717" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我选择创建一个接口，这样我就可以轻松地创建一个分类器的多个实现。一个使用TensorFlow Mobile，一个使用TensorFlow Lite(在第2部分中)。</p><h2 id="1f78" class="mf kd hu bd ke mo mp mq ki mr ms mt km jc mu mv kq jg mw mx ku jk my mz ky na dt translated">使用TensorFlowInferenceInterface</h2><p id="a3de" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">如前所述<code class="eh ml mm mn mb b">TensorFlowInferenceInterface</code>是我们将如何与我们训练有素的网络互动。</p><p id="6373" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">让我们通过编写<code class="eh ml mm mn mb b">TFMobileClassifier</code>来实现我们的<code class="eh ml mm mn mb b">Classifier</code>接口。</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="5de3" class="mf kd hu mb b fv mg mh l mi mj">class TFMobileClassifier(context: Context,<br/>   modelFilename: String,<br/>   private val inputName: String,<br/>   private val inputDimensions: Pair&lt;Long , Long&gt;,<br/>   private val outputName: String,<br/>   private val outputSize: Int) : Classifier {</span><span id="8e31" class="mf kd hu mb b fv mk mh l mi mj">   override predict(input: IntArray): Int {<br/>      TODO()<br/>   }</span><span id="9a20" class="mf kd hu mb b fv mk mh l mi mj">   override close() {<br/>      TODO()<br/>   }<br/>}</span></pre><p id="4710" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们的<code class="eh ml mm mn mb b">TFMobileClassifier</code>有一个带6个参数的构造函数。<code class="eh ml mm mn mb b">Context</code>用于通过<code class="eh ml mm mn mb b">AssetManager</code>访问文件。剩下的参数指定了我们的模型文件以及输入和输出节点规范。</p><p id="96ea" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">实例化一个<code class="eh ml mm mn mb b">TFMobileClassifier</code>。</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="b1cf" class="mf kd hu mb b fv mg mh l mi mj">val classifier: Classifier = TFMobileClassifier(this,<br/>   modelFilename = "file:///android_asset/optimized_graph.pb",<br/>   inputName = "input",<br/>   inputDimensions = Pair(28, 28),<br/>   outputName = "output",<br/>   outputSize = 100)</span></pre><p id="f97c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">让我们创造我们的<code class="eh ml mm mn mb b">TensorFlowInferenceInterface</code>。</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="2af9" class="mf kd hu mb b fv mg mh l mi mj">private val assetManager = context.assetManager<br/>private val inferenceInterface = <br/>   TensorFlowInferenceInterface(assetManager, modelFilename)</span></pre><p id="8558" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在我们已经有了一个<code class="eh ml mm mn mb b">TensorFlowInferenceInterface</code>，让我们通过实现<code class="eh ml mm mn mb b">predict()</code>来开始使用它。</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="c9eb" class="mf kd hu mb b fv mg mh l mi mj">override fun predict(input: FloatArray) {<br/>   // 1) create an array to store our predictions<br/>   val predictions = LongArray(100)</span><span id="ffaf" class="mf kd hu mb b fv mk mh l mi mj">   // 2) feed our data into input layer of our neural network<br/>   inferenceInterface.feed(inputName, floatInput, 1,      <br/>       inputDimensions.first, inputDimensions.second, 1)</span><span id="4e82" class="mf kd hu mb b fv mk mh l mi mj">   // 3) run inference between the input and specified output nodes<br/>   inferenceInterface.run(arrayOf(outputName))</span><span id="e4a3" class="mf kd hu mb b fv mk mh l mi mj">   // 4) fetch the predictions from the specified output node<br/>   inferenceInterface.fetch(outputName, predictions)</span><span id="0f84" class="mf kd hu mb b fv mk mh l mi mj">   // 5) tabulate our predictions and return the most probable<br/>   return processPredictions(predictions)<br/>}</span></pre><p id="cc8d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这里要谈几件事:</p><ol class=""><li id="ac31" class="lg lh hu it b iu iv iy iz jc li jg lj jk lk jo lz lm ln lo dt translated">我们的输出节点发出100个值，因此我们需要将它们存储在一个至少包含100个元素的数组中</li><li id="f857" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo lz lm ln lo dt translated">当您计算X * Y * Z数组中的总元素时，我们的输入数据数组大小必须等于该值。例如，我们的神经网络使用28 x 28的单色图像。我们的尺寸将会是:28×28×1。这意味着我们的输入数据数组应该包含784个值。</li><li id="1948" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo lz lm ln lo dt translated">当运行推理时，我们需要指定推理将结束的输出节点的名称。</li><li id="7345" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo lz lm ln lo dt translated">推断完成后，我们将把结果存储在100个元素的预测数组中。给定输入数据，这个特定的神经网络返回包含100个预测的数组。回到我们的Python训练脚本，我们用batch_size = 100来训练我们的网络。这意味着，即使我们给神经网络提供一张图片，它也会给我们100个关于它认为用户画了什么的预测。</li><li id="59c1" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo lz lm ln lo dt translated">因为我们有100个预测，我们需要计算每个预测的出现次数，然后返回预测次数最多的数字。我们将使用这个值作为我们的预测。</li></ol><p id="4b3d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们实施了<code class="eh ml mm mn mb b">TFMobileClassifier</code>。</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="c86f" class="mf kd hu mb b fv mg mh l mi mj">package com.emuneee.tensorandflow.classifier</span><span id="a268" class="mf kd hu mb b fv mk mh l mi mj">import android.content.Context<br/>import android.content.res.AssetManager<br/>import org.tensorflow.contrib.android.TensorFlowInferenceInterface<br/>import timber.log.Timber<br/>import java.util.*<br/>import kotlin.Comparator</span><span id="8887" class="mf kd hu mb b fv mk mh l mi mj">/**<br/> * Created by evan on 2/28/18.<br/> */<br/>class TFMobileClassifier(context: Context,<br/>   modelFilename: String,<br/>   private val inputName: String,<br/>   private val inputDimensions: &lt;Long , Long&gt;,<br/>   private val outputName: String,<br/>   private val outputSize: Int) : Classifier {</span><span id="bb63" class="mf kd hu mb b fv mk mh l mi mj">   private val assetManager: AssetManager = context.assets<br/>   private val inferenceInterface = <br/>      TensorFlowInferenceInterface(assetManager, modelFilename)</span><span id="8ba7" class="mf kd hu mb b fv mk mh l mi mj">   override fun predict(input: IntArray): Int {<br/>        val floatInput = input.map { it.toFloat() }<br/>                .toFloatArray()<br/>        // 1) create an array to store our predictions<br/>        val predictions = LongArray(outputSize)</span><span id="9999" class="mf kd hu mb b fv mk mh l mi mj">        // 2) feed our data into input layer of our neural network<br/>        inferenceInterface.feed(inputName, floatInput, 1, <br/>           inputDimensions.first, inputDimensions.second, 1)</span><span id="e57f" class="mf kd hu mb b fv mk mh l mi mj">        // 3) run inference between the input and output nodes<br/>        inferenceInterface.run(arrayOf(outputName))</span><span id="bbbd" class="mf kd hu mb b fv mk mh l mi mj">        // 4) fetch the predictions from the specified output node<br/>        inferenceInterface.fetch(outputName, predictions)</span><span id="8afb" class="mf kd hu mb b fv mk mh l mi mj">        // 5) tabulate our predictions and return the most probable<br/>        return processPredictions(predictions)<br/>   }</span><span id="01bd" class="mf kd hu mb b fv mk mh l mi mj">   private fun processPredictions(predictions: LongArray): Int {<br/>      val counts = predictions.toTypedArray()<br/>            .groupingBy { it }<br/>            .eachCount()<br/>      val predictionSet = TreeSet&lt;Pair&lt;Long, Int&gt;&gt;    <br/>         (Comparator&lt;Pair&lt;Long, Int&gt;&gt; { o1, o2 -&gt;     <br/>         o2!!.second.compareTo(o1!!.second) })<br/>      counts.toList()<br/>            .forEach { pair -&gt; predictionSet.add(pair) }<br/>      val pair = predictionSet.first()<br/>      Timber.d("Selecting ${pair.first} @ ${(pair.second / 100.0) *<br/>          100}% confidence")<br/>      return pair.first.toInt()<br/>   }</span><span id="5740" class="mf kd hu mb b fv mk mh l mi mj">   override fun close() {<br/>      inferenceInterface.close()<br/>   }<br/>}</span></pre><h2 id="05ea" class="mf kd hu bd ke mo mp mq ki mr ms mt km jc mu mv kq jg mw mx ku jk my mz ky na dt translated">使用分类器</h2><p id="3ee1" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">现在我们已经实现了一个<code class="eh ml mm mn mb b">Classifier</code>，是时候构建一些UI来允许用户用指尖提交数据了。为了简洁起见，我将跳过许多纯粹的Android概念，比如布局和点击监听器等。我们的用户界面有3个组件:</p><ol class=""><li id="a6a9" class="lg lh hu it b iu iv iy iz jc li jg lj jk lk jo lz lm ln lo dt translated">我们有一个自定义的<code class="eh ml mm mn mb b">CanvasView</code>，允许用户用他们的指尖在一个<code class="eh ml mm mn mb b">Canvas</code>上画画。当用户在<code class="eh ml mm mn mb b">CanvasView</code>上完成绘图时，它将通过<code class="eh ml mm mn mb b">CanvasView.DrawListener</code>发出一个代表用户绘图的位图</li><li id="cd3d" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo lz lm ln lo dt translated">我们将有一个类似于提交给神经网络的实际数据的<code class="eh ml mm mn mb b">ImageView</code>。</li><li id="3f82" class="lg lh hu it b iu lp iy lq jc lr jg ls jk lt jo lz lm ln lo dt translated">最后，我们将有一个显示预测的<code class="eh ml mm mn mb b">TextView</code>。</li></ol><p id="e56f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在我们继续之前，我们需要解决一个问题。我们需要将用户输入转换为类似于MNIST数据集中图像的数据格式。这一点至关重要，因为数据越接近原始训练数据，我们的预测就越准确。MNIST训练数据集用28×28单色图像填充，其中对于给定的像素，值的范围从0(白色)到255(黑色)。</p><p id="58f9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">下面是我们如何将位图从<code class="eh ml mm mn mb b">CanvasView</code>转换成28×28的单色位图:</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="1544" class="mf kd hu mb b fv mg mh l mi mj">private fun toMonochrome(bitmap: Bitmap): Bitmap {<br/>        // scale bitmap to 28 by 28<br/>        val scaled = Bitmap.createScaledBitmap(bitmap, 28, 28, false)</span><span id="e235" class="mf kd hu mb b fv mk mh l mi mj">// convert bitmap to monochrome<br/>        val monochrome = Bitmap.createBitmap(28, 28, Bitmap.Config.ARGB_8888)<br/>        val canvas = Canvas(monochrome)<br/>        val ma = ColorMatrix()<br/>        ma.setSaturation(0f)<br/>        val paint = Paint()<br/>        paint.colorFilter = ColorMatrixColorFilter(ma)<br/>        canvas.drawBitmap(scaled, 0f, 0f, paint)</span><span id="21cd" class="mf kd hu mb b fv mk mh l mi mj">val width = monochrome.width<br/>        val height = monochrome.height</span><span id="f7fe" class="mf kd hu mb b fv mk mh l mi mj">val pixels = IntArray(width * height)<br/>        monochrome.getPixels(pixels, 0, width, 0, 0, width, height)</span><span id="3bce" class="mf kd hu mb b fv mk mh l mi mj">// Iterate over height<br/>        for (y in 0 until height) {</span><span id="ec32" class="mf kd hu mb b fv mk mh l mi mj">for (x in 0 until width) {<br/>                val pixel = monochrome.getPixel(x, y)<br/>                val lowestBit = pixel and 0xff</span><span id="d7c4" class="mf kd hu mb b fv mk mh l mi mj">if (lowestBit &amp;lt; 128) {<br/>                    monochrome.setPixel(x, y, Color.BLACK)<br/>                }<br/>                else {<br/>                    monochrome.setPixel(x, y, Color.WHITE)<br/>                }<br/>            }<br/>        }<br/>        return monochrome<br/>}</span></pre><p id="0989" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><code class="eh ml mm mn mb b">toMonochrome()</code>的输出用于让用户了解神经网络的输入是什么样的。它还被转换成适合推理的格式:</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="4c88" class="mf kd hu mb b fv mg mh l mi mj">private fun formatInput(bitmap: Bitmap): IntArray {<br/>   val pixels = IntArray(bitmap.width * bitmap.height)<br/>   var i = 0</span><span id="3c50" class="mf kd hu mb b fv mk mh l mi mj">   for (y in 0 until bitmap.height) {</span><span id="03e7" class="mf kd hu mb b fv mk mh l mi mj">      for (x in 0 until bitmap.width) {<br/>         pixels[i++] = if (bitmap.getPixel(x, y) == Color.BLACK) 255 <br/>                       else 0<br/>      }<br/>    }<br/>    return pixels<br/>}</span></pre><p id="7695" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们在这里做两件事。首先，我们将28×28位图展平成一个784元素的整数数组。最后，如果像素值是白色或黑色，我们将每个像素值分别转换为<code class="eh ml mm mn mb b">0</code>或<code class="eh ml mm mn mb b">255</code>。</p><p id="bbe9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们的<code class="eh ml mm mn mb b">MainActivity.kt</code>看起来像:</p><pre class="jr js jt ju fq ma mb mc md aw me dt"><span id="4f7f" class="mf kd hu mb b fv mg mh l mi mj">package com.emuneee.tensorandflow<br/><br/>import android.graphics.*<br/>import android.support.v7.app.AppCompatActivity<br/>import android.os.Bundle<br/>import kotlinx.android.synthetic.main.activity_main.*<br/>import android.graphics.Bitmap<br/>import com.emuneee.tensorandflow.classifier.Classifier<br/>import com.emuneee.tensorandflow.classifier.TFMobileClassifier<br/>import com.emuneee.tensorandflow.view.CanvasView<br/>import timber.log.Timber<br/><br/>class MainActivity : AppCompatActivity() {<br/><br/>    private val classifier: Classifier by <em class="nc">lazy </em><strong class="mb hv">{<br/>        </strong>TFMobileClassifier(this,<br/>                modelFilename = "file:///android_asset/optimized_graph.pb",<br/>                inputName = "input",<br/>                inputDimensions = Pair(28, 28),<br/>                outputName = "output",<br/>                outputSize = 100)<br/>    <strong class="mb hv">}<br/><br/>    </strong>override fun onCreate(savedInstanceState: Bundle?) {<br/>        super.onCreate(savedInstanceState)<br/>        setContentView(R.layout.<em class="nc">activity_main</em>)<br/>        Timber.plant(Timber.DebugTree())<br/><br/>        canvas.drawListener = object: CanvasView.DrawListener {<br/>            override fun onNewBitmap(bitmap: Bitmap) {<br/><br/>                Thread(<em class="nc">Runnable </em><strong class="mb hv">{<br/><br/>                    </strong>// convert the drawing to a 28x28 monochrome image<br/>                    val monochrome = toMonochrome(bitmap)<br/><br/>                    // set the nn input image<br/>                    runOnUiThread <strong class="mb hv">{ </strong>scaledCanvas.setImageBitmap(monochrome) <strong class="mb hv">}<br/><br/>                    </strong>// convert the data to something that resembles the MNIST training data set<br/>                    val inputData = toIntArray(monochrome)<br/><br/>                    // predict<br/>                    val pred = classifier.predict(inputData)<br/>                    runOnUiThread <strong class="mb hv">{ </strong>prediction.<em class="nc">text </em>= pred.toString() <strong class="mb hv">}<br/><br/>                }</strong>).start()<br/>            }<br/>        }<br/>    }<br/><br/>    override fun onDestroy() {<br/>        super.onDestroy()<br/>        classifier.close()<br/>    }<br/><br/>    <em class="nc">/**<br/>     * Converts a Bitmap to a 28 x 28 monochrome bitmap<br/>     */<br/>    </em>private fun toMonochrome(bitmap: Bitmap): Bitmap {<br/>        // scale bitmap to 28 by 28<br/>        val scaled = Bitmap.createScaledBitmap(bitmap, 28, 28, false)<br/><br/>        // convert bitmap to monochrome<br/>        val monochrome = Bitmap.createBitmap(28, 28, Bitmap.Config.ARGB_8888)<br/>        val canvas = Canvas(monochrome)<br/>        val ma = ColorMatrix()<br/>        ma.setSaturation(0f)<br/>        val paint = Paint()<br/>        paint.<em class="nc">colorFilter </em>= ColorMatrixColorFilter(ma)<br/>        canvas.drawBitmap(scaled, 0f, 0f, paint)<br/><br/>        val width = monochrome.<em class="nc">width<br/>        </em>val height = monochrome.<em class="nc">height<br/><br/>        </em>val pixels = IntArray(width * height)<br/>        monochrome.getPixels(pixels, 0, width, 0, 0, width, height)<br/><br/>        for (y in 0 <em class="nc">until </em>height) {<br/><br/>            for (x in 0 <em class="nc">until </em>width) {<br/>                val pixel = monochrome.getPixel(x, y)<br/>                val lowestBit = pixel and 0xff<br/><br/>                if (lowestBit &lt; 128) {<br/>                    monochrome.setPixel(x, y, Color.<em class="nc">BLACK</em>)<br/>                }<br/>                else {<br/>                    monochrome.setPixel(x, y, Color.<em class="nc">WHITE</em>)<br/>                }<br/>            }<br/>        }<br/>        return monochrome<br/>    }<br/><br/>    <em class="nc">/**<br/>     * Converts a bitmap to a flattened integer array<br/>     */<br/>    </em>private fun toIntArray(bitmap: Bitmap): IntArray {<br/>        val pixels = IntArray(bitmap.<em class="nc">width </em>* bitmap.<em class="nc">height</em>)<br/>        var i = 0<br/><br/>        for (y in 0 <em class="nc">until </em>bitmap.<em class="nc">height</em>) {<br/><br/>            for (x in 0 <em class="nc">until </em>bitmap.<em class="nc">width</em>) {<br/>                pixels[i++] = if (bitmap.getPixel(x, y) == Color.<em class="nc">BLACK</em>) 255 else 0<br/>            }<br/>        }<br/>        return pixels<br/>    }<br/>}</span></pre><p id="be21" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">就是这样！我们使用TensorFlow训练了一个神经网络来识别手写数字，然后通过一个Android应用程序成功部署了它。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff nd"><img src="../Images/1d508c5f15da209639aaaef3ee23ace8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/0*R_ggEZAW7byM7C-D.gif"/></div></figure><p id="3d73" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在第2部分中，我将使用TensorFlow Lite重新实现我们的分类器接口，而不是TensorFlow Mobile。TensorFlow Lite是一个更轻量级的框架，用于在移动设备上进行推理。它还可以在Android 8.1+设备上利用专门的神经网络加速硬件。</p><p id="3302" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">同时，所有代码、脚本和模型都可以在<a class="ae jp" href="https://github.com/emuneee/tensorandflow" rel="noopener ugc nofollow" target="_blank"> GitHub </a>上访问。</p></div><div class="ab cl ne nf hc ng" role="separator"><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj nk"/><span class="nh bw bk ni nj"/></div><div class="hn ho hp hq hr"><p id="0cb6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="nc">原载于2018年3月8日</em><a class="ae jp" href="https://emuneee.com/blog/2018/03/08/tensor_and_flow_pt_1/" rel="noopener ugc nofollow" target="_blank"><em class="nc">emuneee.com</em></a><em class="nc">。</em></p><figure class="jr js jt ju fq jv"><div class="bz el l di"><div class="nl nm l"/></div></figure></div></div>    
</body>
</html>