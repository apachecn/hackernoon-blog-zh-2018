<html>
<head>
<title>Gentle guide on how YOLO Object Localization works with Keras (Part 1)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">YOLO对象本地化如何与Keras协同工作的简明指南(第1部分)</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/gentle-guide-on-how-yolo-object-localization-works-with-keras-part-1-aec99277f56f?source=collection_archive---------4-----------------------#2018-03-11">https://medium.com/hackernoon/gentle-guide-on-how-yolo-object-localization-works-with-keras-part-1-aec99277f56f?source=collection_archive---------4-----------------------#2018-03-11</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div class="fe ff ir"><img src="../Images/8894b272efbfb83e7d189d64c8c6af06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1152/format:webp/0*fyvPte6hvxp3HgM5.png"/></div><figcaption class="iy iz fg fe ff ja jb bd b be z ek">A sliding window with magnifier</figcaption></figure><p id="dbce" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">TL: DR，我们将深入一点，了解YOLO物体定位算法是如何工作的。</p><p id="2bcc" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我见过一些令人印象深刻的对象本地化实时演示。其中一个是与<a class="ae ka" href="https://github.com/tensorflow/models/tree/master/research/object_detection" rel="noopener ugc nofollow" target="_blank"> TensorFlow对象检测API </a>，你可以定制它来检测你可爱的宠物——浣熊。</p><p id="524b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">玩了一会儿API之后，我开始想知道为什么对象本地化工作得这么好。</p><p id="f2cc" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">很少有网上资源以明确易懂的方式向我解释。所以我决定为那些对对象定位算法的工作原理感兴趣的人写一篇我自己的帖子。</p><p id="d01b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这篇文章可能包含一些高级主题，但我会尽可能友好地解释给初学者听。</p><h1 id="24ae" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">到对象定位</h1><h1 id="6178" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">什么是对象定位，它与对象分类相比如何？</h1><p id="96d8" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">你可能听说过ImageNet模型，它们在图像分类方面做得非常好。一个模型被训练来辨别在给定的图像中是否有特定的物体，例如汽车。</p><p id="dbff" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">对象定位模型类似于分类模型。但是经过训练的定位模型还通过在图像周围绘制边界框来预测对象在图像中的位置。例如，一辆<strong class="je hv">汽车</strong>位于下图中。边界框、中心点坐标、宽度和高度的信息也包括在模型输出中。</p><figure class="lf lg lh li fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff le"><img src="../Images/484c781868074c26a23836a04a591704.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Cfquj_ZfWh7VJS0s.png"/></div></div></figure><p id="5900" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">让我们看看我们有3种类型的目标要检测</p><ul class=""><li id="a135" class="ln lo hu je b jf jg jj jk jn lp jr lq jv lr jz ls lt lu lv dt translated">1-行人</li><li id="8a9f" class="ln lo hu je b jf lw jj lx jn ly jr lz jv ma jz ls lt lu lv dt translated">2-汽车</li><li id="6b60" class="ln lo hu je b jf lw jj lx jn ly jr lz jv ma jz ls lt lu lv dt translated">3 —摩托车</li></ul><p id="09b7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">对于分类模型，输出将是代表每个类别概率的3个数字的列表。上图中只有一辆<strong class="je hv">汽车</strong>在里面，输出可能看起来像<code class="eh mb mc md me b"> [0.001, 0.998, 0.001]</code>。第二类是汽车的概率最大。</p><p id="a26f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">本地化模型的输出将包括边界框的信息，因此输出将如下所示</p><figure class="lf lg lh li fq iv fe ff paragraph-image"><div class="fe ff mf"><img src="../Images/e421aad7c50ec69f909f536a5a769ba3.png" data-original-src="https://miro.medium.com/v2/resize:fit:322/format:webp/0*pMG8ZMAUthRe7jvu.jpg"/></div></figure><ul class=""><li id="2c54" class="ln lo hu je b jf jg jj jk jn lp jr lq jv lr jz ls lt lu lv dt translated">pc:为1表示检测到任何物体。如果为0，输出的其余部分将被忽略。</li><li id="6549" class="ln lo hu je b jf lw jj lx jn ly jr lz jv ma jz ls lt lu lv dt translated">bx: x坐标，对应图像左上角的对象中心</li><li id="6ee7" class="ln lo hu je b jf lw jj lx jn ly jr lz jv ma jz ls lt lu lv dt translated">by: y坐标，对应图像左上角的对象中心</li><li id="3aa4" class="ln lo hu je b jf lw jj lx jn ly jr lz jv ma jz ls lt lu lv dt translated">bh:边界框的高度</li><li id="7e43" class="ln lo hu je b jf lw jj lx jn ly jr lz jv ma jz ls lt lu lv dt translated">bw:边界框的宽度</li></ul><p id="3055" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">此时，您可能已经想到了一种简单的方法来进行对象定位，即在整个输入图像上应用一个滑动窗口。就像我们用放大镜一次看地图的一个区域，看看那个区域是否有我们感兴趣的东西。这种方法很容易实现，甚至不需要我们训练另一个本地化模型。因为我们可以只使用流行的图像分类器模型，并让它查看图像的每个选定区域，并输出每类目标的概率。</p><p id="9399" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">但是这种方法非常慢，因为我们必须预测很多区域，并且尝试很多盒子大小，以便得到更准确的结果。它是计算密集型的，因此很难实现像自动驾驶汽车这样的应用程序所需的良好的实时对象定位性能。</p><p id="b4c4" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这里有一个小技巧可以让它变得更快一点。</p><p id="6fe5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你熟悉卷积网络的工作原理，它可以通过为你拿着<strong class="je hv">虚拟放大镜</strong>来模拟<strong class="je hv">滑动窗口效应</strong>。因此，它在网络的一次前向传递中生成给定边界框大小的所有预测。这在计算上更有效。但是，基于我们如何选择步幅和尝试多少不同大小的边界框，边界框的位置不会非常精确。</p><figure class="lf lg lh li fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="lj lk di ll bf lm"><div class="fe ff mg"><img src="../Images/949d0fd711cb37cd27bc23491bb51241.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8w_ZuDOhhrKKZvSC.jpg"/></div></div></figure><p id="6ed1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><em class="mh">鸣谢:Coursera deeplearning.ai </em></p><p id="755b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在上图中，我们有形状为16 x 16像素和3个颜色通道(RGB)的输入图像。然后是左上角蓝色方块中显示的<strong class="je hv">回旋纵向滑动窗口</strong>，大小为14 x 14，步幅为2。意味着窗口一次垂直或水平滑动2个像素。输出中的左上角给出了左上角14 x 14的图像结果。如果在14×14区域中检测到4种目标对象中的任何一种。</p><p id="6970" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你不完全确定我刚才谈到的滑动窗口的卷积实现，没问题。因为我们稍后解释的YOLO算法将会处理它们。</p><h1 id="8687" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">为什么我们需要对象本地化？</h1><p id="17ab" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">一个明显的应用，自动驾驶汽车，实时检测和定位其他汽车，路标，自行车是至关重要的。</p><p id="7465" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">它还能做什么？</p><p id="68fe" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">一个安全摄像头来跟踪和预测一个可疑的人进入你的财产？</p><p id="d7f6" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">或者在水果包装和配送中心。我们可以建立一个基于图像的体积传感系统。它甚至可以使用边界框的大小来接近传送带上的橙子大小，并进行一些智能分类。</p><figure class="lf lg lh li fq iv fe ff paragraph-image"><div class="fe ff mi"><img src="../Images/c3fbd7a60fbb55670941eb1a794f3897.png" data-original-src="https://miro.medium.com/v2/resize:fit:1024/format:webp/0*_48IFe9iCrSya63S.png"/></div></figure><p id="62b4" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你能想到其他一些有用的物体定位的应用吗？请在下面分享你的酷想法！</p><p id="3093" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">系列文章的第二部分“<a class="ae ka" href="https://heartbeat.fritz.ai/gentle-guide-on-how-yolo-object-localization-works-with-keras-part-2-65fe59ac12d" rel="noopener ugc nofollow" target="_blank">YOLO对象定位如何与Keras协同工作的简明指南(第2部分)</a>”。</p></div><div class="ab cl mj mk hc ml" role="separator"><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo mp"/><span class="mm bw bk mn mo"/></div><div class="hn ho hp hq hr"><p id="68ba" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><em class="mh">最初发表于</em><a class="ae ka" href="https://www.dlology.com/blog/gentle-guide-on-how-yolo-object-localization-works-with-keras/" rel="noopener ugc nofollow" target="_blank">T5【www.dlology.com】</a><em class="mh">。更多深度学习体验！</em></p></div></div>    
</body>
</html>