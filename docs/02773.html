<html>
<head>
<title>Understanding YOLO</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">了解YOLO</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/understanding-yolo-f5a74bbc7967?source=collection_archive---------0-----------------------#2018-03-28">https://medium.com/hackernoon/understanding-yolo-f5a74bbc7967?source=collection_archive---------0-----------------------#2018-03-28</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/f8b20e08958a09084b219f0f084cbbc2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_3cQ2A72SizGfb8ucD2oig.jpeg"/></div></div></figure><p id="1d17" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">本文从想从头开始实现YOLO对象检测体系结构的人的角度解释了它。它不会描述网络的优点/缺点或每个设计选择的原因。相反，它关注于它如何工作。在你阅读这篇文章之前，你应该对神经网络，特别是CNN有一个基本的了解。</p><p id="a831" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这篇文章中的所有描述都与YOLO的原始论文相关:<a class="ae ka" href="https://arxiv.org/abs/1506.02640" rel="noopener ugc nofollow" target="_blank">你只看一次:约瑟夫·雷德蒙、桑托什·迪夫瓦拉、罗斯·吉尔希克和阿里·法尔哈迪(2015) </a>。从那以后，提出了许多改进，这些改进被合并到新的YOLOv2版本中，我可能会在另一个时间写这个版本。先理解这个原始版本，然后检查做了哪些修改以及为什么修改，会更容易一些。</p><h1 id="d254" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">什么是YOLO？</h1><p id="c38c" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">YOLO(你只看一次)，是一个对象检测网络。目标检测任务包括确定图像上某些目标存在的位置，以及对这些目标进行分类。以前的方法，如R-CNN及其变体，使用管道在多个步骤中执行这项任务。这可能运行缓慢，也很难优化，因为每个单独的组件必须单独训练。YOLO，这一切都是通过一个神经网络完成的。来自报纸:</p><blockquote class="le lf lg"><p id="3b32" class="jc jd lh je b jf jg jh ji jj jk jl jm li jo jp jq lj js jt ju lk jw jx jy jz hn dt translated">我们将对象检测重新定义为一个单一的回归问题，直接从图像像素到边界框坐标和类别概率。</p></blockquote><p id="03cf" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">因此，简单地说，你把一幅图像作为输入，让它通过一个看起来像普通CNN的神经网络，你在输出中得到一个包围盒和类预测的向量。</p><p id="fab6" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><em class="lh">那么，这些预测看起来像什么？</em></p><h1 id="ddc4" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">预测向量</h1><p id="30d2" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">理解YOLO的第一步是它如何对其输出进行编码。输入图像被分成一个<em class="lh">S×S</em>网格单元。对于图像上出现的每个物体，一个网格单元被称为“负责”预测它。这是对象中心所在的单元格。</p><p id="f396" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">每个网格单元预测<em class="lh"> B </em>边界框以及<em class="lh"> C </em>类概率。边界框预测有5个部分:<em class="lh"> (x，y，w，h，置信度)</em>。<em class="lh"> (x，y) </em>坐标代表盒子的中心，相对于网格单元的位置(记住，如果盒子的中心<em class="lh">没有</em>落在网格单元内，那么这个单元对它没有责任)。这些坐标被标准化为介于0和1之间。相对于图像尺寸，<em class="lh"> (w，h) </em>框的尺寸也被标准化为[0，1]。让我们看一个例子:</p><figure class="lm ln lo lp fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ll"><img src="../Images/fe6af134b8ab75d9974d728c880200a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oXSVP0HPVIaZqPpSinxsRQ.png"/></div></div><figcaption class="lq lr fg fe ff ls lt bd b be z ek">Example of how to calculate box coordinates in a 448x448 image with S=3. Note how the (x,y) coordinates are calculated relative to the center grid cell</figcaption></figure><p id="c7d8" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在包围盒预测中还有一个组件，即置信度得分。来自报纸:</p><blockquote class="le lf lg"><p id="5410" class="jc jd lh je b jf jg jh ji jj jk jl jm li jo jp jq lj js jt ju lk jw jx jy jz hn dt translated">形式上我们将信心定义为<em class="hu"> Pr(对象)* IOU(预测，真实)</em>。如果该单元格中不存在任何对象，置信度得分应该为零。否则，我们希望置信度得分等于预测框和实际情况之间的交集(IOU)。</p></blockquote><p id="5037" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">注意，置信度反映了<em class="lh">任何类别</em>的对象的存在或不存在。如果你不知道借据是什么，看看这里的<a class="ae ka" href="https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="1bed" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在我们已经理解了框预测的5个组成部分，记住每个网格单元都是这些预测的B，所以总共有<em class="lh"> S x S x B * 5 </em>个输出与边界框预测相关。</p><p id="1a67" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">还需要预测类概率，<em class="lh"> Pr(Class(i) | Object)。</em>这个概率是以包含一个对象的网格单元为条件的(如果你不知道条件概率的意思，参见<a class="ae ka" href="https://en.wikipedia.org/wiki/Conditional_probability" rel="noopener ugc nofollow" target="_blank">这个</a>)。实际上，这意味着如果网格单元上没有对象，损失函数不会因为错误的类预测而惩罚它，我们将在后面看到。该网络仅预测每个单元的一组类别概率，而不考虑盒子<em class="lh"> B </em>的数量。这使得总的分类概率</p><p id="0806" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">将类别预测添加到输出向量，我们得到一个<em class="lh"> S x S x (B * 5 +C) </em>张量作为输出。</p><figure class="lm ln lo lp fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lu"><img src="../Images/d58775e5b2fd3db9895ff626de019082.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_GR3J6_Zkq8c18ugBhQZew.png"/></div></div><figcaption class="lq lr fg fe ff ls lt bd b be z ek">Each grid cell makes B bounding box predictions and C class predictions (S=3, B=2 and C=3 in this example)</figcaption></figure><h1 id="a694" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">网络</h1><p id="2c90" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">一旦你理解了预测是如何编码的，剩下的就容易了。网络结构看起来像一个普通的CNN，有卷积层和最大池层，最后是两个完全连接的层:</p><pre class="lm ln lo lp fq lv lw lx ly aw lz dt"><span id="9fb1" class="ma kc hu lw b fv mb mc l md me">┌────────────┬────────────────────────┬───────────────────┐<br/>│    Name    │        Filters         │ Output Dimension  │<br/>├────────────┼────────────────────────┼───────────────────┤<br/>│ Conv 1     │ 7 x 7 x 64, stride=2   │ 224 x 224 x 64    │<br/>│ Max Pool 1 │ 2 x 2, stride=2        │ 112 x 112 x 64    │<br/>│ Conv 2     │ 3 x 3 x 192            │ 112 x 112 x 192   │<br/>│ Max Pool 2 │ 2 x 2, stride=2        │ 56 x 56 x 192     │<br/>│ Conv 3     │ 1 x 1 x 128            │ 56 x 56 x 128     │<br/>│ Conv 4     │ 3 x 3 x 256            │ 56 x 56 x 256     │<br/>│ Conv 5     │ 1 x 1 x 256            │ 56 x 56 x 256     │<br/>│ Conv 6     │ 1 x 1 x 512            │ 56 x 56 x 512     │<br/>│ Max Pool 3 │ 2 x 2, stride=2        │ 28 x 28 x 512     │<br/>│ Conv 7     │ 1 x 1 x 256            │ 28 x 28 x 256     │<br/>│ Conv 8     │ 3 x 3 x 512            │ 28 x 28 x 512     │<br/>│ Conv 9     │ 1 x 1 x 256            │ 28 x 28 x 256     │<br/>│ Conv 10    │ 3 x 3 x 512            │ 28 x 28 x 512     │<br/>│ Conv 11    │ 1 x 1 x 256            │ 28 x 28 x 256     │<br/>│ Conv 12    │ 3 x 3 x 512            │ 28 x 28 x 512     │<br/>│ Conv 13    │ 1 x 1 x 256            │ 28 x 28 x 256     │<br/>│ Conv 14    │ 3 x 3 x 512            │ 28 x 28 x 512     │<br/>│ Conv 15    │ 1 x 1 x 512            │ 28 x 28 x 512     │<br/>│ Conv 16    │ 3 x 3 x 1024           │ 28 x 28 x 1024    │<br/>│ Max Pool 4 │ 2 x 2, stride=2        │ 14 x 14 x 1024    │<br/>│ Conv 17    │ 1 x 1 x 512            │ 14 x 14 x 512     │<br/>│ Conv 18    │ 3 x 3 x 1024           │ 14 x 14 x 1024    │<br/>│ Conv 19    │ 1 x 1 x 512            │ 14 x 14 x 512     │<br/>│ Conv 20    │ 3 x 3 x 1024           │ 14 x 14 x 1024    │<br/>│ Conv 21    │ 3 x 3 x 1024           │ 14 x 14 x 1024    │<br/>│ Conv 22    │ 3 x 3 x 1024, stride=2 │ 7 x 7 x 1024      │<br/>│ Conv 23    │ 3 x 3 x 1024           │ 7 x 7 x 1024      │<br/>│ Conv 24    │ 3 x 3 x 1024           │ 7 x 7 x 1024      │<br/>│ FC 1       │ -                      │ 4096              │<br/>│ FC 2       │ -                      │ 7 x 7 x 30 (1470) │<br/>└────────────┴────────────────────────┴───────────────────┘</span></pre><p id="4750" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">关于架构的一些评论:</p><ul class=""><li id="2a44" class="mf mg hu je b jf jg jj jk jn mh jr mi jv mj jz mk ml mm mn dt translated">请注意，该架构是为Pascal VOC数据集设计的，作者使用S=7、B=2和C=20。这解释了为什么最终的要素地图是7x7，也解释了输出的大小(7x7x(2*5+20))。使用具有不同格网大小或不同类别数量的网络可能需要调整图层尺寸。</li><li id="bd13" class="mf mg hu je b jf mo jj mp jn mq jr mr jv ms jz mk ml mm mn dt translated">作者提到，有一个快速版本的YOLO，具有较少的卷积层。然而，上表显示的是完整版本。</li><li id="3cbf" class="mf mg hu je b jf mo jj mp jn mq jr mr jv ms jz mk ml mm mn dt translated">1x1缩减层和3x3卷积层的序列受到GoogLeNet (Inception)模型的启发</li><li id="bc79" class="mf mg hu je b jf mo jj mp jn mq jr mr jv ms jz mk ml mm mn dt translated">最后一层使用线性激活函数。所有其他层使用泄漏RELU(φ<em class="lh">(x)= x，如果x&gt;0；否则为0.1x</em></li><li id="84d8" class="mf mg hu je b jf mo jj mp jn mq jr mr jv ms jz mk ml mm mn dt translated">如果你不熟悉卷积网络，看看这个<a class="ae ka" href="http://cs231n.github.io/convolutional-networks/" rel="noopener ugc nofollow" target="_blank">伟大的介绍</a></li></ul><h1 id="c9a6" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">损失函数</h1><p id="2f37" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">损失函数有很多要说的，就分部分来做吧。它是这样开始的:</p><figure class="lm ln lo lp fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mt"><img src="../Images/2389e0d7c0ca059440451b1e2e3d92d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rDTomC-BsvHUqPUzAV8XKg.png"/></div></div><figcaption class="lq lr fg fe ff ls lt bd b be z ek">YOLO Loss Function — Part 1</figcaption></figure><p id="b7eb" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">该等式计算与预测边界框位置<strong class="je hv"> <em class="lh"> (x，y) </em> </strong>相关的损失。现在不要担心<strong class="je hv"> <em class="lh"> λ </em> </strong>，只要考虑它是一个给定的常数。该函数计算每个边界框预测值<strong class="je hv"> ( <em class="lh"> j = 0)的总和..每个网格单元的b</em>)</strong><strong class="je hv">(<em class="lh">I = 0..S^2 </em> ) </strong>。<strong class="je hv"> <em class="lh"> 𝟙 obj </em> </strong>定义如下:</p><ul class=""><li id="2922" class="mf mg hu je b jf jg jj jk jn mh jr mi jv mj jz mk ml mm mn dt translated">1，如果对象出现在网格单元<em class="lh"> i </em>中，并且第<em class="lh"> j </em>边界框预测器“负责”该预测</li><li id="f78c" class="mf mg hu je b jf mo jj mp jn mq jr mr jv ms jz mk ml mm mn dt translated">0，否则</li></ul><p id="83b4" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">但是我们如何知道哪个预测器对该对象负责呢？引用原文:</p><blockquote class="le lf lg"><p id="d1e1" class="jc jd lh je b jf jg jh ji jj jk jl jm li jo jp jq lj js jt ju lk jw jx jy jz hn dt translated"><em class="hu"> YOLO预测每个网格单元有多个边界框。在训练时，我们只希望一个边界框预测器负责每个对象。我们分配一个预测器来“负责”预测一个对象，基于哪个预测具有最高的当前IOU和地面真实值。</em></p></blockquote><p id="a191" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">等式中的其他项应该很容易理解:<strong class="je hv"> <em class="lh"> (x，y) </em> </strong>是预测的包围盒位置，<strong class="je hv"> <em class="lh"> (x̂，ŷ) </em> </strong>帽子<em class="lh"> </em>是来自训练数据的实际位置。</p><p id="fe13" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">让我们进入第二部分:</p><figure class="lm ln lo lp fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mt"><img src="../Images/98aad0bc2667e72ca2a9afa5a189be89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wY4F7t3gkf4f0Xjhgo23Pg.png"/></div></div><figcaption class="lq lr fg fe ff ls lt bd b be z ek">YOLO Loss Function — Part 2</figcaption></figure><p id="580e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这是与预测的盒子宽度/高度相关的损失。这个方程看起来和第一个相似，除了平方根。那是怎么回事？再次引用论文:</p><blockquote class="le lf lg"><p id="80f0" class="jc jd lh je b jf jg jh ji jj jk jl jm li jo jp jq lj js jt ju lk jw jx jy jz hn dt translated">我们的误差指标应该反映出大盒子中的小偏差不如小盒子中的小偏差重要。为了部分解决这个问题，我们预测边界框宽度和高度的平方根，而不是直接预测宽度和高度。</p></blockquote><p id="2b93" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">继续第三部分:</p><figure class="lm ln lo lp fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mt"><img src="../Images/ce8d4a735d0d01764316bb5c79216a27.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MxoBslVDuvxkX_gl0B2xHQ.png"/></div></div><figcaption class="lq lr fg fe ff ls lt bd b be z ek">YOLO Loss Function — Part 3</figcaption></figure><p id="fb28" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这里，我们计算与每个边界框预测器的置信度得分相关联的损失。<strong class="je hv"> <em class="lh"> C </em> </strong>是置信度得分，而<strong class="je hv"><em class="lh">ĉ</em></strong>是预测边界框与基础真值的交集。<strong class="je hv"> <em class="lh"> 𝟙 obj </em> </strong>当单元格中有对象时等于1，否则等于0。<strong class="je hv"> <em class="lh"> 𝟙 noobj </em> </strong>则相反。</p><p id="8dcb" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">此处和第一部分中出现的<strong class="je hv"> <em class="lh"> λ </em> </strong>参数用于对损失函数的不同部分进行加权。这是增加模型稳定性所必需的。最高的惩罚是对于坐标预测(<strong class="je hv"><em class="lh">λcoord</em></strong><em class="lh">= 5)</em>，最低的惩罚是对于没有物体存在时的置信度预测(<strong class="je hv"><em class="lh">λnoobj</em></strong><em class="lh">= 0.5)</em>。</p><p id="5650" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">损失函数的最后一部分是分类损失:</p><figure class="lm ln lo lp fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mt"><img src="../Images/9c27c9c62d2e8ae9fa5e13aff281a4d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*pT50zzLRyJm6CTuGmoYBxA.png"/></div></div><figcaption class="lq lr fg fe ff ls lt bd b be z ek">YOLO Loss Function — Part 4</figcaption></figure><p id="5f6d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">除了<strong class="je hv"> <em class="lh"> 𝟙 obj </em> </strong>项之外，它看起来类似于用于分类的正常平方和误差。使用这个术语是因为当单元上不存在对象时，我们不会惩罚分类错误(因此前面讨论了条件分类概率)。</p><h1 id="cd7f" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">培训</h1><p id="c80f" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">作者以如下方式描述了这种训练</p><ul class=""><li id="57c4" class="mf mg hu je b jf jg jj jk jn mh jr mi jv mj jz mk ml mm mn dt translated">首先，使用ImageNet 1000级竞争数据集，使用224x224的输入大小，预训练前20个卷积层</li><li id="f1de" class="mf mg hu je b jf mo jj mp jn mq jr mr jv ms jz mk ml mm mn dt translated">然后，将输入分辨率提高到448x448</li><li id="2a62" class="mf mg hu je b jf mo jj mp jn mq jr mr jv ms jz mk ml mm mn dt translated">使用64的批量大小、0.9的动量和0.0005的衰减来训练整个网络大约135个时期</li><li id="f6aa" class="mf mg hu je b jf mo jj mp jn mq jr mr jv ms jz mk ml mm mn dt translated">学习率时间表:对于第一个时期，学习率从0.001慢慢提高到0.01。训练大约75个周期，然后开始减少。</li><li id="6361" class="mf mg hu je b jf mo jj mp jn mq jr mr jv ms jz mk ml mm mn dt translated">使用带有随机缩放和转换的数据扩充，并随机调整曝光和饱和度。</li></ul><p id="c3ba" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">该过程在原始文件中有更详细的描述。打算自己重现，还没到那一步:)。</p><h1 id="5b16" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">结论</h1><p id="5e0e" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">我花了一些时间了解这篇论文的所有细节。如果你正在读这篇文章，我希望我分享了我的评论，让你的工作变得更容易。</p><p id="5f1d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我相信检验你是否真正理解了一个算法的最好的测试是从头开始尝试自己实现它。有许多细节在文本上并不明确，直到你把手弄脏并试图用它来建造一些东西时，你才会意识到。</p><p id="fe95" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">感谢您的阅读，如果您有任何意见，请留下您的评论。</p></div></div>    
</body>
</html>