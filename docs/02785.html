<html>
<head>
<title>Nodes and pods and containers oh my…(The fundamentals of K8’s logging)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">节点、豆荚和容器天啊…(K8伐木的基本原理)</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/nodes-and-pods-and-containers-oh-my-the-fundamentals-of-k8s-logging-6267b7fec50d?source=collection_archive---------12-----------------------#2018-03-28">https://medium.com/hackernoon/nodes-and-pods-and-containers-oh-my-the-fundamentals-of-k8s-logging-6267b7fec50d?source=collection_archive---------12-----------------------#2018-03-28</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/bb9c69725a95e64bf8437c94c2558995.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*KEbtVathGx1_XuslXs2RoQ.png"/></div></div></figure><blockquote class="jc jd je"><p id="5550" class="jf jg jh ji b jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz ka kb kc kd hn dt translated"><em class="hu">披露:</em> <a class="ae ke" href="https://goo.gl/Sm26zK" rel="noopener ugc nofollow" target="_blank"> Manifold </a>，独立开发者服务市场<em class="hu">，之前赞助过黑客正午。</em> <a class="ae ke" href="https://goo.gl/Sm26zK" rel="noopener ugc nofollow" target="_blank">使用code HACKERNOON2018获得任何服务10美元优惠。</a></p></blockquote><p id="8c69" class="pw-post-body-paragraph jf jg hu ji b jj jk jl jm jn jo jp jq kf js jt ju kg jw jx jy kh ka kb kc kd hn dt translated">毫不奇怪，Kubernetes在DevOps的土地上迅速成为明星。Kubernetes负责管理大量容器的复杂性，以及容器组(称为pod)和节点组(称为集群)所需的更改和配置。这样，您就可以专注于对您来说最重要的东西——关键应用程序的核心代码和数据。由于这些优势，Kubernetes已经成为当今的主流容器编排工具。</p><p id="6d48" class="pw-post-body-paragraph jf jg hu ji b jj jk jl jm jn jo jp jq kf js jt ju kg jw jx jy kh ka kb kc kd hn dt translated">Kubernetes使大规模管理容器变得容易，但它也可能伴随着陡峭的学习曲线。这就是管理Kubernetes服务的众多产品的原因，例如Platform9、Kismatic、OpenShift和CoreOS structural(现在是Redhat的一部分)。</p><p id="3b4a" class="pw-post-body-paragraph jf jg hu ji b jj jk jl jm jn jo jp jq kf js jt ju kg jw jx jy kh ka kb kc kd hn dt translated">无论您采取哪种方式来管理您的Kubernetes集群，一个基本要求是当事情发生逆转时有效的<strong class="ji hv">日志分析</strong>。传统的应用程序基础架构利用日志数据逐个服务器地排查性能问题、系统故障、错误和攻击。像Kubernetes这样的现代基础设施成倍地增加了虚拟系统(容器)的数量，在这些虚拟系统中，需要对日志进行聚合和标记，以便进行有效的分析。</p><h1 id="a489" class="ki kj hu bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">放弃</h1><p id="a8fe" class="pw-post-body-paragraph jf jg hu ji b jj lg jl jm jn lh jp jq kf li jt ju kg lj jx jy kh lk kb kc kd hn dt translated">本文总结了在构建我们的Kubernetes对<a class="ae ke" href="https://www.logdna.com/?utm_source=manifold&amp;utm_medium=hackernoon-medium" rel="noopener ugc nofollow" target="_blank"> LogDNA </a>的支持时的见解和想法。为我们的客户创造良好的体验很重要，但当我们将大部分自己的服务转移到Kubernetes上时，我们也自私地需要这种体验。我们专注于构建一个漂亮的日志记录平台，它可以神奇地处理您所有系统的日志收集、解析、索引、标记、搜索、分析、警报和存储。</p><h1 id="3044" class="ki kj hu bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">Kubernetes中日志数据的重要性</h1><p id="cb59" class="pw-post-body-paragraph jf jg hu ji b jj lg jl jm jn lh jp jq kf li jt ju kg lj jx jy kh lk kb kc kd hn dt translated">日志数据对Kubernetes管理至关重要。Kubernetes是一个非常动态的平台，每时每刻都在发生大量的变化。随着容器的启动和停止，IP地址和负载会发生变化——Kubernetes会进行更改，以确保服务得到正确扩展且性能不受影响。不可避免地，当出现故障或性能下降时，您需要只有日志数据才能提供的详细信息。在Kubernetes的世界中，容器不断地被部署/终止，在您进行调查时，为您所寻找的内容生成日志的容器很可能已经被终止了。追溯的唯一方法是确保日志是可用的，这样您就可以追溯您的步骤来描述发生了什么。除了性能和故障排除之外，需要法规遵从性的行业还需要日志数据，以确保您满足HIPAA或PCI DSS等要求。在数据泄露的恶劣情况下，您需要及时追溯以确定攻击的来源及其在整个系统中的发展。对于所有这些用例，日志数据是必不可少的。</p><p id="9778" class="pw-post-body-paragraph jf jg hu ji b jj jk jl jm jn jo jp jq kf js jt ju kg jw jx jy kh ka kb kc kd hn dt translated">有许多方法可以访问和分析Kubernetes日志数据，从简单到高级。让我们从最简单的选项开始，沿着链条向上移动。</p><h1 id="7a38" class="ki kj hu bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">在Pod内记录</h1><p id="985b" class="pw-post-body-paragraph jf jg hu ji b jj lg jl jm jn lh jp jq kf li jt ju kg lj jx jy kh lk kb kc kd hn dt translated">容器是Kubernetes中最底层的元素，但是Pod级日志记录是查看Kubernetes日志的最基本形式。Kubectl命令用于单独获取每个pod的日志数据。这些日志存储在pod中，当pod死亡时，日志也随之死亡。当你只有几个豆荚时，它们是有用和有效的。您可以立即检查pods的健康状况，而不需要为大型集群设置健壮的日志记录。</p><h1 id="3776" class="ki kj hu bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">节点内的日志记录</h1><p id="6986" class="pw-post-body-paragraph jf jg hu ji b jj lg jl jm jn lh jp jq kf li jt ju kg lj jx jy kh lk kb kc kd hn dt translated">为每个节点收集的日志存储在一个JSON文件中。这个文件可能会变得非常大，为了处理这种情况，您可以每天使用logrotate函数将日志数据拆分为多个文件，或者在数据达到特定的大小配额时使用。节点级日志比pod级日志更持久。即使pod重新启动，它以前的日志也会保留在节点中。但是，如果一个pod被逐出一个节点，它的日志数据就会被删除。</p><p id="faa1" class="pw-post-body-paragraph jf jg hu ji b jj jk jl jm jn jo jp jq kf js jt ju kg jw jx jy kh ka kb kc kd hn dt translated">虽然pod级和节点级日志记录是Kubernetes中的重要概念，但它们并不意味着是真正的日志记录解决方案。相反，它们是真正的解决方案——集群级日志记录——的构建块。</p><h1 id="9782" class="ki kj hu bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">记录整个集群</h1><p id="ec54" class="pw-post-body-paragraph jf jg hu ji b jj lg jl jm jn lh jp jq kf li jt ju kg lj jx jy kh lk kb kc kd hn dt translated">Kubernetes没有为整个集群提供默认的日志记录机制，而是让用户和第三方工具来解决这个问题。一种方法是构建节点级日志记录。这样，您可以分配一个代理来记录每个节点并组合它们的输出。</p><p id="b314" class="pw-post-body-paragraph jf jg hu ji b jj jk jl jm jn jo jp jq kf js jt ju kg jw jx jy kh ka kb kc kd hn dt translated">默认选项是<a class="ae ke" href="https://kubernetes.io/docs/tasks/debug-application-cluster/logging-stackdriver/" rel="noopener ugc nofollow" target="_blank"> Stackdriver </a>，它使用一个<a class="ae ke" href="https://github.com/fluent/fluentd" rel="noopener ugc nofollow" target="_blank"> Fluentd </a>代理，并将日志输出写入本地文件。但是，您也可以将其设置为将相同的数据发送到Google Cloud。从这里你可以使用<a class="ae ke" href="https://cloud.google.com/logging/docs/reference/tools/gcloud-logging" rel="noopener ugc nofollow" target="_blank">谷歌云的CLI </a>来查询日志数据。然而，这并不是分析日志数据最有效的方法，如果你还没有使用GCP，这可能会很麻烦。这让我们开始讨论目前存在的潜在解决方案。</p><h1 id="377e" class="ki kj hu bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">DIY Kubernetes测井与弹性搜索</h1><p id="26b8" class="pw-post-body-paragraph jf jg hu ji b jj lg jl jm jn lh jp jq kf li jt ju kg lj jx jy kh lk kb kc kd hn dt translated">实现集群级日志记录的一种更流行的方法是使用Fluentd代理从节点收集日志，并将它们传递到外部的Elasticsearch集群。使用Elasticsearch存储和处理日志数据，并可以使用Kibana等工具进行可视化。ELK stack (Elasticsearch，Logstash，Kibana)或我们这里指的EFK (Elasticsearch，Fluentd，Kibana)是当今最流行的开源日志解决方案，其组件通常构成许多其他现代搜索解决方案的基础。ELK堆栈提供了强大的日志功能，并且比Stackdriver / Google Cloud选项具有更大的可扩展性。虽然最初构建ELK堆栈并不困难，但为每个输入源配置Logstash或Fluentd可能会很困难，而且为您即将获得的日志数据量扩展您自己的ELK堆栈可能会比您想象的需要更多的时间和精力。</p><h1 id="90a6" class="ki kj hu bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">使用边车容器收集日志</h1><p id="ec7b" class="pw-post-body-paragraph jf jg hu ji b jj lg jl jm jn lh jp jq kf li jt ju kg lj jx jy kh lk kb kc kd hn dt translated">收集日志的另一种流行方法是在每个pod内部署收集器作为sidecar容器，以在pod级别上提取日志。每个边车容器都包含一个代理，用于收集原木并将其运输到目的地。大多数sidecar容器实现都是轻量级的，但是对于节点/集群中的每个pod都需要额外的资源。对于大规模应用程序，这意味着您需要配置每一个podspec，这可能很麻烦，并且在大规模上不是一个好的实践。</p><h1 id="c793" class="ki kj hu bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">使用DaemonSet收集日志</h1><p id="4c6d" class="pw-post-body-paragraph jf jg hu ji b jj lg jl jm jn lh jp jq kf li jt ju kg lj jx jy kh lk kb kc kd hn dt translated">我们发现的最有效的日志收集方法是简单地将收集器部署为<a class="ae ke" href="https://kubernetes.io/docs/concepts/workloads/controllers/daemonset/" rel="noopener ugc nofollow" target="_blank"> DaemonSet </a>。这在节点级而不是单元级部署了资源，并且保持了边车实现的相同能力，而不需要为每个单元部署额外的过程/容器。作为DaemonSet部署还允许您使用最少的kubectl命令集在整个集群中自动进行部署。设置好了就算了！</p><h1 id="989f" class="ki kj hu bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">丰富的上下文日志元数据</h1><figure class="lm ln lo lp fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ll"><img src="../Images/f9fd6a747247e9b4c46a03a190fee99d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BqQeD_KoGkGxjRBUHxOeoA.png"/></div></div><figcaption class="lq lr fg fe ff ls lt bd b be z ek">Screenshot of Kubernetes logs metadata captured in dropdown (Nginx running Kubernetes).</figcaption></figure><p id="e705" class="pw-post-body-paragraph jf jg hu ji b jj jk jl jm jn jo jp jq kf js jt ju kg jw jx jy kh ka kb kc kd hn dt translated">虽然将日志收集到一个可搜索的集中式数据存储中可能是最重要的功能概念，但是如果您找不到您要找的东西，日志是没有用的。Kubernetes中日志记录最漂亮的一面是单一编排系统带来的框架和组织。Kubernetes存储日志的方式为日志解决方案提供了丰富的上下文信息，可以用丰富的元数据自动标记每个日志。诸如哪个节点、pod、容器甚至标签之类的信息可以附加到日志，以便在需要时更容易地进行日志分析和聚合。一个合适的日志记录解决方案应该利用并允许有趣的用例直接标记特定容器的提交散列，并根据该标记过滤和搜索日志。</p><h1 id="f27e" class="ki kj hu bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">TLDR；&amp;摘要</h1><p id="468b" class="pw-post-body-paragraph jf jg hu ji b jj lg jl jm jn lh jp jq kf li jt ju kg lj jx jy kh lk kb kc kd hn dt translated">Kubernetes是当今领先的容器编排平台。然而，运行Kubernetes的生产集群需要对系统和健壮的工具非常熟悉。当涉及到应用程序日志和日志分析时，Kubernetes提出了一种新的复杂程度，Kubernetes为pod、节点和集群提供了基本的日志收集，但对于生产集群，您需要在集群级别进行统一的日志记录。与在更传统的部署中跟踪应用程序和服务器相比，构建和设计一个能够利用Kubernetes优势的解决方案最终会更加优雅和可伸缩。</p><p id="9b00" class="pw-post-body-paragraph jf jg hu ji b jj jk jl jm jn jo jp jq kf js jt ju kg jw jx jy kh ka kb kc kd hn dt translated">构建自己的ELK或EFK堆栈是访问和管理Kubernetes日志的一种常见方式，但由于需要设置和维护大量工具，这可能会非常复杂。理想情况下，您希望您的日志工具不碍事，让您专注于日志数据和Kubernetes集群。</p><p id="f83f" class="pw-post-body-paragraph jf jg hu ji b jj jk jl jm jn jo jp jq kf js jt ju kg jw jx jy kh ka kb kc kd hn dt translated">一个深度定制的Kubernetes日志记录解决方案应该能够自动识别Kubernetes集群的所有元数据，包括pod、节点、容器和名称空间。它允许您实时分析Kubernetes集群，并提供强大的自然语言搜索、过滤器、解析、快捷方式和警报。</p><p id="ae77" class="pw-post-body-paragraph jf jg hu ji b jj jk jl jm jn jo jp jq kf js jt ju kg jw jx jy kh ka kb kc kd hn dt translated">点击此处了解更多关于Kubernetes的LogDNA信息。</p><figure class="lm ln lo lp fq iv"><div class="bz el l di"><div class="lu lv l"/></div></figure></div></div>    
</body>
</html>