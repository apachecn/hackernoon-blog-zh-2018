<html>
<head>
<title>Semantic Segmentation Datasets for Autonomous Driving</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">用于自动驾驶的语义分割数据集</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/semantic-segmentation-datasets-for-autonomous-driving-1182ebd2aff0?source=collection_archive---------5-----------------------#2018-03-29">https://medium.com/hackernoon/semantic-segmentation-datasets-for-autonomous-driving-1182ebd2aff0?source=collection_archive---------5-----------------------#2018-03-29</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="2fc8" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">对城市语义分割的开放数据集的理解将有助于人们理解在训练自动驾驶汽车模型时如何进行。</h2></div><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff jj"><img src="../Images/2afd3e85759328fa828f7e3b07485530.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*o_WTJv8mpxfxV-tF."/></div></figure><blockquote class="jr js jt"><p id="20f0" class="ju jv jw jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">最初发布于<a class="ae kr" href="https://blog.playment.io/self-driving-car-datasets-semantic-segmentation/" rel="noopener ugc nofollow" target="_blank"> Playment.io </a></p></blockquote><p id="803a" class="pw-post-body-paragraph ju jv hu jx b jy jz iv ka kb kc iy kd ks kf kg kh kt kj kk kl ku kn ko kp kq hn dt translated">在过去的10年里，人们在语义分割任务的算法改进和数据集创建方面做了无数的努力。最近，在这个领域(视觉场景理解的子集)有了快速的进展，这主要归功于深度学习方法的贡献。但是深度<a class="ae kr" href="https://hackernoon.com/tagged/learning" rel="noopener ugc nofollow" target="_blank">学习</a>技术有一个消耗大量注释数据的致命弱点。在这里，我们回顾了一些广泛使用和开放的自动驾驶汽车应用的城市语义细分数据集。</p><h1 id="ce55" class="kv kw hu bd kx ky kz la lb lc ld le lf ja lg jb lh jd li je lj jg lk jh ll lm dt translated">什么是语义切分？</h1><p id="d01c" class="pw-post-body-paragraph ju jv hu jx b jy ln iv ka kb lo iy kd ks lp kg kh kt lq kk kl ku lr ko kp kq hn dt translated">语义分割的任务是用对象类来注释图像的每个像素。这些类别可以是自动驾驶环境中的“行人、车辆、建筑物、植被、天空、空间等”。例如，语义分割有助于SDC(自动驾驶汽车)发现图像上的可驾驶区域。</p><h1 id="8608" class="kv kw hu bd kx ky kz la lb lc ld le lf ja lg jb lh jd li je lj jg lk jh ll lm dt translated">数据集</h1><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="ls lt l"/></div></figure><h2 id="3c48" class="lu kw hu bd kx lv lw lx lb ly lz ma lf ks mb mc lh kt md me lj ku mf mg ll mh dt translated">坎维德</h2><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff jj"><img src="../Images/064bbf1c9235a01087f23547b616cb3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Xd1_qx1WUbd__u2T."/></div><figcaption class="mi mj fg fe ff mk ml bd b be z ek">CamVid(960px x 720px)</figcaption></figure><ul class=""><li id="17d4" class="mm mn hu jx b jy jz kb kc ks mo kt mp ku mq kq mr ms mt mu dt translated">剑桥驾驶标记视频数据库是2007年底在自驾车领域发布的首批语义分段数据集之一。他们使用自己的<a class="ae kr" href="http://mi.eng.cam.ac.uk/projects/cvgroup/software/index.html" rel="noopener ugc nofollow" target="_blank">图像注释软件</a>从10分钟的视频序列中注释了700幅图像。摄像机安装在汽车的仪表板上，视野与驾驶员的视野相似。</li></ul></div><div class="ab cl mv mw hc mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="hn ho hp hq hr"><h2 id="8569" class="lu kw hu bd kx lv lw lx lb ly lz ma lf ks mb mc lh kt md me lj ku mf mg ll mh dt translated">凯蒂</h2><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff jj"><img src="../Images/8cf4eaa0a143e32d1e13b249c0e8c11d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*TLnRWjmfHWZQ6FmE."/></div><figcaption class="mi mj fg fe ff mk ml bd b be z ek">KITTI Dataset(1242px x 375px)</figcaption></figure><ul class=""><li id="2374" class="mm mn hu jx b jy jz kb kc ks mo kt mp ku mq kq mr ms mt mu dt translated">KITTI(卡尔斯鲁厄技术研究院<a class="ae kr" href="https://hackernoon.com/tagged/technolopgy" rel="noopener ugc nofollow" target="_blank">和丰田技术研究院</a>)数据集于2012年发布，但没有语义分割的图像。其他独立的小组已经为他们自己的用例标注了框架。虽然，确实存在用于<a class="ae kr" href="http://www.cvlibs.net/datasets/kitti/eval_road.php" rel="noopener ugc nofollow" target="_blank">道路和车道检测</a>的数据集和基准套件。在这个较小的数据集中，各种传感器，包括灰度和彩色摄像机、激光扫描仪和GPS/IMU单元，都安装在汽车顶部。</li></ul></div><div class="ab cl mv mw hc mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="hn ho hp hq hr"><p id="d67e" class="pw-post-body-paragraph ju jv hu jx b jy jz iv ka kb kc iy kd ks kf kg kh kt kj kk kl ku kn ko kp kq hn dt translated"><strong class="jx hv"> DUS </strong></p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="nd ne di nf bf ng"><div class="fe ff nc"><img src="../Images/7adecf5868de3875dda1e78488cba35b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*UVHBuKb3hmAmIjWztvfZzA.jpeg"/></div></div><figcaption class="mi mj fg fe ff mk ml bd b be z ek">DUS Dataset(1024*440px)</figcaption></figure><ul class=""><li id="3726" class="mm mn hu jx b jy jz kb kc ks mo kt mp ku mq kq mr ms mt mu dt translated">戴姆勒城市分割数据集是由5000幅灰度图像组成的数据集，其中只有500幅图像进行了语义分割。与大多数数据集不同，它不包含“nature”类。这个数据集是由汽车制造商戴姆勒的研究人员发起的名为<a class="ae kr" href="http://www.6d-vision.com/home" rel="noopener ugc nofollow" target="_blank"> 6D视觉</a>的更大研究计划的一部分。</li><li id="d5d5" class="mm mn hu jx b jy nh kb ni ks nj kt nk ku nl kq mr ms mt mu dt translated">由于它的尺寸很小，这将作为一个很好的试验台来观察语义分割模型的推广情况。</li></ul></div><div class="ab cl mv mw hc mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="hn ho hp hq hr"><h2 id="dd18" class="lu kw hu bd kx lv lw lx lb ly lz ma lf ks mb mc lh kt md me lj ku mf mg ll mh dt translated"><strong class="ak">城市景观</strong></h2><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff jj"><img src="../Images/254c7e88c612339bdeb9b2e65abd3b35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*UxWo02t-91KSnQJK."/></div><figcaption class="mi mj fg fe ff mk ml bd b be z ek">Cityscapes Dataset(2048*1024px)</figcaption></figure><ul class=""><li id="0c68" class="mm mn hu jx b jy jz kb kc ks mo kt mp ku mq kq mr ms mt mu dt translated">这是“戴姆勒城市分割”数据集的延续，其中地理和气候的范围已经扩展到捕捉各种城市场景。该数据集还包含粗糙图像，以支持利用大量弱标记数据的方法。与DUS类似，摄像头安装在挡风玻璃后面。</li><li id="af64" class="mm mn hu jx b jy nh kb ni ks nj kt nk ku nl kq mr ms mt mu dt translated">这30个类别还分为8个更高级别的类别。该数据集的一个独特之处在于，作者提供了20000多幅带有粗略分割的图像。许多深度学习技术已经使用这个额外的数据集来提高他们的IoU分数</li><li id="9fc5" class="mm mn hu jx b jy nh kb ni ks nj kt nk ku nl kq mr ms mt mu dt translated">最近的模型目前有超过80%的IoU(交集/并集)。此链接包含对他们的评分方法以及基准测试套件的解释</li></ul></div><div class="ab cl mv mw hc mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="hn ho hp hq hr"><h2 id="39ab" class="lu kw hu bd kx lv lw lx lb ly lz ma lf ks mb mc lh kt md me lj ku mf mg ll mh dt translated">枫叶</h2><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff jj"><img src="../Images/37edb8b7f7a0190c255b51df25e5b814.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*SfyW9nJXB1Omx8_s."/></div><figcaption class="mi mj fg fe ff mk ml bd b be z ek">Mapillary Vistas Dataset (4000+px x 3000+px)</figcaption></figure><ul class=""><li id="9bac" class="mm mn hu jx b jy jz kb kc ks mo kt mp ku mq kq mr ms mt mu dt translated">mapi pile是一个街道级的影像平台，参与者可以在此合作构建更好的地图。他们提供了一部分图像数据集，并以像素级的精度对其进行了标注。在撰写这篇博文时，它是世界上最大和最多样化的开放数据集，地理范围跨越各大洲。</li><li id="f964" class="mm mn hu jx b jy nh kb ni ks nj kt nk ku nl kq mr ms mt mu dt translated">该数据集还包括66个类别中37个类别的实例级城市语义分割。由于mapi piles平台上的图像是协作收集的，它们来自各种视角，正如通过<a class="ae kr" href="https://www.mapillary.com/dataset/vistas" rel="noopener ugc nofollow" target="_blank">这个探索者</a>所看到的</li><li id="ac4d" class="mm mn hu jx b jy nh kb ni ks nj kt nk ku nl kq mr ms mt mu dt translated">人们可以通过<a class="ae kr" href="https://eval-vistas.mapillary.com/" rel="noopener ugc nofollow" target="_blank">在这里</a>提交他们数据集上的算法。</li></ul></div><div class="ab cl mv mw hc mx" role="separator"><span class="my bw bk mz na nb"/><span class="my bw bk mz na nb"/><span class="my bw bk mz na"/></div><div class="hn ho hp hq hr"><h1 id="c183" class="kv kw hu bd kx ky nm la lb lc nn le lf ja no jb lh jd np je lj jg nq jh ll lm dt translated">最后的想法</h1><p id="f3ae" class="pw-post-body-paragraph ju jv hu jx b jy ln iv ka kb lo iy kd ks lp kg kh kt lq kk kl ku lr ko kp kq hn dt translated">随着研究人员寻求创建更新的基准，开放数据集的世界正在不断增长。随着每个新数据集的内容不断增加，可以根据模型对我们周围的自然世界的概括程度来评估模型。而且，如果你认为这是开放数据集发展的终结，那就去看看SYNTHIA，一个来自虚拟城市场景的图片库！</p><p id="899b" class="pw-post-body-paragraph ju jv hu jx b jy jz iv ka kb kc iy kd ks kf kg kh kt kj kk kl ku kn ko kp kq hn dt translated">敬请关注更多关于城市语义细分的深度学习模型。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="nr lt l"/></div></figure></div></div>    
</body>
</html>