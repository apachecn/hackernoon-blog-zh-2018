<html>
<head>
<title>How To Power Your App Using a Realtime Data CDN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何使用实时数据CDN为您的应用提供支持</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/powering-your-app-with-a-realtime-messaging-cdn-13d92a6df5f3?source=collection_archive---------8-----------------------#2018-04-25">https://medium.com/hackernoon/powering-your-app-with-a-realtime-messaging-cdn-13d92a6df5f3?source=collection_archive---------8-----------------------#2018-04-25</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="46dc" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">结合Fastly(大规模拉取)和Fanout(大规模推送)在边缘支持实时消息传递</h2></div><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff jj"><img src="../Images/fe11b92196e86dc6caf5de7b99090324.png" data-original-src="https://miro.medium.com/v2/resize:fit:1100/0*P-Qpk_dV1vLSutGq.gif"/></div><figcaption class="jr js fg fe ff jt ju bd b be z ek"><a class="ae jv" href="https://www.varnish-software.com/solutions/cdn/" rel="noopener ugc nofollow" target="_blank">Varnish Software</a> CDN</figcaption></figure><h1 id="1811" class="jw jx hu bd jy jz ka kb kc kd ke kf kg ja kh jb ki jd kj je kk jg kl jh km kn dt translated">CDN —内容交付网络</h1><p id="5b30" class="pw-post-body-paragraph ko kp hu kq b kr ks iv kt ku kv iy kw kx ky kz la lb lc ld le lf lg lh li lj hn dt translated">让我们从定义CDN开始。<em class="lk">内容交付网络</em> (CDN)是一个分布式服务器系统，传统上根据用户的地理位置、网页的来源和内容交付服务器向用户交付web内容。我传统上使用术语<em class="lk">是因为我们正在进入一个时代，cdn不仅仅提供网络内容。</em></p><p id="396c" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">一个例子是Cloudflare <a class="ae jv" href="https://www.cloudflare.com/products/cloudflare-workers/" rel="noopener ugc nofollow" target="_blank"> Workers </a>，它让你使用他们的CDN在边缘运行代码，而不仅仅是提供网页/缓存内容。基本上，您可以在远离原始服务器的地方部署和运行JavaScript允许您将代码与用户的设备分离。根据Cloudflare的说法，“这些工作人员还支持路由、过滤和响应HTTP请求的编程功能，否则这些功能将需要在客户的原始服务器上运行。”</p><p id="242e" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">要点是cdn和边缘计算正在不断发展，在这个高可扩展性至关重要的时代，这两者开始融合在一起。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="lr ls di lt bf lu"><div class="fe ff lq"><img src="../Images/4ce0df72d92c4cbf024e48ac351950f8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*4un0B07SyM3D36uL.jpg"/></div></div></figure><h1 id="c8d3" class="jw jx hu bd jy jz ka kb kc kd ke kf kg ja kh jb ki jd kj je kk jg kl jh km kn dt translated">融合实时数据推送和实时数据拉取</h1><p id="7758" class="pw-post-body-paragraph ko kp hu kq b kr ks iv kt ku kv iy kw kx ky kz la lb lc ld le lf lg lh li lj hn dt translated">许多实时应用程序需要处理推送和拉取的数据(例如实时体育比分、拍卖、聊天)。分开来看，数据推送和数据拉取作为独立的实体相当简单。在初始化时，可以从拉CDN中检索过去的内容，并且可以从单独的服务中推送新的/未来的更新。</p><p id="bb12" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">但是，如果你能把这些机制连在一起会怎么样呢？</p><h1 id="35d3" class="jw jx hu bd jy jz ka kb kc kd ke kf kg ja kh jb ki jd kj je kk jg kl jh km kn dt translated">具有快速扇出的代理链接</h1><p id="5c2a" class="pw-post-body-paragraph ko kp hu kq b kr ks iv kt ku kv iy kw kx ky kz la lb lc ld le lf lg lh li lj hn dt translated"><a class="ae jv" href="https://www.fastly.com/edge-cloud-platform" rel="noopener ugc nofollow" target="_blank"> Fastly </a>是一个边缘云平台，支持应用在网络边缘处理、服务和保护数据。它本质上是高度可扩展的数据拉取和响应，使用一个可以实时监听和响应用户需求的平台。与传统的CDN类似，Fastly允许您缓存内容，但也允许您在边缘交付应用程序逻辑。</p><p id="4c65" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">另一方面，<a class="ae jv" href="http://fanout.io" rel="noopener ugc nofollow" target="_blank"> Fanout </a>是高可伸缩的数据推送——充当反向代理，处理长期客户端连接，并在数据可用时推送数据。</p><p id="4612" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">Fastly和Fanout都作为反向代理工作，因此有可能让Fanout代理流量通过Fastly，而不是将流量直接发送到您的原始服务器。总之，这个耦合系统有一些有趣的好处:</p><ol class=""><li id="8f18" class="lv lw hu kq b kr ll ku lm kx lx lb ly lf lz lj ma mb mc md dt translated"><strong class="kq hv">高可用性</strong> —如果您的原始服务器出现故障，Fastly可以向扇出提供缓存的数据和指令。这意味着客户端可以连接到您的API端点，接收历史数据，并激活一个流连接，所有这些都不需要访问源服务器。</li><li id="5822" class="lv lw hu kq b kr me ku mf kx mg lb mh lf mi lj ma mb mc md dt translated"><strong class="kq hv">缓存的初始数据</strong> — Fanout允许您构建服务于历史和未来内容的API端点，例如，在切换到推送模式之前返回一些初始数据的HTTP流连接。Fastly可以提供初始数据，减少原始服务器的负载。</li><li id="806b" class="lv lw hu kq b kr me ku mf kx mg lb mh lf mi lj ma mb mc md dt translated"><strong class="kq hv">缓存扇出指令</strong> —扇出的行为(如传输模式、订阅的频道等。)是由源服务器响应中提供的指令确定的(使用称为Grip的特殊头系统)。Fastly随后可以缓存这些指令和头。</li><li id="33fa" class="lv lw hu kq b kr me ku mf kx mg lb mh lf mi lj ma mb mc md dt translated"><strong class="kq hv">高可扩展性</strong> —通过缓存扇出指令和头，Fastly可以进一步降低原始服务器的负载，使处理逻辑更接近边缘。</li></ol><h1 id="55a2" class="jw jx hu bd jy jz ka kb kc kd ke kf kg ja kh jb ki jd kj je kk jg kl jh km kn dt translated">映射网络流</h1><p id="d31d" class="pw-post-body-paragraph ko kp hu kq b kr ks iv kt ku kv iy kw kx ky kz la lb lc ld le lf lg lh li lj hn dt translated">使用Fanout和Fastly，我们来绘制网络流，看看这些推和拉机制是如何协同工作的。</p><p id="e218" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">让我们假设有一个API端点<code class="eh mj mk ml mm b">/stream</code>返回一些初始数据，然后保持打开，直到有新的更新要推送。使用扇出，这可以通过让源服务器响应指令来实现:</p><pre class="jk jl jm jn fq mn mm mo mp aw mq dt"><span id="b6af" class="mr jx hu mm b fv ms mt l mu mv"><strong class="mm hv">HTTP/</strong>1.1 200 <strong class="mm hv">OK</strong><br/>Content-Type: text/plain<br/>Content-Length: 29<br/>Grip-Hold: stream<br/>Grip-Channel: updates<br/><br/>{"data": "current value"}</span></pre><p id="5901" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">当Fanout从源服务器接收到这个响应时，它会将其转换成一个流响应发送给客户端:</p><pre class="jk jl jm jn fq mn mm mo mp aw mq dt"><span id="1edc" class="mr jx hu mm b fv ms mt l mu mv"><strong class="mm hv">HTTP/</strong>1.1 200 <strong class="mm hv">OK</strong><br/>Content-Type: text/plain<br/>Transfer-Encoding: chunked<br/>Connection: Transfer-Encoding<br/><br/>{"data": "current value"}</span></pre><p id="c829" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">Fanout和源服务器之间的请求现在已经完成，但是客户机和Fanout之间的请求仍然打开。这是流程的序列图:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mw"><img src="../Images/c8dad0c89c67ec46785f280535eaa50d.png" data-original-src="https://miro.medium.com/v2/resize:fit:874/format:webp/0*MhJ6EY248bRBKM4F.png"/></div></figure><p id="ed93" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">由于对源服务器的请求只是一个普通的短暂的请求/响应交互，它也可以通过一个缓存服务器(比如Fastly)来提供服务。</p><p id="e284" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">下面是Fastly参与的流程:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mx"><img src="../Images/0b1dcc95c568cad7f9d16aaaf0ae8973.png" data-original-src="https://miro.medium.com/v2/resize:fit:1130/format:webp/0*EdXVgIdr0hd_ELWM.png"/></div></figure><p id="324d" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">现在，当下一个客户机向<code class="eh mj mk ml mm b">/stream</code>端点发出请求时，源服务器完全不参与:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff my"><img src="../Images/f4b68bf1f44abbd01eb961999e3ca082.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/format:webp/0*adtgb2HTH08eQBuG.png"/></div></figure><p id="5028" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">换句话说，Fastly用那些特殊的HTTP头和初始数据向Fanout提供相同的响应，Fanout建立与客户机的流连接。</p><p id="d33e" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">当然，这只是连接设置。要向连接的客户端发送更新，必须将数据发布到扇出。</p><h1 id="042b" class="jw jx hu bd jy jz ka kb kc kd ke kf kg ja kh jb ki jd kj je kk jg kl jh km kn dt translated">清除快速缓存</h1><p id="5d58" class="pw-post-body-paragraph ko kp hu kq b kr ks iv kt ku kv iy kw kx ky kz la lb lc ld le lf lg lh li lj hn dt translated">如果触发发布的事件导致源服务器响应改变，那么我们可能还需要清除快速缓存。</p><p id="16e9" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">例如，假设<code class="eh mj mk ml mm b">/stream</code>端点所服务的“值”已经被改变。新值可以发布给所有当前的连接，但是我们也希望任何后来到达的新连接也接收这个最新的值，而不是旧的缓存值。这可以通过同时从Fastly清除和发布到Fanout来解决。</p><p id="7c9f" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">此序列图说明了一个客户端连接、接收更新，然后另一个客户端连接:</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mz"><img src="../Images/56562a6a32ac25c51f0cdd0f480ebaa1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1332/format:webp/0*FGQvwc9fjXUmxM26.png"/></div></figure><h1 id="d56e" class="jw jx hu bd jy jz ka kb kc kd ke kf kg ja kh jb ki jd kj je kk jg kl jh km kn dt translated">有效处理限速</h1><p id="f8e1" class="pw-post-body-paragraph ko kp hu kq b kr ks iv kt ku kv iy kw kx ky kz la lb lc ld le lf lg lh li lj hn dt translated">如果您的发布数据速率相对较高，那么这会抵消使用Fastly的缓存优势。</p><p id="331c" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">有效利用Fastly缓存的理想数据速率是:</p><ul class=""><li id="5a4c" class="lv lw hu kq b kr ll ku lm kx lx lb ly lf lz lj na mb mc md dt translated"><strong class="kq hv">访问频繁</strong>——每秒钟有许多新访客</li><li id="6fc5" class="lv lw hu kq b kr me ku mf kx mg lb mh lf mi lj na mb mc md dt translated"><strong class="kq hv">变化频繁</strong> —每隔几秒或几分钟更新一次</li><li id="d1be" class="lv lw hu kq b kr me ku mf kx mg lb mh lf mi lj na mb mc md dt translated"><strong class="kq hv">即时交付</strong>——以毫秒计</li></ul><p id="87a3" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">这方面的一个例子是一个实时博客，其中大多数请求可以从缓存中得到服务和处理。</p><p id="9dba" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">但是，如果您的数据每秒改变多次(或者在高峰时刻有可能改变如此之快)，并且您希望频繁访问，那么您真的不希望每秒清除缓存多次。</p><p id="bac4" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">解决方法是限制清除的速率。例如，在高吞吐量期间，您可能会以大约每秒一次的最大速率清除和发布。通过这种方式，可以从缓存中为大多数新访问者提供服务，并且数据会在不久后更新。</p><h1 id="2294" class="jw jx hu bd jy jz ka kb kc kd ke kf kg ja kh jb ki jd kj je kk jg kl jh km kn dt translated">演示</h1><p id="9f93" class="pw-post-body-paragraph ko kp hu kq b kr ks iv kt ku kv iy kw kx ky kz la lb lc ld le lf lg lh li lj hn dt translated">可以参考<a class="ae jv" href="https://github.com/fanout/livecounter" rel="noopener ugc nofollow" target="_blank"> Github源代码</a>进行Fastly/Fanout高比例<a class="ae jv" href="http://livecounter.org/" rel="noopener ugc nofollow" target="_blank">直播计数器</a>演示。请求首先到达Fanout，然后到达Fastly，然后到达管理计数器API逻辑的Django后端服务器。每当计数器递增时，快速缓存被清除，数据通过扇出发布。清除和发布过程也有速率限制，以最大限度地提高缓存效益。</p><h1 id="e7cc" class="jw jx hu bd jy jz ka kb kc kd ke kf kg ja kh jb ki jd kj je kk jg kl jh km kn dt translated">最后的想法:消息CDN的出现？</h1><p id="1b40" class="pw-post-body-paragraph ko kp hu kq b kr ks iv kt ku kv iy kw kx ky kz la lb lc ld le lf lg lh li lj hn dt translated">广义地说，我们可以将<strong class="kq hv">消息传递</strong>内容交付网络定义为一组地理上分布的服务器，它们一起工作以提供动态数据和web内容的近乎实时的交付。</p><p id="9466" class="pw-post-body-paragraph ko kp hu kq b kr ll iv kt ku lm iy kw kx ln kz la lb lo ld le lf lp lh li lj hn dt translated">这种新类型的CDN可以让数据处理发生在边缘，远离应用程序的源头——从而开创一个经济实惠、可扩展的实时计算新时代。</p></div></div>    
</body>
</html>