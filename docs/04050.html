<html>
<head>
<title>How to train a Keras model to recognize text with variable length</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何训练Keras模型识别可变长度的文本</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/how-to-train-a-keras-model-to-recognize-text-with-variable-length-10f30666aa62?source=collection_archive---------4-----------------------#2018-05-12">https://medium.com/hackernoon/how-to-train-a-keras-model-to-recognize-text-with-variable-length-10f30666aa62?source=collection_archive---------4-----------------------#2018-05-12</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/4c70c38a6d3bc41eb635687438181c57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9lLsLKAvHFq0_bMP.png"/></div></div></figure><p id="1b74" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我玩了Keras官方的<strong class="je hv"> image_ocr.py </strong>例子有一段时间了，想在这篇文章中分享一下我的心得。</p><p id="a1d6" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">官方的例子只对模型进行了训练，而忽略了预测部分，我的最终源代码既可以在<a class="ae ka" href="https://github.com/Tony607/keras-image-ocr" rel="noopener ugc nofollow" target="_blank">我的GitHub </a>上获得，也可以在<a class="ae ka" href="https://drive.google.com/file/d/1CdB9rvImJCAl_U9yYVD6HqMFWup_RzpG/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">一台可运行的Google Colab笔记本</a>上获得。OCR(光学字符识别)的更多技术细节，包括模型结构和CTC损失，也将在下面的章节中简要说明。</p><h1 id="8378" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">OCR任务声明</h1><p id="a765" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">输入将是一个包含单行文本的图像，文本可以在图像中的任何位置。模型的任务是输出给定图像的实际文本。</p><p id="68a1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">举个例子，</p><figure class="lf lg lh li fq iv fe ff paragraph-image"><div class="fe ff le"><img src="../Images/5e1d976667e410bd0f25287f3dafc707.png" data-original-src="https://miro.medium.com/v2/resize:fit:1180/format:webp/0*H9G5danlLMOOfcm6.png"/></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek">OCR example input &amp; output</figcaption></figure><p id="bf73" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">官方image_ocr.py示例源代码相当长，可能看起来令人望而生畏。它可以分解成几个部分。</p><ul class=""><li id="ebc3" class="ln lo hu je b jf jg jj jk jn lp jr lq jv lr jz ls lt lu lv dt translated">作为训练样本的生成器，这部分源代码将生成生动的文本图像，类似于带有人工斑点、随机位置和各种正面的扫描文档。</li><li id="e88c" class="ln lo hu je b jf lw jj lx jn ly jr lz jv ma jz ls lt lu lv dt translated">模型回调保存模型权重，并在每个训练时期后使用一些生成的文本图像可视化当前模型的性能。</li><li id="b406" class="ln lo hu je b jf lw jj lx jn ly jr lz jv ma jz ls lt lu lv dt translated">模型构建和训练部分。我们将在下一节详细阐述这一部分。</li></ul><h1 id="3d74" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">模型结构</h1><p id="5528" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">模型输入是图像数据，我们首先将数据馈送到两个卷积网络以提取图像特征，然后进行整形和密集以降低特征向量的维度，然后让双向GRU处理顺序数据。供给GRU的顺序数据是水平划分的图像特征。最终的输出密集层将给定图像的输出转换为一个形状为(32，28)的数组，表示(#水平步长，#字符标签)。</p><figure class="lf lg lh li fq iv fe ff paragraph-image"><div class="fe ff mb"><img src="../Images/5785976a1921468304f13ba5b2688674.png" data-original-src="https://miro.medium.com/v2/resize:fit:784/format:webp/0*OYY7oD7FBRIWTjMN.jpg"/></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek">Base model structure</figcaption></figure><p id="00e2" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">下面是构建Keras模型的部分代码。</p><figure class="lf lg lh li fq iv"><div class="bz el l di"><div class="mc md l"/></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek">Model construction</figcaption></figure><h1 id="2f62" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">CTC损失</h1><p id="8cfd" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">正如我们在示例图像中看到的，文本可以位于任何位置，模型如何在输入和输出之间对齐以定位图像中的每个字符并将它们转换为文本？这就是CTC发挥作用的地方，CTC代表连接主义时间分类。</p><figure class="lf lg lh li fq iv fe ff paragraph-image"><div class="fe ff me"><img src="../Images/965e598d675c6f1f524ce2c69907beef.png" data-original-src="https://miro.medium.com/v2/resize:fit:766/format:webp/0*voVOqCIobToPMKA9.jpg"/></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek">input -&gt; softmax output</figcaption></figure><p id="709e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">注意，模型的输出有32个时间步长，但是输出可能没有32个字符。CTC成本函数允许RNN生成如下输出:</p><figure class="lf lg lh li fq iv fe ff paragraph-image"><div class="fe ff mf"><img src="../Images/55b78e0530be7b8006bb527076e997d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1094/format:webp/0*w1JGwruMPgPKkMH8.jpg"/></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek">Output sequence -“a game” with CTC blanks inserted</figcaption></figure><p id="ff89" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">CTC引入了“空白”标记，它本身并不翻译成任何字符，它所做的是分隔单个字符，以便我们可以折叠没有被空白分隔的重复字符。</p><p id="af74" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">因此前一序列的解码输出将是“一个游戏”。</p><p id="2e90" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们再来看另一个文字“速度”的例子。</p><figure class="lf lg lh li fq iv fe ff paragraph-image"><div class="fe ff mg"><img src="../Images/9f2f0927fe6f26324652e30fdc56ad32.png" data-original-src="https://miro.medium.com/v2/resize:fit:582/format:webp/0*55Lp4_eN0ZV5wy7K.jpg"/></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek">Output sequence -“speed”</figcaption></figure><p id="b4c9" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">根据解码原则，我们首先折叠未被空白标记分隔的重复字符，然后删除空白标记本身。请注意，如果没有空白标记来分隔两个“e ”,它们将合并为一个。</p><p id="4c30" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在Keras中，CTC解码可以在单个函数<code class="eh mh mi mj mk b">K.ctc_decode</code>中执行。</p><figure class="lf lg lh li fq iv"><div class="bz el l di"><div class="mc md l"/></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek">ctc_decode with greedy search mode</figcaption></figure><p id="5e5a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><code class="eh mh mi mj mk b">out</code>是模型输出，它由来自a~z、空格和空白记号的28个记号中的每一个的28个softmax概率值的32个时间步长组成。我们设置参数<code class="eh mh mi mj mk b">greedy</code>来执行贪婪搜索，这意味着该函数将只返回最可能的输出令牌序列。</p><p id="fbb7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">或者，如果我们想让CTC解码器返回前N个可能的输出序列，我们可以要求它以给定的波束宽度执行波束搜索。</p><figure class="lf lg lh li fq iv"><div class="bz el l di"><div class="mc md l"/></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek">ctc_decode with beam search mode</figcaption></figure><p id="917a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">值得一提的是，如果你是波束搜索算法的新手，<code class="eh mh mi mj mk b">top_paths</code>参数不会大于<code class="eh mh mi mj mk b">beam_width</code>参数，因为波束宽度告诉波束搜索算法在迭代所有时间步长时要跟踪多少个顶部结果。</p><p id="eda1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在，解码器的输出将是一个令牌序列，我们只需要将数字类翻译回字符。</p><p id="be79" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">到目前为止，我们只讨论了CTC的解码部分。你可能想知道模型是怎么用CTC丢失训练的？</p><p id="d9ea" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">为了计算CTC损失，不仅需要模型的真实标签和预测输出，还需要输出序列长度和每个真实标签的长度。</p><ul class=""><li id="3c33" class="ln lo hu je b jf jg jj jk jn lp jr lq jv lr jz ls lt lu lv dt translated"><strong class="je hv"> y_true。</strong>它的一个例子看起来像[0，1，2，3，4，26，25]代表文本序列‘abcde z’</li><li id="7afc" class="ln lo hu je b jf lw jj lx jn ly jr lz jv ma jz ls lt lu lv dt translated"><strong class="je hv"> y_pred </strong>是softmax层的输出，其样本具有形状(32，28)，32个时间步长，28个类别，即“a-z”，空格和空白标记。</li><li id="7e9f" class="ln lo hu je b jf lw jj lx jn ly jr lz jv ma jz ls lt lu lv dt translated"><strong class="je hv"> input_length </strong>是输出序列长度img _ w//down sample _ factor—2 = 128/4-2 = 30，2表示前2个丢弃的RNN输出时间步长，因为RNN的第一对输出往往是无用的。</li><li id="b9bd" class="ln lo hu je b jf lw jj lx jn ly jr lz jv ma jz ls lt lu lv dt translated"><strong class="je hv">前一个<strong class="je hv"> y_true </strong>样本的标签_长度</strong>将为7，</li></ul><p id="d7a5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在Keras中，CTC损失封装在一个功能<code class="eh mh mi mj mk b">K.ctc_batch_cost</code>中。</p><figure class="lf lg lh li fq iv"><div class="bz el l di"><div class="mc md l"/></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek">ctc_batch_cost</figcaption></figure><h1 id="0d5a" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">结论</h1><p id="bccf" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">训练模型25个时期后的检查点结果。</p><figure class="lf lg lh li fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ml"><img src="../Images/638adce06f1960a8adf5395ee92a181d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9mwSVONc-Iie8CpT.png"/></div></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek">Model performance check after 25 training epochs</figcaption></figure><p id="1a0c" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你已经读到这里，并在Google Colab上进行实验，你现在应该有一个Keras OCR演示在运行。如果您仍然渴望获得更多关于CTC和beam search的信息，请随时查看以下资源。</p><p id="3028" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ka" href="https://distill.pub/2017/ctc/" rel="noopener ugc nofollow" target="_blank">使用CTC进行序列建模</a> —深入阐述CTC算法和其他可以应用CTC的应用，如语音识别、视频唇读等。</p><p id="b783" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ka" href="https://www.coursera.org/learn/nlp-sequence-models/lecture/4EtHZ/beam-search" rel="noopener ugc nofollow" target="_blank"> Coursera光束搜索视频讲座</a>。快速且易于理解。</p><p id="80ca" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">不要忘了从<a class="ae ka" href="https://github.com/Tony607/keras-image-ocr" rel="noopener ugc nofollow" target="_blank">我的GitHub </a>以及<a class="ae ka" href="https://drive.google.com/file/d/1CdB9rvImJCAl_U9yYVD6HqMFWup_RzpG/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">一个可运行的Google Colab笔记本</a>中获取源代码。</p></div><div class="ab cl mm mn hc mo" role="separator"><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr ms"/><span class="mp bw bk mq mr"/></div><div class="hn ho hp hq hr"><p id="9f54" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><em class="mt">最初发表于</em><a class="ae ka" href="https://www.dlology.com/blog/how-to-train-a-keras-model-to-recognize-variable-length-text/" rel="noopener ugc nofollow" target="_blank"><em class="mt">www.dlology.com</em></a><em class="mt">。</em></p></div></div>    
</body>
</html>