<html>
<head>
<title>Introduction to Machine Learning Algorithms: Logistic Regression</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">机器学习算法简介:逻辑回归</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/introduction-to-machine-learning-algorithms-logistic-regression-cbdd82d81a36?source=collection_archive---------1-----------------------#2018-05-28">https://medium.com/hackernoon/introduction-to-machine-learning-algorithms-logistic-regression-cbdd82d81a36?source=collection_archive---------1-----------------------#2018-05-28</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="0b61" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">从头开始构建您的逻辑回归模型</h2></div><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff jj"><img src="../Images/368ba449806351f2863ee70f5fb55c86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SMlRX2-yBaV-1LBt8Dl7rg.jpeg"/></div></div></figure><p id="5b6f" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">Logistic回归是线性回归之后最著名的<a class="ae kr" href="https://hackernoon.com/tagged/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a> <a class="ae kr" href="https://hackernoon.com/tagged/algorithm" rel="noopener ugc nofollow" target="_blank">算法</a>。在很多方面，线性回归和逻辑回归是相似的。但是，最大的区别在于它们是用来做什么的。线性回归算法用于预测/预报值，而逻辑回归用于分类任务。如果你对线性回归的概念不确定，<a class="ae kr" href="https://towardsdatascience.com/introduction-to-machine-learning-algorithms-linear-regression-14c4e325882a" rel="noopener" target="_blank">看看这个</a>。人们通常会执行许多分类任务。例如，对电子邮件是否是垃圾邮件进行分类、对肿瘤是恶性还是良性进行分类、对网站是否是欺诈性的进行分类等。这些是机器学习算法可以让我们的生活变得容易得多的典型例子。一种真正简单、基本和有用的分类算法是逻辑回归算法。现在，让我们更深入地研究一下逻辑回归。</p><h2 id="6250" class="ks kt hu bd ku kv kw kx ky kz la lb lc ke ld le lf ki lg lh li km lj lk ll lm dt translated">Sigmoid函数(逻辑函数)</h2><p id="aaa5" class="pw-post-body-paragraph jv jw hu jx b jy ln iv ka kb lo iy kd ke lp kg kh ki lq kk kl km lr ko kp kq hn dt translated">逻辑回归算法也使用具有独立预测因子的线性方程来预测值。预测值可以是负无穷大到正无穷大之间的任何值。我们需要算法的输出是类变量，即0-否，1-是。因此，我们将线性方程的输出压缩到范围[0，1]内。为了压缩0和1之间的预测值，我们使用sigmoid函数。</p><div class="jk jl jm jn fq ab cb"><figure class="ls jo lt lu lv lw lx paragraph-image"><img src="../Images/3be8d08500d280e5bd742c98dc50a784.png" data-original-src="https://miro.medium.com/v2/resize:fit:924/format:webp/1*ojw9Vm3A_CoW4H86MqciQw.png"/></figure><figure class="ls jo ly lu lv lw lx paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><img src="../Images/a67b7942c8b72470f95736fd3c12cd31.png" data-original-src="https://miro.medium.com/v2/resize:fit:554/format:webp/1*CTXB1Vb_Y7y7gNFQPYoAQA.png"/></div><figcaption class="lz ma fg fe ff mb mc bd b be z ek md di me mf">Linear Equation and Sigmoid Function</figcaption></figure></div><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff mg"><img src="../Images/df00626cd49303d05ff2e60a2e7e9704.png" data-original-src="https://miro.medium.com/v2/resize:fit:656/format:webp/1*hS34eM_0bCdgRMsjSRtPuQ.png"/></div><figcaption class="lz ma fg fe ff mb mc bd b be z ek">Squashed output-h</figcaption></figure><p id="316c" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们取线性方程的输出(z ),并给函数g(x ),它返回一个压缩值h，值h将在0到1的范围内。为了理解sigmoid函数如何压缩范围内的值，让我们来看一下sigmoid函数的图形。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mh"><img src="../Images/d238e60aabc9aba0e61111b5d257899c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*s6Rhp40yHBtxMIcC.png"/></div></div><figcaption class="lz ma fg fe ff mb mc bd b be z ek">Sigmoid Function graph</figcaption></figure><p id="5ecb" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">从图中可以看出，对于x的正值，sigmoid函数渐近于y=1，对于x的负值，sigmoid函数渐近于y=0。</p><h2 id="5133" class="ks kt hu bd ku kv kw kx ky kz la lb lc ke ld le lf ki lg lh li km lj lk ll lm dt translated">价值函数</h2><p id="ce1f" class="pw-post-body-paragraph jv jw hu jx b jy ln iv ka kb lo iy kd ke lp kg kh ki lq kk kl km lr ko kp kq hn dt translated">由于我们试图预测类值，因此不能使用线性回归算法中使用的相同成本函数。因此，我们使用对数损失函数来计算错误分类的成本。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mi"><img src="../Images/32aacbf710d5ef46ebc09fbc3cd42a46.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lPez4cGdj7v17fnrljvbNA.png"/></div></div></figure><p id="c8aa" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">上述成本函数可以重写如下，因为从上述方程计算梯度是困难的。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mj"><img src="../Images/cfd8aeb422c80e7757b75767b31f0d4d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ba9-yqWcwSNQkxMzF-wmqw.png"/></div></div></figure><h2 id="353d" class="ks kt hu bd ku kv kw kx ky kz la lb lc ke ld le lf ki lg lh li km lj lk ll lm dt translated">计算渐变</h2><p id="6705" class="pw-post-body-paragraph jv jw hu jx b jy ln iv ka kb lo iy kd ke lp kg kh ki lq kk kl km lr ko kp kq hn dt translated">我们对每个参数(θ_ 0，θ_ 1，…)取成本函数的偏导数来获得梯度。在这些梯度的帮助下，我们可以更新θ_ 0，θ_ 1的值…要理解下面的方程，你需要一些微积分。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mk"><img src="../Images/bfaad0c243ca995b3faa7a38d9c151d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lEt-GlC76PIyQBy3WGsbrQ.png"/></div></div><figcaption class="lz ma fg fe ff mb mc bd b be z ek">Gradients</figcaption></figure><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="ml mm l"/></div></figure><p id="b778" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">但是，如果你不能理解它们，你可以问我，或者你可以照原样接受它们。</p><h2 id="e9ae" class="ks kt hu bd ku kv kw kx ky kz la lb lc ke ld le lf ki lg lh li km lj lk ll lm dt translated">密码</h2><p id="c7f9" class="pw-post-body-paragraph jv jw hu jx b jy ln iv ka kb lo iy kd ke lp kg kh ki lq kk kl km lr ko kp kq hn dt translated">既然我们已经制定了必要的方程，让我们写代码。我们将只使用numpy库来从头构建模型。我相信这将有助于理解引擎盖下发生了什么。我们将使用<a class="ae kr" href="https://www.kaggle.com/jchen2186/machine-learning-with-iris-dataset/data" rel="noopener ugc nofollow" target="_blank">虹膜数据集</a>来训练和测试算法。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="mn mm l"/></div></figure><p id="2388" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们使用pandas库加载数据。Iris数据集有三个目标值(“Iris-virginica”、“Iris-setosa”、“Iris-versicolor”)。因为我们想要实现一个二进制分类算法，所以我决定删除目标值为Iris-virginica的行。现在，我们只有两个目标类要预测。我们从数据集中提取自变量和因变量。现在，让我们继续准备培训和测试数据。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="mn mm l"/></div></figure><p id="3abf" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们将数据混洗并分成训练和测试数据。我们的训练数据中有90个例子，测试数据中有10个例子。数据集中有四个预测值。因此，我们提取每个特征并将其存储在单独的向量中。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="mn mm l"/></div></figure><p id="d269" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们用0初始化参数(theta_0，theta_1，…)。在每个时期，我们使用线性方程计算值，在0到1的范围内挤压值，然后计算成本。根据成本函数，我们计算每个参数的梯度，并通过将梯度乘以alpha来更新它们的值。α是算法的学习速率。经过10000个纪元后，我们的算法会收敛到最小值。我们可以用测试数据来测试我们的算法。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="mn mm l"/></div></figure><p id="9706" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们准备的测试数据特征与训练数据相似。我们还将θ_ 0、θ_ 1、θ_ 2、θ_ 3和θ_ 4的值从90x1剪切到10x1，因为测试示例的数量只有10个。我们计算测试类并检查模型的准确性。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mo"><img src="../Images/1c6a6d7110543e228ad1114364afd36b.png" data-original-src="https://miro.medium.com/v2/resize:fit:668/format:webp/1*ENW_-hqEpgwvK-0zi8Ma_w.png"/></div></div><figcaption class="lz ma fg fe ff mb mc bd b be z ek">Accuracy score of our model</figcaption></figure><p id="3106" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">我们的模型能够达到100%的准确率。尽管逻辑回归是一个非常强大的算法，但我们使用的数据集并不复杂。因此，我们的模型能够达到100%的准确率。当我们的模型被训练了10000个时期时，我们也可以将成本函数值可视化。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="mn mm l"/></div></figure><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff mp"><img src="../Images/01449b9db8e0188dadbbd4da1d96d14e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*brFqt_rUMW1a6arpI69s5g.png"/></div></div><figcaption class="lz ma fg fe ff mb mc bd b be z ek">Cost Function</figcaption></figure><p id="d0a7" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">现在，您可能想知道实现一个简单的算法需要很多行代码。为了避免我们键入这么多行代码，我们可以使用scikit学习库。scikit学习库有一个内置逻辑回归类，我们可以导入并使用它。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="mn mm l"/></div></figure><p id="3719" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">50多行代码已经减少到10行以下。通过scikit学习库的逻辑回归类，我们也获得了100%的准确率。</p><h2 id="b1c7" class="ks kt hu bd ku kv kw kx ky kz la lb lc ke ld le lf ki lg lh li km lj lk ll lm dt translated">结论</h2><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="mq mm l"/></div></figure><p id="abba" class="pw-post-body-paragraph jv jw hu jx b jy jz iv ka kb kc iy kd ke kf kg kh ki kj kk kl km kn ko kp kq hn dt translated">逻辑回归是一种简单的算法，可用于二元/多元分类任务。我想现在你应该已经对逻辑回归算法的工作原理有了基本的了解。希望本文对您有所帮助:)</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="mr mm l"/></div></figure></div></div>    
</body>
</html>