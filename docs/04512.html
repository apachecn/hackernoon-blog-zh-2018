<html>
<head>
<title>Building a System to Deliver Billions of Daily Events</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">构建一个交付数十亿日常事件的系统</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/building-a-system-to-deliver-billions-of-daily-events-c3a56be47fc2?source=collection_archive---------16-----------------------#2018-05-29">https://medium.com/hackernoon/building-a-system-to-deliver-billions-of-daily-events-c3a56be47fc2?source=collection_archive---------16-----------------------#2018-05-29</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/e236fe958318aecb09949d49452982e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bJKd4qSm_Kxn1AZ4dVyOeA.png"/></div></div></figure><h2 id="9f2d" class="jc jd hu bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz dt translated">由<a class="ae ka" href="https://twitter.com/calvinfo" rel="noopener ugc nofollow" target="_blank">Calvin French-Owen</a>,<a class="ae ka" href="https://goo.gl/qerTet" rel="noopener ugc nofollow" target="_blank">分部的联合创始人。</a></h2><blockquote class="kb kc kd"><p id="b0bd" class="ke kf kg kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc hn dt translated">这篇文章最初出现在<a class="ae ka" href="https://bit.ly/2J0mhcp" rel="noopener ugc nofollow" target="_blank"> Segment博客</a>上，探讨了Segment如何每天向数百个公共API可靠地发送数十亿条消息，以及用于在生产中运行它的数据模型。Hacker Noon的每周赞助商<a class="ae ka" href="https://segment.com/?utm_source=hacker%20noon%20blog%20post" rel="noopener ugc nofollow" target="_blank"> Segment </a>，目前提供90天免费试用——发送电子邮件至friends@segment，并提及Hacker Noon进行兑换。</p></blockquote><p id="52cc" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">今天，我们很高兴与大家分享离心机的架构——Segment的系统每天向数百个公共API可靠地发送数十亿条消息。这篇文章探讨了离心机解决的问题，以及我们在生产中使用的数据模型。</p><h1 id="42d5" class="ld jd hu bd je le lf lg ji lh li lj jm lk ll lm jq ln lo lp ju lq lr ls jy lt dt translated">离心机问题</h1><p id="b0c2" class="pw-post-body-paragraph ke kf hu kh b ki lu kk kl km lv ko kp jn lw ks kt jr lx kw kx jv ly la lb lc hn dt translated">在<a class="ae ka" href="https://segment.com/" rel="noopener ugc nofollow" target="_blank">细分市场</a>，我们的核心产品每秒收集、处理和交付数十万个分析事件。这些事件由用户操作组成，如查看页面、从Amazon购买商品或喜欢朋友的播放列表。无论事件是什么，它几乎总是互联网上某个人<em class="kg">做</em> <em class="kg">某事的结果。</em></p><p id="20b4" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">我们将这些传入事件转发给数百个下游端点，如<a class="ae ka" href="https://analytics.google.com/analytics/web/" rel="noopener ugc nofollow" target="_blank"> Google Analytics </a>、<a class="ae ka" href="https://www.salesforce.com/" rel="noopener ugc nofollow" target="_blank"> Salesforce </a>和每客户<a class="ae ka" href="https://en.wikipedia.org/wiki/Webhook" rel="noopener ugc nofollow" target="_blank"> Webhooks </a>。</p><p id="e318" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在任何时间点，许多这样的端点都将处于故障状态。我们将看到响应延迟增加10倍，5xx状态代码激增，以及对单个大客户的激进速率限制。</p><p id="28bc" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">为了让您感受一下，这里是我今天早些时候从我们的内部监控中提取的各种延迟和正常运行时间。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div class="fe ff lz"><img src="../Images/621121945bc51dcc902ddc9ced6a0cdc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*9VWG8DHEKW1OC-cP.gif"/></div></figure><p id="7cc3" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在最好的情况下，这些API故障会导致延迟。在最坏的情况下，数据丢失。</p><p id="cd50" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">事实证明，在一个有问题的环境中调度这么多请求是一个复杂的问题。你得好好考虑公平问题(你应该优先考虑哪些数据？)，缓冲语义(应该如何对数据进行排队？)，以及重试行为(现在重试是否会给系统增加不必要的负载？).</p><p id="e8c8" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">纵观所有文献，我们找不到很多在高故障环境中可靠地传递消息的好的“现有技术”。最接近的是<a class="ae ka" href="http://linux-ip.net/articles/Traffic-Control-HOWTO/classless-qdiscs.html" rel="noopener ugc nofollow" target="_blank">网络调度和路由</a>，但是那个学科有<em class="kg">非常</em>不同的关于缓冲分配(非常小)和<a class="ae ka" href="https://en.wikipedia.org/wiki/Back_pressure" rel="noopener ugc nofollow" target="_blank">背压</a>策略(自适应的，并且通常路由到单个地方)的策略。</p><p id="6219" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">因此，我们决定构建自己的通用的、完全分布式的作业调度器，以便可靠地调度和执行HTTP请求。我们称之为离心机。</p><p id="23a9" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">您可以将离心机视为位于我们的基础设施和外部世界之间的一层，它是负责将数据发送到我们所有客户目的地的系统。当第三方API失败时，离心机可以吸收流量。</p><p id="838b" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在正常操作下，离心机有三个职责:向第三方端点传递消息，失败时重试消息，以及存档任何未传递的消息。</p><p id="2ddc" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">我们写了第一篇文章，作为理解离心机解决的问题、它的数据模型以及我们在生产中用来操作它的构件的指南。在随后的帖子中，我们将分享我们如何验证系统的正确性，并让它快得令人眼花缭乱。</p><p id="86b6" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">让我们开始吧。</p><h1 id="70a0" class="ld jd hu bd je le lf lg ji lh li lj jm lk ll lm jq ln lo lp ju lq lr ls jy lt dt translated">当队列停止工作时</h1><p id="804c" class="pw-post-body-paragraph ke kf hu kh b ki lu kk kl km lv ko kp jn lw ks kt jr lx kw kx jv ly la lb lc hn dt translated">在讨论离心机本身之前，您可能会想“为什么不在这里使用队列呢？构建一个完全分布式的作业调度器似乎有点过头了”。</p><p id="e475" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">我们也问过自己同样的问题。我们已经在Segment广泛使用<a class="ae ka" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank"> Kafka </a>(我们每秒通过它传递近100万条消息)，它已经成为我们所有流媒体管道的核心构件。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff me"><img src="../Images/a8ec565cdc12102c3f6921d501c91547.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*FvYI9mOc4BirhmBo.png"/></div></div></figure><p id="8918" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">使用任何一种队列的问题是，就如何访问数据而言，你从根本上受到了限制。毕竟一个队列只支持两种操作(push和pop)。</p><p id="65b9" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">为了查看队列在哪里分解，让我们浏览一下我们在Segment实现的一系列队列拓扑。</p><h1 id="4c18" class="ld jd hu bd je le lf lg ji lh li lj jm lk ll lm jq ln lo lp ju lq lr ls jy lt dt translated">架构1:单个队列</h1><p id="0f4c" class="pw-post-body-paragraph ke kf hu kh b ki lu kk kl km lv ko kp jn lw ks kt jr lx kw kx jv ly la lb lc hn dt translated">首先，让我们先考虑一个简单的方法。我们可以运行一组从单个队列中读取作业的工人。</p><p id="56be" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">工人将从队列中读取一条消息，发送给任何需要的第三方API，然后确认该消息。它似乎应该保护我们免于失败，对吗？</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mf"><img src="../Images/6a4f9c8daf267b756ddbe1c59d1c2c22.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*fQ0exMIwDqVTimIV.png"/></div></div></figure><p id="2806" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">这在一段时间内工作正常，但是当我们开始看到单个端点变慢时会发生什么呢？不幸的是，它会对整个消息流产生反压力。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mf"><img src="../Images/c90071282a1be2ce57b165803392e504.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*p4Nitvg4B1ufv09L.png"/></div></div></figure><p id="6c57" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">显然，这并不理想。如果一个<em class="kg">单个</em>端点可以关闭整个管道，并且每个端点每年都有一个小时的停机时间(99.9%可用)，那么对于200多个端点，我们每天将会看到一个小时的停机时间。</p><h1 id="face" class="ld jd hu bd je le lf lg ji lh li lj jm lk ll lm jq ln lo lp ju lq lr ls jy lt dt translated">架构2:每个目的地的队列</h1><p id="2776" class="pw-post-body-paragraph ke kf hu kh b ki lu kk kl km lv ko kp jn lw ks kt jr lx kw kx jv ly la lb lc hn dt translated">在看到我们的摄取管道一再变慢之后，我们决定重新架构。我们更新了我们的排队拓扑，根据事件将到达的下游端点将事件路由到单独的队列中。</p><p id="9ba6" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">为此，我们在每个队列前面添加了一个路由器。路由器只会将消息发布到目的地为特定API端点的队列。</p><p id="9887" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">假设您启用了三个目的地:Google Analytics、Mixpanel和Salesforce。路由器将发布三条消息，分别针对Google Analytics、Mixpanel和Salesforce的每个专用队列。</p><p id="54ab" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">这种方法的好处是，单个失败的API将只影响去往单个端点的消息(这正是我们想要的！).</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mf"><img src="../Images/61627f3d373c8cc6be6ab7e964e8131f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*lqDcMNX9DGs6n2OX.png"/></div></div></figure><p id="a35c" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">不幸的是，这种方法在实践中存在问题。如果我们看一下应该传递到单个端点的消息的分布，事情会变得稍微微妙一些。</p><p id="9e34" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">Segment是一个大型的多租户系统，因此一些数据源会比其他数据源产生更多的负载。正如您可能想象的那样，在我们的客户群中，这遵循一个相当一致的幂定律:</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mg"><img src="../Images/78ae158ff7c5707d0b15a44a9635dc10.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bBH4hcYHqxkp3spS.png"/></div></div></figure><p id="2e81" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">当这转化为队列中的消息时，分解看起来更像这样:</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mf"><img src="../Images/aeaf465061c6ff4ff697cc7eea07c9d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*y_lzADQQt36RGl3c.png"/></div></div></figure><p id="c94b" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在这种情况下，我们有客户A、B和C的数据，它们都试图发送到同一个下游端点。客户A控制着负载，但是B和C有少量的呼叫混合在一起。</p><p id="0fd0" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">假设我们发送到的API端点被评定为每个客户每秒1000次调用。对于给定的客户API键，当端点在一秒钟内收到超过1000个调用时，它将使用<a class="ae ka" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/429" rel="noopener ugc nofollow" target="_blank"> 429 HTTP头</a>进行响应(超过速率限制)。</p><p id="2f40" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">现在让我们假设客户A试图向API发送50，000条消息。这些消息在我们的队列中都是连续排序的。</p><p id="4cd0" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">此时，我们有几个选择:</p><ul class=""><li id="bb6b" class="mh mi hu kh b ki kj km kn jn mj jr mk jv ml lc mm mn mo mp dt translated">我们可以尝试每秒发送1，000条消息，但这会使B和C的流量延迟50秒。</li><li id="817e" class="mh mi hu kh b ki mq km mr jn ms jr mt jv mu lc mm mn mo mp dt translated">我们可以尝试向客户A的API发送更多的消息，但是我们会看到429(超过速率限制)错误。我们想要重试那些失败的消息，这可能会导致B和c的速度更慢。</li><li id="7841" class="mh mi hu kh b ki mq km mr jn ms jr mt jv mu lc mm mn mo mp dt translated">在第一秒为客户A发送1，000条消息后，我们可以检测到接近速率限制，因此我们可以将客户A接下来的49，000条消息复制到<a class="ae ka" href="https://en.wikipedia.org/wiki/Dead_letter_queue" rel="noopener ugc nofollow" target="_blank">死信队列</a>中，并允许B和C的流量继续进行。</li></ul><p id="b30c" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">这些选择都不理想。在单个客户发送大量数据的情况下，我们要么最终阻塞所有客户的队列，要么最终在死信队列之间复制万亿字节的数据。</p><h1 id="7ce3" class="ld jd hu bd je le lf lg ji lh li lj jm lk ll lm jq ln lo lp ju lq lr ls jy lt dt translated">理想状态:每个<source destination="">的队列</source></h1><p id="7db0" class="pw-post-body-paragraph ke kf hu kh b ki lu kk kl km lv ko kp jn lw ks kt jr lx kw kx jv ly la lb lc hn dt translated">相反，我们想要一个看起来更像下图的架构，其中我们为每个<em class="kg"/><em class="kg">客户和端点</em>的组合拥有单独的队列。这种架构为我们提供了更好的隔离，以及基于每个客户动态调整吞吐量的能力。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mf"><img src="../Images/368d9cbc8316eddeaa47041d7273ecde.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ArT_c1a79z7ppfbe.png"/></div></div></figure><p id="8f4e" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">但是，在大型多租户系统(如Segment)中，这个数量的队列很难管理。</p><p id="f8ba" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">我们有成千上万个这样的源-目的地对。今天，我们有42，000个活动数据源发送到平均2.1个下游端点。我们希望支持的队列总数达到88，000个(而且我们还在快速增长)。</p><p id="ccb9" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">要实现完全隔离的每个源-目的地队列，我们需要成千上万个不同的队列。在<a class="ae ka" href="https://kafka.apache.org/" rel="noopener ugc nofollow" target="_blank"> Kafka </a>、<a class="ae ka" href="https://www.rabbitmq.com/" rel="noopener ugc nofollow" target="_blank"> RabbitMQ </a>、<a class="ae ka" href="http://nsq.io/" rel="noopener ugc nofollow" target="_blank"> NSQ </a>或<a class="ae ka" href="https://aws.amazon.com/kinesis/" rel="noopener ugc nofollow" target="_blank"> Kinesis </a>中，我们还没有看到任何队列支持简单缩放原语的基数水平。<a class="ae ka" href="https://aws.amazon.com/sqs/" rel="noopener ugc nofollow" target="_blank"> SQS </a>是我们发现的唯一一个能够做到这一点的队列，但是成本太高了。我们需要一个新的原语来解决这个高基数隔离的问题。</p><h1 id="f1a8" class="ld jd hu bd je le lf lg ji lh li lj jm lk ll lm jq ln lo lp ju lq lr ls jy lt dt translated">进入“虚拟”队列</h1><p id="955d" class="pw-post-body-paragraph ke kf hu kh b ki lu kk kl km lv ko kp jn lw ks kt jr lx kw kx jv ly la lb lc hn dt translated">我们现在有了理想的最终状态:成千上万的小队列。在这些队列中，我们可以很容易地决定以不同的速率使用来自客户A、B和c的消息。</p><p id="09e1" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">但是当我们开始考虑实现时，我们实际上是如何管理那么多队列的呢？</p><p id="1339" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">我们从虚拟队列系统的几个核心需求开始:</p><p id="468e" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">1)提供每个客户的隔离</p><p id="4651" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">首先，我们需要提供每个客户的隔离。一个发送大量失败流量的客户不应该减慢任何其他数据传输。我们的系统必须在不降低全球交付率的情况下吸收失败。</p><p id="0143" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">2)允许我们对消息重新排序，而无需复制太字节的数据</p><p id="9904" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">我们的第二个约束是，我们的系统必须能够快速调整其交付顺序，而不需要通过网络复制太多的数据。</p><p id="be5f" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">根据我们处理大型数据集的经验，能够立即对邮件进行重新排序以进行传递是至关重要的。我们经常遇到在数据处理中产生大量积压的情况，在这种情况下，我们的消费者在一系列持续失败的消息上打转。</p><p id="c075" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">传统上有两种方法来处理大量的坏消息。第一种方法是停止您的使用者，并在一段时间后重试同一组消息。这在多租户架构中显然是不可接受的，在这种架构中，仍然应该传递有效的消息。</p><p id="1d5c" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">第二种技术是将失败的消息发布到死信队列，并在以后重新使用它们。不幸的是，将带有相同事件副本的消息重新发布到死信队列或主题“层”会导致大量的存储和网络开销。</p><p id="8d59" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在这两种情况下，如果您的数据位于Kafka中，那么您的消息的交付顺序实际上是由生产者“设置”到主题的:</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mv"><img src="../Images/450ba9406b303ff83b141a80513d62ea.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*niwbsrNf_1ppCGVo.png"/></div></div></figure><p id="a90b" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">我们希望能够快速从错误中恢复，而不必在网络中传输数万亿字节的数据。所以这两种方法都不适合我们。</p><p id="754e" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">3)在许多不同的工人之间平均分配工作量</p><p id="9a39" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">最后，我们需要一个能够随着事件量的增加而完全扩展的系统。我们不希望随着客户的增加而不断添加分区或进行额外的分片。我们的系统应该根据我们需要的流量吞吐量水平扩展。</p><h1 id="3015" class="ld jd hu bd je le lf lg ji lh li lj jm lk ll lm jq ln lo lp ju lq lr ls jy lt dt translated">离心机中的数据</h1><p id="613b" class="pw-post-body-paragraph ke kf hu kh b ki lu kk kl km lv ko kp jn lw ks kt jr lx kw kx jv ly la lb lc hn dt translated">至此，我们对离心机解决的问题(可靠的消息传递)、各种队列拓扑的问题以及我们的核心需求有了很好的了解。因此，让我们看看离心机数据层，以了解我们是如何解决上面列出的约束条件的。</p><p id="0bf0" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">离心机的核心输送单元就是我们所说的作业。</p><p id="a377" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">作业既需要发送数据的有效负载，也需要指示数据发送目的地的端点。您可以选择提供标头来管理重试逻辑、消息编码和超时行为等内容。</p><p id="6835" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在我们的例子中，作业是应该交付给合作伙伴API的单个事件。为了让您了解工作在实践中是什么样子，下面是一个细分工作示例:</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mw"><img src="../Images/17b7e5a20775454f9b84b05dddc52307.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*9CDN-FLk25KkCXw-.png"/></div></div></figure><p id="48c4" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">回头看看我们的需求，我们想要一种方法来快速改变我们的作业的交付顺序，而不必创建作业本身的许多副本。</p><p id="89c8" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">队列不会为我们就地解决这个问题。我们的消费者将不得不读取并重写我们新订单中的所有数据。但是一个数据库，另一方面，<em class="kg">做</em>。</p><p id="8a53" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">通过将执行顺序存储在关系数据库中，我们可以通过运行一条SQL语句来立即改变<a class="ae ka" href="https://en.wikipedia.org/wiki/Quality_of_service" rel="noopener ugc nofollow" target="_blank">服务质量</a>。</p><p id="3255" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">类似地，每当我们想要更改消息的交付语义时，我们不必重新洗牌或双重发布到新的数据存储。相反，我们可以部署新版本的服务，它可以立即开始使用新的查询。</p><p id="61f1" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">使用数据库给我们提供了队列极其缺乏的执行灵活性。</p><p id="cb96" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">出于这个原因，我们决定将离心机数据存储在亚马逊的运行在MySQL上的RDS实例中。RDS为我们提供了托管的数据存储，而MySQL为我们提供了重新排序作业的能力。</p><h1 id="e834" class="ld jd hu bd je le lf lg ji lh li lj jm lk ll lm jq ln lo lp ju lq lr ls jy lt dt translated">队列式数据库</h1><p id="563f" class="pw-post-body-paragraph ke kf hu kh b ki lu kk kl km lv ko kp jn lw ks kt jr lx kw kx jv ly la lb lc hn dt translated">离心机数据库模型有几个核心属性，使其性能良好:</p><ul class=""><li id="f29c" class="mh mi hu kh b ki kj km kn jn mj jr mk jv ml lc mm mn mo mp dt translated">不可变的行:我们不希望频繁地更新行，而是在进入新状态时追加新的行。我们已经将所有的作业执行计划建模为完全不可变的，所以我们从不在数据库本身中运行更新。</li><li id="2f1a" class="mh mi hu kh b ki mq km mr jn ms jr mt jv mu lc mm mn mo mp dt translated">没有数据库连接:不需要大量的协调，使用跨数据库或表的锁，离心机只需要在每个作业的基础上查询数据。这允许我们大规模并行化我们的数据库，因为我们从来不需要跨单独的作业连接数据。</li><li id="a225" class="mh mi hu kh b ki mq km mr jn ms jr mt jv mu lc mm mn mo mp dt translated">主要是写负载，工作集很小:因为离心机主要是接受和传递新数据，我们不会从数据库中读取数据。相反，我们可以在内存中缓存大部分新条目，然后在条目提交时将它们从缓存中取出。</li></ul><p id="c517" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">为了让您了解这三个属性是如何相互作用的，让我们仔细看看作业实际上是如何存储在我们的离心机数据库中的。</p><h2 id="8b34" class="jc jd hu bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz dt translated">工作表</h2><p id="2050" class="pw-post-body-paragraph ke kf hu kh b ki lu kk kl km lv ko kp jn lw ks kt jr lx kw kx jv ly la lb lc hn dt translated">首先，我们有jobs表。该表负责存储所有作业和有效负载，包括管理作业应如何交付的元数据。</p><pre class="ma mb mc md fq mx my mz na aw nb dt"><span id="7d92" class="jc jd hu my b fv nc nd l ne nf">mysql&gt; describe jobs;<br/>+----------------------+----------------+------+-----+---------+-------+<br/>| Field                | Type           | Null | Key | Default | Extra |<br/>+----------------------+----------------+------+-----+---------+-------+<br/>| id                   | binary(27)     | NO   | PRI | NULL    |       |<br/>| bucket               | varbinary(64)  | NO   |     | NULL    |       |<br/>| endpoint             | varbinary(255) | NO   |     | NULL    |       |<br/>| headers              | mediumblob     | NO   |     | NULL    |       |<br/>| payload              | mediumblob     | NO   |     | NULL    |       |<br/>| execution_timeout_ms | int(11)        | NO   |     | NULL    |       |<br/>| backoff_min_delay_ms | int(11)        | NO   |     | NULL    |       |<br/>| backoff_coefficient  | float          | NO   |     | NULL    |       |<br/>| created_at           | datetime(6)    | NO   |     | NULL    |       |<br/>| expire_at            | datetime(6)    | NO   |     | NULL    |       |<br/>+----------------------+----------------+------+-----+---------+-------+</span></pre><p id="e151" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">当<code class="eh ng nh ni my b">endpoint</code>、<code class="eh ng nh ni my b">payload</code>和<code class="eh ng nh ni my b">headers</code>字段管理消息传输时，<code class="eh ng nh ni my b">expire_at</code>字段用于指示给定作业何时应该归档。</p><p id="32b8" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">通过将<code class="eh ng nh ni my b">expire_at</code>分割成一个单独的字段，我们的运营团队可以很容易地调整我们是否需要将大量失败的消息刷新到S3，这样我们就可以带外处理它们。</p><p id="5485" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">查看jobs表的索引，我们已经小心地最小化了在每个字段上构建和维护索引的开销。我们在主键上只保留一个索引。</p><pre class="ma mb mc md fq mx my mz na aw nb dt"><span id="cf3c" class="jc jd hu my b fv nc nd l ne nf">mysql&gt; show indexes from jobs;<br/>+-------+------------+----------+--------------+-------------+-----------+-------------+------------+<br/>| Table | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Index_type |<br/>+-------+------------+----------+--------------+-------------+-----------+-------------+------------+<br/>| jobs  |          0 | PRIMARY  |            1 | id          | A         |     2344484 | BTREE      | <br/>+-------+------------+----------+--------------+-------------+-----------+-------------+------------+</span></pre><p id="3e06" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">jobs表的主键是一个<a class="ae ka" href="https://segment.com/blog/a-brief-history-of-the-uuid/" rel="noopener ugc nofollow" target="_blank"> KSUID </a>，这意味着我们的ID都是可以通过时间戳进行排序的<a class="ae ka" href="https://github.com/segmentio/ksuid#1-sortable-by-timestamp" rel="noopener ugc nofollow" target="_blank">，并且是全局唯一的</a>。这让我们可以有效地一举两得——我们可以通过单个作业ID进行查询，也可以通过单个索引按照作业创建的时间进行排序。</p><p id="1138" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">由于单个作业的有效负载和设置的中值大小约为5kb(可能高达750kb)，我们已经尽了最大努力来限制对作业表的读取和更新。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nj"><img src="../Images/a0d6271c1e28c95081f4daa9ea53ff2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*anGgPQP2aug9RYKS.png"/></div></div></figure><p id="abfa" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在正常操作下，jobs表是不可变的，并且只能追加。负责插入作业的golang进程(我们称之为Director)在内存中保存有效负载和设置的缓存版本。大多数情况下，作业在交付后可以立即从内存中过期，从而保持我们的整体内存占用量较低。</p><p id="764d" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在生产中，我们使用指数补偿策略，将作业设置为4小时后到期。</p><pre class="ma mb mc md fq mx my mz na aw nb dt"><span id="5b38" class="jc jd hu my b fv nc nd l ne nf">mysql&gt; select id, endpoint, created_at, expire_at from jobs limit 5;<br/>+-----------------------------+-------------------------------------------------------+----------------------------+----------------------------+<br/>| id                          | endpoint                                              | created_at                 | expire_at                  |<br/>+-----------------------------+-------------------------------------------------------+----------------------------+----------------------------+<br/>| 14NKRmQSBbCB5p0LAXWRp47dN3F | centrifuge://integrations/v2/54efbf12db31d978f14aa8b5 | 2018-05-09 16:16:52.525000 | 2018-05-09 20:16:52.876976 |<br/>| 14NKeihjmWdJLpyGi7L7GiJ9UgL | centrifuge://integrations/v2/54521fd725e721e32a72eec6 | 2018-05-09 16:18:34.426000 | 2018-05-09 20:18:35.041901 |<br/>| 14NL91LEZG694NNQEF3UZMgA9yH | centrifuge://integrations/v2/54521fdc25e721e32a72ef04 | 2018-05-09 16:22:35.723000 | 2018-05-09 20:22:36.339480 |<br/>| 14NLF682LBV5LQJWLJCwnBUYB8P | centrifuge://integrations/v2/54521fd525e721e32a72ee91 | 2018-05-09 16:23:24.365000 | 2018-05-09 20:23:25.353897 |<br/>| 14NLQK7R4QfAON8w2pYp1FxkyEe | centrifuge://integrations/v2/54521fd725e721e32a72eec6 | 2018-05-09 16:24:54.317000 | 2018-05-09 20:24:54.857624 |<br/>+-----------------------------+-------------------------------------------------------+----------------------------+----------------------------+</span></pre><p id="3138" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">当然，我们还希望跟踪每个作业处于什么状态，是等待交付、正在执行还是等待重试。为此，我们使用一个单独的表，job_state_transitions表。</p><h2 id="c2e0" class="jc jd hu bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz dt translated">作业状态转换表</h2><p id="4b80" class="pw-post-body-paragraph ke kf hu kh b ki lu kk kl km lv ko kp jn lw ks kt jr lx kw kx jv ly la lb lc hn dt translated">job_state_transitions表负责记录单个作业可能经历的所有状态转换。</p><p id="b2ab" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在数据库中，作业状态机如下所示:</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nk"><img src="../Images/12cce30505002de2b7ef730c71e7a854.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ScqStx9HlPomZhEQ.png"/></div></div></figure><p id="f9ee" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">作业首先进入<code class="eh ng nh ni my b">awaiting_scheduling</code>状态。它还没有被执行和交付到下游端点。</p><p id="4284" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">从那里，一个作业将开始<code class="eh ng nh ni my b">executing</code>，结果将转换到三个独立状态中的一个。</p><p id="4bb0" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">如果作业成功(并从端点接收到<a class="ae ka" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/200" rel="noopener ugc nofollow" target="_blank"> 200 HTTP响应)，离心机会将作业标记为<code class="eh ng nh ni my b">succeeded</code>。这里没有什么要做的，我们可以从内存缓存中终止它。</a></p><p id="a6a8" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">类似地，如果作业失败(在<a class="ae ka" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/400" rel="noopener ugc nofollow" target="_blank"> 400 HTTP响应</a>的情况下)，那么离心机会将作业标记为<code class="eh ng nh ni my b">discarded</code>。即使我们尝试多次重新发送相同的作业，服务器也会拒绝它。所以我们到达了另一个终极状态。</p><p id="d947" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">然而，我们可能会遇到短暂的故障，如超时、网络断开或<a class="ae ka" href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/500" rel="noopener ugc nofollow" target="_blank"> 500响应代码</a>。在这种情况下，重试实际上会提高我们收集的数据的交付率(我们看到整个用户群中大约1.5%的数据会发生这种情况)，因此我们将重试交付。</p><p id="0576" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">最后，任何超过到期时间的作业都从<code class="eh ng nh ni my b">awaiting_retry</code>转换到<code class="eh ng nh ni my b">archiving</code>。一旦它们被成功地存储在S3上，这些作业最终被转换到终端<code class="eh ng nh ni my b">archived</code>状态。</p><p id="73d8" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">如果我们更深入地观察转换，我们可以看到控制这个执行的字段:</p><pre class="ma mb mc md fq mx my mz na aw nb dt"><span id="fa80" class="jc jd hu my b fv nc nd l ne nf">mysql&gt; describe job_state_transitions;<br/>+-------------------------+---------------------------------------------------------------------------------------------------------+------+-----+---------+<br/>| Field                   | Type                                                                                                    | Null | Key | Default |<br/>+-------------------------+---------------------------------------------------------------------------------------------------------+------+-----+---------+<br/>| id                      | bigint(20)                                                                                              | NO   | PRI | NULL    |<br/>| job_id                  | binary(27)                                                                                              | NO   | PRI | NULL    |<br/>| time                    | datetime(6)                                                                                             | NO   |     | NULL    |<br/>| retry_at                | datetime(6)                                                                                             | NO   |     | NULL    |<br/>| attempts                | smallint(6)                                                                                             | NO   |     | NULL    |<br/>| state                   | enum('awaiting-scheduling','executing','succeeded','discarded','awaiting-retry','archiving','archived') | NO   |     | NULL    |<br/>| error_type              | varbinary(128)                                                                                          | YES  |     | NULL    |<br/>| error_response          | mediumblob                                                                                              | YES  |     | NULL    |<br/>| error_response_encoding | varbinary(16)                                                                                           | YES  |     | NULL    |<br/>+-------------------------+---------------------------------------------------------------------------------------------------------+------+-----+---------+</span></pre><p id="8975" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">与jobs表一样，job_state_transitions中的行也是不可变的，并且是仅追加的。每次进行新的尝试时，尝试次数都会增加。当作业执行失败时，由作业本身中指定的重试行为安排一个<code class="eh ng nh ni my b">retry_at</code>时间进行重试。</p><p id="8b13" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">就索引策略而言，我们在两个字段上保留了一个复合索引:一个单调递增的ID，以及正在执行的作业的ID。</p><pre class="ma mb mc md fq mx my mz na aw nb dt"><span id="50f0" class="jc jd hu my b fv nc nd l ne nf">mysql&gt; show indexes from job_state_transitions;<br/>+-----------------------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+<br/>| Table                 | Non_unique | Key_name | Seq_in_index | Column_name | Collation | Cardinality | Sub_part | Packed | Null | Index_type | Comment | Index_comment |<br/>+-----------------------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+<br/>| job_state_transitions |          0 | PRIMARY  |            1 | job_id      | A         |     5669206 |     NULL | NULL   |      | BTREE      |         |               |<br/>| job_state_transitions |          0 | PRIMARY  |            2 | id          | A         |    11338413 |     NULL | NULL   |      | BTREE      |         |               |<br/>+-----------------------+------------+----------+--------------+-------------+-----------+-------------+----------+--------+------+------------+---------+---------------+</span></pre><p id="6c71" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">您可以在我们的一个生产数据库中看到，序列中的第一个索引总是在job_id上，它保证是全局唯一的。从这里开始，递增的ID确保了单个作业执行的转换表中的每个条目都是连续的。</p><p id="36d8" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">为了让您了解实际情况，这里有一个从生产中提取的单个作业的示例执行跟踪。</p><pre class="ma mb mc md fq mx my mz na aw nb dt"><span id="427b" class="jc jd hu my b fv nc nd l ne nf">mysql&gt; select id, job_id, attempts, state from job_state_transitions limit 7;<br/>+--------+-----------------------------+----------+---------------------+<br/>| id     | job_id                      | attempts | state               |<br/>+--------+-----------------------------+----------+---------------------+<br/>| 169361 | 14NKRmQSBbCB5p0LAXWRp47dN3F |        0 | awaiting-scheduling |<br/>| 169362 | 14NKRmQSBbCB5p0LAXWRp47dN3F |        1 | executing           |<br/>| 169363 | 14NKRmQSBbCB5p0LAXWRp47dN3F |        1 | awaiting-retry      |<br/>| 169364 | 14NKRmQSBbCB5p0LAXWRp47dN3F |        2 | executing           |<br/>| 169365 | 14NKRmQSBbCB5p0LAXWRp47dN3F |        2 | awaiting-retry      |<br/>| 169366 | 14NKRmQSBbCB5p0LAXWRp47dN3F |        3 | executing           |<br/>| 169367 | 14NKRmQSBbCB5p0LAXWRp47dN3F |        3 | awaiting-retry      |<br/>+--------+-----------------------------+----------+---------------------+<br/>7 rows in set (0.00 sec)</span></pre><p id="2124" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">请注意，在快速转换到第一次交付尝试之前，作业首先从<code class="eh ng nh ni my b">awaiting-scheduling</code>状态开始。从那以后，工作总是失败，所以它在<code class="eh ng nh ni my b">executing</code>和<code class="eh ng nh ni my b">awaiting-retry</code>之间摇摆不定。</p><p id="e268" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">虽然这种跟踪对于内部调试肯定是有用的，但是它提供的主要好处是能够向最终客户实际展示给定事件的执行路径。(<em class="kg">敬请关注该功能，即将推出！</em>)</p><h1 id="97f1" class="ld jd hu bd je le lf lg ji lh li lj jm lk ll lm jq ln lo lp ju lq lr ls jy lt dt translated">与数据库交互:控制器</h1><p id="368e" class="pw-post-body-paragraph ke kf hu kh b ki lu kk kl km lv ko kp jn lw ks kt jr lx kw kx jv ly la lb lc hn dt translated">到目前为止，我们只关注我们工作的数据模型。我们已经展示了它们如何存储在RDS实例中，以及如何填充<code class="eh ng nh ni my b">jobs</code>表和<code class="eh ng nh ni my b">jobs_state_transitions</code>表。</p><p id="3cdf" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">但是我们仍然需要理解服务将数据写入数据库并实际执行我们的HTTP请求。我们称这项服务为离心机指导。</p><p id="e25b" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">传统上，网络服务有许多读者和作者与一个单一的、集中的数据库交互。有一个无状态的应用层，它由任意数量的分片数据库支持。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nl"><img src="../Images/c7655e54efd77ba135ffe1e863e940d7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*Ly5Dh4Ku-el9Ltre.png"/></div></div></figure><p id="80f5" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">请记住，该部分的工作负载看起来与传统的web服务非常不同。</p><p id="8a5d" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">我们的工作负载是非常重的写负载，没有读负载，并且不需要跨单独作业的连接或查询协调。相反，我们的目标是最大限度地减少不同写入程序之间的争用，以保持尽可能快的写入速度。</p><p id="9435" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">为此，我们采用了一种体系结构，其中单个控制器与给定的数据库进行交互。控制器管理其所有的缓存、锁定和进程内查询。因为控制器是唯一的写入者，所以它可以通过零协调来管理其所有的<a class="ae ka" href="https://en.wikipedia.org/wiki/Cache_invalidation" rel="noopener ugc nofollow" target="_blank">缓存失效</a>。</p><p id="0ebb" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">控制器唯一需要全局协调的是它要写入的特定数据库。我们将连接的数据库称为JobDB，接下来是控制器如何协调获取和发送消息到JobDB的体系结构视图。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mf"><img src="../Images/00d18ebb662e6459bd6a14a77777ec06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*swfBlJRfQyKtaJDG.png"/></div></div></figure><p id="e0ca" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">当控制器首次启动时，它遵循以下生命周期:</p><p id="886b" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">通过Consul获得一个备用JobDB开始运行；控制器首先进行查找，并获得针对给定JobDB的关键字的<a class="ae ka" href="https://www.consul.io/docs/internals/sessions.html" rel="noopener ugc nofollow" target="_blank">咨询会话</a>。如果另一个控制器已经持有锁，当前控制器将重试，直到找到可用的备用JobDB。</p><p id="e582" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">协商会话确保给定数据库不会被多个控制器同时写入。它们是互斥的，由一个作者持有。会话还允许我们锁定整个密钥空间，以便控制器可以在Consul中自由地更新JobDB的状态，同时它继续持有锁。</p><pre class="ma mb mc md fq mx my mz na aw nb dt"><span id="3712" class="jc jd hu my b fv nc nd l ne nf">import (<br/>    ...<br/>    "github.com/segmentio/consul-go"<br/> )</span><span id="7b66" class="jc jd hu my b fv nm nd l ne nf">// AcquireLock satisfies the centrifuge.Registry interface.<br/>func (r *Registry) AcquireLock(ctx context.Context, locks ...string) (context.Context, context.CancelFunc) {<br/>    lockKeys := make([]string, len(locks))<br/>    for i, lock := range locks {<br/>        lockKeys[i] = r.lockKey(lock)<br/>    }<br/>    sessionCtx, cancel := consul.WithSession(ctx, consul.Session{<br/>        Name:      "centrifuge",<br/>        Behavior:  consul.Delete,<br/>        LockDelay: r.lockDelay,<br/>        TTL:       r.lockTimeout,<br/>    })<br/>    lockCtx, unlock := r.locker.TryLockOne(sessionCtx, lockKeys...)<br/>    if lockCtx.Err() != nil {<br/>        return lockCtx, func() { unlock(); cancel() }<br/>    }<br/>    acquired := lockCtx.Value(consul.LocksKey).([]string)[0]<br/>    for i, lockKey := range lockKeys {<br/>        if lockKey == acquired {<br/>            return context.WithValue(lockCtx, centrifuge.LockKey, locks[i]), func() { unlock(); cancel() }<br/>        }<br/>    }<br/>    unlock()<br/>    cancel()<br/>    panic(fmt.Sprintf("BUG: the lock key acquired by the consul client was not found in the set of lock keys passed to TryLockOne (acquired lock = %s, candidates = %v)", acquired, lockKeys))<br/>}</span></pre><p id="b996" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">连接到作业数据库，并创建新表—一旦控制器连接到备用作业数据库，它需要在连接的数据库中创建必要的表。</p><p id="5bc2" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">我们没有使用ORM层，而是使用了标准的<a class="ae ka" href="https://golang.org/pkg/database/sql/" rel="noopener ugc nofollow" target="_blank">数据库/sql </a> golang接口，由<a class="ae ka" href="https://github.com/go-sql-driver/mysql" rel="noopener ugc nofollow" target="_blank"> go-sql-driver/mysql </a>实现提供支持。许多这些查询和准备好的语句都是通过<a class="ae ka" href="https://blog.golang.org/generate" rel="noopener ugc nofollow" target="_blank"> go:generate </a>生成的，但也有一些是手写的。</p><p id="7cb6" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">开始侦听新作业并在Consul中注册—在Director创建完必要的表后，它会在Consul中注册，以便客户端可以开始向Director发送流量。</p><p id="0686" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">开始执行作业—一旦控制器完全运行，它就开始接受作业。这些作业首先被记录到配对的JobDB然后，控制器开始将每个作业交付给其指定的端点。</p><p id="454a" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">现在我们已经了解了Directors和JobDBs之间的关系，我们可以回顾一下系统的属性(不可变、工作集非常小、没有数据库连接的写负载)，并了解离心机是如何快速吸收流量的。</p><p id="22a4" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在正常操作下，控制器很少需要读取连接的JobDB。因为所有作业都是不可变的，并且控制器是唯一的写入者，所以它可以将所有作业缓存在内存中，并在交付后立即使其过期。它唯一需要从数据库中读取的时间是从故障中恢复的时候。</p><p id="4d42" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">查看我们的内存配置文件的<a class="ae ka" href="https://blog.golang.org/profiling-go-programs" rel="noopener ugc nofollow" target="_blank"> pprof，我们可以看到很大一部分堆对象确实属于缓存作业的范畴:</a></p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nn"><img src="../Images/4729729f10e7aa6c3a052701108b6e87.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZLevofdhC-d1M9G9.png"/></div></div></figure><p id="012c" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">多亏了缓存，我们的写操作控制了我们的读操作。这是我们从单个活动数据库中提取的示例<a class="ae ka" href="https://aws.amazon.com/cloudwatch/" rel="noopener ugc nofollow" target="_blank"> Cloudwatch </a>指标。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff no"><img src="../Images/5271d6ee55b24552f001c5108bd1c9d0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1s1ekSQxaQYsZn63.png"/></div></div></figure><p id="49d7" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">由于所有的作业都非常短暂(通常只有几百毫秒的执行时间)，我们可以快速终止缓存中的作业。</p><h1 id="915f" class="ld jd hu bd je le lf lg ji lh li lj jm lk ll lm jq ln lo lp ju lq lr ls jy lt dt translated">现在都在一起</h1><p id="4f89" class="pw-post-body-paragraph ke kf hu kh b ki lu kk kl km lv ko kp jn lw ks kt jr lx kw kx jv ly la lb lc hn dt translated">退一步讲，我们现在可以将离心机数据模型的概念与Director和JobDB结合起来。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mf"><img src="../Images/91bf965d9a93f43a5dd517d66b298d26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*D9vivaxH_ngg1Bxb.png"/></div></div></figure><p id="98bc" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">首先，主管负责通过RPC接受新的工作。当它收到RPC请求时，它将继续将这些作业记录到附加的JobDB中，并在作业成功持久化后用一个事务ID进行响应。</p><p id="1969" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">从那里，Director向所有指定的端点发出请求，在必要时重试作业，并将所有状态转换记录到JobDB。</p><p id="9aa3" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">如果Director在到期时间(在我们的例子中为4小时)后未能交付任何作业，它们将在S3上存档，以便稍后重新处理。</p><h1 id="a719" class="ld jd hu bd je le lf lg ji lh li lj jm lk ll lm jq ln lo lp ju lq lr ls jy lt dt translated">随负载扩展</h1><p id="a285" class="pw-post-body-paragraph ke kf hu kh b ki lu kk kl km lv ko kp jn lw ks kt jr lx kw kx jv ly la lb lc hn dt translated">当然，单个控制器无法处理我们系统上的所有负载。</p><p id="c13a" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在生产中，我们运行许多独立的控制器，每个控制器可以处理一小部分流量。在过去的一个月里，我们一直在峰值负载下运行80到300个控制器。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff np"><img src="../Images/5dcbff934b2cf1048daf3be2481e16c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*uZGuFGog1gYoaPJJ.gif"/></div></div></figure><p id="9220" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">像我们在细分市场的所有其他服务一样，控制器根据CPU的使用情况进行自我扩展。如果我们的系统开始在负载下运行，<a class="ae ka" href="https://docs.aws.amazon.com/AmazonECS/latest/developerguide/service-auto-scaling.html" rel="noopener ugc nofollow" target="_blank"> ECS自动扩展规则</a>将添加控制器。如果超出容量，ECS会将其移除。</p><p id="3721" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">然而，离心机为我们创造了一种有趣的新运动。我们需要适当地上下扩展我们的存储层(单个作业数据库),以匹配我们的计算层(控制器容器的实例)的扩展。</p><p id="ebe6" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">为此，我们创建了一个名为JobDB Manager的独立二进制文件。经理的工作是不断调整数据库的数量以匹配控制器的数量。它保留了一个“备用”数据库池，以防我们突然需要扩展。它将在非高峰时段淘汰旧的数据库。</p><p id="3943" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">为了保持“小工作集”更小，我们大约每30分钟循环一次这些作业。当作业数据库的填充百分比数据目标即将超过可用RAM时，管理器会循环这些作业数据库。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nq"><img src="../Images/db8009043b0bfac10de550a1e8621d57.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*QIdmzrtldKeeJ10I.png"/></div></div></figure><p id="978a" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">数据库的这种循环确保了没有一个数据库会因为必须在RAM之外不断增加内存而变慢。</p><p id="b18d" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">为了获得更好的性能，我们不再发出大量的随机删除，而是将这些删除批处理到一个<code class="eh ng nh ni my b">drop table</code>中。如果控制器退出并不得不重新启动，它只能将少量数据从JobDB读入内存。</p><p id="0633" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">30分钟过去后，99.9%的事件要么失败，要么被提交，一小部分事件目前正在重试过程中。然后，管理器负责将一个小的drainer进程与每个JobDB配对，它会在完全删除现有表之前将当前正在重试的作业迁移到另一个数据库中。</p><h1 id="bc29" class="ld jd hu bd je le lf lg ji lh li lj jm lk ll lm jq ln lo lp ju lq lr ls jy lt dt translated">生产中</h1><p id="f7a1" class="pw-post-body-paragraph ke kf hu kh b ki lu kk kl km lv ko kp jn lw ks kt jr lx kw kx jv ly la lb lc hn dt translated">今天，我们使用离心机通过细分市场充分传递所有事件。这些数字意味着:</p><ul class=""><li id="bd62" class="mh mi hu kh b ki kj km kn jn mj jr mk jv ml lc mm mn mo mp dt translated">来自5名工程师的800项承诺</li><li id="d208" class="mh mi hu kh b ki mq km mr jn ms jr mt jv mu lc mm mn mo mp dt translated">50000行Go代码</li><li id="b248" class="mh mi hu kh b ki mq km mr jn ms jr mt jv mu lc mm mn mo mp dt translated">9个月的构建、正确性测试和生产部署</li><li id="316e" class="mh mi hu kh b ki mq km mr jn ms jr mt jv mu lc mm mn mo mp dt translated">每秒400，000个出站HTTP请求</li><li id="1eaf" class="mh mi hu kh b ki mq km mr jn ms jr mt jv mu lc mm mn mo mp dt translated">每秒200万个负载测试HTTP请求</li><li id="3519" class="mh mi hu kh b ki mq km mr jn ms jr mt jv mu lc mm mn mo mp dt translated">上个月完成了3400亿份工作</li></ul><p id="f294" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">平均而言，我们发现大约1.5%的全局数据在重试时成功，而在第一次交付尝试时没有成功。</p><p id="1ae2" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">根据你的观点，1.5%听起来可能是也可能不是一个大数字。对于一个早期创业公司来说，1.5%的精度几乎没有意义。对于一家收入数十亿美元的大型零售商来说，1.5%的准确度意义非凡。</p><p id="98a2" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在下图中，您可以看到按“尝试次数”划分的所有成功重试次数。我们通常会在第二次尝试时传递大多数邮件(黄色大条)，但大约50%的重试只有在第三次到第十次尝试时才会成功。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nr"><img src="../Images/820158d09735a07478fe291788da5eb5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*CiphmFA5XctcEw1s.png"/></div></div></figure><p id="cf4d" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">当然，看到系统在“稳态”下运行并不是离心机最有趣的部分。它旨在吸收高负载故障情况下的流量。</p><p id="1c67" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">我们已经在试运行帐户中测试了许多这样的场景，但是还没有在生产中真正看到第三方宕机。全面展示一个月后，我们终于观察到系统在高故障状态下运行。</p><p id="dbf7" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">3月17日下午4:45，我们一个更受欢迎的集成开始报告高延迟和500秒的提升。在正常操作下，这个API每秒接收16，000个请求，这在我们的出站流量负载中占了相当大的一部分。</p><p id="83ee" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">从下午4:45到6:30，我们的监控看到了一个急剧下降，性能急剧下降。成功呼叫的百分比下降到正常流量负载的大约15%。</p><p id="7a34" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在这里，您可以看到深红色的成功呼叫图，它是根据一周前的数据绘制的，用细虚线表示。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ns"><img src="../Images/baca7a256151939985cae4fb33f74a20.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*1eyuA9p-X2NkcPSk.png"/></div></div></figure><p id="f5d1" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在此期间，离心机开始快速重试失败的请求。我们的指数回退策略开始生效，我们开始尝试重新发送任何失败的请求。</p><p id="7af8" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在这里，您可以看到对第三方端点的请求量。无可否认，这一策略仍需要一些调整——在峰值时，我们每秒钟向合作伙伴的API发送大约100，000个请求。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nt"><img src="../Images/b620552fc677bc5e46d3c86111999c11.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*2RWxU4kfSNvL84to.png"/></div></div></figure><p id="cc56" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">您可以看到请求在最初的几分钟内迅速开始重试，但是当它们达到指数级回退周期时就变得平稳了。</p><p id="1559" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">这次停机是我们第一次真正展示离心机的真正威力。在90分钟的时间里，我们设法在细分市场的基础设施中吸收了约8500万次分析事件。在中断后的30分钟内，系统成功地传送了所有排队的流量。</p><p id="c7db" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">观看这一事件令人难以置信地令人信服。系统按照预期工作:它扩大规模，吸收负载，然后在API恢复后刷新它。更好的是，我们共同的客户几乎没有注意到。少数人在向第三方工具交付数据时出现延迟，但没有人出现数据丢失。</p><p id="3a7a" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">最重要的是，这一次中断不会影响我们支持的任何其他集成的数据交付！</p><p id="6c0e" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">总之，关于离心机，我们还有很多可以说的。这就是为什么我们要为以后的文章保留一些实现细节。</p><p id="d6ce" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在本系列的下一篇文章中，我们计划分享:</p><ul class=""><li id="883b" class="mh mi hu kh b ki kj km kn jn mj jr mk jv ml lc mm mn mo mp dt translated">我们如何在将作业移入离心机时验证正确性和一次性交付</li><li id="180f" class="mh mi hu kh b ki mq km mr jn ms jr mt jv mu lc mm mn mo mp dt translated">我们如何优化系统以实现高性能和低成本写入</li><li id="bd95" class="mh mi hu kh b ki mq km mr jn ms jr mt jv mu lc mm mn mo mp dt translated">我们如何在离心机基础上启动一个即将到来的可视化项目</li><li id="302a" class="mh mi hu kh b ki mq km mr jn ms jr mt jv mu lc mm mn mo mp dt translated">我们计划在未来的版本中重新考虑哪些选择和属性</li></ul><p id="8821" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">在那之前，你可以期待离心机将继续发展。我们将继续追求不留任何数据。</p><h2 id="133a" class="jc jd hu bd je jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz dt translated">有兴趣加入我们的探索吗？我们在 <a class="ae ka" href="https://bit.ly/2L5qmMX" rel="noopener ugc nofollow" target="_blank"> <em class="nu">招人。</em> </a></h2></div><div class="ab cl nv nw hc nx" role="separator"><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa ob"/><span class="ny bw bk nz oa"/></div><div class="hn ho hp hq hr"><p id="e0f2" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">离心机是9个月开发和推广期的结果。</p><p id="fc74" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">Rick Branson 设计并构建了这个系统(并给它命名)。<a class="ae ka" href="https://github.com/achille-roussel" rel="noopener ugc nofollow" target="_blank"> Achille Roussel </a>构建了大部分核心功能、QA流程和性能优化。<a class="ae ka" href="https://github.com/maxence-charriere" rel="noopener ugc nofollow" target="_blank"> Maxence Charriere </a>负责构建最初的JobDB管理器以及大量的集成测试和检查。<a class="ae ka" href="https://github.com/anoonan" rel="noopener ugc nofollow" target="_blank"> Alexandra Noonan </a>建立了将排水器与工作数据库配对的功能，并帮助优化系统以满足我们的成本效率。汤姆·霍尔姆斯<a class="ae ka" href="https://github.com/tsholmes" rel="noopener ugc nofollow" target="_blank">编写了大部分的归档代码、过滤程序，并追踪了无数的边缘案例和错误。</a><a class="ae ka" href="https://twitter.com/julien_fabre" rel="noopener ugc nofollow" target="_blank"> Julien Fabre </a>帮助设计和构建了我们的负载测试环境。</p><p id="9723" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">特别感谢<a class="ae ka" href="https://www.linkedin.com/in/jcowling/" rel="noopener ugc nofollow" target="_blank"> James Cowling </a>对技术设计提出建议，并帮助我们思考两阶段提交语义。</p><p id="9e6e" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">最后，我们想分享一些开发和推广过程中的瞬间:</p><p id="98ee" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">2017年6月23日:Max、Rick和Achille首次开始在生产流量的子集上测试离心机。他们很兴奋。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff oc"><img src="../Images/dbd624641e95d17f5ad18442f0f8f7b9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*k7gMUd-a7xahgJEN.png"/></div></div></figure><p id="6021" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">2017年9月22日:Achille获得了一些关于自行车数据库的令人兴奋的想法。狂热的白板随之而来。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff od"><img src="../Images/efed52d6a109c38eba7c124e465a1e1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*jCph_n7X251d98HM.png"/></div></div></figure><p id="275c" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">2018年1月12日:我们达到了70%的流量流经系统的重要里程碑。汤姆对着照相机鞠躬。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mf"><img src="../Images/9982672bb55d131b279ec3d606ffcc37.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*qgzhMXK-DAWBcN6l.png"/></div></div></figure><p id="dc2f" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">2018年3月14日:我们在我们的“黑洞”帐户中创造了每秒2M消息的新负载测试记录。</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff od"><img src="../Images/c7745577fcee76a02df78ad436b0fc51.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*RNQKr69b59aennFj.png"/></div></div></figure><p id="433f" class="pw-post-body-paragraph ke kf hu kh b ki kj kk kl km kn ko kp jn kr ks kt jr kv kw kx jv kz la lb lc hn dt translated">2018年5月22日:汤姆、卡尔文、亚历山德拉和马克斯合影，因为我们之前忘记了。瑞克和阿奇尔正在旅行</p><figure class="ma mb mc md fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff oe"><img src="../Images/eeae090ff59742e1ecb0791ee475dec4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*P4L4BvfMjz0Ut8Do.png"/></div></div></figure><blockquote class="kb kc kd"><p id="87b7" class="ke kf kg kh b ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc hn dt translated">这篇文章最初出现在<a class="ae ka" href="https://bit.ly/2J0mhcp" rel="noopener ugc nofollow" target="_blank"> Segment博客</a>上，探讨了Segment如何每天可靠地向数百个公共API发送数十亿条消息，以及用于在生产中运行它的数据模型。<a class="ae ka" href="https://segment.com/?utm_source=hacker%20noon%20blog%20post" rel="noopener ugc nofollow" target="_blank"> Segment </a>，Hacker Noon的每周赞助商，目前提供90天免费试用——发送电子邮件至friends@segment，并提及Hacker Noon进行兑换。</p></blockquote></div></div>    
</body>
</html>