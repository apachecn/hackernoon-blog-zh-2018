<html>
<head>
<title>Best (and Free!!) Resources to understand Nuts and Bolts of Deep learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">最好(而且免费！！)了解深度学习具体细节的资源</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/best-and-free-resources-to-understand-nuts-and-bolts-of-deep-learning-9c51166ffdf5?source=collection_archive---------1-----------------------#2018-06-10">https://medium.com/hackernoon/best-and-free-resources-to-understand-nuts-and-bolts-of-deep-learning-9c51166ffdf5?source=collection_archive---------1-----------------------#2018-06-10</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/b55fbad3d0659695ad6bc4caac1ba306.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gB3wKIL21_F0zSTSEtdqcg.jpeg"/></div></div></figure><p id="5517" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">互联网上充斥着入门深度学习的教程。你可以选择从一流的斯坦福课程<a class="ae ka" href="http://cs231n.stanford.edu/" rel="noopener ugc nofollow" target="_blank"> CS221 </a>或<a class="ae ka" href="http://cs224d.stanford.edu/" rel="noopener ugc nofollow" target="_blank"> CS224 </a>、<a class="ae ka" href="http://www.fast.ai/" rel="noopener ugc nofollow" target="_blank">快速AI课程</a>或深度学习AI <a class="ae ka" href="https://www.deeplearning.ai/" rel="noopener ugc nofollow" target="_blank">课程</a>开始，如果你是一个绝对的初学者。除了深度学习人工智能，其他都是免费的，可以在家里舒适地使用。你所需要的只是一台好的电脑(最好是配有Nvidia GPU的)，你可以迈出深度学习的第一步。</p><p id="cd85" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">然而，这个博客不是针对绝对初学者的。一旦你对深度学习算法如何工作有了一点直觉，你可能会想了解事情在引擎盖下是如何工作的。虽然深度学习的大多数工作(除了数据管理之外的10%，即总工作的90%)是添加Conv2d之类的层，在ADAM之类的不同类型的优化策略中更改超参数，或者使用batchnorm和其他技术，只是通过用Python编写一行命令(感谢可用的牛逼框架)，但许多人可能会强烈希望知道幕后发生了什么。这是一个资源列表，可以帮助你了解当你放置一个conv2d层或调用T.grad时，发生了什么。</p><h1 id="5bf1" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">综合论文</h1><p id="ca07" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">深度学习的书当然是最有名最知名的<a class="ae ka" href="http://www.deeplearningbook.org/" rel="noopener ugc nofollow" target="_blank">资源</a>。其他好的资源是Charniak教授的<a class="ae ka" href="https://cs.brown.edu/courses/csci1460/assets/files/deep-learning.pdf" rel="noopener ugc nofollow" target="_blank">课程</a>和<a class="ae ka" href="https://arxiv.org/abs/1709.01412" rel="noopener ugc nofollow" target="_blank">论文</a>，这是深度学习的技术介绍。如果你想从某个特定的角度去理解事物，你可能还想利用其他的资源。例如，<a class="ae ka" href="https://arxiv.org/abs/1801.05894" rel="noopener ugc nofollow" target="_blank">教程</a>是从应用数学家的角度编写的，如果你只是想开始编码而不想深入任何理论，那么在这里阅读<a class="ae ka" href="https://arxiv.org/abs/1703.05298" rel="noopener ugc nofollow" target="_blank"/>。还有一个推荐资源是PyTorch <a class="ae ka" href="https://documents.epfl.ch/users/f/fl/fleuret/www/dlc/" rel="noopener ugc nofollow" target="_blank">这里</a>的深度学习课程。本课程讲述自下而上的事情，并帮助你抓住一个更大的视角。</p><h1 id="ce06" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">关于反向传播的问题</h1><figure class="lf lg lh li fq iv fe ff paragraph-image"><div class="fe ff le"><img src="../Images/0025c19c22a35fc286f7d27fb11531e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*zgsFloJ5D7_kMmyy.jpg"/></div></figure><p id="97ff" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">很多时候，人们不确定“梯度下降和反向传播是怎么一回事？”或者“链式法则和反向传播到底是什么？”。为了理解基本原理，我们可以选择阅读鲁梅尔哈特、辛顿和威廉姆斯的原始论文，这是一切开始的地方。该文件位于<a class="ae ka" href="https://web.stanford.edu/class/psych209a/ReadingsByDate/02_06/PDPVolIChapter8.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>，是一份非常简单易懂的文件。</p><p id="3bd5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">除此之外，你还可以阅读一些非常有用的资源，比如Karpathy关于反向<a class="ae ka" rel="noopener" href="/@karpathy/yes-you-should-understand-backprop-e2f06eab496b">道具推导的博客</a>和<a class="ae ka" href="https://www.youtube.com/watch?v=gl3lfL-g5mA" rel="noopener ugc nofollow" target="_blank">解释反向推导的视频</a>。</p><h1 id="57cf" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">线性代数和其他数学</h1><figure class="lf lg lh li fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lj"><img src="../Images/9bd121cee15ca22a0bbf6f5922c10802.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dev19_3fvHjIZPCL.jpg"/></div></div></figure><p id="406a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">任何人都会把渴望学习线性代数的人转到斯特朗教授的<a class="ae ka" href="https://ocw.mit.edu/courses/mathematics/18-06-linear-algebra-spring-2010/" rel="noopener ugc nofollow" target="_blank">课程</a>。这可能是世界上最好的线性代数资源。类似的情况还有Boyd教授的最优化课程<a class="ae ka" href="http://web.stanford.edu/~boyd/cvxbook" rel="noopener ugc nofollow" target="_blank">这里</a>或者向量微积分的流形上的微积分书(你可以在谷歌上搜索“流形上的微积分”找到pdf)。然而，人们不需要通过这些资源查看其主题的深度来跳入深度学习。一个非常快速的开始方法是快速复习深度学习的所有先决微积分，可以在这里<a class="ae ka" href="https://arxiv.org/abs/1802.01528" rel="noopener ugc nofollow" target="_blank">找到</a>。还有一套非常好的<a class="ae ka" href="http://people.eecs.berkeley.edu/~elghaoui/Teaching/EE227BT/lectures.html" rel="noopener ugc nofollow" target="_blank">讲义</a>来看看深度学习中使用的凸优化。另一个很好的资源是Sebastian Reuder的论文。我也喜欢这些讲义来理解<a class="ae ka" href="https://github.com/mtomassoli/tensor-differential-calculus/blob/master/tensor_diff_calc.pdf" rel="noopener ugc nofollow" target="_blank">张量</a>上的导数。</p><h1 id="8db1" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">自动微分和深度学习库</h1><figure class="lf lg lh li fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lj"><img src="../Images/60d7481c52d1fb165b2c701ab9a5e4f9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*7YyexzeuRDEekuc1.jpg"/></div></div></figure><p id="9ffa" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">当你在做深度学习时，自动微分并不是你绝对需要知道的东西。大多数框架如Torch、Theano或tensorflow会自动为您完成。在大多数情况下，你甚至不需要知道微分是如何进行的。也就是说，如果你决心了解深度学习框架如何工作，你可能想了解自动微分如何工作<a class="ae ka" href="https://arxiv.org/abs/1502.05767" rel="noopener ugc nofollow" target="_blank">这里</a>。了解深度学习库如何工作的其他好资源可以在这个<a class="ae ka" href="http://blog.christianperone.com/2018/03/pytorch-internal-architecture-tour" rel="noopener ugc nofollow" target="_blank">博客</a>和<a class="ae ka" href="https://www.youtube.com/watch?v=Lo1rXJdAJ7w" rel="noopener ugc nofollow" target="_blank">视频</a>中找到。</p><h1 id="4e67" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">卷积神经网络；</h1><figure class="lf lg lh li fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lj"><img src="../Images/bb1523fb43e0d4599de0dcd73f1eddb2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*19dCw63XxzmPj5u4.jpg"/></div></div></figure><p id="8b45" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在你完成一些使你能够使用基本修道院的课程后，你可能需要的最有用的东西是理解卷积如何在图像上工作。"对输入应用某种类型的卷积后，输出形状是什么？"，“步幅如何影响卷积？”，“什么是批量正常化？”诸如此类的东西。我见过的关于这类应用题的两个最佳资源是这里的教程<a class="ae ka" href="https://arxiv.org/abs/1603.07285" rel="noopener ugc nofollow" target="_blank">和这里的Ian Goodfellow的演讲</a><a class="ae ka" href="https://www.youtube.com/watch?v=Xogn6veSyxA" rel="noopener ugc nofollow" target="_blank"/>。如果你想得到一个想法，这里有一篇关于Convnets的更全面的<a class="ae ka" href="https://arxiv.org/abs/1803.08834" rel="noopener ugc nofollow" target="_blank">评论</a>。这篇关于物体检测的<a class="ae ka" href="https://towardsdatascience.com/deep-learning-for-object-detection-a-comprehensive-review-73930816d8d9" rel="noopener" target="_blank">综述</a>是该主题中非常好的资源。</p><h1 id="e831" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">自然语言处理中的深度学习</h1><figure class="lf lg lh li fq iv fe ff paragraph-image"><div class="fe ff le"><img src="../Images/05862edb59329cb7102c4ce3b0826641.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*lLK-VimEuw9TO9Od.png"/></div></figure><p id="96a0" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我之前在博客中指出的斯坦福224课程是一个非常好的起点，你应该对几乎所有事情都足够好。youtube上还有Graham Neubig(使用dynet)的课程<a class="ae ka" href="https://www.youtube.com/watch?v=Sss2EA4hhBQ" rel="noopener ugc nofollow" target="_blank">这里</a>。还有一本由Yoav Goldberg写的NLP书籍，你可能会喜欢。在这本书写完之后，NLP的(更新)进展在这里<a class="ae ka" href="https://arxiv.org/abs/1708.02709" rel="noopener ugc nofollow" target="_blank">被回顾</a>。还有一个很常见的问题，关于在文本上使用convnets还是RNNs (LSTMs/GRUs)。这里有一个很好的概述<a class="ae ka" href="https://arxiv.org/pdf/1803.01271.pdf" rel="noopener ugc nofollow" target="_blank"/>。</p><h1 id="b825" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">强化学习</h1><figure class="lf lg lh li fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff lj"><img src="../Images/4ad0bd7a86b9bdf2d3d23c95856e766c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*dNc1D0VEbIGrBkEY.png"/></div></div></figure><p id="2039" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">萨顿和巴尔托是这些方法的入门圣经。这本书是免费的，在这里可以买到。这里有一篇关于最近深度强化学习方法的很好的综述<a class="ae ka" href="https://arxiv.org/abs/1708.05866" rel="noopener ugc nofollow" target="_blank"/>。这里有一本非常有趣的关于强化学习的教程<a class="ae ka" href="https://hackernoon.com/intuitive-rl-intro-to-advantage-actor-critic-a2c-4ff545978752" rel="noopener ugc nofollow" target="_blank"/>。</p><p id="779a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">蒙特卡洛树搜索(除深度强化学习技术外，是Deepmind apart算法的一部分)的一个很好的综述<a class="ae ka" href="http://mcts.ai/pubs/mcts-survey-master.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>。然而，我使用<a class="ae ka" href="http://jeffbradberry.com/posts/2015/09/intro-to-monte-carlo-tree-search/?utm_source=top.caibaojian.com/19271" rel="noopener ugc nofollow" target="_blank">这个</a>快速教程来了解它们。</p><h1 id="998b" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">其他一些好的评论/教程</h1><p id="d50f" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">Goodfellow在2016年ICLR大会上给出了一个关于GANs(生成对抗网络)和生成模型的很好的教程。这里可以找到<a class="ae ka" href="https://www.youtube.com/watch?v=HGYYEUSm-0Q" rel="noopener ugc nofollow" target="_blank">。神经网络已被用于传输art(例如在Prisma app中)，详细的方法调查可在</a><a class="ae ka" href="https://arxiv.org/abs/1705.04058" rel="noopener ugc nofollow" target="_blank">这里</a>找到。Reuder关于多任务学习(通过相同的神经网络组合多个任务)的另一个很好的调查是这里的<a class="ae ka" href="https://arxiv.org/abs/1706.05098" rel="noopener ugc nofollow" target="_blank"/><strong class="je hv">。</strong></p><h1 id="ac50" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">批评</h1><p id="e5f8" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">虽然深度学习在多个问题上的效果令人惊讶，但我们知道总会有一些地方他们还没有到达。一些值得一读的好的批评是Shalev-Shwartz等人的基于梯度的学习的失败，Hinton的这个演讲列出了convnets T21的一些困难，以及conv nets如何不能破译他们在T23上训练的图像的底片。几天前，这里的另一个批评成为了病毒/争议，那就是这个。还有<a class="ae ka" href="https://arxiv.org/abs/1802.07228" rel="noopener ugc nofollow" target="_blank">这篇关于深度学习恶意使用的广泛报道</a>。</p><h1 id="269a" class="kb kc hu bd kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky dt translated">对立的例子</h1><p id="8597" class="pw-post-body-paragraph jc jd hu je b jf kz jh ji jj la jl jm jn lb jp jq jr lc jt ju jv ld jx jy jz hn dt translated">这是一个制造人工/真实数据点的巨大领域，可以欺骗Convnets。我本可以把它放在评论区，但是我没有</p><p id="414e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">1)它们不是所有应用的技术挑战，并且</p><p id="4f02" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">2)我对它们不是很了解。一个非常酷的开始和感兴趣的案例是<a class="ae ka" href="https://www.labsix.org/physical-objects-that-fool-neural-nets/" rel="noopener ugc nofollow" target="_blank">这里</a>他们生成“敌对对象”来欺骗神经网络。</p><p id="19df" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你也可以在这里阅读成为数据科学家<a class="ae ka" href="https://blog.paralleldots.com/data-science/machine-learning/ten-machine-learning-algorithms-know-become-data-scientist/" rel="noopener ugc nofollow" target="_blank">应该知道的机器学习算法。</a></p><p id="661d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们希望你喜欢这篇文章。请<a class="ae ka" href="http://user.apis.paralleldots.com/signing-up?utm_source=blog&amp;utm_medium=chat&amp;utm_campaign=paralleldots_blog" rel="noopener ugc nofollow" target="_blank">注册</a>免费的ParallelDots账户，开始你的AI之旅。你也可以在这里查看PrallelDots AI API<a class="ae ka" href="https://www.paralleldots.com/text-analysis-apis" rel="noopener ugc nofollow" target="_blank">的演示。</a></p><p id="4480" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这里可以阅读原文<a class="ae ka" href="https://blog.paralleldots.com/data-science/deep-learning/best-and-free-resources-to-understand-of-deep-learning/" rel="noopener ugc nofollow" target="_blank">。</a></p><div class="lk ll fm fo lm ln"><a href="https://hackernoon.com/tagged/deep-learning" rel="noopener  ugc nofollow" target="_blank"><div class="lo ab ej"><div class="lp ab lq cl cj lr"><h2 class="bd hv fv z el ls eo ep lt er et ht dt translated">深度学习——黑客正午</h2><div class="lu l"><h3 class="bd b fv z el ls eo ep lt er et ek translated">在黑客正午阅读关于深度学习的写作。黑客如何开始他们的下午？</h3></div><div class="lv l"><p class="bd b gc z el ls eo ep lt er et ek translated">hackernoon.com</p></div></div><div class="lw l"><div class="lx l ly lz ma lw mb ja ln"/></div></div></a></div></div></div>    
</body>
</html>