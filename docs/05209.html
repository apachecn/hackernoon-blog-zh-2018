<html>
<head>
<title>Cats to crazy quilts: Using style transfer to generate adversarial examples</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">从《猫到疯狂的被子》:运用风格转移产生对立的例子</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/cats-to-crazy-quilts-using-style-transfer-to-generate-adversarial-examples-b88eef073d04?source=collection_archive---------15-----------------------#2018-06-20">https://medium.com/hackernoon/cats-to-crazy-quilts-using-style-transfer-to-generate-adversarial-examples-b88eef073d04?source=collection_archive---------15-----------------------#2018-06-20</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><h1 id="e370" class="ir is hu bd it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo dt translated"><strong class="ak">前奏:</strong></h1><p id="d9f8" class="pw-post-body-paragraph jp jq hu jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt translated">让我们先简单介绍一下对抗性输入的世界。这些是进入<a class="ae kn" href="https://hackernoon.com/tagged/machine-learning" rel="noopener ugc nofollow" target="_blank">机器学习</a>分类器的输入，这些输入已经被精明地扰乱，以至于这些变化对于肉眼来说几乎是该死的不可见的，但是可以欺骗机器学习分类器来预测任意的错误类别(无针对性的)或者特定的错误类别(有针对性的)。</p><p id="c531" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">当我想到这个领域时，脑海中浮现出两个典型的形象。第一张是经典的<em class="kt">熊猫变成线虫</em>的图片，来自<a class="ae kn" href="https://arxiv.org/pdf/1412.6572.pdf" rel="noopener ugc nofollow" target="_blank">这里</a>。</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div class="fe ff ku"><img src="../Images/f4e0e9bf45d481585f4aaeb53193191b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*qEDDXIassDlGeL1fnuumCw.png"/></div><figcaption class="lc ld fg fe ff le lf bd b be z ek">The now iconic example of a panda’s image getting perturbed into a gibbon (Source: <a class="ae kn" href="https://arxiv.org/pdf/1412.6572.pdf" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/pdf/1412.6572.pdf</a> )</figcaption></figure><p id="6b7e" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">第二个，是下面的这个，提供了这些对抗性输入实际存在的几何视角。</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div class="fe ff lg"><img src="../Images/bba84e4af616f66cb55b6426dff9fee9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1238/format:webp/1*r-vRrUZgjRi-DesNCM8XtQ.png"/></div><figcaption class="lc ld fg fe ff le lf bd b be z ek">An image that provides a geometrical perspective on the adversarial inputs (Source: <a class="ae kn" href="https://infoscience.epfl.ch/record/229872/files/spm_preprint.pdf" rel="noopener ugc nofollow" target="_blank">https://infoscience.epfl.ch/record/229872/files/spm_preprint.pdf</a> )</figcaption></figure><p id="ab4f" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">在我<a class="ae kn" href="https://unify.id/labs/" rel="noopener ugc nofollow" target="_blank">工作的地方</a>，在非计算机视觉环境中利用对立的例子进行数据集扩充(以提高健壮性和可推广性)是我们管道的关键部分。在这方面，我们已经传播了一些浅显的尝试，例如基于深度学习的步态生物识别对对抗性扰动的脆弱性灰箱对抗性攻击的<a class="ae kn" href="https://unify.id/2017/07/21/vulnerability-of-deep-learning-based-gait-biometric-recognition-to-adversarial-perturbations-2/" rel="noopener ugc nofollow" target="_blank"><em class="kt"/></a><em class="kt"/><a class="ae kn" href="https://unify.id/wp-content/uploads/2018/03/greybox_attack.pdf" rel="noopener ugc nofollow" target="_blank"><em class="kt">以及对李亚普诺夫指数和对抗性扰动的迁移学习</em> </a> <em class="kt">和</em> <a class="ae kn" href="https://unify.id/wp-content/uploads/2018/03/lyap_e.pdf" rel="noopener ugc nofollow" target="_blank"> <em class="kt">。</em>T25】</a></p><p id="5a54" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">最近，在尝试使用<strong class="jr hv"> <em class="kt">插值风格转换</em> </strong>来生成相互对立的图像对的想法时，我偶然发现了围绕机器学习的一个更基本的问题的模糊性:什么构成了真正的标签，以及提供商业现成(OTS)<a class="ae kn" href="https://hackernoon.com/tagged/apis" rel="noopener ugc nofollow" target="_blank">API</a>的机器学习公司如何定义它？</p><h1 id="6fd6" class="ir is hu bd it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo dt translated">TLDR: </h1><p id="8ec4" class="pw-post-body-paragraph jp jq hu jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt translated">1:我们描述了一个实验，该实验需要在特定的流行商业现成(OTS) API的上下文中使用风格转移图像来针对错误分类(我使用<em class="kt"> Watson视觉识别- V3 API，版本2016–05–20</em>API获得此处显示的所有结果。)</p><p id="d56a" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">2:风格转移图像实现了97:5 %的对抗攻击成功率(195/200)。</p><p id="81ba" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">3:目标是<em class="kt">不宣布一个新的黑盒攻击方法</em>或痛斥所使用的商业API，而是仅仅强调围绕什么构成真正的标签或真正的标记的模糊性。这是简单观察的一个原因，即当使用内插风格转移作为产生相互对立对的方法时，对立扰动的“<em class="kt">原始图像</em>不一定是自然出现的图像，而是风格转移图像本身。</p><p id="283a" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">4:提出使用插值风格转移作为生成可用于模型正则化的相互对立的对的配方的想法，以及生成<em class="kt">挑战</em>类图像作为输入到训练管道中的暹罗网的想法，如<em class="kt">嵌入在三重损失成本函数上训练的深网</em>。</p><p id="8eee" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">5:在此提出使用插值权重作为<em class="kt">新语义ε</em>的想法:</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="fe ff lh"><img src="../Images/e78390a4eb5fcae29f2f8d9d2c174235.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*RiG6x4etj-hydp5bgpEfMw.png"/></div></div><figcaption class="lc ld fg fe ff le lf bd b be z ek">Time for a new <strong class="bd lm">semantic epsilon</strong>?</figcaption></figure><h1 id="4ba6" class="ir is hu bd it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo dt translated"><strong class="ak">深潜:</strong></h1><p id="144c" class="pw-post-body-paragraph jp jq hu jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt translated">有了这个前奏，深潜开始了。</p><p id="e6aa" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">让我们首先关注下图:</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div class="fe ff ln"><img src="../Images/d8c1e9a7373e72563de1ace55f299e9f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1372/format:webp/1*AjiSIwHRzFC-YqkCI29CuA.png"/></div><figcaption class="lc ld fg fe ff le lf bd b be z ek">Cat2Fabric: The journey of a cat’s image into a pattern</figcaption></figure><p id="a248" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">我们看到的是使用<em class="kt">任意图像风格化</em>【2】<a class="ae kn" href="https://github.com/tensorflow/magenta/tree/master/magenta/models/arbitrary_image_stylization" rel="noopener ugc nofollow" target="_blank"><em class="kt">洋红色</em> </a> <em class="kt"> </em>项目，对于从0到1(从左到右)单调递增的不同插值权重，将猫的图像的<em class="kt">旅程</em>转换为“图案-风格-图像”。如所看到的，使用原始图像(插值权重(<em class="kt"> w=0 </em>)或具有低插值权重的风格转移图像(直到插值权重<em class="kt"> w=0.1 </em>)作为输入，商业OTS分类API已经如预期的那样<em class="kt">正确地</em>将图像分类为具有高置信度分数(0.97到0.99)的<strong class="jr hv"> <em class="kt">类别</em> </strong>。当我们将插值权重略微增加到<em class="kt"> w=0.15 </em>时，我们会看到推断的标签布局发生了巨大的变化。最容易被猜到的种类发生了戏剧性的变化，从<em class="kt">猫科、猫科和食肉动物</em>到<em class="kt">玻璃纸、蛾类和无脊椎动物</em>。<br/>虽然两幅图像对于肉眼来说实际上是不可区分的，并且在结构相似性距离方面仅仅相距<em class="kt"> 0.03 </em>(这是<em class="kt">1-结构相似性指数</em> [4】)(在无穷范数距离方面相距<em class="kt"> 0.125 </em>)，但是由黑盒分类器分配给两幅图像的标签被证明是非常不同的。<br/>因此，我们将这一对称为构成关于黑盒分类器和所用距离度量的<em class="kt">相互对立对</em>。分类器可能已经学习的基于局部纹理的特征，可能已经诱使它做出错误的分类，而图像仍然看起来像猫的图像。现在出现了一个自然的疑问，艺术风格转移的<strong class="jr hv">合成生成的</strong>图像(具有<em class="kt"> w=0.1) </em> <em class="kt">是否首先值得</em>被归类为<em class="kt">猫</em>。这类似于另一个相关的问题，当输入是一个真实世界的小雕像而不是一个有生命的存在时，什么是标准的期望类，这使我们看到了下图。</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="fe ff lo"><img src="../Images/f03f0ce037882f4aee09b6c902d32d3b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*zV8e46uZGmt9kfp8qT_VfA.png"/></div></div><figcaption class="lc ld fg fe ff le lf bd b be z ek">Is this a ‘Cat’ or a ‘Cat-figurine’?</figcaption></figure><p id="77b6" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">这里，我们看到了输入图像(该图像来源于<a class="ae kn" href="https://www.wayfair.com/keyword.php?keyword=outdoor+cat+sculptures" rel="noopener ugc nofollow" target="_blank">这里是</a>)。我们发现这个特定的购物门户是这种小雕像艺术例子的特别好的来源。<br/>字面上是艺术猫雕像，其导致被归类为具有高置信度得分(<em class="kt"> 0.89 </em>)的<em class="kt">猫</em>的高置信度分类。</p><p id="85a8" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">实验程序的细节: <br/>询问上面讨论的猫的例子是否是特殊选择的确实是合理的。为了减轻这些担忧，我们做了以下实验。<br/>实验背后的主要质疑点如下:<br/> <em class="kt">用全局低插值权重进行风格转移的图像确实会导致误分类吗？</em>为此，我们从<a class="ae kn" href="https://www.kaggle.com/c/dogs-vs-cats" rel="noopener ugc nofollow" target="_blank"> <em class="kt"> Kaggle狗和猫</em> </a>数据集中提取了200张随机选择的猫图像。我们将它们的大小都调整为299 x 299，并使用从DTD数据集[1]中提取的相同样式图像对它们中的每一个进行了样式转换，使用的样式转换算法详见[2]。下图通过一个具体的例子展示了这一点。</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div class="fe ff lp"><img src="../Images/f04c49906b7a35d3f0d09b2ba5a52a76.png" data-original-src="https://miro.medium.com/v2/resize:fit:968/format:webp/1*6vPS_fdqMLuhg9qQVGHXiQ.png"/></div><figcaption class="lc ld fg fe ff le lf bd b be z ek">The concept</figcaption></figure><p id="4738" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">为了确保图像看起来仍然“像猫”，插值权重被设置为低<em class="kt">值</em>0.125。<br/>您可以在下面的gif动画中筛选所有原始图像和风格转换后的图像。</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div class="fe ff lq"><img src="../Images/f9804a139120d977794770e4c4ca6f0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:708/1*9GTAeyaRRPIYLOAqYdjWhA.gif"/></div><figcaption class="lc ld fg fe ff le lf bd b be z ek">Gif of true images and their style transferred counterparts</figcaption></figure><p id="5df8" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">现在，使用<em class="kt"> Watson视觉识别- V3 API，版本2016–05–20</em>API对原始图像和风格转换图像进行分类。<br/>设置输出类名语言的<em class="kt"> Accept-Language头字符串</em>被设置为<em class="kt"> en </em>。<br/><em class="kt">所有者查询数组</em>被设置为默认选项(<em class="kt"> IBM </em>)。<br/>将<em class="kt">分类标识</em>设置为<em class="kt">默认</em>不需要训练，并且<em class="kt">将从数千个通用标签</em>中返回类。代表类必须返回的最低分数的<em class="kt">阈值查询</em>参数被设置为<em class="kt"> 0.5 </em>。<br/>结果将在下一节介绍。<br/> <strong class="jr hv">结果:</strong></p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="fe ff lr"><img src="../Images/c227693726536cb2a0e2567f93fba5a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*SYEKiqjl5IWEnRkT67T2Gw.png"/></div></div><figcaption class="lc ld fg fe ff le lf bd b be z ek">Histogram of the top inferred labels</figcaption></figure><p id="c4d6" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">在上图中，我们看到了API返回的最有可能的类的数量。如所见，包含超过50%测试图像的前4个类别是<em class="kt">疯狂拼布、迷彩、马赛克和拼接</em>。</p><p id="ccc2" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">在下图中，我们看到了与200次分类试验相关的分数以及分数直方图。</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="fe ff ls"><img src="../Images/e392682a7d85eee6bc376c3e522f4774.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*eaEtyK0tX9ivCbWGlvzM8A.png"/></div></div><figcaption class="lc ld fg fe ff le lf bd b be z ek">Scores and histogram of scores returned by the Watson classifier for the 200 test images</figcaption></figure><p id="abea" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">正如所看到的，我们有大量的案例，其中错误分类与高置信度得分相关联。在下图中，我们看到了API正确分类的5张图片。</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div class="fe ff lt"><img src="../Images/80bcf680defc8db110f6a5fc7f1eaa77.png" data-original-src="https://miro.medium.com/v2/resize:fit:1228/format:webp/1*s8XuO5igmFLCxxTRkkVi5A.png"/></div><figcaption class="lc ld fg fe ff le lf bd b be z ek">The lucky 5: Correctly classified as ‘Cat’ by Watson</figcaption></figure><p id="f7b9" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">现在，在这个图中，我们看到随机选择的6个被错误分类的风格转移图像的例子。</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="fe ff lu"><img src="../Images/f32dda67cbc559794fee68216517a440.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hO2hcirlCr-cen43Wo4ECA.png"/></div></div><figcaption class="lc ld fg fe ff le lf bd b be z ek">6 random not-so luckies</figcaption></figure><p id="ff6b" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated"><strong class="jr hv">结论和未来工作</strong> <br/>由于自由层用户使用API的限制，我们无法将实验扩展到更大的数据集，这是我们的近期目标。除此之外，我们想探讨的另一个问题是风格形象的选择。我们选择纹理数据集的图像有两个原因。第一个是预先训练的风格转移模型是容易得到的。第二个原因是基于一种直觉，即纹理实际上是图像的正确方面，以至于<em class="kt">干扰</em>从而导致错误分类。<br/>正如序言中所述，我们的目的不是宣布一种新的黑盒攻击或痛斥商业API。</p><p id="1057" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">除了展示将样式转换视为对立示例生成技术的潜力之外，我们还希望提请注意，在这种API的情况下，什么构成图像类别或“标签”以及什么导致图像错误分类的定义存在固有的模糊性。<br/>我们使用的API<a class="ae kn" href="https://www.ibm.com/watson/services/visual-recognition/index.html\overview" rel="noopener ugc nofollow" target="_blank">将</a>技术描述为:<strong class="jr hv"> <em class="kt">沃森视觉识别的类别特定模型使您能够分析场景、物体、人脸、颜色、食物和其他内容的图像</em> </strong>。关于特定的<a class="ae kn" href="https://www.ibm.com/watson/developercloud/visual-recognition/api/v3/curl.html?curl\get-classify" rel="noopener ugc nofollow" target="_blank"> API文档</a>，据说在与预训练模型(代替定制训练的分类器)一起使用时，API <em class="kt">从数千个通用标签中返回类。</em></p><h1 id="e0a0" class="ir is hu bd it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo dt translated"><strong class="ak">链接:</strong></h1><p id="1869" class="pw-post-body-paragraph jp jq hu jr b js jt ju jv jw jx jy jz ka kb kc kd ke kf kg kh ki kj kk kl km hn dt translated">(该作品将在<a class="ae kn" href="http://vision.soic.indiana.edu/bright-and-dark-workshop-2018/" rel="noopener ugc nofollow" target="_blank">CV-COPS workshop</a>@ CVPR-2018上展示)</p><p id="3b2d" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">github:<a class="ae kn" href="https://github.com/vinayprabhu/Art_Attack" rel="noopener ugc nofollow" target="_blank">https://github.com/vinayprabhu/Art_Attack</a></p><p id="0b16" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">海报:</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="li lj di lk bf ll"><div class="fe ff lv"><img src="../Images/daf7a2c28c8d48dff1a244da25404043.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DrdqZi6P3xjZi54gLuJyfg.png"/></div></div><figcaption class="lc ld fg fe ff le lf bd b be z ek">Poster for the paper</figcaption></figure><p id="12c3" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated"><strong class="jr hv">参考文献</strong></p><p id="7b6c" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">[1] M. Cimpoi、S. Maji、I. Kokkinos、S. Mohamed和A. Vedaldi。描述野外的纹理。计算机视觉和模式识别(CVPR)，2014年IEEE会议，第3606–3613页。IEEE，2014年。</p><p id="750c" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">[2] G. Ghiasi、H. Lee、M. Kudlur、V. Dumoulin和J. Shlens。探索实时任意神经艺术风格化网络的结构。arXiv预印本arXiv:1705.06830，2017。</p><p id="36ec" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">[3]s-m .穆萨维-德兹富利、a .法齐、o .法齐和p .弗罗萨德。普遍的对抗性干扰。<a class="ae kn" href="https://arxiv.org/abs/1610.08401" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1610.08401</a></p><p id="ad1a" class="pw-post-body-paragraph jp jq hu jr b js ko ju jv jw kp jy jz ka kq kc kd ke kr kg kh ki ks kk kl km hn dt translated">[4] Z.Wang、A. C. Bovik、H. R. Sheikh和E. P. Simoncelli。图像质量评估:从误差可见性到结构相似性。IEEE图像处理汇刊，13(4):600–612，2004。</p><figure class="kv kw kx ky fq kz"><div class="bz el l di"><div class="lw lx l"/></div></figure></div></div>    
</body>
</html>