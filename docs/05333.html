<html>
<head>
<title>Generate stories using RNNs |pure Mathematics with code|:</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用RNNs生成故事|带代码的纯数学|:</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/generate-stories-using-rnns-pure-mathematics-with-code-cb6f1e967b22?source=collection_archive---------15-----------------------#2018-06-25">https://medium.com/hackernoon/generate-stories-using-rnns-pure-mathematics-with-code-cb6f1e967b22?source=collection_archive---------15-----------------------#2018-06-25</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><figure class="ht hu fm fo hv hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff hs"><img src="../Images/314cbec63462cef83ca0c67efc2b800e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*poULwl2FT06CkGhP6sZMrQ.jpeg"/></div></div></figure><div class=""/><p id="737e" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你好，读者！</p><blockquote class="ka kb kc"><p id="d9e3" class="jc jd kd je b jf jg jh ji jj jk jl jm ke jo jp jq kf js jt ju kg jw jx jy jz hn dt translated">读者注意:</p><p id="8687" class="jc jd kd je b jf jg jh ji jj jk jl jm ke jo jp jq kf js jt ju kg jw jx jy jz hn dt translated">这篇文章假设你对深度学习的数学世界非常着迷。你想要深入到深度学习的数学中去，以了解在引擎盖下实际发生了什么。</p><p id="6c00" class="jc jd kd je b jf jg jh ji jj jk jl jm ke jo jp jq kf js jt ju kg jw jx jy jz hn dt translated"><strong class="je ig">关于这篇文章的一些信息:</strong></p><p id="e064" class="jc jd kd je b jf jg jh ji jj jk jl jm ke jo jp jq kf js jt ju kg jw jx jy jz hn dt translated">在本文中，我们将从头开始讨论和实现RNNs。然后，我们将使用它们来生成文本(如诗歌、c++代码)。在阅读了Andrej Karpathy关于“<a class="ae kh" href="http://karpathy.github.io/2015/05/21/rnn-effectiveness/" rel="noopener ugc nofollow" target="_blank">递归神经网络</a>的不合理有效性”的博客后，我受到了写这篇文章的启发。这段代码生成的文本并不完美，但它给出了文本生成实际工作方式的直觉。我们的输入将是包含一些文本(如莎士比亚的诗)的纯文本文件，我们的程序将生成类似于输入(诗)的输出，这可能有意义，也可能没有意义。</p></blockquote><p id="5409" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">让我们深入RNNs的数学世界。</p><p id="fb8d" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">那么RNN的基本结构是什么呢？</p><figure class="kj kk kl km fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff ki"><img src="../Images/0fcac18e55b714cdf609e1ad8774bf8d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uubYiUNDmhmR5KOPdJKYtQ.png"/></div></div><figcaption class="kn ko fg fe ff kp kq bd b be z ek">Fig 1 :Vanilla RNN</figcaption></figure><figure class="kj kk kl km fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff kr"><img src="../Images/ce9ed6a2d5d360bb512d44d26069f785.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NKhwsOYNUT5xU7Pyf6Znhg.png"/></div></div><figcaption class="kn ko fg fe ff kp kq bd b be z ek">Fig 2: Unrolled Vanilla RNN</figcaption></figure><p id="0762" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">不要担心任何条款。我们将逐一讨论它们。它们很容易理解。</p><p id="7f03" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在图1中:</p><p id="fb86" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig">h(t)</strong>:RNN在时间t=t时的隐藏状态</p><p id="5472" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig"> fw </strong>:非线性函数(主要是tanh)</p><p id="71f5" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig"> Whh </strong>:随机初始化的权重矩阵。当我们从<strong class="je ig"> h </strong>移动到<strong class="je ig"> h </strong>时使用(隐藏状态到另一个隐藏状态)。</p><p id="351f" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig"> Wxh </strong>:随机初始化的权重矩阵。当我们从'<strong class="je ig"> x' </strong>移动到'<strong class="je ig"> h' </strong>(隐藏状态的输入)时使用。</p><p id="2e9a" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig">为什么</strong>:当我们从'<strong class="je ig"> h' </strong>移动到'<strong class="je ig"> y' </strong>呈现隐藏状态输出时，随机初始化权重矩阵。</p><p id="a240" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig"> bh(不在照片中)</strong>:随机初始化的列矩阵，作为偏差矩阵加入h(t)的计算中。</p><p id="aaef" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig"> by(不在照片中)</strong>:随机初始化的列矩阵，作为计算y(t)时要加入的偏置矩阵。</p><p id="3b25" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig">代码:</strong></p><p id="c9be" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们从导入数据开始:</p><p id="f590" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">从<a class="ae kh" href="https://github.com/Manik9/RNNs-from-scratch-" rel="noopener ugc nofollow" target="_blank">这里</a>下载数据。</p><figure class="kj kk kl km fq hw"><div class="bz el l di"><div class="ks kt l"/></div></figure><figure class="kj kk kl km fq hw"><div class="bz el l di"><div class="ks kt l"/></div></figure><pre class="kj kk kl km fq ku kv kw kx aw ky dt"><span id="e467" class="kz la if kv b fv lb lc l ld le"><strong class="kv ig">char_to_ix:</strong> it's a dictionary to assign a unique number to each unique character<br/><strong class="kv ig">ix_to_char:</strong>it's a dictionary to assign a unique character to each number.<br/>We deal with assigned number of each character and predict number of next character and then use this predicted number to find the next character.</span></pre><figure class="kj kk kl km fq hw"><div class="bz el l di"><div class="ks kt l"/></div></figure><p id="8c71" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><em class="kd">隐藏大小</em>:隐藏神经元的数量</p><p id="1c41" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><em class="kd"> seq_length </em>:这是指我们希望我们的RNN记住多少个先前的紧接的状态。</p><p id="70cd" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><em class="kd"> lr </em>:代表学习率。</p><blockquote class="ka kb kc"><p id="0cc2" class="jc jd kd je b jf jg jh ji jj jk jl jm ke jo jp jq kf js jt ju kg jw jx jy jz hn dt translated"><strong class="je ig">初始化参数:</strong></p></blockquote><p id="24ad" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">初始化我们上面讨论的参数(Whh …… by)。</p><figure class="kj kk kl km fq hw"><div class="bz el l di"><div class="ks kt l"/></div></figure><blockquote class="ka kb kc"><p id="4c38" class="jc jd kd je b jf jg jh ji jj jk jl jm ke jo jp jq kf js jt ju kg jw jx jy jz hn dt translated"><strong class="je ig">向前传球:</strong></p></blockquote><figure class="kj kk kl km fq hw"><div class="bz el l di"><div class="ks kt l"/></div><figcaption class="kn ko fg fe ff kp kq bd b be z ek">ForwardPass.py</figcaption></figure><p id="8082" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">xs，ys，hs，ps都是字典。</p><p id="4446" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig"> xs[t] </strong>:在时间(character) t=t，我们使用独热编码来表示字符，即除了一个元素之外，独热向量的所有元素都是零，并且我们使用char_to_ix字典来找到该元素(字符)的位置。示例:假设我们的数据为“abcdef”。我们通过使用独热编码将“a”表示为</p><pre class="kj kk kl km fq ku kv kw kx aw ky dt"><span id="c2a7" class="kz la if kv b fv lb lc l ld le">this is what we are doing in 25th,26th line in the code above.<br/>a=[[1], <br/>   [0],<br/>   [0],<br/>   [0],<br/>   [0],<br/>   [0]]<br/></span></pre><p id="7c5e" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig"> ys[t] </strong>:在时间(character) t=t，我们存储那个RNN单元格的最终输出。</p><p id="261d" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig">hs【t】</strong>:在时间(character)t=t，我们存储当前RNN单元格的隐藏状态。</p><p id="284b" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je ig">PS【t】</strong>:在时间(字符)t=t，我们存储每个字符出现的概率。</p><p id="260b" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">正如你在上面的代码中看到的，我们实现了简单的计算，如图1所示的xs[t]，ys[t]，hs[t]，ps[t]。</p><p id="1fcc" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">最后，我们计算softmax损失。</p><figure class="kj kk kl km fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff lf"><img src="../Images/9e96d7a8233ffed3671634f57506eb0a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bOz5Ic527G_T-IgWGk9JhA.png"/></div></div><figcaption class="kn ko fg fe ff kp kq bd b be z ek">Forward Pass</figcaption></figure><blockquote class="ka kb kc"><p id="bdb9" class="jc jd kd je b jf jg jh ji jj jk jl jm ke jo jp jq kf js jt ju kg jw jx jy jz hn dt translated"><strong class="je ig">向后传球</strong></p></blockquote><p id="6dc6" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">dWxh:导数w.r.t矩阵Wxh。我们将用它来修正我们的Wxh矩阵。以及类似的dWhh，dWhy，dbh，dby，dhnext。</p><figure class="kj kk kl km fq hw"><div class="bz el l di"><div class="ks kt l"/></div></figure><p id="7e6a" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">为了返回到y:我们从正确的下一个字符的出现概率中减去1，因为:</p><figure class="kj kk kl km fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff lg"><img src="../Images/0458929130753e6f0c63c9fdb402d76d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6f0KcnS9Qy0j_9brJmeI-g.png"/></div></div><figcaption class="kn ko fg fe ff kp kq bd b be z ek">stanford CS231N notes</figcaption></figure><pre class="kj kk kl km fq ku kv kw kx aw ky dt"><span id="6818" class="kz la if kv b fv lb lc l ld le">Now:<br/>To calculate:<br/><strong class="kv ig">dy</strong>: ps[t]-1</span><span id="4f76" class="kz la if kv b fv lh lc l ld le"><strong class="kv ig">dWhy</strong> += : dy•hs[t].T<br/><strong class="kv ig">dh</strong> += Why.T•dy + dhnext</span><span id="2622" class="kz la if kv b fv lh lc l ld le"><strong class="kv ig">dby</strong> += dy (As matrix multiplication term becomes zero in   derivative )</span><span id="0d15" class="kz la if kv b fv lh lc l ld le">#backprop in hs[t] now:<br/><strong class="kv ig">dhraw</strong> adds derivative w.r.t tanh(derivative of tanh is 1-tanh^2)<br/>dhraw= (1-hs[t]^2)*dh</span><span id="67c1" class="kz la if kv b fv lh lc l ld le">dbh += dhraw (because derivative matrix multiplication terms is zero w.r.t dbh)<br/>dWhx += (dhraw•xs[t].T)<br/>dWhh += (dhraw•hs[t-1])<br/>finally:<br/>dhnext += (Whh.T•dhraw)</span></pre><p id="7853" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">一切都准备好了:</p><h2 id="59c4" class="kz la if bd li lj lk ll lm ln lo lp lq jn lr ls lt jr lu lv lw jv lx ly lz ma dt translated"><strong class="ak">该运行程序了:DeepLearning Studio </strong></h2><p id="012d" class="pw-post-body-paragraph jc jd if je b jf mb jh ji jj mc jl jm jn md jp jq jr me jt ju jv mf jx jy jz hn dt translated">rnn在计算上非常昂贵。为了训练我们的程序，我使用了Deep Cognition的<strong class="je ig">深度学习工作室</strong>。它提供了预装的深度学习框架，如Tensorflow-gpu/cpu、keras-gpu/cpu、py torch…等等。查看<strong class="je ig"> </strong> <a class="ae kh" href="https://deepcognition.ai/" rel="noopener ugc nofollow" target="_blank"> <strong class="je ig">这里</strong> </a>。</p><div class="kj kk kl km fq ab cb"><figure class="mg hw mh mi mj mk ml paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><img src="../Images/f309cadaf171bda7a941d1dbfb19cdeb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1246/format:webp/1*g_u5-xAH4j-AcONk1waD4A.png"/></div></figure><figure class="mg hw mm mi mj mk ml paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><img src="../Images/289ef4f5e5caadca3e2e09fd0491771a.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*RTQGzBOTxRhTSEbKTWFHkw.png"/></div><figcaption class="kn ko fg fe ff kp kq bd b be z ek mn di mo mp">click on Notebooks and you’re ready to code! ✋</figcaption></figure></div><div class="ht hu fm fo hv mq"><a href="https://deepcognition.ai/" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab ej"><div class="ms ab mt cl cj mu"><h2 class="bd ig fv z el mv eo ep mw er et ie dt translated">深度认知——今天就成为一个人工智能驱动的组织</h2><div class="mx l"><h3 class="bd b fv z el mv eo ep mw er et ek translated">无需编码即可设计、训练和部署深度学习模型。深度学习工作室简化并加速了…</h3></div><div class="my l"><p class="bd b gc z el mv eo ep mw er et ek translated">deepcognition.ai</p></div></div><div class="mz l"><div class="na l nb nc nd mz ne ib mq"/></div></div></a></div><figure class="kj kk kl km fq hw"><div class="bz el l di"><div class="ks kt l"/></div></figure><p id="4a5a" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">mbh，mby是Adagrad optimiser的内存变量。</p><figure class="kj kk kl km fq hw fe ff paragraph-image"><div role="button" tabindex="0" class="hx hy di hz bf ia"><div class="fe ff nf"><img src="../Images/db042448bafdfbd99fb0ca4b327d1622.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*OhNes4zteJJkeqwCXe2KkQ.png"/></div></div><figcaption class="kn ko fg fe ff kp kq bd b be z ek">For line number 7–11. Here one-step = seq_length.</figcaption></figure><p id="01b5" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">最后，根据不同参数(Why…h(t))的损失函数计算损失，并从相应参数中减去损失。</p><figure class="kj kk kl km fq hw"><div class="bz el l di"><div class="ks kt l"/></div></figure><pre class="kj kk kl km fq ku kv kw kx aw ky dt"><span id="b045" class="kz la if kv b fv lb lc l ld le">line number 5-6 is the way we Adagrad works.<br/>Like in normal gradient descent we do:<br/>theta= theta-lr*grad<br/>1e-8 is used to prevent DivisionByZero exception.</span></pre><blockquote class="ka kb kc"><p id="deaa" class="jc jd kd je b jf jg jh ji jj jk jl jm ke jo jp jq kf js jt ju kg jw jx jy jz hn dt translated"><strong class="je ig">培训结果:</strong></p></blockquote><figure class="kj kk kl km fq hw fe ff paragraph-image"><div class="fe ff ng"><img src="../Images/8b99b7be840df8add13e2214f80d450a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1056/format:webp/1*4Q9sgROt4ZYbIxiPTjd63w.png"/></div></figure><pre class="kj kk kl km fq ku kv kw kx aw ky dt"><span id="1ab7" class="kz la if kv b fv lb lc l ld le">At epoch zero:Generated text<br/><strong class="kv ig">loss=106.56699692603289<br/>iteration:0</strong></span><span id="c1ae" class="kz la if kv b fv lh lc l ld le">QZBipoe.M<br/>prb’gxc]QXECCY“f);wqEnJAVV-Dn-<br/>Fl-tXTFTNI[ ?Jpzi”BPM’TxJlhNyFamgIj)wvxJDwBgGbF!D“F‘bU;[)KXrT km*;xwYZIx-<br/>AX<br/>dDl_zk(QlW(KolSenbudmX.yq<br/>H-(uPUl-B:mj]o’E-ZTjzH)USf:!<br/>sCiTkTMcmgUY)rCj<br/>ZaL*rhWVpS----<br/><strong class="kv ig">---------------------------------------------------<br/></strong>l was  beginning begiginning to Alice walicegininn to geteginninato giteginniito geteginninn to geteginninatg gegeginninasto get beginninnninnigw to gicleaaaa  was ginniicg benning to get a wen----<br/><strong class="kv ig">loss=11.115271278781561<br/>iteration:66200</strong></span></pre><p id="25d3" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">它开始学习像“开始，爱丽丝，曾经，去，去……”这样的单词。一点都不完美。但它给人一种直觉，即给定一些样本数据，我们可以生成适当的文本。LSTMs的性能比RNNs好得多。LSTMs是具有3-4个门的RNNs的扩展。请务必查看我在LSTMs上的文章</p><div class="ht hu fm fo hv mq"><a href="https://hackernoon.com/understanding-architecture-of-lstm-cell-from-scratch-with-code-8da40f0b71f4" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab ej"><div class="ms ab mt cl cj mu"><h2 class="bd ig fv z el mv eo ep mw er et ie dt translated">用代码从零开始理解LSTM细胞的结构。</h2><div class="mx l"><h3 class="bd b fv z el mv eo ep mw er et ek translated">在数据序列很重要的情况下，包括CNN在内的普通神经网络表现不佳。比如说…</h3></div><div class="my l"><p class="bd b gc z el mv eo ep mw er et ek translated">hackernoon.com</p></div></div><div class="mz l"><div class="nh l nb nc nd mz ne ib mq"/></div></div></a></div><p id="16da" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在<strong class="je ig"/><a class="ae kh" href="https://github.com/Manik9/RNNs-from-scratch-" rel="noopener ugc nofollow" target="_blank"><strong class="je ig">github repo</strong></a><strong class="je ig">上访问带有数据集的完整代码。</strong></p><p id="7d61" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">恭喜读者，现在你已经深入了解了RNNs(简单线性代数)的数学知识。</p><p id="5dd0" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">感谢您抽出宝贵的时间阅读我的文章。如果你真的喜欢它，请分享并鼓掌👏。</p><p id="802f" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在<a class="ae kh" rel="noopener" href="/@maniksoni653">媒体</a>和<a class="ae kh" href="https://www.linkedin.com/in/maniksoni" rel="noopener ugc nofollow" target="_blank"> LinkedIn </a>上关注我。</p><p id="cecd" class="pw-post-body-paragraph jc jd if je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">快乐深度学习。</p><div class="ht hu fm fo hv mq"><a rel="noopener follow" target="_blank" href="/@maniksoni653"><div class="mr ab ej"><div class="ms ab mt cl cj mu"><h2 class="bd ig fv z el mv eo ep mw er et ie dt translated">马尼克索尼培养基</h2><div class="mx l"><h3 class="bd b fv z el mv eo ep mw er et ek translated">阅读媒介上的Manik Soni的作品。机器学习研究员。每天，Manik Soni和成千上万的其他人…</h3></div><div class="my l"><p class="bd b gc z el mv eo ep mw er et ek translated">medium.com</p></div></div><div class="mz l"><div class="ni l nb nc nd mz ne ib mq"/></div></div></a></div><div class="ht hu fm fo hv mq"><a href="https://www.linkedin.com/in/maniksoni" rel="noopener  ugc nofollow" target="_blank"><div class="mr ab ej"><div class="ms ab mt cl cj mu"><h2 class="bd ig fv z el mv eo ep mw er et ie dt translated">Manik Soni -机器学习研究员-自雇| LinkedIn</h2><div class="mx l"><h3 class="bd b fv z el mv eo ep mw er et ek translated">查看Manik Soni在全球最大的职业社区LinkedIn上的个人资料。Manik有2份工作列在他们的…</h3></div><div class="my l"><p class="bd b gc z el mv eo ep mw er et ek translated">www.linkedin.com</p></div></div><div class="mz l"><div class="nj l nb nc nd mz ne ib mq"/></div></div></a></div></div></div>    
</body>
</html>