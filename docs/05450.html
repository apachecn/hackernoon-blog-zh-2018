<html>
<head>
<title>“Hello,” from the Mobile Side: TensorFlow Lite in Speaker Recognition</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">“你好”，来自移动端:说话人识别中的TensorFlow Lite</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/hello-from-the-mobile-side-tensorflow-lite-in-speaker-recognition-7519b18c2646?source=collection_archive---------4-----------------------#2018-06-28">https://medium.com/hackernoon/hello-from-the-mobile-side-tensorflow-lite-in-speaker-recognition-7519b18c2646?source=collection_archive---------4-----------------------#2018-06-28</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="9d2e" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated"><em class="jq">阿里巴巴技术团队探索了一种新的移动语音识别方法，解决了该领域的主要挑战</em></p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff jr"><img src="../Images/dc46cdb779d093d14ba2e0bf716d71c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FqmZZ3F0V3pyteUA6Y8UyA.jpeg"/></div></div></figure><p id="003f" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">声音生物识别，或声纹，已经被银行用来验证客户身份，如<a class="ae kd" href="https://www.telegraph.co.uk/technology/news/10044493/Say-goodbye-to-the-pin-voice-recognition-takes-over-at-Barclays-Wealth.html" rel="noopener ugc nofollow" target="_blank">巴克莱</a>和<a class="ae kd" href="https://www.theguardian.com/business/2016/feb/19/hsbc-rolls-out-voice-touch-id-security-bank-customers" rel="noopener ugc nofollow" target="_blank">汇丰</a>。随着技术的改进，它可能会在银行和安全领域得到进一步的应用。说话人识别也可以在监视犯罪调查中找到应用。</p><p id="1a7f" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">尽管该技术有这些潜力，但在该领域仍有许多挑战需要克服。目前大多数说话人识别发生在服务器端。阿里巴巴科技团队提出了一个在客户端使用TensorFlow Lite的解决方案，通过机器学习和其他优化措施来解决当前模型的许多常见问题。</p><p id="1732" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated"><strong class="iu hv">服务器端模型的问题:</strong></p><p id="0f8f" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">由于目前大多数说话人识别都是在服务器端进行的，因此以下问题非常普遍:</p><p id="a558" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">网络连接性差</p><p id="cde1" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">延长的延迟</p><p id="4bd6" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">用户体验差</p><p id="c474" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">过度扩展的服务器资源</p><p id="6e22" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated"><strong class="iu hv">阿里巴巴的客户端替代:</strong></p><p id="d742" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">为了解决这些问题，阿里巴巴科技团队决定在客户端实现说话人识别，并使用机器学习来优化说话人识别。</p><p id="d297" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">这种解决方案本身也存在一定的挑战。在客户端实现说话人识别非常耗时，为了弥补这一点，需要进行多种优化。阿里巴巴技术团队设计了一些方法来:</p><p id="41b7" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">通过机器学习优化结果</p><p id="8698" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">加速计算</p><p id="aa41" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">减少耗时的操作</p><p id="913c" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">减少预处理时间</p><p id="14b8" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">过滤掉不重要的音频样本</p><p id="9943" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">删除不必要的计算操作</p><p id="1b10" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">阿里巴巴科技团队提出的方法构成了一套解决方案，有助于解决说话人识别技术面临的挑战。</p><h1 id="5ecc" class="ke kf hu bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb dt translated">定义说话人识别</h1><h2 id="813e" class="lc kf hu bd kg ld le lf kk lg lh li ko jd lj lk ks jh ll lm kw jl ln lo la lp dt translated">情节</h2><p id="fe56" class="pw-post-body-paragraph is it hu iu b iv lq ix iy iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp hn dt translated">语音识别可以有效地应用于许多场景，包括:</p><p id="e81d" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">1) <strong class="iu hv">媒体质量分析:</strong>识别人声、通话中的静音、背景噪音。</p><p id="86e4" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">2) <strong class="iu hv">说话人识别:</strong>为手机语音解锁、远程语音识别等验证语音。</p><p id="c28d" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">3) <strong class="iu hv">情绪识别:</strong>识别说话人的情绪和情绪状态。当与一个人的声纹、正在说的内容、情绪识别相结合时，可以增加安全性并防止声纹伪造和模仿。</p><p id="696b" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">4) <strong class="iu hv">性别识别</strong>:区分说话人是男是女。这是另一个有助于确认说话者身份的工具。</p><h2 id="a752" class="lc kf hu bd kg ld le lf kk lg lh li ko jd lj lk ks jh ll lm kw jl ln lo la lp dt translated">过程</h2><p id="0129" class="pw-post-body-paragraph is it hu iu b iv lq ix iy iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp hn dt translated">训练和预测是说话人识别的两个主要阶段。训练阶段用旧数据建立计算模型，预测阶段用模型给出当前数据的参考结果..</p><p id="ffd4" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">培训可以进一步分为三个步骤:</p><p id="c9e2" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">1)用梅尔频率倒谱算法提取音频特征。</p><p id="3b21" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">2)将人类声音标记为正面，将非人类样本标记为负面。用这些样本训练神经网络模型。</p><p id="4de0" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">3)使用最终训练结果来创建移动预测模型。</p><p id="19d6" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">简而言之，训练流程就是特征提取、模型训练和移动模型移植。对于预测，流程是提取语音特征，用该特征运行移动模型，得到最终的预测结果。</p><h1 id="32b6" class="ke kf hu bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb dt translated">人工智能框架</h1><p id="0ff1" class="pw-post-body-paragraph is it hu iu b iv lq ix iy iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp hn dt translated">TensorFlow Lite的推出是在2017年11月的谷歌I/O年度开发者大会上宣布的。TensorFlow Lite是一款面向移动和嵌入式设备的轻量级解决方案，支持在多种平台上运行，从机架式服务器到小型物联网设备。</p><p id="19e5" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">随着机器学习模型的广泛使用，出现了在移动和嵌入式设备上部署TensorFlow Lite的需求。幸运的是，TensorFlow Lite允许机器学习模型在低延迟推理的设备上运行。</p><p id="dd59" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">Tensorflow Lite是谷歌的一个AI学习系统。它的名字来源于它的工作原理。张量意味着N维数组，流意味着基于数据流图的计算。TensorFlow是指张量从数据流图的一端流向另一端的计算过程。TensorFlow是一个将复杂的数据结构传输到AI神经网络进行分析和处理的系统。</p><p id="30ad" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">下图显示了TensorFlow Lite数据结构<strong class="iu hv"> </strong>:</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff lv"><img src="../Images/efa89b0f195e793c5fd577b760d77725.png" data-original-src="https://miro.medium.com/v2/resize:fit:1138/format:webp/1*9aJcBlhvcCGeaaJ26T76uA.png"/></div><figcaption class="lw lx fg fe ff ly lz bd b be z ek">TensorFlow Lite architecture diagram</figcaption></figure><h1 id="4b68" class="ke kf hu bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb dt translated">梅尔频率倒谱算法</h1><h2 id="bb4d" class="lc kf hu bd kg ld le lf kk lg lh li ko jd lj lk ks jh ll lm kw jl ln lo la lp dt translated">算法介绍</h2><p id="d7cf" class="pw-post-body-paragraph is it hu iu b iv lq ix iy iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp hn dt translated">对于这个解决方案，阿里巴巴技术团队使用了梅尔频率倒谱算法。该算法用于说话人识别。使用该算法包含以下步骤:</p><p id="1fe8" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">1)输入声音文件并将其解析为原始声音数据(时域信号)。</p><p id="aa52" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">2)通过短时傅立叶变换、加窗和分帧将时域信号转换为频域信号。</p><p id="7d10" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">3)通过梅尔频谱变换，将频率变成人类可以感知的线性关系。</p><p id="123f" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">4)通过Mel倒谱分析，采用DCT变换分离DC分量和正弦分量。</p><p id="3d15" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">5)提取声谱特征向量，转换成图像。</p><p id="5b8c" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">开窗和成帧的目的是确保语音在时域中的短期平稳特性。梅尔频谱变换用于将人类听觉对频率的感知转换成线性关系。梅尔倒谱分析用于理解傅立叶变换，通过傅立叶变换，任何信号都可以分解为一个DC分量和多个正弦信号的和。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff ma"><img src="../Images/06784859a4a0e358c4f800661dd9ac7c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-z3QRhVuUEE0xGjsUe1z_A.jpeg"/></div></div><figcaption class="lw lx fg fe ff ly lz bd b be z ek">The Mel-frequency cepstrum algorithm implementation process</figcaption></figure><h2 id="e432" class="lc kf hu bd kg ld le lf kk lg lh li ko jd lj lk ks jh ll lm kw jl ln lo la lp dt translated">短时傅立叶变换</h2><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff mb"><img src="../Images/39bf936d8546e6271f3c7fd25903aeae.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*bfppaRHsSKXdu1I4gRINWQ.png"/></div></div><figcaption class="lw lx fg fe ff ly lz bd b be z ek">Time domain sound signals</figcaption></figure><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff mc"><img src="../Images/f457d8e4c04e802296a70632bf753e48.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_umSOdkaiQrjQN6UTb1uRA.png"/></div></div><figcaption class="lw lx fg fe ff ly lz bd b be z ek">Frequency domain sound signals</figcaption></figure><p id="8d4b" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">声音信号是一维时域信号。很难找到频率如何变化的规律。如果我们通过傅立叶变换将声音信号转换到频域，就会显示出信号的频率分布。但同时它的时域信息会缺失，无法看到频率分布随时间的变化。为了解决这个问题，出现了许多联合时频分析方法。短时傅立叶变换、小波和维格纳分布都是常用的方法。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff md"><img src="../Images/22ce17d5564b3008aaa7a56795f31212.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dVljrKiblaKICvs6XRRPgg.png"/></div></div><figcaption class="lw lx fg fe ff ly lz bd b be z ek">FFT transform and STFT transform</figcaption></figure><p id="1a7d" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">信号频谱可以通过傅立叶变换获得，并且可以被广泛地利用。例如，信号压缩和噪声降低都可以基于频谱。然而，傅立叶变换建立在信号是稳定的假设上，也就是说，信号的统计特性不随时间变化。然而，声音信号不是静止的。在很长一段时间内，有许多信号会出现，然后立即消失。如果所有的信号都经过傅立叶变换，声音随时间的变化就无法准确反映。</p><p id="c515" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">本文使用的短时傅里叶变换(STFT)是经典的联合时频分析方法。短时傅立叶变换(STFT)是一种与傅立叶变换(FT)相关联的数学变换，用于确定时变信号的局部区域中正弦波的频率和相位。</p><p id="6183" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">短时傅立叶变换(STFT)的概念是首先选择具有时频局部化的窗函数，然后假设分析窗函数h (t)在短时间内是平稳的，这确保f (t) h (t)在不同的有限时间宽度内是平稳信号。最后计算各个时刻的功率谱。STFT使用固定窗函数，最常用的包括汉宁窗、汉明窗和布莱克曼-哈里斯窗。汉明窗是一种广义余弦窗，在本文的解决方案中使用。海明窗可以有效地反映某一时刻能量与时间的衰减关系。</p><p id="0516" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">本文中的STFT公式采用原始的傅里叶变换公式，</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff me"><img src="../Images/beae20ead2bf0b032d5c8142c743ba3e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*m0yj1LU3Ap0dg9QWGGflEg.png"/></div></div></figure><p id="fc52" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">并向其添加窗口函数，创建以下更新的STFT公式:</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff mf"><img src="../Images/bdc95c8420ad90da8e0f5b5661d02ba0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ul799L3jaUrKrVxomrzOpw.png"/></div></div></figure><p id="ea10" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">下面是一个汉明窗函数:</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff mg"><img src="../Images/1f890d389d5db93a1c6e28e046d5ea0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*aRaeRPvLa8TENg631_Fxgg.png"/></div></div></figure><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff mh"><img src="../Images/3f51c6d5eb4ef43c11788db14049175c.png" data-original-src="https://miro.medium.com/v2/resize:fit:960/format:webp/1*k7mCH6zMkNoU0JbK3Ts3dg.png"/></div><figcaption class="lw lx fg fe ff ly lz bd b be z ek">STFT transform based on the Hamming window</figcaption></figure><h1 id="5ddc" class="ke kf hu bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb dt translated">梅尔光谱</h1><p id="1072" class="pw-post-body-paragraph is it hu iu b iv lq ix iy iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp hn dt translated">光谱图通常是大地图的形式。为了将声音特征转换成合适的大小，通常需要通过Mel尺度滤波器组将其转换成Mel谱。</p><h2 id="9b15" class="lc kf hu bd kg ld le lf kk lg lh li ko jd lj lk ks jh ll lm kw jl ln lo la lp dt translated">梅尔标度</h2><p id="6f3a" class="pw-post-body-paragraph is it hu iu b iv lq ix iy iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp hn dt translated">梅尔量表是由史蒂文斯、沃尔克曼和纽曼在1937年命名的。众所周知，频率的单位是赫兹(Hz ),人类听觉的频率范围是20–20000Hz。</p><p id="cb87" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">但是人类的听觉并不以线性方式与诸如Hz的标度单位相关。例如，如果我们已经适应了1000赫兹的音调，那么当音调频率增加到2000赫兹时，我们的耳朵只能感知到频率可能增加了一点，而我们永远不会意识到频率增加了一倍。将普通频率标度转换为Mel频率标度的映射如下:</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff mi"><img src="../Images/94df6a70a0731a5b65161691405b657b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e2gHJGdBNk0gGn_cexJa2Q.png"/></div></div></figure><p id="6d90" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">上面的公式改变了频率，使其与人的听觉感知成线性关系。也就是说，如果一个梅尔标度频率是另一个梅尔标度频率的两倍，人耳可以感知到一个频率大致是另一个的两倍。</p><p id="c11b" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">由于Hz与Mel频率之间存在对数关系，如果频率较低，Mel-frequency会随Hz快速变化；如果频率很高，Mel频率将缓慢变化。这说明人的耳朵对低频声音比较敏感，对高频声音反应较弱。该规则构成了Mel比例滤波器组的重要基础。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff mj"><img src="../Images/dea0fab4587eb0d15dd9c32126e2cb64.png" data-original-src="https://miro.medium.com/v2/resize:fit:978/format:webp/1*q8bchly12DRSQyMssWEbHw.png"/></div><figcaption class="lw lx fg fe ff ly lz bd b be z ek">Frequency transforms to Mel frequency</figcaption></figure><p id="300f" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">下图显示了构成过滤器组的12个三角形过滤器。该滤波器组在低频区具有密集滤波器和高阈值，在高频区具有稀疏滤波器和低阈值。这与人耳对较高频率的声音反应较弱的事实相符。上图所示的具有相同库面积的Mel滤波器库是一种滤波器，广泛应用于语音和说话人识别等领域。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff mk"><img src="../Images/120e199f4f285bfa31d107086ef764e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*lJrlJhwSHQxPQKCzLFhQ6A.png"/></div><figcaption class="lw lx fg fe ff ly lz bd b be z ek">Mel filter bank</figcaption></figure><h2 id="2a20" class="lc kf hu bd kg ld le lf kk lg lh li ko jd lj lk ks jh ll lm kw jl ln lo la lp dt translated">梅尔频率倒谱</h2><p id="1822" class="pw-post-body-paragraph is it hu iu b iv lq ix iy iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp hn dt translated">对梅尔对数谱应用DCT变换以分离DC信号和正弦信号的分量的结果是梅尔频率倒谱(MFC)。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff ml"><img src="../Images/a4a566d45bb17f25125bbd3d07c70213.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*4KK_0Zbp3JeCEI7iyg5CWQ.png"/></div></div></figure><h2 id="5095" class="lc kf hu bd kg ld le lf kk lg lh li ko jd lj lk ks jh ll lm kw jl ln lo la lp dt translated">优化算法处理速度</h2><p id="0824" class="pw-post-body-paragraph is it hu iu b iv lq ix iy iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp hn dt translated">由于该算法是为在客户端使用而设计的，因此需要快速处理。可以采取以下步骤来优化算法处理速度。</p><p id="eb94" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">1) <strong class="iu hv">指令集加速:</strong>算法特点是矩阵加法和矩阵乘法运算多。ARM指令集的引入是为了加速运算。它可以将速度提高4-8倍。</p><p id="a742" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">2) <strong class="iu hv">算法加速:</strong></p><blockquote class="mm mn mo"><p id="9380" class="is it jq iu b iv iw ix iy iz ja jb jc mp je jf jg mq ji jj jk mr jm jn jo jp hn dt translated">a)选择人声频率范围(20HZ~20KHZ)，滤除非人声频率范围以外的输入，减少冗余计算。</p><p id="ee13" class="is it jq iu b iv iw ix iy iz ja jb jc mp je jf jg mq ji jj jk mr jm jn jo jp hn dt translated">b)降低音频采样率以减少不必要的数据计算。这是可能的，因为人耳对过高的采样率不敏感。</p><p id="8bdf" class="is it jq iu b iv iw ix iy iz ja jb jc mp je jf jg mq ji jj jk mr jm jn jo jp hn dt translated">c)合理切割窗口和截面，避免计算量过大。</p><p id="0fa7" class="is it jq iu b iv iw ix iy iz ja jb jc mp je jf jg mq ji jj jk mr jm jn jo jp hn dt translated">d)检测无声部分，以便可以删除不必要的部分。</p></blockquote><p id="cd9c" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">3) <strong class="iu hv">采样频率加速:</strong>如果无线电采样频率过高，选择下采样，将最高采样频率设置为32 kHz。</p><p id="74ec" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">4) <strong class="iu hv">多线程加速:</strong>将音频分成多个片段，由多线程并发处理。线程数量取决于机器容量。默认设置是四个线程。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff ms"><img src="../Images/58cd94e147cf8cc47e593d99ce8a07c5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-592uVFDMKBpXEloVZom6w.png"/></div></div><figcaption class="lw lx fg fe ff ly lz bd b be z ek">Algorithm parameters selected by the engineering team</figcaption></figure><h1 id="12d9" class="ke kf hu bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb dt translated">说话人识别模型</h1><h2 id="f4a1" class="lc kf hu bd kg ld le lf kk lg lh li ko jd lj lk ks jh ll lm kw jl ln lo la lp dt translated">型号选择</h2><p id="69b9" class="pw-post-body-paragraph is it hu iu b iv lq ix iy iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp hn dt translated">卷积神经网络(CNN)是一种前馈神经网络。CNN网络包含人工神经元，可以对其领域中的一些神经元做出反应。这种类型的神经网络非常适合处理大型图像。</p><p id="e215" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">20世纪60年代，Hubel和Wiesel在研究猫大脑皮层中帮助局部感知和方向选择的神经元时，发现了可以用来简化反馈神经网络的独特细胞结构。这导致他们提出了CNN的概念。细胞神经网络已经成为许多研究领域的热点，特别是在模式分类方面。</p><p id="9340" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">CNN受欢迎的部分原因是它们能够跳过复杂的图像预处理，并允许直接导入原始图像。<a class="ae kd" href="https://www.rctn.org/bruno/public/papers/Fukushima1980.pdf" rel="noopener ugc nofollow" target="_blank">第一个类似CNN的网络是由K.Fukushima在1980年提出的新认知网络</a>。从那以后，多名研究人员致力于改进CNN模型。这些努力中最重要的是亚历山大和泰勒提出的改善认知的工作。这项关于改善认知的研究结合了各种方法的优势，避免了耗时的误差反向传播。</p><p id="82ff" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">一般来说，CNN结构由两个基本层组成。其中一层是特征提取层。在这一层中，每个神经元的输入连接到前一层的局部接受域，并提取该局部域的特征。一旦提取，该局部域特征相对于其他特征的位置关系是固定的。</p><p id="1905" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">另一个是特征映射层，它们聚集在一起形成网络的每个计算层。每个特征映射层是一个表面，其中所有神经元具有相同的权重。使用具有小影响函数核的函数，例如sigmoid和relu作为CNN的激活函数，特征映射结构保证了特征映射的恒定位移。自由网络参数的数量减少了，因为同一映射表面上的神经元共享相同的权重。在CNN中，每个卷积层后面紧跟着一个计算层，用于获得局部平均值和二次提取。这种特定的次要特征提取降低了特征分辨率。</p><p id="9f20" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">CNN主要用于识别被修改但没有变形的2D图像，例如被放大的图像。由于CNN的特征检测层通过训练数据进行隐式学习，因此使用CNN可以避免显式特征提取的需要。</p><p id="8fd8" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">CNN也可以同时学习，因为它在相同的特征映射表面上为神经元赋予相同的权重。这使得CNN比神经元相互连接的网络更有优势。局部权重共享使CNN在语音识别和图像处理方面具有独特的优势。在布局上，CNN更接近实际的生物神经网络。权重共享确保网络不太复杂，并且CNN不必在特征提取和分类期间处理数据重构的复杂性，因为多维输入向量的图像可以直接输入到网络中。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff mt"><img src="../Images/b323c276e1c1b37c35bb9c5a4749afa7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*WRALDHzL4NLzZNQ1fLtJIg.jpeg"/></div></div><figcaption class="lw lx fg fe ff ly lz bd b be z ek">Inception-v3 model</figcaption></figure><p id="ac35" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">精确的Inception-v3模型在本文中被用作说话人识别模型。分解是v3模型最重要的改进之一。7x7 CNNs分解成2个一维卷积(1x7，7x1)，3x3 CNNs也分解成2个卷积(1x3，3x1)。这加速了计算，进一步深化了网络，并使其更加非线性。v3型号网络输入从224x224升级到299x299，并且改进了35x35/17x17/8x8模块的设计。</p><p id="c358" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">使用TensorFlow会话使模块能够在代码层实现训练和预测。TensorFlow官方网站提供了如何使用TensorFlow会话的详细信息。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff mu"><img src="../Images/718b08a3315da86b014ad3d16e591027.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*lYO3ewyfi6N31eBL8jilUg.png"/></div></div><figcaption class="lw lx fg fe ff ly lz bd b be z ek">Using a TensorFlow session</figcaption></figure><h2 id="34f5" class="lc kf hu bd kg ld le lf kk lg lh li ko jd lj lk ks jh ll lm kw jl ln lo la lp dt translated">模型示例</h2><p id="c61d" class="pw-post-body-paragraph is it hu iu b iv lq ix iy iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp hn dt translated">在受监控的机器学习中，样本通常分为三组:</p><blockquote class="mm mn mo"><p id="8185" class="is it jq iu b iv iw ix iy iz ja jb jc mp je jf jg mq ji jj jk mr jm jn jo jp hn dt translated"><em class="hu"> </em> <strong class="iu hv"> <em class="hu">列车设置:</em> </strong> <em class="hu">此设置用于估算车型。它学习样本数据集，并通过匹配一些参数来建立分类器。它创建了用于训练模型的分类方式。</em></p><p id="9666" class="is it jq iu b iv iw ix iy iz ja jb jc mp je jf jg mq ji jj jk mr jm jn jo jp hn dt translated"><em class="hu"> </em> <strong class="iu hv"> <em class="hu">验证集:</em> </strong> <em class="hu">该集用于确定控制模型复杂度的网络结构或控制参数。它调整通过学习获得的模型的分类器参数，例如选择隐藏神经网络中的单元数。验证集还用于确定控制模型复杂性的网络结构或参数，以试图避免模型的过度拟合。</em></p><p id="4f54" class="is it jq iu b iv iw ix iy iz ja jb jc mp je jf jg mq ji jj jk mr jm jn jo jp hn dt translated"><em class="hu"> </em> <strong class="iu hv"> <em class="hu">测试集:</em> </strong> <em class="hu">该集用于检查最终选定的最优模型的执行情况。主要用于测试训练好的模型的识别能力(比如识别率)。</em></p></blockquote><p id="1c3d" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">在第二章中描述的梅尔频率倒谱算法可以用于获得作为样本文件的说话人识别。人类声谱内的声音作为正样本，动物声音和其他非人类噪声用作负样本。这些样本然后被用于训练Inception-v3模型。</p><p id="2ae8" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">本文以TensorFlow作为训练框架，以5000个人声样本和5000个非人声样本作为测试集，以1000个样本作为验证集。</p><h2 id="9eaf" class="lc kf hu bd kg ld le lf kk lg lh li ko jd lj lk ks jh ll lm kw jl ln lo la lp dt translated">模特培训</h2><p id="6776" class="pw-post-body-paragraph is it hu iu b iv lq ix iy iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp hn dt translated">一旦样本准备好了，它们就可以用来训练Inception-v3模型。经过训练的模型的收敛可以生成在客户端上可用的pb模型。在型号选择中，选择编译armeabi-v7a或更高版本，NEON优化默认开启。换句话说，打开USE_NEON的宏可以加速指令集。CNN中超过一半的运算发生在卷积上，因此指令集优化可以将运算速度提高至少四倍。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff mv"><img src="../Images/270de65669248e156186b5764a51d459.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YnzFovo8FnSGseN0xfxPnA.png"/></div></div><figcaption class="lw lx fg fe ff ly lz bd b be z ek">Convolution processing function</figcaption></figure><p id="f713" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">TensorFlow提供的toco工具可用于生成lite模型，该模型可由客户端上的TensorFlow Lite框架直接调用。</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div role="button" tabindex="0" class="jx jy di jz bf ka"><div class="fe ff mw"><img src="../Images/d407da7b260ad78da88b0761abbc4083.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fq4N3FSHtnYwC_ump_k3pQ.png"/></div></div><figcaption class="lw lx fg fe ff ly lz bd b be z ek">Toco calling interface</figcaption></figure><h2 id="6891" class="lc kf hu bd kg ld le lf kk lg lh li ko jd lj lk ks jh ll lm kw jl ln lo la lp dt translated">模型预测法</h2><p id="6c1f" class="pw-post-body-paragraph is it hu iu b iv lq ix iy iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp hn dt translated">MFC可以用来提取人声文件特征，生成预测图像。使用在培训中生成的lite预测模型会产生以下结果:</p><figure class="js jt ju jv fq jw fe ff paragraph-image"><div class="fe ff mx"><img src="../Images/18bba25425dfb0f66d424276196ede35.png" data-original-src="https://miro.medium.com/v2/resize:fit:1068/format:webp/1*xNheVWRGVyOgHlgWvtfo4Q.png"/></div><figcaption class="lw lx fg fe ff ly lz bd b be z ek">Model prediction result</figcaption></figure><h1 id="7273" class="ke kf hu bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb dt translated">结论</h1><p id="2d01" class="pw-post-body-paragraph is it hu iu b iv lq ix iy iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp hn dt translated">上面提出的方法可以帮助解决当今说话人识别领域中的一些最困难的挑战。在客户端使用TensorFlow Lite是一项有用的创新，有助于利用机器学习和学习以及神经网络来推动技术向前发展。</p><p id="815e" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt">(Original article by Chen Yongxin陈永新)</p><h1 id="115c" class="ke kf hu bd kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb dt translated"><strong class="ak">参考文献:</strong></h1><p id="b911" class="pw-post-body-paragraph is it hu iu b iv lq ix iy iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp hn dt translated">[1]https://www.tensorflow.org/mobile/tflite<a class="ae kd" href="https://www.tensorflow.org/mobile/tflite" rel="noopener ugc nofollow" target="_blank"/></p><p id="c722" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt">[2] <a class="ae kd" href="http://kns.cnki.net/kcms/detail/detail.aspx?filename=2009059683.nh&amp;dbcode=CMFD&amp;dbname=CMFD2010&amp;v=" rel="noopener ugc nofollow" target="_blank">基于MFCC与IMFCC的说话人识别研究</a>[D]. 刘丽岩. 哈尔滨工程大学 . 2008</p><p id="6672" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt">[3] <a class="ae kd" href="http://kns.cnki.net/kcms/detail/detail.aspx?filename=JSJY200604040&amp;dbcode=CJFQ&amp;dbname=cjfd2006&amp;v=" rel="noopener ugc nofollow" target="_blank">一种基于MFCC和LPCC的文本相关说话人识别方法</a>[J]. 于明,袁玉倩,董浩,王哲. 计算机应用. 2006(04)</p><p id="8ff6" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">[4]噪声环境中的文本相关说话人识别[C].库马尔·帕万，贾汉瓦尔·尼蒂卡，</p><p id="14f2" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">钱德拉·马赫什。设备与通信国际会议。2011</p><p id="19ec" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">[5]https://github.com/weedwind/MFCC<a class="ae kd" href="https://github.com/weedwind/MFCC" rel="noopener ugc nofollow" target="_blank"/></p><p id="ddbc" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt">[6] <a class="ae kd" href="https://baike.baidu.com/item/ARM指令集/907786?fr=aladdin" rel="noopener ugc nofollow" target="_blank">https://baike.baidu.com/item/ARM指令集/907786?fr=aladdin</a></p><p id="7219" class="pw-post-body-paragraph is it hu iu b iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo jp hn dt translated">[7]<a class="ae kd" href="https://www.tensorflow.org/api_docs/python/tf/Session" rel="noopener ugc nofollow" target="_blank">https://www.tensorflow.org/api_docs/python/tf/Session</a></p></div><div class="ab cl my mz hc na" role="separator"><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd ne"/><span class="nb bw bk nc nd"/></div><div class="hn ho hp hq hr"><h1 id="9120" class="ke kf hu bd kg kh nf kj kk kl ng kn ko kp nh kr ks kt ni kv kw kx nj kz la lb dt translated">阿里巴巴科技</h1><p id="01dc" class="pw-post-body-paragraph is it hu iu b iv lq ix iy iz lr jb jc jd ls jf jg jh lt jj jk jl lu jn jo jp hn dt translated">第一手、详细、深入的阿里巴巴最新技术信息→脸书:<a class="ae kd" href="http://www.facebook.com/AlibabaTechnology" rel="noopener ugc nofollow" target="_blank"> <strong class="iu hv">【阿里巴巴科技】</strong> </a>。Twitter:<a class="ae kd" href="https://twitter.com/AliTech2017" rel="noopener ugc nofollow" target="_blank"><strong class="iu hv">【AlibabaTech】</strong></a>。</p></div></div>    
</body>
</html>