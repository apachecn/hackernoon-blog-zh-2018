<html>
<head>
<title>Google X’s Deep Reinforcement Learning in Robotics using Vision</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Google X在机器人领域使用视觉的深度强化学习</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/google-xs-deep-reinforcement-learning-in-robotics-using-vision-7a78e87ab171?source=collection_archive---------4-----------------------#2018-06-30">https://medium.com/hackernoon/google-xs-deep-reinforcement-learning-in-robotics-using-vision-7a78e87ab171?source=collection_archive---------4-----------------------#2018-06-30</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="1e5b" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">#3 <a class="ae jj" href="http://ai.googleblog.com/2018/06/scalable-deep-reinforcement-learning.html" rel="noopener ugc nofollow" target="_blank">研究论文</a>讲解</h2></div><p id="af79" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated"><a class="ae jj" href="https://hackernoon.com/tagged/google" rel="noopener ugc nofollow" target="_blank">谷歌</a>因其尖端技术和项目而闻名，包括自动驾驶汽车、Project Loon(互联网气球)、Project Ara等等。但是很多研究都是在幕后进行的，这产生了一些有趣的研究论文，这些论文给了我们对这些有趣实验的了解和洞察力。鼓励我们自己复制实验，并进一步突破极限。</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff kg"><img src="../Images/a4bc1467adc0f103440c3e10acbf6191.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/1*6NbWiuuDq47bqEFtMfxNvw.gif"/></div></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">Project Ara | <a class="ae jj" href="https://www.google.com/url?sa=i&amp;rct=j&amp;q=&amp;esrc=s&amp;source=images&amp;cd=&amp;cad=rja&amp;uact=8&amp;ved=2ahUKEwj6qaLEuvnbAhWTWysKHfOvCdkQjRx6BAgBEAU&amp;url=https%3A%2F%2Fdribbble.com%2Fshots%2F1507631-google-project-ara-animation&amp;psig=AOvVaw0SsdIcgwRdLXIVXgxI4yoH&amp;ust=1530375170666411" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="f9b7" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">由<a class="ae jj" href="https://x.company/projects/" rel="noopener ugc nofollow" target="_blank"> GoogleX </a>发起的<a class="ae jj" href="https://hackernoon.com/tagged/learning" rel="noopener ugc nofollow" target="_blank">学习</a>机器人项目已经发布了<a class="ae jj" href="https://arxiv.org/abs/1806.10293" rel="noopener ugc nofollow" target="_blank"> <strong class="jm hv"> QT-Opt:基于视觉的机器人操作</strong> </a> <strong class="jm hv"> </strong>的可扩展深度强化学习，即<strong class="jm hv"> </strong>试图掌握抓取不同形状物体的简单任务。旨在复制一些常见的人类活动。</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff kw"><img src="../Images/df1f499bec23f6782542ee71d36f8c25.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hPUCMLXiPFd5M6UfivRZCA.jpeg"/></div></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek"><a class="ae jj" href="https://ai.googleblog.com/" rel="noopener ugc nofollow" target="_blank">Source</a> (<strong class="bd kx">Look at robot no. 6 learning stuff</strong>)</figcaption></figure><p id="bf43" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">而且成功率惊人。</p><p id="fd44" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">这个实验使用了7个机械臂，在4个月的过程中运行了800个小时来抓取放在它们面前的物体。每台都使用分辨率为472x472的RBG相机(上图为)。基于视觉的闭环控制系统基于机器人操作的一般公式，即马尔可夫决策过程(MDP)。</p><div class="kh ki kj kk fq ab cb"><figure class="kz kl la lb lc ld le paragraph-image"><img src="../Images/c88ebaffee6e02129fb4392d3a63f740.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*mJpFASqBjDApWht8l1hMPg.jpeg"/></figure><figure class="kz kl lf lb lc ld le paragraph-image"><img src="../Images/d839f3be2218726719773dc5c575be29.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*xZQykZVJ7rQegfHFmuIINQ.jpeg"/><figcaption class="ks kt fg fe ff ku kv bd b be z ek lg di lh li">Same objects with Different Colours | <a class="ae jj" href="https://ai.googleblog.com/" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure></div><p id="5b8b" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">为了提高效率，使用了偏离策略的强化学习，它能够从几小时、几天甚至几周前收集的数据中学习。</p><p id="95f2" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated"><strong class="jm hv"> Qt-Opt </strong>算法结合两种方法设计:</p><p id="175d" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt lj translated"><span class="l lk ll lm bm ln lo lp lq lr di"> 1。</span> <strong class="jm hv"> L </strong> <a class="ae jj" href="https://ai.googleblog.com/2016/10/how-robots-can-acquire-new-skills-from.html" rel="noopener ugc nofollow" target="_blank"> <strong class="jm hv">大规模分布式优化</strong> </a> <strong class="jm hv"> </strong> <em class="ky">(使用多个机器人更快地训练模型，使之成为大规模分布式系统)</em></p><p id="eec4" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt lj translated"><span class="l lk ll lm bm ln lo lp lq lr di"> 2。</span>深度<a class="ae jj" href="https://en.wikipedia.org/wiki/Q-learning" rel="noopener ugc nofollow" target="_blank"> <strong class="jm hv"> Q-learning </strong> </a>算法(<em class="ky"> RL技术用于学习策略，告诉代理在何种情况下采取何种行动)</em></p><h1 id="0b39" class="ls lt hu bd lu lv lw lx ly lz ma mb mc ja md jb me jd mf je mg jg mh jh mi mj dt translated">什么是Qt-Opt？</h1><p id="0701" class="pw-post-body-paragraph jk jl hu jm b jn mk iv jp jq ml iy js jt mm jv jw jx mn jz ka kb mo kd ke kf hn dt translated">QT-Opt是大规模分布式优化<strong class="jm hv"> </strong>和Q-学习算法<strong class="jm hv"> </strong>的结合，产生了支持连续动作空间的<strong class="jm hv">分布式Q-学习算法</strong>，使其非常适合机器人问题。</p><p id="d1ed" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">为了使机器人在最初的尝试中不会变得疯狂，模型最初是用离线数据训练的，这不需要真实的机器人，并提高了可扩展性。</p><p id="47c6" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">对于这种情况，该策略获取一幅图像，并返回手臂和手爪在3D空间中应该如何移动的序列。</p><h1 id="6b09" class="ls lt hu bd lu lv lw lx ly lz ma mb mc ja md jb me jd mf je mg jg mh jh mi mj dt translated">结果</h1><p id="2b76" class="pw-post-body-paragraph jk jl hu jm b jn mk iv jp jq ml iy js jt mm jv jw jx mn jz ka kb mo kd ke kf hn dt translated">结果给出了令人难以置信的96% <em class="ky">的抓取成功率</em>。</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div role="button" tabindex="0" class="km kn di ko bf kp"><div class="fe ff mp"><img src="../Images/9ce337f48eb2ed57219182bf2296d7d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yhv7AS8vIX79Isk4Aoykog.jpeg"/></div></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek"><a class="ae jj" href="https://arxiv.org/abs/1806.10293" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="2065" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">这个模型学到了许多复杂的、近乎人道的新事物。</p><p id="d942" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt lj translated"><span class="l lk ll lm bm ln lo lp lq lr di"> 1。</span>当砖块彼此靠得太近，没有空间容纳抓取器时，策略会在抓取之前将砖块与其余部分分开。</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div class="fe ff mq"><img src="../Images/fd0bf90abd4e01051298ac9909a9fe48.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*uPmuUrPeUpxoNWnDUjX-aQ.gif"/></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek"><a class="ae jj" href="https://ai.googleblog.com/" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure><p id="03e8" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt lj translated"><span class="l lk ll lm bm ln lo lp lq lr di"> 2。</span>抓取器中的对象不属于数据集的一部分，但它会自动重新定位抓取器以进行另一次尝试。</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><div class="fe ff mq"><img src="../Images/b1bdf8d027b5c8c5b71f30475dd1560b.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/1*LbZSbuKK2UW3_XKefNYw3g.gif"/></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek"><a class="ae jj" href="https://ai.googleblog.com/" rel="noopener ugc nofollow" target="_blank">Source</a></figcaption></figure></div><div class="ab cl mr ms hc mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="hn ho hp hq hr"><p id="469e" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">我鼓励你阅读研究论文以获得更多见解。</p><p id="4f9d" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated"><strong class="jm hv">在Medium和Twitter上关注我</strong>了解更多<strong class="jm hv"># research paper explained</strong>通知。</p><figure class="kh ki kj kk fq kl fe ff paragraph-image"><a href="https://medium.com/@sagarsharma4244"><div class="fe ff mq"><img src="../Images/45303d02b0c43f98f0ac2c3cd1446db6.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*d318hSQDEA-NP2sgKkTINw.png"/></div></a></figure><figure class="kh ki kj kk fq kl fe ff paragraph-image"><a href="https://twitter.com/SagarSharma4244"><div class="fe ff mq"><img src="../Images/ce2f13e1aad357cb162c5550d2fd4868.png" data-original-src="https://miro.medium.com/v2/resize:fit:800/format:webp/1*YnbtD8IipCsqVjNwkjtY8w.png"/></div></a></figure><p id="1ddc" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated">如果你对这篇论文有任何疑问，或者想让我解释你最喜欢的论文，请在下面评论。</p><p id="d6a0" class="pw-post-body-paragraph jk jl hu jm b jn jo iv jp jq jr iy js jt ju jv jw jx jy jz ka kb kc kd ke kf hn dt translated"><strong class="jm hv">鼓掌吧…分享吧…并再次鼓掌。</strong></p></div><div class="ab cl mr ms hc mt" role="separator"><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw mx"/><span class="mu bw bk mv mw"/></div><div class="hn ho hp hq hr"><h1 id="d0f4" class="ls lt hu bd lu lv my lx ly lz mz mb mc ja na jb me jd nb je mg jg nc jh mi mj dt translated">你会喜欢的以前的故事:</h1><div class="nd ne fm fo nf ng"><a href="https://hackernoon.com/deepminds-amazing-mix-match-rl-techique-a6f8ce6ac0b4" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab ej"><div class="ni ab nj cl cj nk"><h2 class="bd hv fv z el nl eo ep nm er et ht dt translated">DeepMind惊人的混搭RL技术</h2><div class="nn l"><h3 class="bd b fv z el nl eo ep nm er et ek translated">#1研究论文解释</h3></div><div class="no l"><p class="bd b gc z el nl eo ep nm er et ek translated">hackernoon.com</p></div></div><div class="np l"><div class="nq l nr ns nt np nu kq ng"/></div></div></a></div><div class="nd ne fm fo nf ng"><a href="https://hackernoon.com/what-the-hell-is-tensor-in-tensorflow-e40dbf0253ee" rel="noopener  ugc nofollow" target="_blank"><div class="nh ab ej"><div class="ni ab nj cl cj nk"><h2 class="bd hv fv z el nl eo ep nm er et ht dt translated">“TensorFlow”里的“Tensor”是什么鬼？</h2><div class="nn l"><h3 class="bd b fv z el nl eo ep nm er et ek translated">我不知道…</h3></div><div class="no l"><p class="bd b gc z el nl eo ep nm er et ek translated">hackernoon.com</p></div></div><div class="np l"><div class="nv l nr ns nt np nu kq ng"/></div></div></a></div><figure class="kh ki kj kk fq kl"><div class="bz el l di"><div class="nw nx l"/></div></figure></div></div>    
</body>
</html>