<html>
<head>
<title>How to Classify when linear Regression Fails?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">线性回归失败时如何分类？</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/classification-and-logistic-regression-8a20a5c9603d?source=collection_archive---------9-----------------------#2018-07-08">https://medium.com/hackernoon/classification-and-logistic-regression-8a20a5c9603d?source=collection_archive---------9-----------------------#2018-07-08</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/7a7eaa2ec6cb9928cededfdb54680890.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ew0AoxyQYBy_6O1X6GPzGQ.jpeg"/></div></div></figure><p id="4d20" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><a class="ae ka" href="https://hackernoon.com/tagged/linear-regression" rel="noopener ugc nofollow" target="_blank">线性回归</a>是解决我们分类问题的简单方法，但是当它失败时会发生什么呢？正如我们将在下面的问题中看到的</p><p id="bf5b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">假设我们要分类<strong class="je hv"> Y= {0，1} </strong>和<strong class="je hv"> X </strong>是<strong class="je hv">数据样本</strong>。是二元分类。让我们用线性回归来试试</p><figure class="kc kd ke kf fq iv fe ff paragraph-image"><div class="fe ff kb"><img src="../Images/272bfd1e19a70fd5f1d002a5d46072aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:866/format:webp/1*ofqIt_tKJj6ZD8nBuo2gTg.png"/></div></figure><p id="9a5a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">哇，线性回归完成了这项工作。这确实是一个很好的选择，但是如果我向给定的数据集中添加一个新的数据，会发生什么呢？</p><figure class="kc kd ke kf fq iv fe ff paragraph-image"><div class="fe ff kg"><img src="../Images/9b2d155ff043e54dcca813dd27e57964.png" data-original-src="https://miro.medium.com/v2/resize:fit:1278/format:webp/1*6ZtPRB6A7naf0ky3JuVX0A.png"/></div></figure><p id="b758" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">真是个烂<a class="ae ka" href="https://hackernoon.com/tagged/solution" rel="noopener ugc nofollow" target="_blank">解</a>。线性回归不起作用。下一步我们应该做什么？有问题就有解决方案，解决方案是<a class="ae ka" href="https://hackernoon.com/tagged/logistic-regression" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">逻辑回归</strong> </a> <strong class="je hv">。</strong>让我们从形式定义开始，了解一下什么是线性回归和逻辑回归:</p><p id="0c70" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在<a class="ae ka" href="https://towardsdatascience.com/deep-dive-into-supervised-learning-e7952c0692e9" rel="noopener" target="_blank"> <strong class="je hv"> <em class="kh">线性回归</em> </strong> </a>中，结果(因变量)是连续的。它可以有无限个可能值中的任何一个。在<strong class="je hv">逻辑回归</strong>中，结果(因变量)只有有限数量的可能值。<strong class="je hv">当响应变量本质上是分类变量时，使用逻辑回归</strong>。</p><p id="d0d1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">直观上，在已知y ∈ {0，1}的情况下，h(x)取大于1或小于0的值也是没有意义的。为了解决这个问题，让我们改变假设h(x)的形式。我们将选择如下假设:</p><figure class="kc kd ke kf fq iv fe ff paragraph-image"><div class="fe ff ki"><img src="../Images/b70db28729b8f7be7823b6d23175d713.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*D4CIwT2zRCcVq88iji6qYQ.png"/></div></figure><p id="8d19" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">g(z)称为<strong class="je hv"> <em class="kh">乙状结肠函数</em> </strong>或L <strong class="je hv"> <em class="kh">逻辑函数</em> </strong>。它看起来如下:</p><figure class="kc kd ke kf fq iv fe ff paragraph-image"><div class="fe ff kj"><img src="../Images/4c31c70f721ecc572b5189ef29a958af.png" data-original-src="https://miro.medium.com/v2/resize:fit:640/format:webp/1*JFNqqLZoaTguEfSgTq6Zgg.png"/></div></figure><p id="6b42" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">让我们假设</p><figure class="kc kd ke kf fq iv fe ff paragraph-image"><div class="fe ff kk"><img src="../Images/b8d8b6ed7f507e0e6cda6fc32248670f.png" data-original-src="https://miro.medium.com/v2/resize:fit:776/format:webp/1*iMFtCGIfxyxTxAPbsDgOjg.png"/></div></figure><p id="1f63" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果我们将上述等式结合在一起，它可以改写如下:</p><figure class="kc kd ke kf fq iv fe ff paragraph-image"><div class="fe ff kl"><img src="../Images/b81a637c5b6aded4908c37d02049e23c.png" data-original-src="https://miro.medium.com/v2/resize:fit:756/format:webp/1*1v8Raq07JVPheYxKXnJE7w.png"/></div></figure><p id="190a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如上式当<strong class="je hv"> y =0 </strong>时，h(x)将变为1，p(y | x；theta) = (1-h(x))而当<strong class="je hv"> y =1 </strong>，(1-h(x))就会变成1，p(y | x；θ)= h(x)</p><p id="c549" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在，<strong class="je hv">参数</strong>的可能性由下式给出</p><figure class="kc kd ke kf fq iv fe ff paragraph-image"><div class="fe ff km"><img src="../Images/a9aae80202882058873a2d34ae223d89.png" data-original-src="https://miro.medium.com/v2/resize:fit:1044/format:webp/1*wA5dN-oyWu8KcYMRHQ6Xmg.png"/></div></figure><p id="d854" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">而当我们将<strong class="je hv"><em class="kh"/></strong><em class="kh">的对数似然最大化时，它将由</em> <strong class="je hv"> <em class="kh"> </em> </strong>给出:</p><figure class="kc kd ke kf fq iv fe ff paragraph-image"><div class="fe ff kn"><img src="../Images/378c297e78dfc3136ae7f5fab0a6db23.png" data-original-src="https://miro.medium.com/v2/resize:fit:1134/format:webp/1*U7VoRhd7kToafLGjijqQFQ.png"/></div></figure><p id="0055" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在我们可以用<strong class="je hv">梯度下降</strong>，我们已经知道h(x)由sigmoid函数给出。</p><figure class="kc kd ke kf fq iv fe ff paragraph-image"><div class="fe ff ki"><img src="../Images/b70db28729b8f7be7823b6d23175d713.png" data-original-src="https://miro.medium.com/v2/resize:fit:888/format:webp/1*D4CIwT2zRCcVq88iji6qYQ.png"/></div></figure><p id="6789" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">为方便起见，g(z)相对于z的偏导数由下式给出</p><figure class="kc kd ke kf fq iv fe ff paragraph-image"><div class="fe ff ko"><img src="../Images/30273d4116ee9cf25be6a04e0b07f8e5.png" data-original-src="https://miro.medium.com/v2/resize:fit:966/format:webp/1*hfBX0p8u2nUneE_k-KeClQ.png"/></div></figure><p id="a273" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在，如果通过对对数似然性对θ取<strong class="je hv"> <em class="kh">的偏导数来应用梯度下降</em></strong></p><figure class="kc kd ke kf fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff kp"><img src="../Images/4ab6641278f75b17024dd22471dc00ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GKiNLofz7qMwggVf8p1_wQ.png"/></div></div></figure><p id="fefc" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果我们将上述规则与最小均方法相比较，看起来是一样的，但事实并非如此。这是一个不同的<a class="ae ka" href="https://hackernoon.com/tagged/learning" rel="noopener ugc nofollow" target="_blank">学习</a>算法，因为h(x)现在被定义为theta转置* x[i]的非线性函数。</p><figure class="kc kd ke kf fq iv fe ff paragraph-image"><div class="fe ff kq"><img src="../Images/9fd19680416e65e5043f77f93f982e1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/format:webp/1*6XZYyIs45VgbkgPp3aULng.png"/></div></figure><p id="86a5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你发现我的帖子有不一致的地方，欢迎在评论中指出。感谢阅读。</p></div><div class="ab cl kr ks hc kt" role="separator"><span class="ku bw bk kv kw kx"/><span class="ku bw bk kv kw kx"/><span class="ku bw bk kv kw"/></div><div class="hn ho hp hq hr"><p id="d556" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你想和我交流。请随时在LinkedIn上与我联系。</p><div class="ky kz fm fo la lb"><a href="https://www.linkedin.com/in/sameer-negi-356881115/" rel="noopener  ugc nofollow" target="_blank"><div class="lc ab ej"><div class="ld ab le cl cj lf"><h2 class="bd hv fv z el lg eo ep lh er et ht dt translated">Sameer Negi -自动驾驶汽车运输公司- Infosys | LinkedIn</h2><div class="li l"><h3 class="bd b fv z el lg eo ep lh er et ek translated">查看Sameer Negi在全球最大的职业社区LinkedIn上的个人资料。Sameer有3份工作列在他们的…</h3></div><div class="lj l"><p class="bd b gc z el lg eo ep lh er et ek translated">www.linkedin.com</p></div></div><div class="lk l"><div class="ll l lm ln lo lk lp ja lb"/></div></div></a></div><figure class="kc kd ke kf fq iv"><div class="bz el l di"><div class="lq lr l"/></div></figure></div></div>    
</body>
</html>