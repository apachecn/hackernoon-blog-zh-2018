<html>
<head>
<title>Where next? After SVMs, CNNs and Word Embeddings</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">接下来去哪里？在支持向量机、CNN和单词嵌入之后</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/where-next-after-svms-cnns-and-word-embeddings-2becb8576cba?source=collection_archive---------8-----------------------#2018-08-13">https://medium.com/hackernoon/where-next-after-svms-cnns-and-word-embeddings-2becb8576cba?source=collection_archive---------8-----------------------#2018-08-13</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/47c8fd9cbb8203d20f08890a4819c746.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*afHgkASVnLhAQwukZoVu7g.png"/></div></div></figure><p id="130c" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">机器学习所涉及的大量知识是这门学科最精彩的地方。理论和编码的平衡需要一个稳定的和有纪律的方法。在这五个系列教程中，我们看到了CNN，其中我们看到了不同场景的各种方法，然后研究了词嵌入，这是我们自然语言处理的门户，最后以支持向量机(SVMs)结束，在支持向量机诞生之初，它与人工神经网络一样强大。</p><p id="070a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这就是机器学习的全部内容吗？</p><p id="cd4e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果我们有这个问题，那么我们完全有理由这么想！上面提到的主题只是对适用于各种领域的监督学习模型的一瞥。CNN捕获深度学习，嵌入捕获NLP和SVMs捕获监督ML算法，但广义地说，所有这些都适合监督学习方法。因此，我们还应该意识到，最初，当我们谈论机器学习时，我们被告知有三种类型的机器学习。</p><ol class=""><li id="508b" class="ka kb hu je b jf jg jj jk jn kc jr kd jv ke jz kf kg kh ki dt translated">监督学习</li><li id="9e46" class="ka kb hu je b jf kj jj kk jn kl jr km jv kn jz kf kg kh ki dt translated">无监督学习</li><li id="10d4" class="ka kb hu je b jf kj jj kk jn kl jr km jv kn jz kf kg kh ki dt translated">强化学习</li></ol><p id="de73" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">无监督学习:</strong></p><p id="6854" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这是监督学习的重新审视，但这一次没有地面真实数据。数据集没有关于数据正确性的信息，因此，算法需要找到数据中的模式。有各种类型的无监督学习算法，从聚类到深度学习中的自动编码器。</p><p id="1a61" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv"> k均值聚类</strong></p><p id="960b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">聚类的目标是创建数据点组，使得不同聚类中的点不相似，而一个聚类中的点相似，k是类的数量。在k-means中，定义这些组的方法是为每个组创建一个质心。</p><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div class="ab fr cl ks"><img src="../Images/12563457a2ec727807723124c81f0b47.png" data-original-src="https://miro.medium.com/v2/0*i8ErSXipZpjNWjk4."/></div></figure><p id="6a28" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">层次聚类:</strong></p><p id="599b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这里的挑战是独特的，因为我们打算建立一个集群的层次结构，也就是说，在各种类中获得粒度感。算法是这样的…</p><ol class=""><li id="481e" class="ka kb hu je b jf jg jj jk jn kc jr kd jv ke jz kf kg kh ki dt translated">从最初的k个簇开始</li><li id="9d62" class="ka kb hu je b jf kj jj kk jn kl jr km jv kn jz kf kg kh ki dt translated">合并彼此最接近的两个聚类以获得k-1个聚类</li><li id="509a" class="ka kb hu je b jf kj jj kk jn kl jr km jv kn jz kf kg kh ki dt translated">重新计算聚类之间的距离</li><li id="276a" class="ka kb hu je b jf kj jj kk jn kl jr km jv kn jz kf kg kh ki dt translated">重复直到获得k个数据点的单个集群。</li></ol><h1 id="1f64" class="kt ku hu bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq dt translated"><strong class="ak">降维:</strong></h1><h2 id="b7f2" class="lr ku hu bd kv ls lt lu kz lv lw lx ld jn ly lz lh jr ma mb ll jv mc md lp me dt translated">主成分分析</h2><p id="094d" class="pw-post-body-paragraph jc jd hu je b jf mf jh ji jj mg jl jm jn mh jp jq jr mi jt ju jv mj jx jy jz hn dt translated">首先，稍微复习一下线性代数——我们来谈谈<strong class="je hv">空间</strong>和<strong class="je hv">基</strong>。</p><p id="68e3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你熟悉原点为O(0，0)的坐标平面，并且<strong class="je hv">基向量</strong>将是i(1，0)和j(0，1)。基向量告诉我们它所覆盖的坐标平面的跨度。因此，我们可以让多个向量覆盖同一个空间。</p><p id="dddd" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这意味着我们可以改变空间的基础。现在想象一下更高维度的空间。大概50K的尺寸。您可以为该空间选择一个基，然后只选择该基的200个最重要的向量。这些基向量被称为<strong class="je hv">主成分</strong>，你选择的子集构成了一个新的空间，它的维度比原始空间更小，但尽可能保持了数据的复杂性。</p><p id="8b3b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">对此的另一种思考方式是，PCA重新映射我们的数据所在的空间，使其更具可压缩性。转换后的尺寸小于原始尺寸。</p><h1 id="b382" class="kt ku hu bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq dt translated">奇异向量分解；</h1><p id="7a07" class="pw-post-body-paragraph jc jd hu je b jf mf jh ji jj mg jl jm jn mh jp jq jr mi jt ju jv mj jx jy jz hn dt translated">奇异值分解是一种稳健有效的矩阵分解技术。与特征值分解技术等其他技术不同，它也适用于矩形矩阵。伪逆是将方阵的矩阵逆推广到行数和列数不相等的矩形矩阵，也称为Moore-Penrose逆。</p><pre class="ko kp kq kr fq mk ml mm mn aw mo dt"><span id="6c67" class="lr ku hu ml b fv mp mq l mr ms">from numpy import array<br/>from scipy.linalg import svd<br/># define a matrix<br/>A = array([[1, 2], [3, 4], [5, 6]])<br/>U, s, VT = svd(A)</span></pre><p id="4bfc" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">NumPy提供了函数pinv()来计算矩形矩阵的伪逆。</p><pre class="ko kp kq kr fq mk ml mm mn aw mo dt"><span id="3971" class="lr ku hu ml b fv mp mq l mr ms">from numpy import array<br/>from numpy.linalg import pinv<br/>A = array([[0.1, 0.2],[0.3, 0.4],[0.5, 0.6],[0.7, 0.8]])<br/># calculate pseudoinverse<br/>B = pinv(A)</span></pre><p id="ba71" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">在降维中的应用</strong></p><p id="3a0c" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">具有大量特征的数据，例如比观察值(行)更多的特征，可以被减少到与预测问题最相关的特征的较小子集。结果是一个具有较低秩的矩阵，据说该矩阵近似于原始矩阵。为此，我们可以对原始数据执行SVD操作，并选择适马中前k个最大的奇异值。这些列可以从西格玛中选择，而行可以从V^T.中选择</p><p id="b7cd" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">下一步是什么？</strong></p><p id="91d8" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在无监督学习方法下有基于能量的模型，这很有趣，因为，这些概率模型正与物理学中粒子的能量分布平行…我们当然要探索这些领域！受限玻尔兹曼机器、深度信念网络和自动编码器。</p><h1 id="dc8e" class="kt ku hu bd kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm ln lo lp lq dt translated"><strong class="ak">强化学习:</strong></h1><p id="a45d" class="pw-post-body-paragraph jc jd hu je b jf mf jh ji jj mg jl jm jn mh jp jq jr mi jt ju jv mj jx jy jz hn dt translated">这种类型的ML是最有趣的一种，因为它代表了我们采取行动的方式。多巴胺是我们成功完成一项行动后得到的奖励。在技术术语中，强化学习代理决定如何执行给定的任务，无论是玩游戏，还是在两点之间寻找最佳路径，或者学习如何驾驶无人机和做后空翻。试错是最好的说法。</p><p id="f584" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">对于对深入研究RL及其背后的数学感兴趣的读者，我建议你去看看大卫·西尔弗的讲座和理查德·萨顿关于RL的书。一些惊人的数学支持机器学习的这个美丽的子域。</p><p id="442b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">术语:</strong></p><p id="1a4d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">马尔可夫决策过程(MDPs): </strong>受有限状态机的启发，这些是有限状态的模型。对该过程进行概率建模，使得在每个状态下，基于概率预测未来状态。有道理对吗？在代理培训期间，奖励与发生的每次转变相关联。MDP的定义是当前状态独立于先前的状态。因此，它是无记忆的。</p><p id="9cb0" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv"> Q-Learning: </strong>我们有一个函数Q，它将一个状态和一个动作作为输入，并返回该动作在当前状态下的回报。在我们探索环境之前，Q给出相同的(任意的)固定值。但是，随着我们对环境探索的深入，Q给了我们一个在状态<em class="mt"> s </em>下动作<em class="mt"> a </em>越来越好的近似值。我们不断更新我们的函数Q。</p><figure class="ko kp kq kr fq iv fe ff paragraph-image"><div class="ab fr cl ks"><img src="../Images/882b4c8315fbf726e8db6233006575fb.png" data-original-src="https://miro.medium.com/v2/0*q8Dnp4guvDD230if."/></div></figure><p id="5f57" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">折扣因子有助于决定重要的状态和奖励，也是一个超参数。</p><p id="0bac" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">编码时间:</strong></p><p id="5134" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">让我们看看Andrej Karpathy的130行代码，它仅使用numpy从零开始实现强化学习，建立在OpenAI gym的ATARI 2600 Pong上。我建议你在这里阅读他的博客，以获得对RL的见解。</p><figure class="ko kp kq kr fq iv"><div class="bz el l di"><div class="mu mv l"/></div><figcaption class="mw mx fg fe ff my mz bd b be z ek">Source: <a class="ae na" href="http://karpathy.github.io/2016/05/31/rl/" rel="noopener ugc nofollow" target="_blank">http://karpathy.github.io/2016/05/31/rl/</a></figcaption></figure><p id="f4b2" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">好吧，OpenAI的成立是为了加快RL的进程，让它与监督学习并驾齐驱。我们将在另一个博客中讨论如何使用开放式健身房。他们的文档也很容易理解。我建议你去看看Andrej Karpathy的博客，这是让你开始学习RL的最好文章。这是5部分系列中的教程5。</p><p id="28e8" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如有任何疑问、建议或反馈，请通过lalith@dataturks.com联系我。</p></div></div>    
</body>
</html>