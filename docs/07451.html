<html>
<head>
<title>Tutorial : AWS Glue Billing report with PySpark with Unittest</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">教程:AWS用PySpark和Unittest粘合计费报表</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/tutorial-aws-glue-billing-report-with-pyspark-with-unittest-fbda9042b470?source=collection_archive---------8-----------------------#2018-09-02">https://medium.com/hackernoon/tutorial-aws-glue-billing-report-with-pyspark-with-unittest-fbda9042b470?source=collection_archive---------8-----------------------#2018-09-02</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/2d6c72eb505a3aedf43c47747f29877d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8D301fHKliN6r5Km.png"/></div></div></figure><p id="fcf0" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">本教程展示了如何为AWS Glue ETL作业使用生成账单(简化和假设的问题细节)，目的是学习:</p><ol class=""><li id="98dd" class="ka kb hu je b jf jg jj jk jn kc jr kd jv ke jz kf kg kh ki dt translated">PySpark中的单元测试</li><li id="97a3" class="ka kb hu je b jf kj jj kk jn kl jr km jv kn jz kf kg kh ki dt translated">编写基本函数定义并转换到UDF</li></ol><p id="f896" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">知识库:<a class="ae ko" href="https://gitlab.com/suekto.andreas/gluebilling" rel="noopener ugc nofollow" target="_blank">https://gitlab.com/suekto.andreas/gluebilling</a></p><h1 id="3763" class="kp kq hu bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm dt translated">商业问题</h1><p id="53a2" class="pw-post-body-paragraph jc jd hu je b jf ln jh ji jj lo jl jm jn lp jp jq jr lq jt ju jv lr jx jy jz hn dt translated">本教程将构建一个为AWS Glue ETL作业的使用生成计费报告的简化问题。(免责声明:此处的所有细节仅是假设性的，并与作者的假设相混合)</p><p id="4839" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">假设输入数据是正在运行的作业id的日志记录、RFC3339中的开始时间、RFC3339中的结束时间以及它使用的DPU。</p><p id="2609" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">使用价格为每DPU小时0.44美元，每秒计费，每个ETL作业最少10分钟，而crawler的成本为每DPU小时0.20美元，每秒计费，每次运行最少200秒(同样，这些数字是出于学习目的而编造的。)</p><p id="ccd5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在，我们将计算AWS Glue ETL使用的每日账单汇总。</p><h1 id="dce8" class="kp kq hu bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm dt translated">先决条件</h1><ol class=""><li id="f62e" class="ka kb hu je b jf ln jj lo jn ls jr lt jv lu jz kf kg kh ki dt translated">安装JDK 1.8，并将JAVA_HOME设置到相应的位置(我个人使用的是Mac，按照这个<a class="ae ko" href="https://docs.oracle.com/javase/8/docs/technotes/guides/install/mac_jdk.html" rel="noopener ugc nofollow" target="_blank">链接</a>和<a class="ae ko" href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html" rel="noopener ugc nofollow" target="_blank">下载链接</a>，JAVA_HOME会是/Library/JAVA/JAVA virtual machines/JDK 1 . 8 . 0 _ 181 . JDK/Contents/HOME/)</li><li id="847c" class="ka kb hu je b jf kj jj kk jn kl jr km jv kn jz kf kg kh ki dt translated">Python 2.7.x</li><li id="a321" class="ka kb hu je b jf kj jj kk jn kl jr km jv kn jz kf kg kh ki dt translated">Python覆盖率、unittest和PySpark包(最好安装在virtualenv下)</li></ol><p id="0236" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">实际上，对于这个项目，我正在使用bash-script builder来建立项目的基础，它仍然处于beta状态，本教程用于查看我对这个自动脚本构建器有多熟悉。通过手动遵循以下文章可以获得类似的结果:</p><ul class=""><li id="83ef" class="ka kb hu je b jf jg jj jk jn kc jr kd jv ke jz lv kg kh ki dt translated"><a class="ae ko" href="https://hackernoon.com/setting-up-python-dev-in-vs-code-e84f01c1f64b" rel="noopener ugc nofollow" target="_blank">https://hacker noon . com/setting-up-python-dev-in-vs-code-e 84 f 01 C1 f 64 b</a></li><li id="685c" class="ka kb hu je b jf kj jj kk jn kl jr km jv kn jz lv kg kh ki dt translated"><a class="ae ko" rel="noopener" href="/@suekto.andreas/automate-documentation-in-python-925c38eae69f">https://medium . com/@ suekto . Andreas/automate-documentation-in-python-925 c 38 aee 69 f</a></li></ul><h1 id="6a42" class="kp kq hu bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm dt translated">活动</h1><p id="be2e" class="pw-post-body-paragraph jc jd hu je b jf ln jh ji jj lo jl jm jn lp jp jq jr lq jt ju jv lr jx jy jz hn dt translated">为了做到这一点，我们将使用下面的伪代码:</p><ol class=""><li id="f38a" class="ka kb hu je b jf jg jj jk jn kc jr kd jv ke jz kf kg kh ki dt translated">载入PySpark数据帧</li><li id="d82f" class="ka kb hu je b jf kj jj kk jn kl jr km jv kn jz kf kg kh ki dt translated">计算从unix时间戳到UNIX时间戳的持续时间(秒)</li><li id="4446" class="ka kb hu je b jf kj jj kk jn kl jr km jv kn jz kf kg kh ki dt translated">计算每条记录的费用</li></ol><h2 id="559e" class="lw kq hu bd kr lx ly lz kv ma mb mc kz jn md me ld jr mf mg lh jv mh mi ll mj dt translated">001 —计算持续时间(+单元测试)</h2><p id="44b2" class="pw-post-body-paragraph jc jd hu je b jf ln jh ji jj lo jl jm jn lp jp jq jr lq jt ju jv lr jx jy jz hn dt translated">首先让我们构建计算持续时间函数。下面是我们将要使用的模块目录结构:</p><figure class="ml mm mn mo fq iv fe ff paragraph-image"><div class="fe ff mk"><img src="../Images/63e4cd604f9a09559a6b0b38623c52dc.png" data-original-src="https://miro.medium.com/v2/resize:fit:942/format:webp/1*Fx3_fNJGBJI0pDaaNrgxwA.png"/></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">module gluebilling — billing.py</figcaption></figure><p id="a2b4" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">所有文件*。py从空文件__init__开始。py表示我们将gluebilling定义为一个python模块。</p><p id="183b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">先从编写billing.py中的函数骨架开始。</p><pre class="ml mm mn mo fq mt mu mv mw aw mx dt"><span id="a942" class="lw kq hu mu b fv my mz l na nb">"""Process records of ETL Job usage into the billing of fee"""<br/>from datetime import datetime as dt</span><span id="a5b1" class="lw kq hu mu b fv nc mz l na nb">def calculate_duration(from_timestamp, to_timestamp):<br/>    """Returns duration in second between two time<br/>    return 0</span></pre><p id="cf6b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">基于这个框架，我们已经对如何调用它以及它将返回什么样的值有了更清晰的认识，现在让我们为这个函数创建单元测试，以更详细地定义它的行为。这是写在billing_utest.py中的</p><pre class="ml mm mn mo fq mt mu mv mw aw mx dt"><span id="f177" class="lw kq hu mu b fv my mz l na nb">"""Unit Testing for Glue Billing Project"""<br/>import unittest</span><span id="4d11" class="lw kq hu mu b fv nc mz l na nb">import gluebilling.billing as billing</span><span id="3734" class="lw kq hu mu b fv nc mz l na nb">class CalculateDurationTest(unittest.TestCase):<br/>    """Test Cases for Glue Billing Unit Testing"""</span><span id="da27" class="lw kq hu mu b fv nc mz l na nb">    def test_positive_duration(self):<br/>        """Test successfully calculate duration<br/>        between 2 unix timestamp string"""<br/>        duration = billing.calculate_duration(<br/>            "1535824800", "1535835600")<br/>        self.assertEqual(duration, 10800)</span><span id="a0df" class="lw kq hu mu b fv nc mz l na nb">    def test_negative_duration(self):<br/>        """Test successfully generate negative number"""<br/>        duration = billing.calculate_duration(<br/>            "1535835600", "1535824800")<br/>        self.assertEqual(duration, -10800)</span></pre><p id="9080" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在编写一个单元测试时，我们导入unittest模块，以及我们想要测试的模块(gluebilling.billing)模块。</p><p id="980e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">接下来，我们定义类来托管扩展基类(unittest)的测试用例(CalculateDurationTest)。测试案例)</p><p id="f1e4" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">随后，在CalculateDurationTest中，我们在带有“test_”前缀的对象方法格式中定义了测试用例列表。我们输入输入参数，执行我们想要测试的函数，最后使用来自unittest.TestCase的assertEqual函数检查结果。</p><p id="1afd" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果我们现在运行单元测试，它应该会失败</p><pre class="ml mm mn mo fq mt mu mv mw aw mx dt"><span id="b357" class="lw kq hu mu b fv my mz l na nb">$ coverage run --source=gluebilling -m unittest discover -p "*utest*.py" -f -s gluebilling/</span></pre><figure class="ml mm mn mo fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nd"><img src="../Images/e4316062a4838fbdc82a4990e0659cb3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*02p8eZwkd_RDsD7O6UoxDg.png"/></div></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">coverage with unittest result</figcaption></figure><p id="ac4a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在有了红色状态之后，让我们开始实现这个函数</p><pre class="ml mm mn mo fq mt mu mv mw aw mx dt"><span id="a9bd" class="lw kq hu mu b fv my mz l na nb">"""Process records of ETL Job usage into the billing of fee"""<br/>from datetime import datetime as dt</span><span id="ff28" class="lw kq hu mu b fv nc mz l na nb">def calculate_duration(from_timestamp, to_timestamp):<br/>    """Returns duration in second between two time<br/>    provided in unix timestamp"""<br/>    from_dt = dt.fromtimestamp(float(from_timestamp))<br/>    to_dt = dt.fromtimestamp(float(to_timestamp))</span><span id="12ec" class="lw kq hu mu b fv nc mz l na nb">    time_delta = to_dt - from_dt<br/>    return time_delta.total_seconds()</span></pre><p id="57c3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在我们将拥有所有绿色状态的测试用例</p><figure class="ml mm mn mo fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ne"><img src="../Images/dc79819742ac95fe519ade0a884c6557.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*-i_CL4Ioxqe3txUm2a6UWQ.png"/></div></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">calculate_duration implementation completed !</figcaption></figure><p id="0056" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">注意，上面的截图是一个开发环境设置，基于<a class="ae ko" rel="noopener" href="/hackernoon/setting-up-python-dev-in-vs-code-e84f01c1f64b">https://medium . com/hacker noon/setting-up-python-dev-in-vs-code-e 84 f 01 C1 f 64 b</a></p><h2 id="dec3" class="lw kq hu bd kr lx ly lz kv ma mb mc kz jn md me ld jr mf mg lh jv mh mi ll mj dt translated">002 —计算费用(+单元测试)</h2><p id="68a4" class="pw-post-body-paragraph jc jd hu je b jf ln jh ji jj lo jl jm jn lp jp jq jr lq jt ju jv lr jx jy jz hn dt translated">遵循上面的相同技术，我们添加如下计算费用功能:</p><p id="d24a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">in billing.py</p><pre class="ml mm mn mo fq mt mu mv mw aw mx dt"><span id="e630" class="lw kq hu mu b fv my mz l na nb">"""Process records of ETL Job usage into the billing of fee"""<br/>from datetime import datetime as dt<br/>from decimal import Decimal</span><span id="e8aa" class="lw kq hu mu b fv nc mz l na nb">...</span><span id="10c0" class="lw kq hu mu b fv nc mz l na nb">def calculate_fee(duration_in_second, dpu_num,<br/>                  minimum_duration, fee_dpu_hour):<br/>    """Returns a decimal of the fee incurred in USD,<br/>    quantized into 8 digit behind comma"""</span><span id="ef7d" class="lw kq hu mu b fv nc mz l na nb">    charged_duration = duration_in_second<br/>    if charged_duration &lt; minimum_duration:<br/>        charged_duration = minimum_duration</span><span id="1403" class="lw kq hu mu b fv nc mz l na nb">    fee = charged_duration * dpu_num * Decimal(fee_dpu_hour) / 3600<br/>    return fee.quantize(Decimal('0.00000000'))</span></pre><p id="8716" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在billing_utest.py中，我们将添加另一个类来托管calculate_fee的测试用例。</p><pre class="ml mm mn mo fq mt mu mv mw aw mx dt"><span id="e1ab" class="lw kq hu mu b fv my mz l na nb">"""Unit Testing for Glue Billing Project"""<br/>import unittest<br/>from decimal import Decimal</span><span id="5d30" class="lw kq hu mu b fv nc mz l na nb">import gluebilling.billing as billing</span><span id="9b4b" class="lw kq hu mu b fv nc mz l na nb">...</span><span id="99a3" class="lw kq hu mu b fv nc mz l na nb">class CalculateFeeTest(unittest.TestCase):<br/>    """Unit Test for calculate_fee function"""</span><span id="e55e" class="lw kq hu mu b fv nc mz l na nb">def test_more_than_10_min(self):<br/>        """When usage is more than 10 min"""<br/>        fee = billing.calculate_fee(800, 3, 600, "0.44")<br/>        self.assertEqual(fee, Decimal("0.29333333"))</span></pre><blockquote class="nf ng nh"><p id="4758" class="jc jd ni je b jf jg jh ji jj jk jl jm nj jo jp jq nk js jt ju nl jw jx jy jz hn dt translated">注意，dpu_hour值被设置为<strong class="je hv">字符串“0.44”</strong>而不是float，因为如果我们进一步将其转换为十进制类型，这是更准确的计算结果。</p></blockquote><p id="c6ff" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我之所以将这两个函数的测试用例分成不同的类，是因为<a class="ae ko" href="http://pylint-messages.wikidot.com/messages:c0103" rel="noopener ugc nofollow" target="_blank"> pylint C0103 </a> snake用例要求函数的长度不超过30个字符，所以为了保持可读性，我们将每个函数分成不同的类进行测试。</p><figure class="ml mm mn mo fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nm"><img src="../Images/c63b5c6d9230c00caba6f447a721d242.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*fRduW0tA0x0AskopLimSVQ.png"/></div></div><figcaption class="mp mq fg fe ff mr ms bd b be z ek">The coverage test result after implementing calculate_fee, notice that the coverage can be done better, it is left for the reader to exercise (see the red colour bar)</figcaption></figure><h2 id="aa03" class="lw kq hu bd kr lx ly lz kv ma mb mc kz jn md me ld jr mf mg lh jv mh mi ll mj dt translated">003 — PySpark计费计算(+功能测试)</h2><p id="da61" class="pw-post-body-paragraph jc jd hu je b jf ln jh ji jj lo jl jm jn lp jp jq jr lq jt ju jv lr jx jy jz hn dt translated">本文使用了David Illes 的<a class="ae ko" href="https://blog.cambridgespark.com/unit-testing-with-pyspark-fb31671b1ad8" rel="noopener ugc nofollow" target="_blank">教程中类似的基本概念，不同之处在于我们将设置完全独立的细节(这将反映在我们如何初始化Spark会话，以及我们如何准备测试数据)</a></p><p id="1966" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这是我们将要使用的版本，我们将其存储为pyspark_htest.py</p><pre class="ml mm mn mo fq mt mu mv mw aw mx dt"><span id="28a6" class="lw kq hu mu b fv my mz l na nb">"""PySparkTest is base class to do functional testing on PySpark"""<br/>import unittest<br/>import logging<br/>import os<br/>from pyspark.sql import SparkSession<br/>from pandas.testing import assert_frame_equal<br/></span><span id="37b4" class="lw kq hu mu b fv nc mz l na nb">class PySparkTest(unittest.TestCase):<br/>    """BaseClass which setup local PySpark"""</span><span id="e5cf" class="lw kq hu mu b fv nc mz l na nb">    @classmethod<br/>    def suppress_py4j_logging(cls):<br/>        """Supress the logging level into WARN and above"""<br/>        logger = logging.getLogger('py4j')<br/>        logger.setLevel(logging.WARN)</span><span id="7e14" class="lw kq hu mu b fv nc mz l na nb">    @classmethod<br/>    def create_testing_pyspark_session(cls):<br/>        """Returns SparkSession connecting to local context<br/>        the extrajava session is to generate <br/>        the metastore_db and derby.log into .tmp/ directory"""<br/>        tmp_dir = os.path.abspath(".tmp/")<br/>        return (SparkSession.builder<br/>                .master('local[1]')<br/>                .appName('local-testing-pyspark-context')<br/>                .config("spark.driver.extraJavaOptions",<br/>                        "-Dderby.system.home="+tmp_dir)<br/>                .config("spark.sql.warehouse.dir", tmp_dir)<br/>                .getOrCreate())</span><span id="db4a" class="lw kq hu mu b fv nc mz l na nb">    @classmethod<br/>    def setUpClass(cls):<br/>        """Setup the Spark"""<br/>        cls.suppress_py4j_logging()<br/>        cls.spark = cls.create_testing_pyspark_session()</span><span id="0e74" class="lw kq hu mu b fv nc mz l na nb">    @classmethod<br/>    def tearDownClass(cls):<br/>        """Clean up the Class"""<br/>        cls.spark.stop()</span><span id="98d2" class="lw kq hu mu b fv nc mz l na nb">    @classmethod<br/>    def assert_dataframe_equal(cls, actual, expected, keycolumns):<br/>        """Helper function to compare small dataframe"""<br/>        exp_pd = expected.toPandas().sort_values(<br/>            by=keycolumns<br/>        ).reset_index(drop=True)<br/>        <br/>        act_pd = actual.toPandas().sort_values(<br/>            by=keycolumns<br/>        ).reset_index(drop=True)<br/>        return assert_frame_equal(act_pd, exp_pd)</span></pre><p id="a836" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">注意，这个基类提供了许多有用的类方法，目的是:</p><ul class=""><li id="6d43" class="ka kb hu je b jf jg jj jk jn kc jr kd jv ke jz lv kg kh ki dt translated">仅禁止将任何日志记录到WARN(PySpark使用py4j进行日志记录)</li><li id="3ffa" class="ka kb hu je b jf kj jj kk jn kl jr km jv kn jz lv kg kh ki dt translated">用1个内核在localhost中构建Spark会话，并设置要整理的临时metastore_db存储在。tmp/ directory，以及derby.log(这样我们的工作区就整洁干净了)—create _ testing _ py spark _ session</li><li id="fefc" class="ka kb hu je b jf kj jj kk jn kl jr km jv kn jz lv kg kh ki dt translated">setUpClass和tearDownClass被自动调用一次。</li><li id="8d8a" class="ka kb hu je b jf kj jj kk jn kl jr km jv kn jz lv kg kh ki dt translated">assert_dataframe_equal —接收PySpark数据帧，然后将它们全部转换成Pandas，按键排序(因为PySpark结果不保持顺序)，然后我们使用Pandas测试来比较这两个数据帧。</li></ul><p id="3f6e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">让我们创建函数的框架(billing.py)以及输入记录和目标输出(计费记录)的预期模式定义。</p><pre class="ml mm mn mo fq mt mu mv mw aw mx dt"><span id="be6d" class="lw kq hu mu b fv my mz l na nb">def get_usage_record_schema():<br/>    """Retruns StructType containing the Input Usage<br/>    Data Expected Schema"""<br/>    return StructType([<br/>        StructField("job_id", StringType(), False),<br/>        StructField("type", StringType(), False),<br/>        StructField("dpu", IntegerType(), False),<br/>        StructField("from_unix_timestamp", StringType(), False),<br/>        StructField("to_unix_timestamp", StringType(), False)<br/>    ])</span><span id="6140" class="lw kq hu mu b fv nc mz l na nb">def get_pricing_schema():<br/>    """Retruns StructType containing the Input<br/>     Pricing Data Expected Schema"""<br/>    return StructType([<br/>        StructField("type", StringType(), False),<br/>        StructField("dpu_hour", StringType(), False),<br/>        StructField("minimum_duration", IntegerType(), False)<br/>    ])</span><span id="d4d5" class="lw kq hu mu b fv nc mz l na nb">def get_billing_schema():<br/>    """Retruns StructType containing the Billing Schema"""<br/>    return StructType([<br/>        StructField("job_id", StringType(), False),<br/>        StructField("type", StringType(), False),<br/>        StructField("dpu", IntegerType(), False),<br/>        StructField("from_unix_timestamp", StringType(), False),<br/>        StructField("to_unix_timestamp", StringType(), False),<br/>        StructField("dpu_hour", StringType(), False),<br/>        StructField("minimum_duration", IntegerType(), False),<br/>        StructField("duration", IntegerType(), False),<br/>        StructField("fee", DecimalType(20, 8), False),<br/>    ])</span><span id="bba2" class="lw kq hu mu b fv nc mz l na nb">def generate_billing(usage_df, pricing_df):<br/>    """Returns DataFrame of Fee from a DataFrame of Usage Records"""<br/>    return None</span></pre><p id="098b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">接下来，我们进入billing_ftest.py，为我们的功能测试做准备。</p><pre class="ml mm mn mo fq mt mu mv mw aw mx dt"><span id="e5a8" class="lw kq hu mu b fv my mz l na nb">"""Functional Testing for Glue Billing Project"""<br/>from decimal import Decimal<br/>from pyspark.sql import Row, SQLContext</span><span id="1993" class="lw kq hu mu b fv nc mz l na nb">import gluebilling.billing as billing<br/>import gluebilling.pyspark_htest as pysparktest</span><span id="0315" class="lw kq hu mu b fv nc mz l na nb">class GenerateBillingTest(pysparktest.PySparkTest):<br/>    """Test Cases for Generate Billing"""</span><span id="36d6" class="lw kq hu mu b fv nc mz l na nb">    def generate_usage_data_001(self):<br/>        """Generate usage data for testing it is a record of<br/>        AWS Glue ETL usage"""<br/>        rdd = self.spark.sparkContext.parallelize([<br/>            Row("JOB001", "etl", 3, "1535824800", "1535835600"),<br/>            Row("JOB002", "crawler", 3, "1535824800", "1535824850"),<br/>            Row("JOB003", "crawler", 3, "1535824800", "1535835600")<br/>        ])<br/>        schema = billing.get_usage_record_schema()</span><span id="20df" class="lw kq hu mu b fv nc mz l na nb">        sqlctx = SQLContext(self.spark.sparkContext)<br/>        return sqlctx.createDataFrame(rdd, schema)</span><span id="b5fb" class="lw kq hu mu b fv nc mz l na nb">    def generate_pricing_data_001(self):<br/>        """Generate pricing data for testing it is a record of<br/>        AWS Glue ETL usage"""<br/>        rdd = self.spark.sparkContext.parallelize([<br/>            Row("etl", "0.44", 600),<br/>            Row("crawler", "0.20", 200)<br/>        ])<br/>        schema = billing.get_pricing_schema()</span><span id="8c24" class="lw kq hu mu b fv nc mz l na nb">        sqlctx = SQLContext(self.spark.sparkContext)<br/>        return sqlctx.createDataFrame(rdd, schema)</span><span id="6c06" class="lw kq hu mu b fv nc mz l na nb">    def generate_expected_billing_001(self):<br/>        """Generate expected billing"""<br/>        rdd = self.spark.sparkContext.parallelize([<br/>            Row("JOB001", "etl", 3, "1535824800", "1535835600",    <br/>                "0.44", 600, 10800, Decimal("3.96")),<br/>            Row("JOB002", "crawler", 3, "1535824800", "1535824850", <br/>                "0.20", 200, 50, Decimal("0.03333333")),<br/>            Row("JOB003", "crawler", 3, "1535824800", "1535835600", <br/>                "0.20", 200, 10800, Decimal("1.80"))<br/>        ])<br/>        schema = billing.get_billing_schema()</span><span id="5ecd" class="lw kq hu mu b fv nc mz l na nb">        sqlctx = SQLContext(self.spark.sparkContext)<br/>        return sqlctx.createDataFrame(rdd, schema)</span><span id="b01f" class="lw kq hu mu b fv nc mz l na nb">    def test_with_set_001(self):<br/>        """Using all 001 test data set"""<br/>        usage_df = self.generate_usage_data_001()<br/>        pricing_df = self.generate_pricing_data_001()<br/>        expected = self.generate_expected_billing_001()</span><span id="13d7" class="lw kq hu mu b fv nc mz l na nb">        actual = billing.generate_billing(usage_df, pricing_df)</span><span id="40b8" class="lw kq hu mu b fv nc mz l na nb">        self.assert_dataframe_equal(actual, expected, ["job_id"])</span></pre><p id="30cd" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们在两个函数中准备输入数据。生成_使用_数据_001 <br/> 2。generate_pricing_data_001 <br/>这里使用的技术是通过使用SparkContext的Row和paralellize方法创建rdd，然后与主脚本中定义的模式相结合。</p><p id="374f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们还在函数generate_expected_billing_001中的billing_ftest.py中准备了预期的输出数据，使用了与准备输入数据类似的技术。</p><p id="7e22" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">billing_ftest.py的最后一个组件是test_with_set_001，在这里通过组合输入和预期数据帧的生成函数来执行测试，然后我们执行主脚本函数generate_billing，最后我们通过利用我们在pyspark_htest.py中定义的helper assert方法来执行assert。</p><p id="d43c" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">最后让我们在billing.py中完成功能实现。</p><pre class="ml mm mn mo fq mt mu mv mw aw mx dt"><span id="8dc6" class="lw kq hu mu b fv my mz l na nb">def generate_billing(usage_df, pricing_df):<br/>    """Returns DataFrame of Fee from a DataFrame of Usage Records"""</span><span id="f1cf" class="lw kq hu mu b fv nc mz l na nb">    duration_udf = udf(calculate_duration, IntegerType())</span><span id="0d07" class="lw kq hu mu b fv nc mz l na nb">    join_data_df = usage_df.join(<br/>        pricing_df,<br/>        usage_df.type == pricing_df.type<br/>    ).select(<br/>        usage_df.job_id, usage_df.type,<br/>        usage_df.dpu, usage_df.from_unix_timestamp,<br/>        usage_df.to_unix_timestamp,<br/>        pricing_df.dpu_hour, pricing_df.minimum_duration,<br/>        duration_udf(<br/>            usage_df.from_unix_timestamp,<br/>            usage_df.to_unix_timestamp).alias("duration")<br/>    )</span><span id="593f" class="lw kq hu mu b fv nc mz l na nb">    fee_udf = udf(calculate_fee, DecimalType(20, 8))</span><span id="99b8" class="lw kq hu mu b fv nc mz l na nb">    billing_df = join_data_df.select(<br/>        "job_id", "type", "dpu", "from_unix_timestamp",<br/>        "to_unix_timestamp", "dpu_hour", "minimum_duration",    <br/>        "duration",<br/>        fee_udf(<br/>            join_data_df.duration, join_data_df.dpu,<br/>            join_data_df.minimum_duration, join_data_df.dpu_hour<br/>        ).alias("fee")<br/>    )</span><span id="5441" class="lw kq hu mu b fv nc mz l na nb">    return billing_df</span></pre><p id="0d7c" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们将calculate_fee和calculate_duration函数封装到udf中，因为这是可以传递给pyspark的类型。第一个参数是要包装的函数，而第二个参数是预期的返回类型。</p><p id="150e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">然后，我们在PySpark SQL数据帧的SELECT部分使用它来生成两个新列duration和fee。</p><h1 id="1b47" class="kp kq hu bd kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll lm dt translated">结论</h1><p id="4688" class="pw-post-body-paragraph jc jd hu je b jf ln jh ji jj lo jl jm jn lp jp jq jr lq jt ju jv lr jx jy jz hn dt translated">就这样，现在我们已经实现了功能测试，我用calculate_fee和calculate_duration来区分它，因为这个测试的执行速度，它需要几秒钟来启动pyspark，因此它值得进行不同的分组。</p><p id="5dfa" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这为我们提供了过滤掉我们想要在保存时运行哪种测试的选项(如果我们正在自动化开发体验的话)</p></div></div>    
</body>
</html>