<html>
<head>
<title>A gentle introduction to hardware accelerated data processing</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">硬件加速数据处理简介</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/a-gentle-introduction-to-hardware-accelerated-data-processing-81ac79c2105?source=collection_archive---------5-----------------------#2018-09-03">https://medium.com/hackernoon/a-gentle-introduction-to-hardware-accelerated-data-processing-81ac79c2105?source=collection_archive---------5-----------------------#2018-09-03</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/3b193812e32a9527cc89b937a766876f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*A9DRNS_pC1K0gF8Qpn6uYQ.png"/></div></div></figure><p id="bf3b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt ka translated">用于数据处理的硬件加速有着悠久的历史。这不是新的。当我还是个孩子的时候，我爸爸为我们的12 MHz 286系统配备了可选的80287浮点单元(FPU)协处理器，运行速度高达4.7MHz。</p><figure class="kk kl km kn fq iv fe ff paragraph-image"><div class="fe ff kj"><img src="../Images/9341fd9dfb6d42f07c534897f7e595eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1122/format:webp/0*VcCV9sG3jJjwSI-z.jpg"/></div></figure><p id="5ad7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">那东西是一头野兽。它为Lotus 1–2–3创造了奇迹。</p><p id="7289" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">不久之后，这种特定的FPU被集成到CPU中，减少了数学运算对外部协处理器的需求。然而，协处理器实际上存在的时间更长。</p><p id="c172" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你知道你用来读这篇文章的GPU吗？你手机里的DSP？声卡？他们都是协处理器，他们仍然存在是有原因的。</p><h1 id="dd2e" class="ko kp hu bd kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf lg lh li lj lk ll dt translated">你的CPU不能做所有的事情</h1><p id="db78" class="pw-post-body-paragraph jc jd hu je b jf lm jh ji jj ln jl jm jn lo jp jq jr lp jt ju jv lq jx jy jz hn dt translated">不，真的。它不能。英特尔x86(8086的继承者，也是我最爱的80286)架构的实际芯片已经非常复杂了。根据EETimes的Rick Merrit的说法，向x86体系结构添加额外的操作具有递减的回报，<a class="ae lr" href="https://www.eetimes.com/document.asp?doc_id=1333109" rel="noopener ugc nofollow" target="_blank">到了可能不值得的地步</a>。</p><p id="798e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">事实上，全球最大的硅芯片制造商之一GlobalFoundries已经宣布<a class="ae lr" href="https://www.anandtech.com/show/13277/globalfoundries-stops-all-7nm-development" rel="noopener ugc nofollow" target="_blank">放弃7纳米芯片</a>的计划。只是已经不值得了。</p><figure class="kk kl km kn fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ls"><img src="../Images/360e93c78bfa4930859f8a2503e439d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*YEgoGEVemkNXa2__.jpg"/></div></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">Intel Haswell-EP Xeon E5–2699 V3 Die on <a class="ae lr" href="https://wccftech.com/intel-xeon-e52600-v3-haswellep-workstation-server-processors-unleashed-highperformance-computing/" rel="noopener ugc nofollow" target="_blank">wccftech</a></figcaption></figure><p id="f85c" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">为什么这是个问题？嗯，x86架构中的每个处理器内核都做许多不同的事情，这实际上让程序员们沾沾自喜。不用担心写不好的软件——处理器会保证它运行的很快！</p><p id="8ba7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">当然，英特尔早在21世纪初就知道这一点。他们试图用Itanium来扼杀x86架构，Itanium是一个为64位计算设计的处理器系列。然而，AMD有一个不同的计划，并发布了64位x86处理器，阻碍了英特尔的计划。这就是我们如何结束这场混乱。</p><h2 id="5bd2" class="lx kp hu bd kq ly lz ma ku mb mc md ky jn me mf lc jr mg mh lg jv mi mj lk mk dt translated">走向多核</h2><p id="a4de" class="pw-post-body-paragraph jc jd hu je b jf lm jh ji jj ln jl jm jn lo jp jq jr lp jt ju jv lq jx jy jz hn dt translated">让CPU发挥更大威力的唯一方法是向外扩展。这就是为什么今天的CPU几乎都是多核的原因。对于英特尔至强系列等高端服务器芯片，它们有2到28个内核。</p><p id="ca63" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">x86架构中巧妙的流水线和向量化、缓存以及其他一些复杂的系统允许很好地利用微型电子设备。有些任务可以成组运行，处理器甚至可以在下一步动作发生之前就正确预测它们。然而，正如我之前提到的，这些处理器已经非常复杂了。</p><p id="e5a6" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">其他架构确实存在。你可以在各种各样的设备中找到ARM——从电池充电器到你的手机，甚至你的汽车——它有一个精简指令集，也称为RISC。</p><p id="a7af" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">IBM同样走了RISC路线。RISC处理器有一个简单得多的核心，它不能做更多复杂的CPU核心所做的事情。软件必须专门编写为多核，才能从这类处理器中受益。</p><p id="58fc" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">目前，x86还没有被执行。可能再过10年、15年，x86就会消失。</p><p id="1bfa" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果您有兴趣了解英特尔为实现并行处理所做的更多工作，请阅读关于英特尔SPMD计划编译器的“ISPC的故事:【https://pharr.org/matt/blog/2018/04/18/ispc-origins.html】T2</p></div><div class="ab cl ml mm hc mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="hn ho hp hq hr"><h1 id="3ff7" class="ko kp hu bd kq kr ms kt ku kv mt kx ky kz mu lb lc ld mv lf lg lh mw lj lk ll dt translated">GPU和GPGPUs来了</h1><p id="587f" class="pw-post-body-paragraph jc jd hu je b jf lm jh ji jj ln jl jm jn lo jp jq jr lp jt ju jv lq jx jy jz hn dt translated">图形处理单元(GPU)也不是什么新东西。这个术语至少在1986年就已经在<a class="ae lr" href="https://books.google.dk/books?id=2j4hTAqxJ_sC&amp;pg=PA169&amp;redir_esc=y#v=onepage&amp;q&amp;f=false" rel="noopener ugc nofollow" target="_blank">使用了，但是倾向于严格地集中在图形上。NVIDIA的第一张作为“GPU”上市的卡是2009年的GeForce 256。然而，通用GPU(<strong class="je hv">gp GPU</strong>s)实际上在2007年左右开始出现，当时NVIDIA和ATI(现在的AMD)开始为他们的3D显卡配备越来越多的功能，如统一像素着色器。这些功能可以重新用于执行矩阵乘法、快速傅立叶变换、小波变换等操作。</a></p><figure class="kk kl km kn fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mx"><img src="../Images/ad3b5674f15e523eb7e97c47be507040.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Fz2R-L_79w2-pVFsU0vCfA.png"/></div></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">NVIDIA Tesla C870 with 128 CUDA cores (<a class="ae lr" href="https://www.nvidia.com/docs/IO/43395/C870-BoardSpec_BD-03399-001_v04.pdf" rel="noopener ugc nofollow" target="_blank">NVIDIA</a>)</figcaption></figure><p id="21f5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">访问这些特性意味着必须发明新的编程结构。所以，2008年，苹果开始开发OpenCL。到2009年底，它已经被AMD、IBM、高通、英特尔甚至NVIDIA采用。AMD决定广泛支持OpenCL，而不是他们“接近金属”的框架。</p><figure class="kk kl km kn fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff my"><img src="../Images/1a3b89cfaba11d32571886ad77aef1d9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*v1R_xOHPWhT5CjN9.jpg"/></div></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">AMD’s Radeon Pro V340, with 512GB/s of memory bandwidth. Source: AMD</figcaption></figure><p id="44f9" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">虽然NVIDIA过去和现在都支持OpenCL，但他们并没有放弃自己的框架，即CUDA。今天，CUDA是高速、高吞吐量GPU计算的事实上的标准。它本质上是一个软件层，可以直接访问GPU的虚拟指令集和并行计算元素，以执行计算内核。</p><figure class="kk kl km kn fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mz"><img src="../Images/09b372b7f36e9284bc8669b677dac838.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Jrtim8A-ZAzsujg1sNOK3A.png"/></div></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">Newer NVIDIA GPUs have up to 5,760 CUDA cores</figcaption></figure><p id="675c" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">凭借2009年的256个内核，以及单个现代GPU中多达5，760个内核，我认为很容易理解为什么GPU对于需要高度并行性的操作非常有用。但这不仅仅是并行性——GPU拥有极大的内存带宽，这使其适合高吞吐量的应用。</p><h2 id="3918" class="lx kp hu bd kq ly lz ma ku mb mc md ky jn me mf lc jr mg mh lg jv mi mj lk mk dt translated">为什么不干脆把CPU换成GPU？</h2><p id="7e41" class="pw-post-body-paragraph jc jd hu je b jf lm jh ji jj ln jl jm jn lo jp jq jr lp jt ju jv lq jx jy jz hn dt translated">并不是所有的应用都适合GPU。GPU在以下情况下最有用:</p><ul class=""><li id="5697" class="na nb hu je b jf jg jj jk jn nc jr nd jv ne jz nf ng nh ni dt translated">这些动作是重复的</li><li id="ab42" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated">这些动作大多是独立的(不相互依赖)</li><li id="455f" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated">这些操作计算量很大</li></ul><p id="65ca" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">除了图形(和密码挖掘)，GPU还发现了一些有趣的用途。今天，在各种数据处理场景中都可以找到GPU。它们可以用作数据处理管道的一部分，用于在上运行机器学习模型，作为硬件加速关系数据库的一部分，或者只是很好地呈现结果。</p><p id="a67e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">让我们来看看GPU在数据处理管道中可以发挥作用的三个主要领域:</p><h2 id="5ebb" class="lx kp hu bd kq ly lz ma ku mb mc md ky jn me mf lc jr mg mh lg jv mi mj lk mk dt translated">用于流处理的GPU</h2><p id="7bf2" class="pw-post-body-paragraph jc jd hu je b jf lm jh ji jj ln jl jm jn lo jp jq jr lp jt ju jv lq jx jy jz hn dt translated">新的流处理解决方案，如<a class="ae lr" href="https://www.fastdata.io/" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv"> FASTDATA.io </strong> </a>的等离子引擎可以利用GPU对进出数据库的数据进行流处理(无论是否使用GPU)。该工具可用于在GPU上执行流数据的分析和/或转换。</p><p id="05d6" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">FASTDATA引擎的主要竞争对手是<a class="ae lr" href="https://github.com/IBMSparkGPU/SparkGPU" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">支持GPU的Spark </strong> </a>，它是IBM的开源插件。</p><h2 id="3b04" class="lx kp hu bd kq ly lz ma ku mb mc md ky jn me mf lc jr mg mh lg jv mi mj lk mk dt translated">用于分析的GPU数据库</h2><p id="8195" class="pw-post-body-paragraph jc jd hu je b jf lm jh ji jj ln jl jm jn lo jp jq jr lp jt ju jv lq jx jy jz hn dt translated">几乎所有的GPU数据库都是为分析而构建的。</p><figure class="kk kl km kn fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff no"><img src="../Images/fa251e1af1ee554829c4912f0c6ec334.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DPOOwTXPz64vPqM3mpeT8w.png"/></div></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">GPU Databases. Source: <a class="ae lr" href="http://mattturck.com/bigdata2018/" rel="noopener ugc nofollow" target="_blank">The 2018 Big Data Landscape</a></figcaption></figure><p id="8264" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">从头开始构建GPU数据库的原因似乎是用非常不同的技术改造旧的基于行的数据库存在困难。</p><p id="94f9" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">GPU数据库领域有几个参与者，每个参与者都有自己的优势:</p><ul class=""><li id="ce6e" class="na nb hu je b jf jg jj jk jn nc jr nd jv ne jz nf ng nh ni dt translated"><a class="ae lr" href="https://www.omnisci.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv"> OmniSci </strong> </a> <strong class="je hv">(以前为MapD)——用于地理空间用例的内存GPU数据库</strong></li><li id="2e32" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="https://sqream.com" rel="noopener ugc nofollow" target="_blank"><strong class="je hv">SQream DB</strong></a><strong class="je hv">—针对大于RAM的数据集的GPU数据仓库</strong></li><li id="dc60" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="https://blazingdb.com" rel="noopener ugc nofollow" target="_blank"><strong class="je hv">BlazingDB</strong></a><strong class="je hv">—基于拼花的GPU数据库</strong></li><li id="898f" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="https://www.kinetica.com/" rel="noopener ugc nofollow" target="_blank"><strong class="je hv">Kinetica</strong></a><strong class="je hv">—内存GPU数据库</strong></li><li id="8dc8" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="http://heterodb.com/" rel="noopener ugc nofollow" target="_blank"><strong class="je hv">HeteroDB</strong></a><strong class="je hv">—Postgres插件，基于UDF，用于快速NVMe访问</strong></li><li id="53c3" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="https://www.brytlyt.com/" rel="noopener ugc nofollow" target="_blank"><strong class="je hv">Brytlyt</strong></a><strong class="je hv">—用于内存计算的Postgres插件</strong></li><li id="89ab" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="https://www.blazegraph.com/" rel="noopener ugc nofollow" target="_blank"><strong class="je hv">Blazegraph</strong></a><strong class="je hv">—图形数据库</strong></li></ul><h2 id="3507" class="lx kp hu bd kq ly lz ma ku mb mc md ky jn me mf lc jr mg mh lg jv mi mj lk mk dt translated"><strong class="ak">用于机器学习的GPU</strong></h2><p id="ed23" class="pw-post-body-paragraph jc jd hu je b jf lm jh ji jj ln jl jm jn lo jp jq jr lp jt ju jv lq jx jy jz hn dt translated">机器学习往往非常适合GPU架构。这不仅仅是高水平的并行性和众多的矩阵运算。很大一部分原因其实就是前面提到的内存带宽。</p><figure class="kk kl km kn fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff np"><img src="../Images/f61dac9f43bd336250473d15511f0bf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*6_cBDYEC94A42BPu.jpg"/></div></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">NVIDIA Tesla V100 core-arrangement. Source: <a class="ae lr" href="https://www.servethehome.com/nvidia-v100-volta-update-hot-chips-2017/" rel="noopener ugc nofollow" target="_blank">ServeTheHome</a></figcaption></figure><p id="14e5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">CPU就是我们所说的面向延迟的处理器。面向延迟意味着他们倾向于降低纳秒级时钟周期的操作延迟(一条数据每秒约30亿次操作)。相比之下，GPU是面向吞吐量的。它们将以较低的时钟速度(每秒对多个数据块执行约10亿次操作)对大量数据同时执行单个操作。</p><p id="1d68" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">GPU以较慢的时钟速度牺牲延迟，以便在每个时钟周期获得更高的吞吐量。</p><p id="1c4d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">不同的GPU支持的机器学习框架并不缺乏:</p><ul class=""><li id="7473" class="na nb hu je b jf jg jj jk jn nc jr nd jv ne jz nf ng nh ni dt translated"><a class="ae lr" href="https://www.tensorflow.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">张量流</strong> </a></li><li id="4702" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="https://developer.nvidia.com/cublas" rel="noopener ugc nofollow" target="_blank">T5】库布拉斯T7】</a></li><li id="6d72" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="http://caffe.berkeleyvision.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">韩菲</strong> </a></li><li id="a215" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="http://deeplearning.net/software/theano/" rel="noopener ugc nofollow" target="_blank"><strong class="je hv">theno</strong></a></li><li id="4c5f" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="https://github.com/torch/torch7" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">火炬7 </strong> </a></li><li id="a2f6" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="https://developer.nvidia.com/cudnn" rel="noopener ugc nofollow" target="_blank"><strong class="je hv">cud nn</strong>T23】</a></li><li id="d97c" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="https://www.mathworks.com/discovery/matlab-gpu.html" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv"> MATLAB </strong> </a></li><li id="feea" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="https://mxnet.apache.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv"> cxxnet/mxnet </strong> </a></li><li id="e572" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="https://deeplearning4j.org/" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">深度学习4j </strong> </a></li><li id="07ad" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"><strong class="je hv"/></a></li><li id="692e" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><a class="ae lr" href="https://reference.wolfram.com/language/example/SpeedUpComputationsWithParallelGPUComputing.html" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv"> Mathematica </strong> </a></li></ul><p id="5944" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">还有很多。</p></div><div class="ab cl ml mm hc mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="hn ho hp hq hr"><h1 id="1821" class="ko kp hu bd kq kr ms kt ku kv mt kx ky kz mu lb lc ld mv lf lg lh mw lj lk ll dt translated">不仅仅是GPU，还有ASICs、FPGAs和其他奇特的硬件</h1><p id="3a1d" class="pw-post-body-paragraph jc jd hu je b jf lm jh ji jj ln jl jm jn lo jp jq jr lp jt ju jv lq jx jy jz hn dt translated">虽然CPU和GPU是通用的，但我们在硬件上有一些其他替代方案，但也有一些权衡。</p><figure class="kk kl km kn fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nq"><img src="../Images/8e6229a55d0afc95c3290ab63533d252.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*9vzNsVrkxrLksDBntyFHnQ.png"/></div></div></figure><p id="404a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们已经讨论过CPU和GPU了，下面具体说说FPGAs和ASICs。</p><h2 id="a05c" class="lx kp hu bd kq ly lz ma ku mb mc md ky jn me mf lc jr mg mh lg jv mi mj lk mk dt translated">FPGAs</h2><p id="726f" class="pw-post-body-paragraph jc jd hu je b jf lm jh ji jj ln jl jm jn lo jp jq jr lp jt ju jv lq jx jy jz hn dt translated">现场可编程门阵列(FPGA)是一种高速可编程芯片。它们非常受原型和专业设备的欢迎。它们包含一个可编程逻辑块阵列和一个可重新配置的互连层次结构。</p><p id="da21" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">因为FPGAs是可编程的，它们可以在制造出来后被修改，但不能被任何人修改。它们提供了良好的性能，但成本相当高——这就是为什么它们仍然主要用于低产量设备的原因。您可以在医疗设备、汽车、专业设备等中找到FPGAs。</p><p id="2bbd" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">与CPU(和GPU)相比，FPGAs提供了更高的内存带宽和更低的功耗，但它们可能会与浮点计算相冲突，并且很难使用。事实上，它们很难编程，即使最近有像OpenCL for FPGA这样的工具存在。</p><p id="92af" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在数据分析中，FPGAs适合简单的重复性任务。它们出现在现代平台中，如微软的 <a class="ae lr" href="https://www.microsoft.com/en-us/research/project/project-brainwave/" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">项目脑波</strong> </a>、Postgres的<a class="ae lr" href="https://swarm64.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv"> Swarm64数据库加速器</strong></a><strong class="je hv"/>、Xilinx的<a class="ae lr" href="https://www.xilinx.com/products/boards-and-kits/alveo/u250.html" rel="noopener ugc nofollow" target="_blank"><strong class="je hv">Alveo数据中心加速器</strong> </a>，以及类似<a class="ae lr" href="http://www.ryft.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv"> Ryft </strong> </a>的设备。FPGA在分析中最广为人知的用法之一是<a class="ae lr" href="https://www.ibm.com/analytics/netezza" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv"> IBM的Netezza </strong> </a>，虽然Netezza的FPGA方面似乎已经大部分被放弃了。</p><p id="984a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">最终，Netezza成为了IBM PureData的一部分，FPGA组件主要用于受益于FPGA的特定操作，如解压缩和转换。其他操作仍然使用CPU。</p><figure class="kk kl km kn fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff nr"><img src="../Images/a1c5d46d78efc5ae9ee7145314ef98a6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*_hBpka5SQiUBaOoW.jpg"/></div></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">Source: <a class="ae lr" href="https://www.youtube.com/watch?v=xcny1gU0x18" rel="noopener ugc nofollow" target="_blank">IBM Data Retrieval Technologies RDBMS, BLU, IBM Netezza and Hadoop</a></figcaption></figure><h2 id="a307" class="lx kp hu bd kq ly lz ma ku mb mc md ky jn me mf lc jr mg mh lg jv mi mj lk mk dt translated">专用集成电路（ApplicationSpecificIntegratedCircuits）</h2><p id="b9fe" class="pw-post-body-paragraph jc jd hu je b jf lm jh ji jj ln jl jm jn lo jp jq jr lp jt ju jv lq jx jy jz hn dt translated">定制设计的专用集成电路(ASIC)是硅级高速操作的最快选择。因为这些芯片是高度定制的，所以它们能够以最小的开销提供最佳的性能。</p><p id="acbf" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">ASICs通常是数字信号处理器(DSP)，用于音频处理、视频编码和网络等领域。这些应用主要是在大规模生产的设备中，如照相机、移动电话、无线路由器等。</p><p id="c5f5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">由于创建定制ASICs的高成本和时间投资，它们也是最昂贵的选择。如果你计划生产数百万个，它们实际上是更便宜的选择，但在小批量生产时，它们很难证明是合理的。出于这个原因，它们在分析或数据处理中并不常见。</p><h2 id="47fd" class="lx kp hu bd kq ly lz ma ku mb mc md ky jn me mf lc jr mg mh lg jv mi mj lk mk dt translated">比较权衡</h2><p id="5f01" class="pw-post-body-paragraph jc jd hu je b jf lm jh ji jj ln jl jm jn lo jp jq jr lp jt ju jv lq jx jy jz hn dt translated">以下是不同处理器及其权衡的总结:</p><figure class="kk kl km kn fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ns"><img src="../Images/fe6052bb39488c0d6b2cd008c4f2430f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gnkYBIN1qVBdo3CmlMo7BA.png"/></div></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">Each of the processor types has its own tradeoffs</figcaption></figure></div><div class="ab cl ml mm hc mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="hn ho hp hq hr"><h1 id="1f16" class="ko kp hu bd kq kr ms kt ku kv mt kx ky kz mu lb lc ld mv lf lg lh mw lj lk ll dt translated">硬件加速数据处理的未来</h1><p id="9bac" class="pw-post-body-paragraph jc jd hu je b jf lm jh ji jj ln jl jm jn lo jp jq jr lp jt ju jv lq jx jy jz hn dt translated">未来是硬件多样化，但不是所有的协处理器都适合每一项任务。</p><ul class=""><li id="73eb" class="na nb hu je b jf jg jj jk jn nc jr nd jv ne jz nf ng nh ni dt translated">CPU的工作:保持标准的、顺序的程序和代码运行</li><li id="0843" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><strong class="je hv">协处理器的工作:</strong>运行高吞吐量并行代码</li><li id="46b0" class="na nb hu je b jf nj jj nk jn nl jr nm jv nn jz nf ng nh ni dt translated"><strong class="je hv"> CPU +协处理器:</strong>提高并行程序的吞吐量</li></ul><p id="d22a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">很明显，x86 CPU架构不会永远存在。从长远来看，这是不可持续的。它与现代数据工作负载的发展速度不同。</p><p id="c2d9" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">因为它们没有绑定到相同的向后兼容性，GPU进步得更快。现代数据工作负载多种多样、不断变化、不断增长且发展迅速。GPU和其他硬件加速数据处理应用程序越来越受欢迎，在机器学习领域和数据仓库领域取得了一些显著的成功。</p><figure class="kk kl km kn fq iv fe ff paragraph-image"><div class="fe ff nt"><img src="../Images/e1ecc5ca9284a6b04e2a8486e00901a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1252/format:webp/0*gfT0Aanj_U6tm8He.png"/></div><figcaption class="lt lu fg fe ff lv lw bd b be z ek">Tesla V100 with NVLink GPU-to-GPU and GPU-to-CPU (Power9) connections. Source: <a class="ae lr" href="https://www.nvidia.com/en-us/data-center/nvlink/" rel="noopener ugc nofollow" target="_blank">NVIDIA</a></figcaption></figure><p id="9919" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">支持FPGA和GPU的硬件，如带有NVLINK和OpenCAPI的IBM Power9，以及Azure和AWS GPU和FPGA实例只是未来发展的一个迹象。</p></div><div class="ab cl ml mm hc mn" role="separator"><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq mr"/><span class="mo bw bk mp mq"/></div><div class="hn ho hp hq hr"><h1 id="da02" class="ko kp hu bd kq kr ms kt ku kv mt kx ky kz mu lb lc ld mv lf lg lh mw lj lk ll dt translated">结论</h1><p id="e8e1" class="pw-post-body-paragraph jc jd hu je b jf lm jh ji jj ln jl jm jn lo jp jq jr lp jt ju jv lq jx jy jz hn dt translated">我认为硬件加速数据处理仍处于起步阶段，但随着加速技术在今天的CPU架构上继续取得进展，它可能会变得更加广泛。</p><p id="75e7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">谢谢你把这个看完！我知道这并不容易——有很多信息(和缩略语)需要消化。</p><p id="9ed5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">本文是硬件加速数据系列文章的第一篇。在我的下一篇文章中，我将深入探讨不同的硬件加速数据库如何利用它们各自的硬件加速器。</p><p id="ced6" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果你喜欢这篇文章，请在下面留下评论，或者与你的朋友和同事分享。</p></div></div>    
</body>
</html>