<html>
<head>
<title>“If I were a girl” — Magic Mirror by StarGAN</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">《如果我是女孩》——斯塔根的魔镜</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/if-i-were-a-girl-magic-mirror-by-stargan-b2cc6787badf?source=collection_archive---------39-----------------------#2018-09-03">https://medium.com/hackernoon/if-i-were-a-girl-magic-mirror-by-stargan-b2cc6787badf?source=collection_archive---------39-----------------------#2018-09-03</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/1f190c32df773decc7a37dfa1e195407.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*gOQ5GcWVjYMBN1u7.jpg"/></div></div><figcaption class="jc jd fg fe ff je jf bd b be z ek">Magic mirror</figcaption></figure><blockquote class="jg"><p id="daa0" class="jh ji hu bd jj jk jl jm jn jo jp jq ek translated">有没有想过如果你是女孩，你会是什么样子？</p></blockquote><blockquote class="jr js jt"><p id="1f2b" class="ju jv jw jx b jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr jq hn dt translated">想象一下。我跳下床，看着镜子。我是金发的！</p><p id="7b8a" class="ju jv jw jx b jy ks ka kb kc kt ke kf kg ku ki kj kk kv km kn ko kw kq kr jq hn dt translated">你问:“那是你作为一个女孩的样子吗？”</p><p id="f271" class="ju jv jw jx b jy ks ka kb kc kt ke kf kg ku ki kj kk kv km kn ko kw kq kr jq hn dt translated">我说:“是的，天啊，是的，是的，是的！这是我一直想要的！</p></blockquote><p id="f568" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">魔镜由StarGAN提供支持，StarGAN是一个用于多域图像到图像翻译的统一生成对抗网络。这篇文章将向你展示这个模型是如何工作的，以及你如何建造魔镜。</p><figure class="lb lc ld le fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff la"><img src="../Images/2fe49b965290aadbed48d53898f5f9b2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*ZgvjahtsgSafO4C3.png"/></div></div></figure><h2 id="e3a9" class="lf lg hu bd lh li lj lk ll lm ln lo lp kx lq lr ls ky lt lu lv kz lw lx ly lz dt translated">在这里欣赏YouTube演示<a class="ae ma" href="https://youtu.be/PkWIalWnYUg" rel="noopener ugc nofollow" target="_blank">。</a></h2><h2 id="2eeb" class="lf lg hu bd lh li lj lk ll lm ln lo lp kx lq lr ls ky lt lu lv kz lw lx ly lz dt translated">我的<a class="ae ma" href="https://github.com/Tony607/DeepMagicMirror" rel="noopener ugc nofollow" target="_blank"> GitHub </a>页面上有完整的源代码。</h2><h1 id="5a45" class="mb lg hu bd lh mc md me ll mf mg mh lp mi mj mk ls ml mm mn lv mo mp mq ly mr dt translated">StarGAN简介</h1><p id="eca3" class="pw-post-body-paragraph ju jv hu jx b jy ms ka kb kc mt ke kf kx mu ki kj ky mv km kn kz mw kq kr jq hn dt translated">图像到图像的转换是将给定图像的特定方面改变为另一个，例如，将人的性别从男性改变为女性。随着生成对抗网络(GANs)的引入，这项任务经历了重大的改进，结果包括从边缘地图生成照片，改变风景图像的季节，以及从莫奈的画作重建照片。</p><figure class="lb lc ld le fq iv fe ff paragraph-image"><div class="fe ff mx"><img src="../Images/6ce19f44b9e40680c5ccd55a60229bbc.png" data-original-src="https://miro.medium.com/v2/resize:fit:1308/format:webp/1*_1zuakEREFgtcMN7Bhbbuw.png"/></div><figcaption class="jc jd fg fe ff je jf bd b be z ek">Images generated with GANs</figcaption></figure><p id="0a80" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">给定来自两个不同领域的训练数据，这些模型学习以单向方式将图像从一个领域翻译到另一个领域。例如，一个生成模型被训练成将黑头发的人翻译成金发。任何单个现有的GAN模型都不能“向后”翻译，就像前面的例子中从金色头发到黑色头发。此外，单一模型无法处理灵活的多领域图像翻译任务。比如性别和头发颜色的可配置转换。这就是StarGAN脱颖而出的地方，这是一个新颖的生成式对抗网络，它只使用一个生成器和一个鉴别器来学习多个域之间的映射，从所有域的图像中有效地进行训练。StarGAN的模型不是学习固定的翻译(例如，从黑人到金发)，而是将图像和域信息都作为输入，并学习将输入图像灵活地翻译到相应的域中。<br/>预训练的StarGAN模型像其他GAN模型一样由两个网络组成，即生成网络和判别网络。虽然只需要生成网络来构建魔镜，但是理解完整的模型来自哪里仍然是有用的。</p><p id="b42d" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">生成网络将两条信息作为输入，即分辨率为256×256的原始RGB图像和目标标签，以生成具有相同分辨率的伪图像，判别网络学习区分真实图像和伪图像，并将真实图像分类到其对应的域。</p><p id="a266" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">我们将要使用的预训练模型是在CelebA数据集上训练的，该数据集包含202，599张名人的面部图像，每张图像都用40个二元属性进行了注释，而研究人员使用以下属性选择了七个域:头发颜色(黑色、金色、棕色)、性别(男性/女性)和年龄(年轻/年老)。</p><figure class="lb lc ld le fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff my"><img src="../Images/1b8e36bc48976e5b758b78bfcfdc8480.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*5myheLhT18dikE9U.png"/></div></div><figcaption class="jc jd fg fe ff je jf bd b be z ek">StarGAN</figcaption></figure><h1 id="e93e" class="mb lg hu bd lh mc md me ll mf mg mh lp mi mj mk ls ml mm mn lv mo mp mq ly mr dt translated">建造魔镜</h1><p id="8ecf" class="pw-post-body-paragraph ju jv hu jx b jy ms ka kb kc mt ke kf kx mu ki kj ky mv km kn kz mw kq kr jq hn dt translated">StarGAN的研究人员在我们的魔镜项目所在的GitHub上发布了他们的<a class="ae ma" href="https://github.com/yunjey/StarGAN" rel="noopener ugc nofollow" target="_blank">代码</a>。我也是第一次处理PyTorch框架，到目前为止进展顺利。如果你像我一样是PyTorch框架的新手，你会发现很容易上手，尤其是有了Keras或TensorFlow等深度学习框架的经验之后。</p><p id="7d93" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">完成这个项目只需要PyTorch框架最基本的知识，比如PyTorch张量、加载预定义的模型权重等。</p><p id="ce9b" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">让我们从安装框架开始。在我的情况下，在Windows 10上，这是最新的PyTorch官方支持的。</p><p id="7299" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">要使魔镜实时运行，并将可察觉的延迟降至最低，请使用游戏电脑的Nvidia显卡(如果有)来加速模型执行。</p><p id="edd9" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">从Nvidia开发者网站上的<a class="ae ma" href="https://developer.nvidia.com/cuda-90-download-archive" rel="noopener ugc nofollow" target="_blank">这个链接安装CUDA 9。</a></p><figure class="lb lc ld le fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mz"><img src="../Images/edf0469f85bc68e9afd5ab73234f7165.png" data-original-src="https://miro.medium.com/v2/resize:fit:1316/format:webp/0*TCqc8uKWjb2wluYq.png"/></div></div><figcaption class="jc jd fg fe ff je jf bd b be z ek">Install CUDA 9</figcaption></figure><p id="bec2" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">之后安装PyTorch与CUDA 9.0支持以下<a class="ae ma" href="https://pytorch.org/" rel="noopener ugc nofollow" target="_blank">其官方网站</a>的指示。</p><figure class="lb lc ld le fq iv fe ff paragraph-image"><div class="fe ff na"><img src="../Images/b15199d0879dc4448426c2a3a2694ecd.png" data-original-src="https://miro.medium.com/v2/resize:fit:1098/format:webp/0*DAY4th3ZOHtONnib.png"/></div><figcaption class="jc jd fg fe ff je jf bd b be z ek">Install PyTorch</figcaption></figure><p id="03c6" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">当PyTorch和其他Python依赖项安装好后，我们就可以开始编写代码了。</p><p id="a872" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">为了实现简单的实时人脸跟踪和裁剪效果，我们将使用Python的OpenCV库中的轻量级<strong class="jx hv"> CascadeClassifier </strong>模块。该模块从网络摄像头帧中获取灰度图像，并返回检测到的人脸的边界框信息。如果在给定的帧中检测到多个面部，我们将采用具有最大计算边界框面积的“主要”面部。</p><p id="f63a" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">由于StarGAN生成网络期望图像的像素值在-1到1之间，而不是在0到255之间，我们将使用PyTorch的内置图像转换实用程序来处理图像预处理。</p><figure class="lb lc ld le fq iv"><div class="bz el l di"><div class="nb nc l"/></div><figcaption class="jc jd fg fe ff je jf bd b be z ek">PyTorch image transform</figcaption></figure><p id="04c5" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">生成网络将PyTorch的<code class="eh nd ne nf ng b">nn.Module</code>子类化，这意味着您可以通过将输入张量作为参数传入来直接调用它。</p><figure class="lb lc ld le fq iv"><div class="bz el l di"><div class="nb nc l"/></div><figcaption class="jc jd fg fe ff je jf bd b be z ek">Run the generative network</figcaption></figure><p id="dbf2" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated"><code class="eh nd ne nf ng b">labels</code>变量是PyTorch张量，有5个值，每个值设置为0或1，以指示5个目标标签。</p><p id="fe3a" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">['黑发'，'金发'，'棕发'，'男性'，'年轻']</p><p id="fea0" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">例如，我们希望将一幅肖像转换为金发的年轻女性。<code class="eh nd ne nf ng b">labels</code>的值将被设置为[0，1，0，0，1]。</p><p id="c7a2" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">为了显示用cv2的imshow()函数生成的图像张量，下面是一行代码。</p><figure class="lb lc ld le fq iv"><div class="bz el l di"><div class="nb nc l"/></div></figure><p id="cd30" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">这就是崩溃，</p><ol class=""><li id="3f6e" class="nh ni hu jx b jy ks kc kt kx nj ky nk kz nl jq nm nn no np dt translated">首先通过调用<code class="eh nd ne nf ng b">cpu()</code>将图像数据从GPU移动到CPU。</li><li id="5e83" class="nh ni hu jx b jy nq kc nr kx ns ky nt kz nu jq nm nn no np dt translated">使用<code class="eh nd ne nf ng b">detach()</code>调用从图中检测它。</li><li id="e77e" class="nh ni hu jx b jy nq kc nr kx ns ky nt kz nu jq nm nn no np dt translated"><code class="eh nd ne nf ng b">numpy()</code> call以Numpy数组的形式返回张量值。</li><li id="d276" class="nh ni hu jx b jy nq kc nr kx ns ky nt kz nu jq nm nn no np dt translated">第一个[0]从生成的批次中取出第一个图像(即使批次大小为1)。</li><li id="f957" class="nh ni hu jx b jy nq kc nr kx ns ky nt kz nu jq nm nn no np dt translated">交换轴，将(3，256，256)形状的数组变成(256，256，3)。</li><li id="f9bc" class="nh ni hu jx b jy nq kc nr kx ns ky nt kz nu jq nm nn no np dt translated">将像素值从范围-1~1恢复到0~1。</li><li id="9dca" class="nh ni hu jx b jy nq kc nr kx ns ky nt kz nu jq nm nn no np dt translated">用<code class="eh nd ne nf ng b">::-1</code>操作水平翻转生成的图像。</li><li id="9774" class="nh ni hu jx b jy nq kc nr kx ns ky nt kz nu jq nm nn no np dt translated">将图像通道顺序从RGB转换为BGR，最后一个<code class="eh nd ne nf ng b">::-1</code>操作为<code class="eh nd ne nf ng b">cv2.imshow()</code>功能需要BGR通道顺序的图像。</li></ol><p id="c7a7" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">将代码包装成一个函数调用<code class="eh nd ne nf ng b">MagicMirror()</code>，该函数调用带有几个可选参数。</p><ul class=""><li id="46b4" class="nh ni hu jx b jy ks kc kt kx nj ky nk kz nl jq nv nn no np dt translated">videoFile:保留默认值0以使用第一个网络摄像头，或者传入一个视频文件路径。</li><li id="4aae" class="nh ni hu jx b jy nq kc nr kx ns ky nt kz nu jq nv nn no np dt translated">setHairColor:三种之一，“黑色”，“金色”，“棕色”。</li><li id="3acf" class="nh ni hu jx b jy nq kc nr kx ns ky nt kz nu jq nv nn no np dt translated">变形为男性？设置为真或假。</li><li id="dde7" class="nh ni hu jx b jy nq kc nr kx ns ky nt kz nu jq nv nn no np dt translated">setYoung:转变成一个年轻人？设置为真或假。</li><li id="217c" class="nh ni hu jx b jy nq kc nr kx ns ky nt kz nu jq nv nn no np dt translated">showZoom:缺省值为4，这是在显示在屏幕上之前放大生成的图像的系数。</li></ul><h1 id="75fd" class="mb lg hu bd lh mc md me ll mf mg mh lp mi mj mk ls ml mm mn lv mo mp mq ly mr dt translated">结论和进一步的思考</h1><p id="af44" class="pw-post-body-paragraph ju jv hu jx b jy ms ka kb kc mt ke kf kx mu ki kj ky mv km kn kz mw kq kr jq hn dt translated">本教程向您展示了使用PyTorch这样的新框架，并使用预先训练好的StarGAN网络构建一些有趣的东西是多么容易和有趣。</p><p id="49f5" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated">生成的图像可能看起来还不是非常真实，而<a class="ae ma" href="https://arxiv.org/abs/1711.09020" rel="noopener ugc nofollow" target="_blank"> StarGAN的论文</a>显示了一个与CelebA + RaFD数据集联合训练的模型可以通过利用这两个数据集来改善面部关键点检测和分割等共享的低级任务，从而生成伪影更少的图像。你可以跟随他们的官方GitHub 下载数据集并训练这样一个模型，只要你有一台强大的机器和额外的一周时间来运行训练。</p><p id="dd79" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated"><a class="ae ma" href="https://twitter.com/intent/tweet?url=https%3A//www.dlology.com/blog/if-i-were-a-girl-magic-mirror-by-stargan/&amp;text=%22If%20I%20were%20a%20girl%22%20-%20Magic%20Mirror%20by%20StarGAN" rel="noopener ugc nofollow" target="_blank">在Twitter上分享</a> <a class="ae ma" href="https://www.facebook.com/sharer/sharer.php?u=https://www.dlology.com/blog/if-i-were-a-girl-magic-mirror-by-stargan/" rel="noopener ugc nofollow" target="_blank">在脸书分享</a></p></div><div class="ab cl nw nx hc ny" role="separator"><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob oc"/><span class="nz bw bk oa ob"/></div><div class="hn ho hp hq hr"><p id="ddce" class="pw-post-body-paragraph ju jv hu jx b jy ks ka kb kc kt ke kf kx ku ki kj ky kv km kn kz kw kq kr jq hn dt translated"><em class="jw">最初发表于</em><a class="ae ma" href="https://www.dlology.com/blog/if-i-were-a-girl-magic-mirror-by-stargan/" rel="noopener ugc nofollow" target="_blank"><em class="jw">【www.dlology.com】</em></a><em class="jw">。</em></p></div></div>    
</body>
</html>