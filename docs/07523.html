<html>
<head>
<title>Key-point detection in flower images using deep learning</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">基于深度学习的花卉图像关键点检测</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/key-point-detection-in-flower-images-using-deep-learning-66a06aadc765?source=collection_archive---------5-----------------------#2018-09-04">https://medium.com/hackernoon/key-point-detection-in-flower-images-using-deep-learning-66a06aadc765?source=collection_archive---------5-----------------------#2018-09-04</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="a481" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在这篇文章中，我们描述了如何使用卷积神经网络(CNN)来估计花卉图像中关键点的位置。需要诸如茎位置和花位置的关键点来在3D模型上呈现这些图像。</p><h2 id="54db" class="jq jr hu bd js jt ju jv jw jx jy jz ka jc kb kc kd jg ke kf kg jk kh ki kj kk dt translated">布鲁姆普罗</h2><p id="c6d8" class="pw-post-body-paragraph ir is hu it b iu kl iw ix iy km ja jb jc kn je jf jg ko ji jj jk kp jm jn jo hn dt translated">首先，让我们介绍一下我们的客户:布鲁米。他们的软件平台<a class="ae kq" href="https://bloomypro.com/" rel="noopener ugc nofollow" target="_blank"> BloomyPro </a>允许用户在浏览器中使用3D模型设计他们的花束。它被养殖户、零售商、批发商和花卉产业的供应商所使用。</p><p id="6531" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">他们可以完全在网上完成这个过程，而不是制作一个真正的实物花束，拍一张照片然后发给客户。这为他们节省了大量的时间和金钱。</p><div class="kr ks kt ku fq ab cb"><figure class="kv kw kx ky kz la lb paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/3103a51fed2b3bf2beaf842a53321f17.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/format:webp/1*63oKBN1yth2SFcAOs9XzzQ.png"/></div></figure><figure class="kv kw li ky kz la lb paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><img src="../Images/211e5648285a234fbd4e9b14e5698b85.png" data-original-src="https://miro.medium.com/v2/resize:fit:1002/format:webp/1*cgUT75pIgSllkf0hfdrppw.png"/></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek ln di lo lp">The BloomyPro User Interface</figcaption></figure></div><p id="8acb" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为了能够与真实花束的照片竞争，创建的图像必须尽可能逼真。这是通过从多个角度使用花卉的真实照片并在3D模型上渲染它们来实现的。</p><p id="746a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">对于每一朵新的花，他们从7个不同的角度拍摄照片。在照相亭里，花是由马达自动旋转的。</p><figure class="kr ks kt ku fq kw fe ff paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="fe ff lq"><img src="../Images/46633791a5994bd95bf400dd6e9145ab.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Grv_shFfL338JYZNrnI4Yg.jpeg"/></div></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek">The flower photo booth</figcaption></figure><p id="dbdd" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">相比之下，图片的后处理还没有完全自动化。目前数据库中有成千上万的鲜花，每天都有新的鲜花加入。将此乘以角度数，您将获得大量需要手动处理的图片！</p><p id="0722" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">后处理步骤之一是在图像上定位3D模型需要附着的几个关键点。最重要的是茎位和花顶位。这现在是手动完成的。我们的解决方案旨在自动化这一步骤。</p><h2 id="cf56" class="jq jr hu bd js jt ju jv jw jx jy jz ka jc kb kc kd jg ke kf kg jk kh ki kj kk dt translated">资料组</h2><p id="8620" class="pw-post-body-paragraph ir is hu it b iu kl iw ix iy km ja jb jc kn je jf jg ko ji jj jk kp jm jn jo hn dt translated">幸运的是，成千上万的图片已经用关键点进行了人工注释。所以我们有大量的训练数据可以处理！</p><figure class="kr ks kt ku fq kw fe ff paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="fe ff lr"><img src="../Images/461b8aeda93fca795f8badd7f74b02a1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0Q31gOQsuHznNhZ6H9zEOg.png"/></div></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek">Annotated images at different angles</figcaption></figure><p id="9c69" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">上面是来自训练集的一些带注释的花。它从几个不同的角度展示了同一朵花。茎的位置是蓝色的，花的顶部位置是绿色的。</p><p id="da2b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在一些照片中，茎的起点被花本身隐藏了。在这种情况下，我们需要一个“有根据的猜测”,茎最有可能在哪里。</p><figure class="kr ks kt ku fq kw fe ff paragraph-image"><div class="fe ff ls"><img src="../Images/4cc372c2dd72c3b351a92ccf23c377ce.png" data-original-src="https://miro.medium.com/v2/resize:fit:864/1*h94DqYI7WXJv-4tvKVzCRA.gif"/></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek">Example with hidden stem</figcaption></figure><h2 id="0a30" class="jq jr hu bd js jt ju jv jw jx jy jz ka jc kb kc kd jg ke kf kg jk kh ki kj kk dt translated">网络体系结构</h2><p id="7ba4" class="pw-post-body-paragraph ir is hu it b iu kl iw ix iy km ja jb jc kn je jf jg ko ji jj jk kp jm jn jo hn dt translated">因为模型必须输出一个数字而不是一个类，所以我们本质上是在做回归。CNN最出名的是分类任务，但也可以在回归上表现良好。例如<a class="ae kq" href="https://arxiv.org/pdf/1802.00434.pdf" rel="noopener ugc nofollow" target="_blank"> DensePose </a>使用基于CNN的方法进行人体姿态估计。再比如这篇<a class="ae kq" href="https://towardsdatascience.com/detecting-facial-features-using-deep-learning-2e23c8660a7a" rel="noopener" target="_blank">关于面部关键点检测的文章</a>。</p><p id="5720" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我不打算解释卷积网络的一般工作原理，如果你感兴趣，你可以阅读这篇文章中的CNN基础知识:</p><div class="lt lu fm fo lv lw"><a href="https://adeshpande3.github.io/A-Beginner%27s-Guide-To-Understanding-Convolutional-Neural-Networks/" rel="noopener  ugc nofollow" target="_blank"><div class="lx ab ej"><div class="ly ab lz cl cj ma"><h2 class="bd hv fv z el mb eo ep mc er et ht dt translated">理解卷积神经网络的初学者指南</h2><div class="md l"><h3 class="bd b fv z el mb eo ep mc er et ek translated">卷积神经网络。听起来像是生物学和数学的奇怪结合，还有点CS的成分，但是…</h3></div><div class="me l"><p class="bd b gc z el mb eo ep mc er et ek translated">adeshpande3.github.io</p></div></div><div class="mf l"><div class="mg l mh mi mj mf mk lg lw"/></div></div></a></div><p id="9e46" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">网络从几个标准卷积块开始。这些块由3个卷积层组成，后面是最大汇集、批量标准化和丢弃层。</p><ul class=""><li id="5235" class="ml mm hu it b iu iv iy iz jc mn jg mo jk mp jo mq mr ms mt dt translated"><strong class="it hv">卷积</strong>层包含许多过滤器。每个过滤器都像模式识别器一样工作。接下来，卷积块有更多的过滤器，所以它可以找到模式内的模式。</li><li id="03a3" class="ml mm hu it b iu mu iy mv jc mw jg mx jk my jo mq mr ms mt dt translated"><strong class="it hv"> Max-pooling </strong>降低图像的分辨率。这限制了模型中的参数数量。通常，在图像分类中，我们对某个物体在图像中的位置不感兴趣，只要它在那里。在我们的例子中，我们感兴趣的是位置。尽管如此，拥有几个最大池层不会影响性能。</li><li id="2d48" class="ml mm hu it b iu mu iy mv jc mw jg mx jk my jo mq mr ms mt dt translated"><strong class="it hv">批量标准化</strong>层帮助模型更快地训练(收敛)。在一些深度网络中，没有它们，训练完全失败。</li><li id="01f8" class="ml mm hu it b iu mu iy mv jc mw jg mx jk my jo mq mr ms mt dt translated"><strong class="it hv"> Dropout </strong>随机禁用节点，这可以防止模型过度拟合。</li></ul><p id="317f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在卷积块之后，我们展平张量，使其与密集层兼容。全局最大汇集或平均最大汇集也将实现平坦张量，但将丢失所有空间信息。在我们的实验中，扁平化的效果更好，尽管它的(计算)代价是拥有更多的模型参数，导致训练时间更长。</p><p id="f8c0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">激活两个密集隐藏层<a class="ae kq" href="https://en.wikipedia.org/wiki/Rectifier_(neural_networks)" rel="noopener ugc nofollow" target="_blank"> Relu </a>后是输出层。我们希望预测2个关键点的<code class="eh mz na nb nc b">x</code>和<code class="eh mz na nb nc b">y</code>坐标，因此我们需要在输出层中有4个节点。这些图像可以有不同的分辨率，所以我们将坐标缩放到0和1之间，并在使用前将其放大。</p><p id="ee42" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">输出层没有激活功能。尽管目标变量在0和1之间，但对我们来说，这比使用<a class="ae kq" href="https://en.wikipedia.org/wiki/Sigmoid_function" rel="noopener ugc nofollow" target="_blank"> sigmoid </a>更好。</p><p id="d8ca" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">作为参考，下面是来自我们使用的Python深度学习库<a class="ae kq" href="https://keras.io/" rel="noopener ugc nofollow" target="_blank"> Keras </a>的完整模型摘要:</p><pre class="kr ks kt ku fq nd nc ne nf aw ng dt"><span id="8972" class="jq jr hu nc b fv nh ni l nj nk">_________________________________________________________________<br/>Layer (type)                 Output Shape              Param #   <br/>=================================================================<br/>conv2d_1 (Conv2D)            (None, 126, 126, 64)      2368      <br/>_________________________________________________________________<br/>conv2d_2 (Conv2D)            (None, 124, 124, 64)      36928     <br/>_________________________________________________________________<br/>conv2d_3 (Conv2D)            (None, 122, 122, 64)      36928     <br/>_________________________________________________________________<br/>max_pooling2d_1 (MaxPooling2 (None, 61, 61, 64)        0         <br/>_________________________________________________________________<br/>batch_normalization_1 (Batch (None, 61, 61, 64)        256       <br/>_________________________________________________________________<br/>dropout_1 (Dropout)          (None, 61, 61, 64)        0         <br/>_________________________________________________________________<br/>conv2d_4 (Conv2D)            (None, 59, 59, 128)       73856     <br/>_________________________________________________________________<br/>conv2d_5 (Conv2D)            (None, 57, 57, 128)       147584    <br/>_________________________________________________________________<br/>conv2d_6 (Conv2D)            (None, 55, 55, 128)       147584    <br/>_________________________________________________________________<br/>max_pooling2d_2 (MaxPooling2 (None, 27, 27, 128)       0         <br/>_________________________________________________________________<br/>batch_normalization_2 (Batch (None, 27, 27, 128)       512       <br/>_________________________________________________________________<br/>dropout_2 (Dropout)          (None, 27, 27, 128)       0         <br/>_________________________________________________________________<br/>flatten_1 (Flatten)          (None, 93312)             0         <br/>_________________________________________________________________<br/>dense_1 (Dense)              (None, 256)               23888128  <br/>_________________________________________________________________<br/>batch_normalization_3 (Batch (None, 256)               1024      <br/>_________________________________________________________________<br/>dropout_3 (Dropout)          (None, 256)               0         <br/>_________________________________________________________________<br/>dense_2 (Dense)              (None, 256)               65792     <br/>_________________________________________________________________<br/>batch_normalization_4 (Batch (None, 256)               1024      <br/>_________________________________________________________________<br/>dropout_4 (Dropout)          (None, 256)               0         <br/>_________________________________________________________________<br/>dense_3 (Dense)              (None, 4)                 1028      <br/>=================================================================<br/>Total params: 24,403,012<br/>Trainable params: 24,401,604<br/>Non-trainable params: 1,408<br/>_________________________________________________________________</span></pre><p id="5551" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">你可能会问:为什么是3个卷积层？或者为什么是2个卷积块？我们在超参数搜索中将这些数字作为超参数。连同诸如密集层数、漏失水平、批量标准化和卷积滤波器数量等参数，我们进行了随机搜索，以找到超参数的最佳组合。</p><p id="7884" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为什么是随机搜索而不是网格搜索？这有点违背直觉，但在实践中，这会让你的钱得到更好的回报。参见<a class="ae kq" href="https://www.oreilly.com/ideas/evaluating-machine-learning-models/page/5/hyperparameter-tuning" rel="noopener ugc nofollow" target="_blank">这篇关于超参数调整的文章</a>。</p><p id="342f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">对于训练，我们使用学习率为<code class="eh mz na nb nc b">0.005</code>的<a class="ae kq" href="https://machinelearningmastery.com/adam-optimization-algorithm-for-deep-learning/" rel="noopener ugc nofollow" target="_blank"> Adam优化器</a>。当确认损失在几个时期内没有改善时，学习率自动降低。</p><p id="68f8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">作为损失函数，我们使用均方差(MSE)。因此，大错误比小错误受到更多的惩罚。</p><h2 id="fa78" class="jq jr hu bd js jt ju jv jw jx jy jz ka jc kb kc kd jg ke kf kg jk kh ki kj kk dt translated">培训和绩效</h2><p id="b24f" class="pw-post-body-paragraph ir is hu it b iu kl iw ix iy km ja jb jc kn je jf jg ko ji jj jk kp jm jn jo hn dt translated">这些是训练50个时期后的损失(误差)图:</p><figure class="kr ks kt ku fq kw fe ff paragraph-image"><div class="fe ff nl"><img src="../Images/d581d7dec75510bc860f615d8b6eeb86.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*yXIIQWyvRey1gmmsbrlCeA.png"/></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek">Loss plots</figcaption></figure><p id="f284" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在大约8个时期之后，验证损失变得高于训练损失。直到训练结束，验证损失仍然减少，因此我们没有看到模型强烈过度拟合的迹象。</p><p id="99ee" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">测试集的最终损失(MSE)为<code class="eh mz na nb nc b">0.0064</code>。MSE可能很难理解。平均误差(MAE)更容易向人类解释。</p><blockquote class="nm nn no"><p id="2efb" class="ir is jp it b iu iv iw ix iy iz ja jb np jd je jf nq jh ji jj nr jl jm jn jo hn dt translated">MAE是<strong class="it hv"/><code class="eh mz na nb nc b"><strong class="it hv">0.0017</strong></code><strong class="it hv">——</strong>这意味着预测平均误差1.7%</p></blockquote><p id="c260" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">下面是测试集的几个例子。白色圆圈包含目标关键点，实心圆圈包含我们的预测。在大多数情况下，它们非常接近(重叠)。</p><figure class="kr ks kt ku fq kw fe ff paragraph-image"><div role="button" tabindex="0" class="lc ld di le bf lf"><div class="fe ff ns"><img src="../Images/8cd071b78bd141442cbabc8183737c2b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cG0UWZEHZygRLOltSMe_8Q.png"/></div></div><figcaption class="lj lk fg fe ff ll lm bd b be z ek">Some images from the test set</figcaption></figure><h2 id="224c" class="jq jr hu bd js jt ju jv jw jx jy jz ka jc kb kc kd jg ke kf kg jk kh ki kj kk dt translated">部署</h2><p id="266c" class="pw-post-body-paragraph ir is hu it b iu kl iw ix iy km ja jb jc kn je jf jg ko ji jj jk kp jm jn jo hn dt translated">模型的性能足够好，可以增加产品的价值。关键点现在用于在上传新的花朵图像时设置默认坐标。在大多数情况下，不需要手动调整！</p><p id="baf3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">模型本身通过API公开，并打包在docker容器中。这个容器是通过bitbucket管道建立在push之上的。经过训练的重量也包含在docker图像中。因为你不想在Git中存储大文件，我们使用Git LFS来存储它们。</p><h2 id="6234" class="jq jr hu bd js jt ju jv jw jx jy jz ka jc kb kc kd jg ke kf kg jk kh ki kj kk dt translated">进一步的改进</h2><p id="5b79" class="pw-post-body-paragraph ir is hu it b iu kl iw ix iy km ja jb jc kn je jf jg ko ji jj jk kp jm jn jo hn dt translated">我们有一些改进的想法，但还没有时间去实施:</p><ol class=""><li id="0b89" class="ml mm hu it b iu iv iy iz jc mn jg mo jk mp jo nt mr ms mt dt translated">目前，一个单一的模型正在评估这两个关键点。为每个关键点训练一个特定的模型可能会更好。这有一个额外的好处，您可以在以后添加新的关键点，而不必重新训练整个模型。</li><li id="7bd6" class="ml mm hu it b iu mu iy mv jc mw jg mx jk my jo nt mr ms mt dt translated">另一个想法是考虑照片的角度。例如通过将其添加为密集层的输入。你可能会争辩说，角度改变了任务的性质，所以提供这些信息可能有助于网络。按照这种思路，为每个角度训练一个独立的网络也是有益的。</li></ol><h2 id="9232" class="jq jr hu bd js jt ju jv jw jx jy jz ka jc kb kc kd jg ke kf kg jk kh ki kj kk dt translated">后续步骤</h2><p id="1a4e" class="pw-post-body-paragraph ir is hu it b iu kl iw ix iy km ja jb jc kn je jf jg ko ji jj jk kp jm jn jo hn dt translated">除了设置关键点之外，后处理过程还包含更多的步骤。例如设置茎的颜色。3D引擎绘制与照片的茎颜色相匹配的人造茎。我们希望同样的技术也适用于这种情况。</p><h2 id="9749" class="jq jr hu bd js jt ju jv jw jx jy jz ka jc kb kc kd jg ke kf kg jk kh ki kj kk dt translated">结论</h2><p id="1450" class="pw-post-body-paragraph ir is hu it b iu kl iw ix iy km ja jb jc kn je jf jg ko ji jj jk kp jm jn jo hn dt translated">通过这项研究，我们证明了使用细胞神经网络检测花卉图像中关键点的可行性。所使用的方法可能也适用于其他领域的后处理任务，如产品摄影。</p><p id="ffba" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">有什么问题吗？请在评论中告诉我们。如果你喜欢这篇文章，请点击拍手按钮，这样更多的人可以阅读这个故事！</p></div><div class="ab cl nu nv hc nw" role="separator"><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz oa"/><span class="nx bw bk ny nz"/></div><div class="hn ho hp hq hr"><blockquote class="nm nn no"><p id="208c" class="ir is jp it b iu iv iw ix iy iz ja jb np jd je jf nq jh ji jj nr jl jm jn jo hn dt translated"><strong class="it hv">关于</strong> <a class="ae kq" href="https://www.artificialindustry.com/" rel="noopener ugc nofollow" target="_blank"> <strong class="it hv">人工产业</strong> </a> <strong class="it hv"> : </strong>我们帮助创业者将他们的想法快速高效地转化为成功的在线业务，从而改变世界。我们通过为客户创建(数据)原型和MVP来做到这一点。</p></blockquote></div></div>    
</body>
</html>