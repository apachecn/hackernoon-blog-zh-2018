<html>
<head>
<title>Real-time Linux communications</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">实时Linux通信</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/real-time-linux-communications-2faabf31cf5e?source=collection_archive---------7-----------------------#2018-09-05">https://medium.com/hackernoon/real-time-linux-communications-2faabf31cf5e?source=collection_archive---------7-----------------------#2018-09-05</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="70f6" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">实时机器人应用的Linux通信栈的评估</h2></div><p id="0a1f" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><em class="kf">本文内容来自“</em>实时Linux通信:实时机器人应用的Linux通信栈评估<em class="kf">”，可在https://arxiv.org/pdf/1808.10821.pdf</em><a class="ae kg" href="https://arxiv.org/pdf/1808.10821.pdf" rel="noopener ugc nofollow" target="_blank"/>获得。<em class="kf">同行的有卡洛斯·圣维森特·古铁雷斯、兰德·乌萨特吉·圣胡安和</em> <a class="kh ki gr" href="https://medium.com/u/e9b73593e3f?source=post_page-----2faabf31cf5e--------------------------------" rel="noopener" target="_blank"> <em class="kf">伊拉蒂·扎马罗亚·乌加特</em> </a> <em class="kf">。</em></p><figure class="kk kl km kn fq ko fe ff paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="fe ff kj"><img src="../Images/8be6fee7a7203c936877e61b52d59fe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T107gJrzqQWXLSW-x9Mopw.jpeg"/></div></div><figcaption class="kv kw fg fe ff kx ky bd b be z ek">Linux networking stack transmission path</figcaption></figure><blockquote class="kz la lb"><p id="58a2" class="jj jk kf jl b jm jn iv jo jp jq iy jr lc jt ju jv ld jx jy jz le kb kc kd ke hn dt translated">随着机器人系统变得更加分布式，不同机器人模块之间的通信对于整个机器人控制的可靠性起着关键作用。在本文中，我们介绍了一个针对实时机器人应用的Linux通信栈的研究。我们以多核嵌入式设备为测试平台，评估了基于UDP的Linux通信的实时性能。我们证明，在适当的配置下，Linux内核大大增强了使用UDP协议的通信的确定性。此外，我们还证明了并发流量会破坏有限的延迟，并提出了一种通过在CPU中分离实时应用程序和相应中断的解决方案。</p></blockquote><h1 id="a6a9" class="lf lg hu bd lh li lj lk ll lm ln lo lp ja lq jb lr jd ls je lt jg lu jh lv lw dt translated">介绍</h1><p id="5a50" class="pw-post-body-paragraph jj jk hu jl b jm lx iv jo jp ly iy jr js lz ju jv jw ma jy jz ka mb kc kd ke hn dt translated">以太网通信标准因其普及性和低成本而广泛应用于机器人系统。当谈到实时通信时，虽然历史上以太网是一个受欢迎的竞争者，但许多制造商选择了现场总线。正如在以前的工作[1]中介绍的，我们开始观察到一种变化。随着“时间敏感网络”(TSN)标准的到来，以太网有望在实时机器人应用中获得更广泛的采用。目前有几种基于以太网协议的通信技术。Profinet RT [2]或Powerlink [3]等一些协议使用专门为协议设计的网络堆栈1。其他协议，如数据分布式服务(DDS) [4]、OPC-UA [5]或Profinet都建立在众所周知的TCP/IP和UDP/IP OSI层之上。这促进了与通用传输协议的互操作过程，并确保了设备之间的高度兼容性。然而，它们相应的网络堆栈和驱动程序通常没有针对实时通信进行优化。与具有特定网络堆栈的其他以太网替代方案相比，实时性能有限。</p><p id="08a5" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">在这项工作中，我们的目标是测量和评估Linux网络子系统与UDP和IP协议的实时性能。UDP被几种实时传输协议使用，例如实时发布订阅协议(RTPS)。我们旨在确定哪种配置在混合关键流量场景中提供更好的隔离。为了实现实时性能，网络堆栈将部署在实时操作系统(RTOS)中。在Linux的情况下，标准内核不提供实时功能。然而，使用实时抢占补丁(PREEMPT-RT)，可以实现实时计算能力，如所示[6]。尽管Linux网络子系统没有针对有限的最大延迟进行优化，但通过这项工作，我们期望使用PREEMPT-RT实现合理的确定性通信，以及合适的配置。</p><h1 id="72a1" class="lf lg hu bd lh li lj lk ll lm ln lo lp ja lq jb lr jd ls je lt jg lu jh lv lw dt translated">在Linux中设置实时通信</h1><h2 id="220e" class="mc lg hu bd lh md me mf ll mg mh mi lp js mj mk lr jw ml mm lt ka mn mo lv mp dt translated">实时抢占补丁(PREEMPT-RT)</h2><p id="5b7f" class="pw-post-body-paragraph jj jk hu jl b jm lx iv jo jp ly iy jr js lz ju jv jw ma jy jz ka mb kc kd ke hn dt translated">目前有不同的方法将Linux用于实时应用程序。一种常见的方法是将最关键的任务留给嵌入式RTOS，而将最高级别的命令交给Linux。第二种方法是使用像Xenomai [7]和RTAI [8]这样的双核方案，它们部署了一个与独立的Linux内核并行运行的微内核。这种解决方案的问题是它需要特殊的工具和库。</p><p id="f5eb" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">第三种方法是使用单内核。实时Linux (RTL)合作项目[9]是与这一选择最相关的开源解决方案。该项目基于PREEMPT-RT补丁，旨在创建一个可预测和确定的环境，将Linux内核转变为一个可行的实时平台。RTL项目的最终目标是主线PREEMPT-RT补丁。这项工作背后的重要性与创建基于Linux的RTOS无关，而是为Linux内核提供实时功能。主要的好处是可以使用Linux标准工具和库，而不需要特定的实时API。此外，Linux得到了广泛的使用和有力的支持，这有助于操作系统不断更新新的技术和特性，这在较小的项目中由于资源限制常常是一个问题。</p><h2 id="5943" class="mc lg hu bd lh md me mf ll mg mh mi lp js mj mk lr jw ml mm lt ka mn mo lv mp dt translated">Linux网络架构</h2><p id="64c9" class="pw-post-body-paragraph jj jk hu jl b jm lx iv jo jp ly iy jr js lz ju jv jw ma jy jz ka mb kc kd ke hn dt translated">虽然可以使用定制驱动程序或用户空间网络库绕过Linux网络栈，但我们对使用Linux网络栈感兴趣；主要是因为它更容易维护和集成用户空间应用程序或通信中间件。此外，Linux网络栈支持广泛的驱动程序，这些驱动程序允许在不同的设备上部署应用程序。</p><p id="c8d5" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jl hv"> Linux流量控制<br/> </strong>联网子系统的一个重要模块是Linux内核包调度器，它是用用户空间工具Linux流量控制(TC) [10]配置的。TC提供了控制排队数据包发送和接收方式的机制。它提供了一系列功能，如整形、调度、监管和丢弃网络流量。</p><p id="80d5" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">Linux数据包调度程序模块的主要元素是排队规则(Qdisc ),它是为接收和传输创建队列和服务质量(QoS)规则的网络流量规则。有入口和出口分别用于接收和发送。出口Qdisc为从网络协议层到网络接口环形缓冲区的数据传输提供整形、调度和过滤功能。另一方面，入口Qdisc为从网络接口环形缓冲区到网络协议层的接收路径提供过滤和丢弃能力(尽管这些通常很少使用)。</p><p id="2b73" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">对于出口Qdisc，有两种基本类型的规程:无类Qdisc和有类Qdisc。无类的Qdisc不包含另一个Qdisc，所以只有一级排队。无类Qdisc仅确定数据包是被分类、延迟还是被丢弃。有类的Qdisc可以包含另一个Qdisc，所以可以有几个级别的队列。在这种情况下，可能有不同的过滤器来确定将从哪个Qdisc发送分组。</p><figure class="kk kl km kn fq ko fe ff paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="fe ff kj"><img src="../Images/8be6fee7a7203c936877e61b52d59fe2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*T107gJrzqQWXLSW-x9Mopw.jpeg"/></div></div></figure><p id="c4e0" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">Qdisc可用于避免传输路径上非实时流量的流量拥塞(见图)。对于无类Qdisc，默认规则是PFIFO_FAST，它有三个FIFO优先级带。在有类Qdisc的情况下，有PRIO qdisc，它可以包含任意数量的不同优先级的类。还有指定给多队列网络设备的特定出口Qdisc，例如MQPRIO Qdisc [11]，它是一种排队规则，根据数据包的优先级将流量映射到硬件队列。该Qdisc将使具有较高优先级的分组出列，从而避免传输路径中的争用问题。除了优先级Qdisc之外，通常还会附加一个整形器来限制低优先级流量带宽，例如“令牌桶过滤器”TBF Qdisc [12]。</p><p id="c64b" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">最近，由于对Linux网络栈中支持TSN的兴趣，新的Qdiscs已经被创建或者正在开发中。IEEE 802.1Q-2014基于信用的整形器(CBS) [13]，Qdisc已经包含在内核4.15中。CBS用于通过限制流量类别的数据速率来加强服务质量。目前有两个正在开发中的Qdisc，一个是“最早传输时间优先(ETF)”[ 14]，它提供基于每个队列传输时间的调度，另一个是“时间感知优先级调度器”(TAPRIO)，它提供每个端口的调度。这些Qdisc将允许在软件中创建确定性调度，或者如果支持的话，将工作卸载到网络硬件。</p><p id="6f57" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jl hv">流量分类<br/> </strong>为了将流量导向Qdisc或环形缓冲区，通常必须通过标记优先级来对流量进行分类。有几种方法可以设置特定通信流的优先级:a)从用户空间使用套接字选项SO_PRIORITY和IP_TOS，b)使用iptables，c)使用net_prio cgroups。设置流的优先级会将来自套接字(或应用程序)的流量映射到套接字缓冲区(SKB)优先级，这是内核网络层的内部优先级。MQPRIO Qdisc使用SKB优先级将业务流映射到Qdisc的业务类别。同时，每个流量类别被映射到一个TX环形缓冲区。</p><p id="5ecc" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jl hv">网络硬IRQ线程和软irq<br/>T5】在接收路径，数据包的处理由内核中断处理机制和“新API”(NAPI)网络驱动程序驱动。NAPI是一种旨在提高高网络负载性能的机制。当有大量输入流量时，会产生大量中断。当有许多分组已经排队时，处理每个中断来处理分组不是很有效。因此，当检测到高带宽输入数据包时，NAPI会使用中断缓解。然后，内核切换到基于轮询的处理，定期检查是否有排队的数据包。当负载减少时，中断会再次重新启用。总之，Linux内核默认使用中断驱动模式，只有当传入数据包的流量超过某个阈值(称为网络接口的“权重”)时，才会切换到轮询模式。这种方法作为延迟和吞吐量之间的折衷非常有效，使其行为适应网络负载状态。问题是NAPI可能会引入额外的延迟，例如当有突发流量时。</strong></p><p id="e652" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">PREEMPT-RT和普通内核处理中断的方式有所不同，因此在接收路径上处理数据包的方式也有所不同。PREEMPT-RT的修改允许配置系统以改进网络堆栈确定性。</p><p id="005b" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">在PREEMPT-RT中，大多数中断请求(IRQ)处理程序被迫运行在专门为该中断创建的线程中。这些线程被称为IRQ线程[15]。将IRQ作为内核线程处理允许单独管理优先级和CPU关联性。在线程中运行的IRQ处理程序本身也可以被中断，这样就减少了中断造成的延迟。对于多队列网卡，网络接口的每个TX和RX队列都有一个IRQ，允许对每个队列的处理分别进行优先级排序。例如，可以为实时流量使用一个队列，并提高该队列的优先级，使其高于其他队列IRQ线程。</p><p id="cde6" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">另一个重要的区别是软中断执行的环境。从版本3.6.1-rt1开始，软IRQ处理程序在产生该软IRQ的线程的上下文中执行[16]。这意味着NET_RX软IRQ通常将在网络设备IRQ线程的上下文中执行，这允许对网络处理上下文进行精细控制。但是，如果网络IRQ线程被抢占或者耗尽了它的NAPI权重时间片，它将在ksoftirqd/n(其中n是CPU的逻辑号)中执行。</p><p id="a079" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">在ksoftirqd/n上下文中处理数据包对于实时来说很麻烦，因为该线程被不同的进程用于延迟工作，并且会增加延迟。此外，由于ksoftirqd使用SCHED_OTHER策略运行，线程执行很容易被抢占。实际上，软IRQ通常在NIC IRQ线程和ksoftirqd/n线程的上下文中执行，用于高网络负载和高压力(CPU、内存、I/O等)。).</p><p id="d886" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jl hv">套接字分配<br/> </strong>网络堆栈对于有限延迟的当前限制之一是套接字内存分配。<a class="ae kg" href="https://hackernoon.com/tagged/network" rel="noopener ugc nofollow" target="_blank">网络</a>栈中的每个数据包都需要一个保存数据包元数据的sckbuff结构。需要为每个分组分配该结构，并且分配所需的时间代表了处理分组和抖动源的大部分开销。</p><p id="3645" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">Linux网络开发者的最后一个项目是XDP或快速数据路径[17]，其目的是在Linux内核中提供高性能、<a class="ae kg" href="https://hackernoon.com/tagged/programmable" rel="noopener ugc nofollow" target="_blank">可编程的</a>网络数据路径。XDP将通过消除套接字元数据分配来提供更快的数据包处理。尽管实时通信不是这个项目背后的主要动机，但XDP看起来像是一个有趣的功能，可以用作实时通信的快速数据通道[18]。</p><h1 id="e5bd" class="lf lg hu bd lh li lj lk ll lm ln lo lp ja lq jb lr jd ls je lt jg lu jh lv lw dt translated">实验结果</h1><p id="f45f" class="pw-post-body-paragraph jj jk hu jl b jm lx iv jo jp ly iy jr js lz ju jv jw ma jy jz ka mb kc kd ke hn dt translated">为了评估网络堆栈的实时性能，我们使用了两个嵌入式设备，测量往返测试的延迟。</p><h2 id="71ea" class="mc lg hu bd lh md me mf ll mg mh mi lp js mj mk lr jw ml mm lt ka mn mo lv mp dt translated">往返测试</h2><p id="10ec" class="pw-post-body-paragraph jj jk hu jl b jm lx iv jo jp ly iy jr js lz ju jv jw ma jy jz ka mb kc kd ke hn dt translated">网络延迟以往返时间(RTT)来衡量，也称为乒乓测试。为了进行测试，我们在一个设备中使用一个客户端，在另一个设备中使用一个服务器。往返延迟是指消息从客户端传输到服务器，再从服务器传输回客户端所需的时间。对于客户端和服务器，我们使用了cyclict test[19]的修改版本，它允许我们保存统计数据并创建延迟直方图，以显示测试的抖动量和最坏情况下的延迟。此外，对于1毫秒的目标循环时间，我们计算错过截止日期的次数。</p><p id="3144" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">对于定时循环，我们使用了clock_nanosleep原语。我们还使用了内存锁定、FIFO调度程序，并将实时优先级设置为80。在所有测试中，我们使用套接字选项SO_PRIORITY将流量标记为优先级流量。为了在系统中生成负载，我们使用了程序stress，为了生成流量，我们使用了程序iperf。</p><figure class="kk kl km kn fq ko fe ff paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="fe ff mq"><img src="../Images/efe64d3899a3a1c0dd85d79d914f25e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*gur-a44R8HSwy1LL25VuHg.jpeg"/></div></div><figcaption class="kv kw fg fe ff kx ky bd b be z ek">Graphical presentation of the measured round-trip latency. T1 is the time-stamp when data is send from the round-trip client and T2 is the time-stamp when data is received again at the round-trip client. Round-trip latency is defined as T2 — T1.</figcaption></figure><h2 id="f847" class="mc lg hu bd lh md me mf ll mg mh mi lp js mj mk lr jw ml mm lt ka mn mo lv mp dt translated">任务和IRQ关联以及CPU屏蔽</h2><p id="543b" class="pw-post-body-paragraph jj jk hu jl b jm lx iv jo jp ly iy jr js lz ju jv jw ma jy jz ka mb kc kd ke hn dt translated">在实时系统中，实时任务和中断可以被固定到特定的CPU上，以将它们的资源与非实时任务分开。这是防止非实时过程干扰的有效方法。</p><p id="6e41" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">有几种方法可以设置任务和IRQ与CPU的密切关系。在实验中，我们决定比较两种隔离级别。在第一种情况下，我们将实时任务和实时业务队列的IRQ固定在同一个CPU上。我们使用“pthread_setaffinity_np”和“smp irq affinity”来设置irq的优先级。</p><p id="3d54" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">在第二种情况下，我们使用cpusets [20]，它是Linux cgroups的一部分，用于为实时任务分配CPU。通过这种方法，我们还可以迁移在隔离的CPU中运行的所有进程，以便只允许实时任务在该CPU中运行。我们还设置了所有IRQ与非实时CPU的亲缘关系，而(网络设备的)实时队列的IRQ在隔离的CPU中设置亲缘关系。</p><p id="a782" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">在实验设置中，我们使用所描述的方法来隔离发送和接收实时流量的应用。使用不同的配置运行测试:<em class="kf"> no-rt </em>、<em class="kf"> rt-normal </em>、<em class="kf"> rt-affinities </em>和<em class="kf"> rt-isolation </em>。在第一种情况下，<em class="kf"> no-rt </em>，我们使用一个普通内核。在第二种情况下，<em class="kf"> rt-normal </em>，我们使用PREEMPT-RT内核，没有将往返程序和网络IRQ绑定到任何CPU。在第三种情况下，<em class="kf"> rt-affinities </em>，我们将优先级队列的IRQ线程以及客户端和服务器程序绑定到每个设备的CPU 1。最后，在第四种情况下，<em class="kf"> rt-isolation </em>，我们在一个隔离的CPU中运行往返应用程序。在所有情况下，我们将RTT测试客户端和服务器的优先级设置为80。</p><p id="d0ad" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">为了直观地了解每个配置的确定性，我们运行了一个1小时的cyclictest，获得了以下最坏情况下的延迟:no-rt: 13197 s，rtnormal/rt-affinities: 110 s，rt-isolation: 88 s。</p><p id="63ef" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated"><strong class="jl hv">系统和网络负载<br/> </strong>对于每种情况，我们在不同的负载条件下运行测试:空闲、压力、tx-traffic和rx-traffic:</p><ul class=""><li id="0317" class="mr ms hu jl b jm jn jp jq js mt jw mu ka mv ke mw mx my mz dt translated"><strong class="jl hv">空闲</strong>:除了客户端和服务器端，没有其他用户空间程序运行。</li><li id="191a" class="mr ms hu jl b jm na jp nb js nc jw nd ka ne ke mw mx my mz dt translated"><strong class="jl hv">压力</strong>:我们生成一些负载来给CPU和内存以及块内存施加压力。</li><li id="8a89" class="mr ms hu jl b jm na jp nb js nc jw nd ka ne ke mw mx my mz dt translated"><strong class="jl hv"> tx-traffic </strong>:我们在客户端的传输路径上生成一些并发流量。我们从客户端向PC发送100 Mbps的流量。</li><li id="435a" class="mr ms hu jl b jm na jp nb js nc jw nd ka ne ke mw mx my mz dt translated"><strong class="jl hv"> rx-traffic </strong>:我们在服务器的接收路径中生成一些并发流量。我们从电脑向服务器发送100 Mbps的流量</li></ul><p id="3ef2" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">当产生并发流量时，两台设备的MAC队列中也会出现拥塞。但是，由于测试的流量具有优先级，因此链路层增加的延迟对测试没有意义。</p><h2 id="771a" class="mc lg hu bd lh md me mf ll mg mh mi lp js mj mk lr jw ml mm lt ka mn mo lv mp dt translated">结果</h2><p id="f3d2" class="pw-post-body-paragraph jj jk hu jl b jm lx iv jo jp ly iy jr js lz ju jv jw ma jy jz ka mb kc kd ke hn dt translated">我们比较了3小时往返测试的结果，以1毫秒的速率发送500字节的UDP数据包。下表显示了在不同条件下使用的不同配置的统计数据。对于实时基准测试，最重要的指标是最坏情况(Max)、数据包丢失和错过截止日期的次数。在这种情况下，我们决定设置一个1毫秒的截止时间来匹配发送速率。</p><figure class="kk kl km kn fq ko fe ff paragraph-image"><div role="button" tabindex="0" class="kp kq di kr bf ks"><div class="fe ff nf"><img src="../Images/63357453ae21d0d16ad9bf0c82fc08fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tFBuf6DEax5y-sgj72U-tw.png"/></div></div></figure><p id="b95e" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">从表1中可以看出，非实时内核产生了看似最佳的平均性能，但相比之下，它错过了大量的最后期限，并且最大延迟值也很高；即使系统空闲时也是如此。当系统由于内核中缺少抢占而承受压力时，延迟尤其严重。</p><p id="958a" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">对于rt-normal(表II)，当系统承受压力时，延迟是有限的。当生成并发流量时，我们观察到较高的延迟值和一些遗漏的致命性。</p><p id="dd37" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">对于rt-affinity，我们可以看到与前面的场景相比有所改进。特别是并发流量(表三)。我们还可以看到，当将往返线程和以太网IRQ的优先级固定到同一个CPU时，延迟似乎是有限的。</p><p id="43c6" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">在非隔离的情况下(表IV)，当与亲和的情况相比时，我们欣赏类似的行为。我们可以看到，给非隔离CPU施加压力会对隔离内核的任务产生一些影响。然而，在空闲情况下，对于短测试，我们观察到非常低的抖动。据我们所知，这种延迟的主要原因之一是调度器ticker，它每10毫秒生成一次。虽然可以在客户机中避免它，因为它是在一个定时循环中运行的，但是在服务器端，不可能避免跑马灯。由于两个设备不同步，在某些时候，服务器端的时钟会偏离客户端，并且调度器跑马灯会干扰服务器的执行。下图中可以看到这种效果:</p><figure class="kk kl km kn fq ko fe ff paragraph-image"><div class="fe ff ng"><img src="../Images/c2140d05954279c1a424814ffbfffc4e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1200/format:webp/1*dMyb4VmloGVGL66P2Ts71Q.png"/></div><figcaption class="kv kw fg fe ff kx ky bd b be z ek">Time-plot for isolated CPU. At the beginning, we can observe the effect of the scheduler ticker preempting the real-time task and adding latency to the round-trip test latencies.</figcaption></figure><p id="c65b" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">当使用200 Mbps接收流量运行测试时，我们观察到尽力而为流量在ksoftirqd/0上下文中被连续处理。这在所有情况下都会产生高延迟尖峰，即使对于隔离情况也是如此。为了跟踪这些延迟尖峰的来源，我们应该跟踪内核在延迟发生时拍摄快照。</p><figure class="kk kl km kn fq ko fe ff paragraph-image"><div class="fe ff nh"><img src="../Images/c24e4098ac49731ba482d1c9af11c771.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*ErH1XQnP1v5FH6XH76kt7g.png"/></div><figcaption class="kv kw fg fe ff kx ky bd b be z ek">Real-time Ethernet round-trip-time histograms for idle system.</figcaption></figure><figure class="kk kl km kn fq ko fe ff paragraph-image"><div class="fe ff nh"><img src="../Images/0480a9b83508368218cfd611fd6bcc55.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*A0N3zwzL3k1HCIh1zWKnFA.png"/></div><figcaption class="kv kw fg fe ff kx ky bd b be z ek">Real-time Ethernet round-trip-time histograms for system under load (stress).</figcaption></figure><figure class="kk kl km kn fq ko fe ff paragraph-image"><div class="fe ff nh"><img src="../Images/12fd0f5ef1144164c9e825553fb19d0d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*0dA9oo-olIAqRp5PxbdXlg.png"/></div><figcaption class="kv kw fg fe ff kx ky bd b be z ek">Real-time Ethernet round-trip-time histograms for concurrent low priority traffic in the transmission path.</figcaption></figure><figure class="kk kl km kn fq ko fe ff paragraph-image"><div class="fe ff nh"><img src="../Images/1eda71981aa321dcf63bd44cb71d331a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*3PeJBbSVO8aPneG8rhlg7w.png"/></div><figcaption class="kv kw fg fe ff kx ky bd b be z ek">Real-time Ethernet round-trip-time histograms for concurrent low priority traffic in the reception path.</figcaption></figure><h1 id="4edc" class="lf lg hu bd lh li lj lk ll lm ln lo lp ja lq jb lr jd ls je lt jg lu jh lv lw dt translated">结论和未来工作</h1><p id="3134" class="pw-post-body-paragraph jj jk hu jl b jm lx iv jo jp ly iy jr js lz ju jv jw ma jy jz ka mb kc kd ke hn dt translated">所获得的结果证明，所提出的Linux实时设置大大提高了使用UDP协议的通信的确定性。首先，我们确认，通过利用实时内核和以实时优先级运行应用程序，减轻了当系统处于重负载下时引起的通信延迟。其次，我们证明了，无论何时有并发流量，简单地设置实时进程的优先级是不够的。在CPU中分离实时应用程序和相应的中断似乎是避免高延迟的有效方法。然而，对于更高的并发流量负载，我们仍然可以看到无限的延迟，需要进一步的研究来克服我们当前设置的这一限制。</p><p id="d266" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">我们的结论是，在某些情况下，对于各种压力和流量过载的情况，Linux确实可以满足一些实时通信的限制。在此，我们对用于实时机器人应用的Linux通信栈进行了评估。未来的工作应考虑到网络堆栈尚未针对低延迟和有限延迟进行充分优化；当然还有改进的余地。在我们看来，在Linux网络栈内部有一些正在进行的工作，例如XDP [17]项目，显示了改进实时性能的前景。在未来的工作中，测试这些特性并比较结果可能会很有趣。</p><h1 id="a527" class="lf lg hu bd lh li lj lk ll lm ln lo lp ja lq jb lr jd ls je lt jg lu jh lv lw dt translated">参考</h1><p id="0cb5" class="pw-post-body-paragraph jj jk hu jl b jm lx iv jo jp ly iy jr js lz ju jv jw ma jy jz ka mb kc kd ke hn dt translated">[1] C. S. V. Gutiérrez，L. U. S. Juan，I. Z. Ugarte和V. M. Vilches，“机器人的时间敏感网络”，CoRR，第abs/1804.07643卷，2018年。【在线】。可用:<a class="ae kg" href="http://arxiv.org/abs/1804.07643" rel="noopener ugc nofollow" target="_blank">http://arxiv.org/abs/1804.07643</a></p><p id="a5db" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[2]“ProFi net领先的工业以太网标准，”<a class="ae kg" href="https://www." rel="noopener ugc nofollow" target="_blank"> https://www .</a>profibus.com/technology/profinet/,访问时间:2018–04–12。</p><p id="ee77" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[3]“POWERLINK—POWERLINK标准化组”，<a class="ae kg" href="https://www." rel="noopener ugc nofollow" target="_blank"> https://www .</a>ethernet-powerlink.org/powerlink/technology,访问时间:2018-04-12。</p><p id="602f" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[4]《数据分发服务规范，1.4版》，<a class="ae kg" href="https://www." rel="noopener ugc nofollow" target="_blank"> https://www .</a>omg.org/spec/DDS/1.4/,访问时间:2018-04-12。</p><p id="94ee" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[5]“OPC-UA—OPC统一架构(UA)，”<a class="ae kg" href="https://opcfoundation." rel="noopener ugc nofollow" target="_blank"> https://opcfoundation。</a>org/about/OPC-technologies/OPC-ua/，访问时间:2018–04–12。</p><p id="5037" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[6] H. Fayyad-Kazan，L. Perneel，M. Timmerman，“Linuxpreempt-rt与商业rtoss:性能差距有多大？”《GSTF计算杂志》(JoC)，2018年第3卷第1期。【在线】。可用:<a class="ae kg" href="http://dl6.globalstf.org/index.php/joc/article/view/1088" rel="noopener ugc nofollow" target="_blank">http://dl6.globalstf.org/index.php/joc/article/view/1088</a></p><p id="9cb0" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[7]“Xenomai项目主页”，2018年4月，[访问时间:2018–04–12]。【在线】。可用:<a class="ae kg" href="https://xenomai.org/" rel="noopener ugc nofollow" target="_blank">https://xenomai.org/</a></p><p id="eb46" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[8]“Rtai项目主页”，2018年4月，[访问时间:2018–04–12]。【在线】。可用:<a class="ae kg" href="https://www.rtai.org/" rel="noopener ugc nofollow" target="_blank">https://www.rtai.org/</a></p><p id="760f" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[9]“RTL合作项目”，<a class="ae kg" href="https://wiki.linuxfoundation.org/" rel="noopener ugc nofollow" target="_blank">https://wiki.linuxfoundation.org/</a>实时/rtl/start，访问时间:2018–04–12。</p><p id="ecbb" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[10]《流量控制— linux排队规则》，<a class="ae kg" href="http://man7.org/linux/" rel="noopener ugc nofollow" target="_blank">http://man7.org/linux/</a>man-pages/man 8/TC . 8 . html，访问时间:2018–04–12。</p><p id="a136" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[11]“多队列优先级Qdisc — linux手册页”，<a class="ae kg" href="https://www." rel="noopener ugc nofollow" target="_blank"> https://www .</a>systutorials.com/docs/linux/man/8-tc-mqprio/,访问时间:2018–04–12。</p><p id="d3df" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[12]“令牌桶过滤器— linux排队规则”，<a class="ae kg" href="https://www." rel="noopener ugc nofollow" target="_blank"> https://www .【systutorials.com/docs/linux/man/8-tc-tbf/, T21】访问时间:2018-04-12。</a></p><p id="4b7a" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[13]“CBS—基于信用的整形器(CBS) Qdisc”，<a class="ae kg" href="http://man7.org/linux/" rel="noopener ugc nofollow" target="_blank">http://man7.org/linux/</a>手册页/man8/tc-cbs.8.html，访问时间:2018–04–12</p><p id="3b68" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[14]“预定分组传输:Etf”，[访问时间:2018–04–12]。【在线】。可用:<a class="ae kg" href="https://lwn.net/Articles/758592/" rel="noopener ugc nofollow" target="_blank">https://lwn.net/Articles/758592/</a></p><p id="1fff" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[15] J. Edge，“将中断移动到线程”，2008年10月，[访问时间:2018–04–12]。【在线】。可用:<a class="ae kg" href="https://lwn.net/Articles/302043/" rel="noopener ugc nofollow" target="_blank">https://lwn.net/Articles/302043/</a></p><p id="5807" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[16] J. Corbet，“软件中断和实时”，2012年10月，[访问时间:2018–04–12]。【在线】。可用:【https://lwn.net/Articles/】T2520076/</p><p id="3839" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[17]“XDP(快速数据路径)文档”，<a class="ae kg" href="https://lwn.net/Articles/" rel="noopener ugc nofollow" target="_blank">https://lwn.net/Articles/</a>701224/，访问时间:2018–04–12。</p><p id="1ab6" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[18]“通往linux tsn基础设施之路，jesus sanchezpalencia”，2018年4月，[访问时间:2018–04–12]。【在线】。可用:<a class="ae kg" href="https://elinux.org/images/5/56/ELC-2018-USA-TSNonLinux.pdf" rel="noopener ugc nofollow" target="_blank">https://elinux.org/images/5/56/ELC-2018-USA-TSNonLinux.pdf</a></p><p id="909f" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[19]“循环测试”，2018年4月，[访问时间:2018–04–12]。【在线】。可用:<a class="ae kg" href="https://wiki.linuxfoundation.org/realtime/documentation/howto/" rel="noopener ugc nofollow" target="_blank">https://wiki . Linux foundation . org/real time/documentation/how to/</a>tools/cyclic test</p><p id="0e55" class="pw-post-body-paragraph jj jk hu jl b jm jn iv jo jp jq iy jr js jt ju jv jw jx jy jz ka kb kc kd ke hn dt translated">[20] S. Derr，" CPUSETS "，<a class="ae kg" href="https://www.kernel.org/doc/Documentation/" rel="noopener ugc nofollow" target="_blank">https://www.kernel.org/doc/Documentation/</a>c group-v1/CPUSETS . txt，访问时间:2018–04–12。</p><figure class="kk kl km kn fq ko"><div class="bz el l di"><div class="ni nj l"/></div></figure></div></div>    
</body>
</html>