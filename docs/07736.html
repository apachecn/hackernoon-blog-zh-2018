<html>
<head>
<title>Going on a Tair: A Guide to NVM Caching Optimization</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">继续前行:NVM缓存优化指南</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/going-on-a-tair-an-alibaba-guide-to-nvm-caching-optimization-97f799675a44?source=collection_archive---------22-----------------------#2018-09-11">https://medium.com/hackernoon/going-on-a-tair-an-alibaba-guide-to-nvm-caching-optimization-97f799675a44?source=collection_archive---------22-----------------------#2018-09-11</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="da26" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">阿里巴巴缓存技术团队关于如何将非易失性内存(NVM)部署到生产环境的最佳实践</em></p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff jq"><img src="../Images/5d08e8d9e85a203485094da08446b29e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ZT_qq_13q8E8e186jhnhBw.jpeg"/></div></div></figure><p id="f955" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">有效的数据存储在任何计算任务中都是必不可少的，但当你运行一个服务于数十亿消费者的多部门电子商务平台生态系统时，它是无可替代的。对于运营全球最大在线市场的阿里巴巴来说，这意味着开发自己的非易失性存储器(NVM)缓存服务包，统称为Tair MDB，最初推出是为了支持天猫6.18在线购物节，然后进行优化以进行更广泛的推广。</p><p id="34b8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为了诊断必要的改进，Tair团队对系统进行了两次全链路压力测试，暴露了一系列问题，包括不平衡的写入和锁开销。今天，我们更仔细地看看阿里巴巴生产环境中的NVM基础，重点是在优化工作中发现的最佳实践。以及三个有助于确保长期可操作性的战略设计规则，相关领域的读者将发现NVM优化的丰富见解广泛适用于其他产品。</p><h1 id="52a2" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">NVM的案例</h1><p id="3722" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">在采用NVM时，Tair MDB已经在阿里巴巴集团内部广泛部署。随着其用户空间网络协议栈和无锁数据结构的引入，单个单元的QPS极限已经超过了1000瓦口径。所有Tair MDB数据都存储在内存中，提高的单单元QPS限制使内存容量成为决定集群大小的最重要因素。</p><p id="9710" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">NVM提供了更高的单个DIMM容量，同时也比DRAM便宜得多，这表明有可能突破单个单元内存容量的限制。</p><h1 id="4e92" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">NVM进入生产环境:初步结果</h1><p id="5d8e" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">端到端，在相同软件版本下使用DRAM节点数据的平均读写延迟水平，服务证明能够使用NVM正常运行，生产环境的压力远低于Tair MDB节点限制。在随后的章节中，将更详细地解释压力测试过程中遇到的问题以及解决这些问题的方法。</p><p id="8975" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如前所述，单个NVM的最大DIMM容量高于DIMM，这意味着相同DIMM容量的成本低于DRAM。使用NVM来弥补不足的内存容量，可以大大减少Tair MDB容量集群的大小。如果将设备成本、电费和机架成本考虑在内，总体成本可降低30%至50%。</p><h1 id="2532" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">行动原则:NVM实施指南</h1><p id="4fe9" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">Tair MDB使用NVM作为块设备，同时使用PMem感知的文件系统挂载(DAX挂载)。在分配NVM空间时，第一步是在相应的文件系统路径中创建并打开文件，并使用posix_fallocate来分配空间。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff lf"><img src="../Images/578e5a6e0fb3f2ed6e3a323fd68a8ef6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Z_JL6b-DR5G_SgL7N2gsuw.png"/></div></div></figure><h2 id="5702" class="lg kd hu bd ke lh li lj ki lk ll lm km jc ln lo kq jg lp lq ku jk lr ls ky lt dt translated">首先要考虑的是:内存分配器</h2><p id="eb6a" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">NVM本质上是非易失性的。缓存服务Tair MDB将NVM识别为易失性设备，无需考虑原子性和崩溃后恢复，也无需显式调用clflush/clwb等命令将CPU缓存内容强制刷新回介质。</p><p id="1450" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">使用DRAM空间时，tcmalloc/jemalloc等内存分配器是可选的。NVM空间将文件(或字符设备)暴露给上层，因此首先要考虑的是如何使用内存分配器。开源程序pmem[1]保护易失性内存管理库libmemkind，以及类似malloc/free的易用API。在大多数应用程序中切换时，这种模式提供了一个很好的选择。</p><p id="a931" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Tair MDB的实现没有使用libmemkind[2]。为了解释这个选择，Tair MDB内存布局将在下一节中介绍。</p><h2 id="c0da" class="lg kd hu bd ke lh li lj ki lk ll lm km jc ln lo kq jg lp lq ku jk lr ls ky lt dt translated">存储配置</h2><p id="b2e0" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">Tair MDB采用slab机制进行内存管理，它不会在使用时动态分配匿名内存，而是在系统启动时分配一个大内存。随后，内置的内存管理模块在这个大内存块中连续分布元数据和数据页，如下图所示:</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff lu"><img src="../Images/43e6d2399fbebef493499033aa875975.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xLwL89_u-WkbfepTLR8wdw.png"/></div></div></figure><p id="7fbf" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Tair MDB的内存使用分为以下几个部分:</p><p id="8ca6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">缓存元数据:它存储元数据信息，比如片的最大数量，以及片管理器的索引信息。</p><p id="51bd" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Slab Manager:每个Slab Manager管理一个固定大小的Slab。</p><p id="0cdd" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Hashmap:全局哈希表的索引，使用线性冲突链处理哈希冲突，所有对键的访问都由Hashmap处理。</p><p id="6cd1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">页面池:在启动时，页面池将内存分成页面，每个页面的大小为1M。平板管理器从页面池中请求页面，并将它们格式化为指定大小的平板。</p><p id="ea71" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在启动时，Tair MDB初始化所有可用的内存。因此，后续的数据存储部分不再需要操作系统动态分配内存。</p><p id="877e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">使用NVM时，需要将相应的文件映射到内存中，以获得虚拟地址空间。内置的内存管理模块可以透明地使用这个空间。因此，在这个过程中，不需要再次调用malloc/free来管理NVM上的空间。</p><h1 id="c799" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">压力测试开始:问题暴露</h1><p id="0946" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">部署NVM后，使用100字节的条目在Tair MDB上执行压力测试，产生以下数据:</p><p id="e8f8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">引擎查看延迟:</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff lv"><img src="../Images/cac9efc255a25bf8875cdc52134e3c56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*zMq0m9iM1oU-YRGjgVemiQ.png"/></div></figure><p id="d1ff" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">客户查看QPS:</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff lv"><img src="../Images/be6548e1ebefbacacdc71e5ebb31e218.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/1*YDZYjosTtXMCDdCompfOqQ.png"/></div></figure><p id="b254" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如这些图表所示，基于NVM的读取QPS延迟大致相当于DRAM的延迟，而其写入TPS延迟大约是DRAM的三分之一。</p><h2 id="e2a6" class="lg kd hu bd ke lh li lj ki lk ll lm km jc ln lo kq jg lp lq ku jk lr ls ky lt dt translated">分析</h2><p id="8bfb" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">perf结果表明所有的写性能损失都发生在锁上。这个锁管理的关键部分包括前面指定的内存布局中提到的页面写操作。在这种情况下，可能的原因是与DRAM相比，NVM上的写入延迟更长。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff lw"><img src="../Images/f7ee5cf49c6924046849c4bddcbcbd1a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*dEdAO6Gm4oNtmxwpNK-Sag.png"/></div></div></figure><p id="6574" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在压力测试期间，pcm[3]用于查看NVM DIMMS的带宽统计数据，显示一个DIMM上的写入高度不平衡。在稳定状态下，该DIMM上的写入量超过其他DIMM的两倍。</p><p id="b576" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">上述内容的详细信息如下图所示:</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff lx"><img src="../Images/45892e9db7c41777d7c903e9829be6d3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ifw5qz9eFXUF-bsUbuS7ug.png"/></div></div></figure><p id="a212" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在进一步探讨这些细节之前，下一节将概述用于NVM的DIMM放置策略。</p><h2 id="2cb1" class="lg kd hu bd ke lh li lj ki lk ll lm km jc ln lo kq jg lp lq ku jk lr ls ky lt dt translated">DIMM放置策略</h2><p id="9a48" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">一个插槽配有四块NVM DIMM，分布如下:</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff ly"><img src="../Images/40c9b6790090883e13ca0e857378393f.png" data-original-src="https://miro.medium.com/v2/resize:fit:872/format:webp/1*OTPCJy5HUCPO2APIIPmi4Q.png"/></div></figure><p id="8d3f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这种布局策略被称为2–2–1。每个插座都配有4块DIMM，分别属于4个不同的通道。使用多个通道时，CPU会进行交错，以便更有效地使用内存带宽。在当前的放置策略和配置中，CPU有一个4K单元，并在DIMM序列中交错。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff lz"><img src="../Images/e4efd540c0cfad26d33beee342b391f1.png" data-original-src="https://miro.medium.com/v2/resize:fit:240/format:webp/1*3ooPlvYVR7VVAtRcfxHnIA.png"/></div></figure><h2 id="8a8f" class="lg kd hu bd ke lh li lj ki lk ll lm km jc ln lo kq jg lp lq ku jk lr ls ky lt dt translated">诊断热点:不平衡的原因</h2><p id="b2a1" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">根据内存交错策略，可以推断出所有写入都是在不平衡的DIMM上的单个区域中完成的，导致该DIMM比其他DIMM保留更多的写入。</p><p id="778b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这种情况下的下一个任务是识别导致写入热点的处理逻辑。一种简单的方法是定位可疑点并逐个排除它们。下面的部分描述了Tair团队用来确定处理逻辑的方法。</p><h2 id="b89d" class="lg kd hu bd ke lh li lj ki lk ll lm km jc ln lo kq jg lp lq ku jk lr ls ky lt dt translated">优化开始:定位热点</h2><p id="0ca0" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">如上所述，写入热点会导致NVM DIMM访问不平衡。因此，优化的第一步是找到并处理写入热点，例如通过分散热点访问或将访问热点放入DRAM。</p><p id="b19f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Tair团队使用Pin来寻找热点[4]。前面提到的Tair MDB通过对文件执行mmap来获得操作内存的逻辑地址。所以可以用Pin来抓取mmap的返回值，进一步获取NVM在程序内存空间的逻辑地址。然后，该团队继续使用Pin来清除所有操作存储器的编程指令，并计算从NVM映射到地址空间的每个字节的写入次数。</p><p id="c63a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">最后，确认书写热点的存在，并将其对应的区域建立为页面的元数据。该团队考虑了几个解决写入热点问题的选项，包括向每个DIMM添加填充和交错热点，通过DIMM将基本相似的热数据分组存储，以及将热点移回DRAM。该团队的最终决定是将slab_manager和page_info移回DRAM。修订后的结构如下:</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff ma"><img src="../Images/82789cbaa899e18185ccb1b153beeda0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ysnffL0QdBy8Jd9-qC_xvg.png"/></div></div></figure><p id="7a3f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">通过这些更改，不平衡问题得到了有效解决，TPS从85w提高到140w，同时将引擎内写入延迟从40us降低到12us。</p><h2 id="dc2d" class="lg kd hu bd ke lh li lj ki lk ll lm km jc ln lo kq jg lp lq ku jk lr ls ky lt dt translated">解决过多的锁开销</h2><p id="76a4" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">当TPS在140w时，前面提到的pthread_spin_lock的开销仍然非常高。性能记录结果表明pthread_spin_lock使用了这个调用堆栈:</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff mb"><img src="../Images/91be64144c13ed01a4c988c31028d12f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MWc0cIv8u9V_YktYcO9lvA.png"/></div></div></figure><p id="0340" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">对batch_alloc_item的分析表明，初始化页面中的项目会将大量数据写入NVM。这是大量时间被浪费的地方，因为写入NVM比写入DRAM慢。</p><p id="a66d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">按照Tair MDB的逻辑，只有在将页面链接到slab_manager时才需要加锁。因此，对该项目的初始化操作可以移出临界区。在这一发现之后，Tair MDB代码中所有写入NVM的操作都进行了相应的筛选和优化。</p><p id="07e8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">优化后，pthread_spin_lock的开销下降到正常范围，TPS增加到170w，而引擎内延迟为9us。</p><h2 id="e76b" class="lg kd hu bd ke lh li lj ki lk ll lm km jc ln lo kq jg lp lq ku jk lr ls ky lt dt translated">优化结果</h2><p id="eedc" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">除了其他优化工作之外，平衡写入和锁粒度细化有效地减少了延迟，并将TPS提高到170w，比之前的数据增长了100%。介质的差异仍然比DRAM的写入性能低30%。但是，由于缓存服务的特点是读多于写，这种不足不会显著影响整体性能。</p><h1 id="190b" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">通道发现:新的设计指南</h1><p id="3c5d" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">基于他们的优化努力和生产环境试验，Tair团队能够确定一组三个关键的设计规则来实现基于NVM的缓存服务。这些规则与特定的NVM硬件特性密切相关，这些特性会显著影响缓存服务的构建。具体来说，NVM比DRAM密度更大、价格更低、延迟更高、带宽更小。它还存在不平衡的读写问题以及比读取延迟更高的写入延迟，并且当在相同位置重复写入时容易快速磨损。</p><h2 id="ef53" class="lg kd hu bd ke lh li lj ki lk ll lm km jc ln lo kq jg lp lq ku jk lr ls ky lt dt translated">第一条规则:避免写热点</h2><p id="afb3" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">Tair MDB在实施NVM后遇到了写热点问题，写热点加剧了介质磨损，导致负载不平衡。在优化之前，写入压力正好落在一个DIMM上，反映出未能充分利用整个DIMM带宽。除了内存布局(以元数据和数据的混合存储为特征)，来自事务的访问也可能导致写入热点。</p><p id="1ea1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Tair团队避免编写热点的方法包括:</p><p id="206b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">通过将元数据移动到DRAM中来分离元数据和数据。元数据比数据更容易被访问。元数据的一个例子是前面提到的Tair MDB的page_info。这使得NVM较高的写入延迟(与DRAM相比)对上层来说不那么不利。</p><p id="32a1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在上层应用用于实现写入时复制的逻辑。在某些情况下，这可以减少指定区域的硬件磨损。对Tair MDB中的数据条目的更新不会就地更新先前的条目，而是在hashmap冲突链的头部添加一个新条目。这样的先前条目将被异步删除。</p><p id="bd22" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">定期检查写入热点，并动态迁移到DRAM进行合并。对于访问上述事务导致的写热点，Tair MDB定期检查并合并写热点，以限制对低层介质的访问。</p><h2 id="86da" class="lg kd hu bd ke lh li lj ki lk ll lm km jc ln lo kq jg lp lq ku jk lr ls ky lt dt translated">第二条规则:减少对关键部分的访问</h2><p id="ba13" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">NVM比DRAM具有更高的写入延迟。因此，当临界区包括对NVM的操作时，由于临界区的放大影响，上层的并发度降低。</p><p id="7b3e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">前面提到的锁开销问题在DRAM上运行Tair MDB时不会出现，因为在DRAM上运行会自动假设这个关键部分的开销很低。然而，当使用NVM时，这种假设变得不真实。</p><p id="4a85" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">使用新媒体的一个常见问题是，在以前的软件过程中有效的假设在新媒体中可能不再适用，因此必须改变程序来解决这一问题。在这种情况下，Tair团队建议在缓存服务中使用NVM时，尽可能采用无锁设计(基于数据存储)。这限制了对临界区的访问，并避免了由更高的等待时间引起的级联连接效应。</p><p id="05ce" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Tair MDB通过引入用户空间RCU，使访问路径上的大多数操作都是无锁的，从而显著降低了NVM延迟对上层的影响。</p><h2 id="6ac1" class="lg kd hu bd ke lh li lj ki lk ll lm km jc ln lo kq jg lp lq ku jk lr ls ky lt dt translated">第三条规则:实现一个合适的分配器</h2><p id="01d9" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">分配器是使用NVM的事务中的基本组件。分配器的并发性直接影响软件的效率，而分配器的空间管理决定了空间利用率。在使用NVM的缓存服务中，设计和实现适合特定软件环境的分配器至关重要。</p><p id="52ff" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Tair MDB研究表明，适用于NVM的分配器必须提供以下功能和特性:</p><p id="4f31" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">碎片整理:NVM密度大，容量大。因此，在相同的碎片率下，NVM比DRAM浪费更多的空间。分片完成机制的存在要求上层应用避免就地更新，并且分配器尽可能分配固定大小的空间。</p><p id="7de1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">threadlocal配额:类似于上面讨论的减少对临界区的访问，从全局资源池分配资源的延迟将减少分配操作的并发性，除非存在threadlocal配额。</p><p id="ae25" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">容量意识:分配器需要解释它们管理的空间，缓存服务必须相应地扩展它们管理的空间。因此，分配器必须具有相应的功能来满足这些需求。</p><p id="46fa" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">实验表明，上述设计规则在实际应用场景中是可行和有效的，并且可以扩展到NVM实施可以证明有益的其他产品。</p><h1 id="2849" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">展望未来</h1><p id="b4f2" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">如前所述，Tair MDB仍然将NVM视为易失性设备，由于NVM的高密度和低价格，降低了服务的总体成本。展望未来，Tair团队将寻求新的硬件和方法来利用NVM的非易失性，实现交易和其他上层服务。</p><p id="1604" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt">(Original article by Fu Qiulei付秋雷)</p><p id="e42d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> <em class="jp">如果你有兴趣为阿里巴巴的Tair工作做出贡献，该集团目前欢迎来自阿里巴巴招聘页面</em> </strong>  <strong class="it hv"> <em class="jp">的</em> </strong> <a class="ae mc" href="https://job.alibaba.com/zhaopin/position_detail.htm?trace=qrcode_share&amp;positionCode=GP052397" rel="noopener ugc nofollow" target="_blank"> <strong class="it hv"> <em class="jp">的有兴趣的开发者申请。</em>T13】</strong></a></p><h1 id="f23e" class="kc kd hu bd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz dt translated">参考资料:</h1><p id="1dd2" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated"><em class="jp">[1]https://github . com/pmem</em></p><p id="1f94" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">【2】https://github . com/memkind/memkind</em></p><p id="1551" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">【3】https://github . com/opcm/PCM</em></p><p id="cad6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">[4]https://software . Intel . com/en-us/articles/pin-a-dynamic-binary-instrumentation-tool</em></p><p id="1107" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">【5】</em><a class="ae mc" href="https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&amp;mid=2247486968&amp;idx=1&amp;sn=6fcbbfdb9c053e3193beec526ee0fceb&amp;chksm=e92930f7de5eb9e121421ad248248469f345c2c8ee61d6bceee8ae3b58520a94ad2e46e55c87&amp;scene=21#wechat_redirect" rel="noopener ugc nofollow" target="_blank"><em class="jp">揭开技术！</em></a><em class="jp"/><a class="ae mc" href="https://mp.weixin.qq.com/s?__biz=MzIzOTU0NTQ0MA==&amp;mid=2247486968&amp;idx=1&amp;sn=6fcbbfdb9c053e3193beec526ee0fceb&amp;chksm=e92930f7de5eb9e121421ad248248469f345c2c8ee61d6bceee8ae3b58520a94ad2e46e55c87&amp;scene=21#wechat_redirect" rel="noopener ugc nofollow" target="_blank"><em class="jp">Tair，处理双11上千亿访问量的分布式缓存系统</em> </a></p><p id="bd50" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">【6】持久内存编程:生态系统的当前状态</em></p><p id="09e8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">(http://storageconference.us/2017/Presentations/Rudoff.pdf)</em></p><p id="6541" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">【7】持久记忆:做过的事，即将到来，预期长期</em></p><p id="452b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="jp">(https://blog . linuxplumpersconf . org/2015/OCW/system/presentations/3015/original/plumbers _ 2015 . pdf)</em></p></div><div class="ab cl md me hc mf" role="separator"><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi mj"/><span class="mg bw bk mh mi"/></div><div class="hn ho hp hq hr"><h1 id="104d" class="kc kd hu bd ke kf mk kh ki kj ml kl km kn mm kp kq kr mn kt ku kv mo kx ky kz dt translated">阿里巴巴科技</h1><p id="01dc" class="pw-post-body-paragraph ir is hu it b iu la iw ix iy lb ja jb jc lc je jf jg ld ji jj jk le jm jn jo hn dt translated">关于阿里巴巴最新技术的第一手深度资料→脸书:<a class="ae mc" href="http://www.facebook.com/AlibabaTechnology" rel="noopener ugc nofollow" target="_blank"> <strong class="it hv">【阿里巴巴科技】</strong> </a>。Twitter:<a class="ae mc" href="https://twitter.com/AliTech2017" rel="noopener ugc nofollow" target="_blank"><strong class="it hv">【AlibabaTech】</strong></a>。</p></div></div>    
</body>
</html>