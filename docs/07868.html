<html>
<head>
<title>Nvidia filling the blanks: A Partial Convolutions Research Paper</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Nvidia填补空白:部分卷积研究论文</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/nvidia-filling-the-blanks-a-partial-convolutions-research-paper-a2bd92459245?source=collection_archive---------11-----------------------#2018-09-17">https://medium.com/hackernoon/nvidia-filling-the-blanks-a-partial-convolutions-research-paper-a2bd92459245?source=collection_archive---------11-----------------------#2018-09-17</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="cea3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">所以，现在是2018年，英伟达的研究人员又开始研究了。这一次，一个革命性的图像在绘画和本质上，洞填充和质量提高算法。</p></div><div class="ab cl jp jq hc jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hn ho hp hq hr"><h1 id="03aa" class="jw jx hu bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dt translated">与其他技术的比较</h1><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="fe ff ku"><img src="../Images/fcafe57e37d038500aea6e0447001962.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*llqDcp6Gj93qXHS8Drn84g.png"/></div></div><figcaption class="lg lh fg fe ff li lj bd b be z ek">comparison of images</figcaption></figure><p id="b9c9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这篇研究论文(arXiv:1804.07723v1 [cs。CV])于2018年4月20日问世。它将重点放在最近的in-painting方法上，这些方法不使用深度学习，而是使用剩余图像的图像统计来填补漏洞。</p><p id="5414" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><a class="ae lk" href="http://pixl.cs.princeton.edu/pubs/Barnes_2009_PAR/index.php" rel="noopener ugc nofollow" target="_blank">补片匹配</a>，一种最先进的方法，反复搜索最佳拟合补片以填充孔洞。虽然这种方法通常产生平滑的结果，但是它受到可用图像统计的限制，并且没有视觉语义的概念。</p><blockquote class="ll lm ln"><p id="5de8" class="ir is lo it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hn dt translated">PatchMatch能够使用来自周围阴影和墙壁的图像补片来平滑地填充绘画中缺失的组件，但是语义感知方法会使用绘画中的补片来代替。</p></blockquote><p id="3293" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">深度神经网络以端到端的方式学习语义先验和有意义的隐藏表示，这已经被用于最近的图像内画eﬀorts.这些<a class="ae lk" href="https://hackernoon.com/tagged/networks" rel="noopener ugc nofollow" target="_blank">网络</a>在图像上采用卷积滤波器，用固定值替换移除的内容。</p><p id="b7a7" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">其他技术像<a class="ae lk" href="http://hi.cs.waseda.ac.jp/~iizuka/projects/completion/en/" rel="noopener ugc nofollow" target="_blank"> <strong class="it hv">饭冢等人</strong> </a> <strong class="it hv">。</strong>采用快速行进和泊松图像融合，而<a class="ae lk" href="https://arxiv.org/abs/1801.07892" rel="noopener ugc nofollow" target="_blank"> <strong class="it hv">余等人</strong> </a>。采用后续调整网络来调整其原始网络预测。许多最近的方法的另一个限制是聚焦在矩形孔上，通常假设在图像的中心。我们发现这些限制可能会导致过度拟合矩形孔，并最终限制这些模型在应用中的效用。</p><blockquote class="ll lm ln"><p id="2630" class="ir is lo it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hn dt translated">为了专注于更实际的不规则孔用例，我们收集了具有不同大小的不规则遮罩的大型图像基准。在我们的分析中，我们不仅关注孔的大小，还关注孔是否与图像边界接触的eﬀects。</p></blockquote></div><div class="ab cl jp jq hc jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hn ho hp hq hr"><h1 id="4bdf" class="jw jx hu bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dt translated">这种模式有什么不同？</h1><p id="792f" class="pw-post-body-paragraph ir is hu it b iu ls iw ix iy lt ja jb jc lu je jf jg lv ji jj jk lw jm jn jo hn dt translated">研究人员提出了对标准U-Net类结构的以下修改。</p><ul class=""><li id="96ef" class="lx ly hu it b iu iv iy iz jc lz jg ma jk mb jo mc md me mf dt translated">使用<strong class="it hv">部分卷积和自动掩模更新</strong>步骤实现图像内涂的最新技术。</li><li id="5e1b" class="lx ly hu it b iu mg iy mh jc mi jg mj jk mk jo mc md me mf dt translated">虽然以前的工作未能在具有典型卷积的U网络中使用跳跃链接实现良好的内绘结果，但他们证明了用部分卷积和掩模更新替换卷积层可以实现最先进的内绘结果。</li><li id="a07d" class="lx ly hu it b iu mg iy mh jc mi jg mj jk mk jo mc md me mf dt translated">他们提出了一个大的不规则掩膜数据集。</li></ul><p id="2131" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">研究给出了一个相当清晰的面具更新的原因。请允许我在此如实提及:</p><blockquote class="ll lm ln"><p id="0203" class="ir is lo it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hn dt translated">为了正确处理不规则的掩码，我们建议使用部分卷积层，包括掩码和重新归一化卷积操作，然后是掩码更新步骤。在图像分割任务中，屏蔽和重新归一化卷积的概念也被称为分割感知卷积，但是它们没有对输入屏蔽进行修改。我们对部分卷积的使用是这样的:给定一个二进制掩码，我们的卷积结果只取决于每一层的非空穴区域。<strong class="it hv">我们的主要扩展是自动屏蔽更新步骤，在部分卷积能够对未屏蔽值</strong>进行操作的情况下，该步骤移除任何屏蔽。给定连续更新的suﬃcient图层，即使最大的掩蔽洞最终也会缩小，仅在要素地图中留下有效响应。部分卷积层最终使我们的模型对占位符洞值不可知。</p></blockquote></div><div class="ab cl jp jq hc jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hn ho hp hq hr"><h1 id="2f10" class="jw jx hu bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dt translated">建模方法和体系结构</h1><p id="705c" class="pw-post-body-paragraph ir is hu it b iu ls iw ix iy lt ja jb jc lu je jf jg lv ji jj jk lw jm jn jo hn dt translated">所提出的模型使用堆叠部分卷积运算和掩模更新步骤来执行图像嵌入。让我们从定义卷积和掩码更新机制开始。</p><p id="21ed" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为简洁起见，我们将我们的部分卷积运算和掩码更新功能合称为<strong class="it hv">部分卷积层</strong>。</p><p id="42a4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">设<strong class="it hv"> W </strong>为卷积滤波器的卷积滤波器权重，<strong class="it hv"> b </strong>为相应的偏置。<strong class="it hv"> X </strong>是当前卷积(滑动)窗口的特征值(像素值),而<strong class="it hv"> M </strong>是相应的二进制掩码。每个位置的部分卷积类似于中的定义，表示为:</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div class="fe ff ml"><img src="../Images/9ac3498cc18ef93b3f936def4d227e6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1022/format:webp/1*gFFG_49Moz_Cx8NYyJ_Bvw.png"/></div><figcaption class="lg lh fg fe ff li lj bd b be z ek">Partial Convolution mechanism</figcaption></figure><p id="1c35" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在每个部分卷积操作之后，我们然后<strong class="it hv">更新我们的掩码</strong>。我们的去屏蔽规则很简单:如果卷积能够根据至少一个有效的输入值来调节其输出，那么我们就去除该位置的屏蔽。这表示为:</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div class="fe ff mm"><img src="../Images/42a3a4e0a86b9c9b6510a68b10832097.png" data-original-src="https://miro.medium.com/v2/resize:fit:622/format:webp/1*n-2y6SaDba79z3rkahImFA.png"/></div><figcaption class="lg lh fg fe ff li lj bd b be z ek">Mask Update Scheme</figcaption></figure><p id="2cb1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">并且可以作为正向传递的一部分在任何深度学习框架中容易地实现。通过部分卷积层的suﬃcient连续应用，如果输入包含任何有效像素，则任何掩模最终都将是全1。</p><h2 id="c11f" class="mn jx hu bd jy mo mp mq kc mr ms mt kg jc mu mv kk jg mw mx ko jk my mz ks na dt translated">电力网设计</h2><p id="6d77" class="pw-post-body-paragraph ir is hu it b iu ls iw ix iy lt ja jb jc lu je jf jg lv ji jj jk lw jm jn jo hn dt translated">网络设计在很大程度上基于UNet like架构，仅使用一个较小的调整，即用部分卷积层替换所有卷积层。</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div class="fe ff nb"><img src="../Images/4488e822aef8285477059ba3fd2dadf1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*BPCuVcbrjQVx3QSzmIJ2jg.png"/></div><figcaption class="lg lh fg fe ff li lj bd b be z ek">The network architecture</figcaption></figure><p id="77b6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在阐述网络架构时，必须提及的是<strong class="it hv"> PConv 1至PConv 8 </strong>是编码网络，以下具有上采样跳跃链接的网络是相同的解码架构。</p><p id="e922" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv"> BatchNorm </strong>列表示<strong class="it hv"> PConv </strong>之后是否有一个批次归一化层。非线性列显示是否使用了非线性层以及使用了什么非线性层(如果使用了BatchNorm，则在BatchNorm之后)。</p><h2 id="2d45" class="mn jx hu bd jy mo mp mq kc mr ms mt kg jc mu mv kk jg mw mx ko jk my mz ks na dt translated">损失函数</h2><p id="5cfa" class="pw-post-body-paragraph ir is hu it b iu ls iw ix iy lt ja jb jc lu je jf jg lv ji jj jk lw jm jn jo hn dt translated">研究论文摘录如下:</p><blockquote class="ll lm ln"><p id="4d58" class="ir is lo it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hn dt translated">我们的损失函数以每像素重建精度和组成为目标，即预测的孔洞值过渡到其周围环境的平滑程度。</p><p id="18ab" class="ir is lo it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hn dt translated">给定具有孔洞I_in、初始二进制掩码M (0表示孔洞)、网络预测I_out和地面真实图像I_gt的输入图像，我们首先定义每像素损失<strong class="it hv">L _ hole = k(1M)⊙(I _ out I _ gt)k1和L _ valid = kM⊙(I _ out I _ gt)k1</strong>。这些分别是孔和非孔像素在网络输出上的L1损耗。</p></blockquote><p id="71bf" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">永久损失</strong>已使用以下公式计算:</p><p id="2bc6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">其中<strong class="it hv">ψn</strong>是第n个选定层的激活图。</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="fe ff nc"><img src="../Images/14fa6b47c35c6694b54b3a00fb8673c4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*DT7lLiPFJdTyxubV6L4maQ.png"/></div></div><figcaption class="lg lh fg fe ff li lj bd b be z ek">Perpetual Loss</figcaption></figure><p id="7cc3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">而风格损失已被考虑并被用作:</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="fe ff nd"><img src="../Images/89c47dd62cb938579ac4b25f6262989f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2gXc-T3K6ZSIbIBs6aspmw.png"/></div></div><figcaption class="lg lh fg fe ff li lj bd b be z ek">Style Losses</figcaption></figure><p id="56ec" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们的最终损失项是总变化<strong class="it hv"> (TV) </strong>损失<strong class="it hv"> <em class="lo"> L_tv </em> </strong>:这是对P的平滑惩罚，其中P是孔区域的1像素膨胀的区域。</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="fe ff ne"><img src="../Images/1db9f51ad7fe77bde93a2502238dcb0b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*oRD2-iS3jvM9NqKBYzwZzw.png"/></div></div><figcaption class="lg lh fg fe ff li lj bd b be z ek">Smoothing Penalty</figcaption></figure><p id="3a0f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">因此，<strong class="it hv">总损耗</strong>(系数超参数调整后)为:</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="fe ff nf"><img src="../Images/cc34edab2a125eaf79083bf09cf4489d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*B-RnDQDVPCwphrU8trrmHQ.png"/></div></div><figcaption class="lg lh fg fe ff li lj bd b be z ek">Total Loss</figcaption></figure></div><div class="ab cl jp jq hc jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hn ho hp hq hr"><h1 id="044b" class="jw jx hu bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dt translated">填孔的测试和结果</h1><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="fe ff ng"><img src="../Images/d341d18a73c6ef0a0d9e09c0e3e78caa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*Mnw2K7PEshUMGz_O0apGMw.png"/></div></div><figcaption class="lg lh fg fe ff li lj bd b be z ek">Comparisons among PConv</figcaption></figure><p id="7759" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">人们可以很容易地看到研究人员的结果(PConv)，并了解它与使用256*256像素尺寸的其他模型相比表现如何。</p><blockquote class="ll lm ln"><p id="aefc" class="ir is lo it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hn dt translated">需要注意的是<strong class="it hv"> ImageNet和Places2模特训练10天</strong>，而<strong class="it hv"> CelebA-HQ训练3天</strong>。所有微调都在一天内完成。</p></blockquote><p id="7b45" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">所以，你可以看到即使使用<strong class="it hv"> NVIDIA V100 GPU (16GB) </strong>批量为6个之后，训练这样的模型所需要的时间量！</p></div><div class="ab cl jp jq hc jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hn ho hp hq hr"><h1 id="0e09" class="jw jx hu bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dt translated">模型基准</h1><p id="946f" class="pw-post-body-paragraph ir is hu it b iu ls iw ix iy lt ja jb jc lu je jf jg lv ji jj jk lw jm jn jo hn dt translated">我想承认时间的敏感性，同时进行精度结果作为个人意见。考虑到这一点，这款<strong class="it hv"> PConv </strong>车型在<strong class="it hv"> L1 </strong>得分和<strong class="it hv"> IScores </strong>两方面都是令人信服的完美替代品。</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="fe ff nh"><img src="../Images/4eba72f40c23706299951a2e9c760cb7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MNnTwZI34H5cNWrZgT8C5A.png"/></div></div></figure><p id="54a9" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">研究人员声称:</p><blockquote class="ll lm ln"><p id="dc47" class="ir is lo it b iu iv iw ix iy iz ja jb lp jd je jf lq jh ji jj lr jl jm jn jo hn dt translated">在大多数情况下，我们的方法在diﬀerent时间周期和孔-像面积比方面优于其他方法。</p></blockquote><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="fe ff ni"><img src="../Images/76a8c85ab043fd7bb5f03f3b2a573b63.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PNUCcOYi0ndL4_bi4Q-3sQ.png"/></div></div><figcaption class="lg lh fg fe ff li lj bd b be z ek">Graphical Benchmarks</figcaption></figure><p id="0a1d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">看一下图形基准，我不会真的争辩。</p></div><div class="ab cl jp jq hc jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hn ho hp hq hr"><h1 id="5153" class="jw jx hu bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dt translated">其他用途</h1><h2 id="6007" class="mn jx hu bd jy mo mp mq kc mr ms mt kg jc mu mv kk jg mw mx ko jk my mz ks na dt translated">图像超分辨率任务</h2><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="fe ff nj"><img src="../Images/b97d485838850edaf25d682aab43e853.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*BR63erPw21W0Yr19eERujw.png"/></div></div><figcaption class="lg lh fg fe ff li lj bd b be z ek">Resolution Enhance Task Results</figcaption></figure><p id="bc3d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">是的，这种算法也可以用来提高图像分辨率。让下面的图像讲述它自己的故事。我将把这一个作为秘密留下😉</p><figure class="kv kw kx ky fq kz fe ff paragraph-image"><div role="button" tabindex="0" class="la lb di lc bf ld"><div class="fe ff nk"><img src="../Images/f6623c085e292a0b796d6668b38b9e95.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*XVtAXLArR2zDdF2sNJyBLQ.png"/></div></div><figcaption class="lg lh fg fe ff li lj bd b be z ek">Mask Updates with one-one mappings</figcaption></figure></div><div class="ab cl jp jq hc jr" role="separator"><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju jv"/><span class="js bw bk jt ju"/></div><div class="hn ho hp hq hr"><h1 id="7969" class="jw jx hu bd jy jz ka kb kc kd ke kf kg kh ki kj kk kl km kn ko kp kq kr ks kt dt translated">限制</h1><p id="26b9" class="pw-post-body-paragraph ir is hu it b iu ls iw ix iy lt ja jb jc lu je jf jg lv ji jj jk lw jm jn jo hn dt translated">我想引用这篇研究论文来说明，这个模型本身不会因为孔洞大小的增加而导致灾难性的性能下降，但它确实会对一些结构稀疏的图像失败，如门上的<strong class="it hv">条</strong>，并且像大多数方法一样，在最大的孔洞上挣扎。</p><p id="ce42" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><strong class="it hv">注意</strong>:我在这篇文章中引用了之后的<a class="ae lk" href="https://arxiv.org/abs/1804.07723" rel="noopener ugc nofollow" target="_blank">资源。</a></p><p id="70c7" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">下次见，快乐学习！</p><figure class="kv kw kx ky fq kz"><div class="bz el l di"><div class="nl nm l"/></div></figure></div></div>    
</body>
</html>