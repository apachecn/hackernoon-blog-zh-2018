<html>
<head>
<title>Distributed log analytics using Apache Kafka, Kafka Connect and Fluentd</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Apache Kafka、Kafka Connect和Fluentd的分布式日志分析</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/distributed-log-analytics-using-apache-kafka-kafka-connect-and-fluentd-303330e478af?source=collection_archive---------5-----------------------#2018-09-23">https://medium.com/hackernoon/distributed-log-analytics-using-apache-kafka-kafka-connect-and-fluentd-303330e478af?source=collection_archive---------5-----------------------#2018-09-23</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="df13" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">一个实用的流数据基础设施用例</h2></div><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div role="button" tabindex="0" class="jp jq di jr bf js"><div class="fe ff jj"><img src="../Images/bd4d86f6b4cfd1ecfd56b48879c18094.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Souk6aI6hwmE3OAk"/></div></div><figcaption class="jv jw fg fe ff jx jy bd b be z ek">“brown cutted log” by <a class="ae jz" href="https://unsplash.com/@lastly?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Tyler Lastovich</a> on <a class="ae jz" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="3f18" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">在<a class="ae jz" href="https://cloudboxlabs.com/" rel="noopener ugc nofollow" target="_blank"> Cloudbox Labs </a>，我们认为日志是一个非常有趣的数据集。它们是我们技术堆栈的核心。它们让我们深入了解用户如何与我们互动。它们提供实时应用智能。因此，我们构建了一套强大的数据基础设施，可以处理来自所有应用程序的大量日志，并允许实时分析和批处理。</p><p id="8943" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">对于运行分布式服务的数据处理架构来说，从生产服务中收集和聚合日志可能是一项挑战。对于我们的一些客户，我们部署基于<a class="ae jz" href="https://docs.docker.com/" rel="noopener ugc nofollow" target="_blank"> Docker </a>的分布式服务，确保我们从所有容器中捕获日志并将它们路由到各种下游分析引擎的任务变得非常有趣。</p><p id="b7f0" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">我们的日志处理管道使用<a class="ae jz" href="https://docs.fluentd.org/v1.0" rel="noopener ugc nofollow" target="_blank"> Fluentd </a>在Docker容器内进行统一日志记录，使用<a class="ae jz" href="http://kafka.apache.org/documentation/" rel="noopener ugc nofollow" target="_blank"> Apache Kafka </a>作为持久存储和流管道，使用<a class="ae jz" href="https://docs.confluent.io/current/connect/index.html" rel="noopener ugc nofollow" target="_blank"> Kafka Connect </a>将日志路由到<a class="ae jz" href="https://www.elastic.co/guide/index.html" rel="noopener ugc nofollow" target="_blank"> ElasticSearch </a>进行实时索引和搜索，并使用S3进行批量分析和归档。</p><p id="82d3" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated"><a class="ae jz" href="https://docs.fluentd.org/v1.0" rel="noopener ugc nofollow" target="_blank"> Fluentd </a>是一个开源的统一日志应用，可以智能地收集许多不同类型系统的日志，从app日志、nginx日志到数据库和系统日志。它配有各种插件<a class="ae jz" href="https://www.fluentd.org/plugins" rel="noopener ugc nofollow" target="_blank">用于连接fluentd和外部系统。我们将使用其</a><a class="ae jz" href="https://github.com/fluent/fluent-plugin-kafka" rel="noopener ugc nofollow" target="_blank"> Apache Kafka插件</a>以JSON格式将日志转发到Kafka主题。</p><p id="6d4e" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated"><a class="ae jz" href="http://kafka.apache.org/documentation/" rel="noopener ugc nofollow" target="_blank">阿帕奇卡夫卡</a>几乎无需介绍。这是一个流行的分布式发布-订阅消息平台，提供持久存储和高可伸缩性。在Kafka上聚合我们所有的Docker容器日志允许我们处理高消息吞吐量，并从那里使用Kafka Connect将它们路由到任意数量的下游系统。</p><p id="7cdd" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated"><a class="ae jz" href="https://docs.confluent.io/current/connect/index.html" rel="noopener ugc nofollow" target="_blank"> Kafka Connect </a>是一组<a class="ae jz" href="https://docs.confluent.io/current/connect/managing/connectors.html" rel="noopener ugc nofollow" target="_blank">连接器</a>的统称，用于连接Kafka与外部系统，如JDBC数据库、AWS S3、Google Cloud BigQuery等。每个连接器可以单独安装在Connect平台上，用户可以通过Kafka Connect上的REST接口与连接器进行交互。我们将在日志处理中使用S3和ElasticSearch连接器。</p><p id="31a4" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated"><a class="ae jz" href="https://www.elastic.co/guide/index.html" rel="noopener ugc nofollow" target="_blank"> Elasticsearch </a>是一款流行的开源索引和搜索软件。出于我们的目的，我们将把我们的日志下沉并索引到可以实时分析的弹性搜索中。</p><p id="61da" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">整体架构是这样的。</p><figure class="jk jl jm jn fq jo fe ff paragraph-image"><div class="fe ff kw"><img src="../Images/bb626549966fb8fca705ae1171373df9.png" data-original-src="https://miro.medium.com/v2/resize:fit:1032/format:webp/1*FCIf2tB2XQtbB9RcZe94Yg.png"/></div></figure><p id="52ae" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">在本文中，出于演示目的，我们将使用<a class="ae jz" href="https://docs.docker.com/compose/overview/" rel="noopener ugc nofollow" target="_blank"> Docker Compose </a>加速整个日志处理管道，包括web app、fluentd、kafka、zookeeper、kafka connect和elasticsearch。<a class="ae jz" href="https://docs.docker.com/compose/overview/" rel="noopener ugc nofollow" target="_blank"> Docker Compose </a>允许我们在隔离的环境中轻松运行多容器Docker应用，快速迭代开发。</p><p id="3041" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">整个堆栈可以通过使用一个YAML文件来创建。下面是<a class="ae jz" href="https://github.com/cloudboxlabs/blog-code/blob/master/distributed-logging/docker-compose-dist-logging.yaml" rel="noopener ugc nofollow" target="_blank">的完整代码</a>。</p><p id="7727" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">关于容器之间的网络，以便它们可以互相交谈。Docker compose建立了一个每个容器都可以加入的网络。在默认网络中，每个容器都可以通过其容器名称被发现。例如，Kafka bootstrap服务器可以通过kafka:9092访问，Zookeep可以通过zookeeper:2181发现。Docker compose负责所有底层网络设置。</p><p id="f7e3" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">现在让我们浏览一下我们的Docker容器。</p><ol class=""><li id="193d" class="kx ky hu kc b kd ke kg kh kj kz kn la kr lb kv lc ld le lf dt translated">为了模拟我们的web应用程序，我们简单地创建了一个Docker容器，它使用现有的<a class="ae jz" href="https://hub.docker.com/_/httpd/" rel="noopener ugc nofollow" target="_blank"> httpd图像</a>运行Apache HTTP服务器。它有一个REST api，每次收到GET请求时都会生成日志。我们还将主机端口8080映射到容器端口80，apache服务器在该端口上运行，因此我们可以在<a class="ae jz" href="http://localhost:8080/." rel="noopener ugc nofollow" target="_blank"> http://localhost:8080/上运行web应用程序。</a>它还链接fluentd容器，以便日志可以跨容器转发。最后，我们设置了一个名为fluentd的日志驱动程序，带有一个标签。</li></ol><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="lg lh l"/></div></figure><p id="268f" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">2.接下来，我们设置一个运行fluentd的容器。我们没有使用现有的Docker映像，而是选择运行我们自己的Docker文件，这样我们就可以安装fluentd <a class="ae jz" href="https://github.com/fluent/fluent-plugin-kafka" rel="noopener ugc nofollow" target="_blank"> kafka插件</a>来将日志转发到我们的kafka容器。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="lg lh l"/></div></figure><p id="c865" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">我们的docker文件如下所示。它运行fluentd:v0.12-debian镜像并安装kafka插件。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="lg lh l"/></div></figure><p id="acba" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">kafka插件配置文件被挂载到Docker容器的/fluentd/conf/fluentd.conf中。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="lg lh l"/></div></figure><p id="fbdb" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">这很简单。它指定了一个名为kafka_buffered的插件类型，因为它将日志缓冲到位于/buffer/td的本地文件中，并每3秒钟将内容刷新到kafka。在默认网络中，kafka:9092联系到Kafka经纪人。日志以gzipped JSON blob的形式发布到Kafka主题“log-messages”。</p><p id="c5ce" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">3.接下来，我们使用现有的Docker映像设置Apache Kafka和Zookeeper对作为我们的主要pubsub主干。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="lg lh l"/></div></figure><p id="58d2" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">有趣的是，我们指定Kafka应该创建4个主题进行处理。</p><ul class=""><li id="2dff" class="kx ky hu kc b kd ke kg kh kj kz kn la kr lb kv li ld le lf dt translated">log-messages:这是我们所有容器日志的存放位置。出于演示目的，这是一个1分区，不兼容的主题。</li><li id="8074" class="kx ky hu kc b kd lj kg lk kj ll kn lm kr ln kv li ld le lf dt translated">connect-config/offset/status:这3个主题由Kafka connect使用，它们必须是Connect要求的紧凑主题</li></ul><p id="3d22" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">4.现在是整个堆栈中最有趣的容器。Kafka连接容器。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="lg lh l"/></div></figure><p id="c037" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">在这里，我们以分布式模式运行Kafka连接器。分布式模式提供了更多的可伸缩性和容错能力，因为所有的连接器工作人员都可以相互协调。分布式工作者是无状态的，可以通过运行在容器中的REST api来控制。Kafka连接器有丰富的<a class="ae jz" href="https://docs.confluent.io/current/connect/references/allconfigs.html#connect-allconfigs" rel="noopener ugc nofollow" target="_blank">工人配置选项</a>。这里我们使用无模式JSON转换器进行消息解编/序列化。</p><p id="0839" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">我们还使用docker文件，这样我们就可以安装Elasticsearch和S3连接器，并将连接器配置安装到容器文件系统上。</p><figure class="jk jl jm jn fq jo"><div class="bz el l di"><div class="lg lh l"/></div></figure><p id="b640" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">Confluent Inc .发布了Elasticsearch连接器的tarball，但是我找不到预打包的S3连接器，所以我们打包了自己的连接器，并将jar安装在/opt/connectors/connector_jars中的容器中，Kafka Connect可以加载它们。</p><p id="f370" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">5.最后，我们基于官方Docker图像建立了一个elasticsearch容器，这样日志就可以被索引和搜索。</p><p id="5567" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">现在让我们按照这些简单的步骤来运行日志处理堆栈。</p><ol class=""><li id="72b5" class="kx ky hu kc b kd ke kg kh kj kz kn la kr lb kv lc ld le lf dt translated">从撰写构建Docker映像</li></ol><pre class="jk jl jm jn fq lo lp lq lr aw ls dt"><span id="803a" class="lt lu hu lp b fv lv lw l lx ly">docker-compose -f docker-compose-dist-logging.yaml build</span></pre><p id="a1a5" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">2.运行将设置所有容器的Docker映像</p><pre class="jk jl jm jn fq lo lp lq lr aw ls dt"><span id="a641" class="lt lu hu lp b fv lv lw l lx ly">docker-compose -f docker-compose-dist-logging.yaml up</span></pre><p id="3019" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">3.Exec进入kafka_connect容器，使用REST api添加Elasticsearch和S3连接器</p><pre class="jk jl jm jn fq lo lp lq lr aw ls dt"><span id="79a3" class="lt lu hu lp b fv lv lw l lx ly">docker-compose -f docker-compose-dist-logging.yaml exec kafka_connect bash</span><span id="9d34" class="lt lu hu lp b fv lz lw l lx ly">&gt;&gt; curl -X POST -H "Content-Type: application/json" --data @/opt/connector_conf/connector_elasticsearch.json <a class="ae jz" href="http://localhost:8083/connectors" rel="noopener ugc nofollow" target="_blank">http://localhost:8083/connectors</a></span><span id="40bc" class="lt lu hu lp b fv lz lw l lx ly">&gt;&gt; curl -X POST -H "Content-Type: application/json" --data @/opt/connector_conf/connector_s3.json http://localhost:8083/connectors</span></pre><p id="9fbb" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">就是这样！现在有了完整的数据管道，可以从分布式Docker容器中收集和聚合日志，并将其发送到Elasticsearch进行实时索引和搜索，以及发送到S3进行批处理和长期存档。</p></div><div class="ab cl ma mb hc mc" role="separator"><span class="md bw bk me mf mg"/><span class="md bw bk me mf mg"/><span class="md bw bk me mf"/></div><div class="hn ho hp hq hr"><p id="3566" class="pw-post-body-paragraph ka kb hu kc b kd ke iv kf kg kh iy ki kj kk kl km kn ko kp kq kr ks kt ku kv hn dt translated">一如既往，你可以在<a class="ae jz" href="https://github.com/cloudboxlabs/blog-code/tree/master/distributed-logging" rel="noopener ugc nofollow" target="_blank"> Cloudbox Labs github </a>上找到这篇文章中讨论的完整代码。</p></div></div>    
</body>
</html>