<html>
<head>
<title>How to do Novelty Detection in Keras with Generative Adversarial Network (Part 2)</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">如何利用生成对抗网络在Keras中进行新颖性检测(下)</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/how-to-do-novelty-detection-in-keras-with-generative-adversarial-network-part-2-546d97632f63?source=collection_archive---------23-----------------------#2018-09-28">https://medium.com/hackernoon/how-to-do-novelty-detection-in-keras-with-generative-adversarial-network-part-2-546d97632f63?source=collection_archive---------23-----------------------#2018-09-28</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/32e95ce15e496b00fe76efd79ab27e2a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*oEnl8x7NbFw6amEl.jpg"/></div></div></figure><p id="1b30" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">前一部分介绍了用于新奇检测的ALOCC模型如何工作，以及一些关于autoencoder和GANs的背景信息，在本文中，我们将在Keras中实现它。</p><p id="4156" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">建议在继续之前对模型的工作原理有一个大致的了解。你可以在这里阅读第一部分，<a class="ae ka" rel="noopener" href="/@chengweizhang2012/how-to-do-novelty-detection-in-keras-with-generative-adversarial-network-part-1-e288ba745b9d">如何用生成对抗网络在Keras中进行新颖性检测(第一部分)</a></p><h2 id="8d0e" class="kb kc hu bd kd ke kf kg kh ki kj kk kl jn km kn ko jr kp kq kr jv ks kt ku kv dt translated">从<a class="ae ka" href="https://github.com/Tony607/ALOCC_Keras" rel="noopener ugc nofollow" target="_blank"> my GitHub </a>下载源代码。</h2><h1 id="de72" class="kw kc hu bd kd kx ky kz kh la lb lc kl ld le lf ko lg lh li kr lj lk ll ku lm dt translated">构建模型</h1><figure class="lo lp lq lr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ln"><img src="../Images/b410d3ab3a294e7a27582afeb918d28b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rUz7RgFKBmky4gxh.png"/></div></div></figure><p id="d896" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">让我们从上图所示的R网络开始。该模型在Keras functional API中实现。</p><figure class="lo lp lq lr fq iv"><div class="bz el l di"><div class="ls lt l"/></div><figcaption class="lu lv fg fe ff lw lx bd b be z ek">R or reconstruction network</figcaption></figure><p id="86ba" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">一些值得一提的要点。</p><ul class=""><li id="367d" class="ly lz hu je b jf jg jj jk jn ma jr mb jv mc jz md me mf mg dt translated">为了提高网络的稳定性，我们在这个网络中使用步长卷积而不是池层。</li><li id="54b6" class="ly lz hu je b jf mh jj mi jn mj jr mk jv ml jz md me mf mg dt translated">在每个卷积层之后，利用批量归一化操作，这增加了我们的结构的稳定性。要了解更多，您可以参考我专门针对该主题的帖子，<a class="ae ka" href="https://www.dlology.com/blog/one-simple-trick-to-train-keras-model-faster-with-batch-normalization/" rel="noopener ugc nofollow" target="_blank">一个用批处理规范化更快训练Keras模型的简单技巧</a>。</li><li id="96ce" class="ly lz hu je b jf mh jj mi jn mj jr mk jv ml jz md me mf mg dt translated"><code class="eh mm mn mo mp b">UpSampling</code>采用分层代替Keras’<code class="eh mm mn mo mp b">Conv2DTranspose</code>以减少产生的伪影，使输出形状更具确定性。</li><li id="2012" class="ly lz hu je b jf mh jj mi jn mj jr mk jv ml jz md me mf mg dt translated">我们建议使用<code class="eh mm mn mo mp b">LeakyReLU</code>层代替<code class="eh mm mn mo mp b">ReLU</code>激活。它类似于ReLU，但是它通过允许较小的负激活值来放松稀疏性约束。</li></ul><p id="7427" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">D或鉴别器的架构是一系列卷积层，这些卷积层被训练成最终在没有任何监督的情况下区分新样本或异常样本。</p><figure class="lo lp lq lr fq iv"><div class="bz el l di"><div class="ls lt l"/></div><figcaption class="lu lv fg fe ff lw lx bd b be z ek">D or discriminator network</figcaption></figure><p id="c781" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">d网络输出单个浮点数的范围相对于输入属于目标类的可能性在0~1之间。</p><h1 id="b6ac" class="kw kc hu bd kd kx ky kz kh la lb lc kl ld le lf ko lg lh li kr lj lk ll ku lm dt translated">训练模型</h1><p id="1019" class="pw-post-body-paragraph jc jd hu je b jf mq jh ji jj mr jl jm jn ms jp jq jr mt jt ju jv mu jx jy jz hn dt translated">出于简单和可再现的原因，我们选择教导模型将标记为“1”的MNIST手写数字识别为目标或正常图像，而模型将能够在测试阶段将其他数字区分为新奇/异常。</p><p id="62aa" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们在对抗过程中训练R+D神经网络。</p><p id="7cdd" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">当训练D网络时，它暴露于作为输入的重建图像和原始图像，其中它们的输出分别标记为0和1。3d网络通过最小化这两种类型数据的<code class="eh mm mn mo mp b">binary_crossentropy</code>损失来学习辨别真实图像和生成图像。</p><p id="443f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">当训练R网络时，从标准偏差采样的统计噪声被添加到输入中，以使R对输入图像中的噪声和失真具有鲁棒性。这就是上图中η代表的意思。R被训练以共同减少重构损失和“愚弄R网络以输出目标类”损失。有一个权衡超参数控制这两个术语的相对重要性。</p><p id="6fd5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">下面的代码构造并连接鉴别器和生成器模块。</p><p id="4c4c" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">请注意，在编译组合<code class="eh mm mn mo mp b">adversarial_model</code>之前，我们将鉴别器的权重设置为不可训练，因为对于组合模型，我们只想训练生成器，您很快就会发现这一点。不会妨碍已经编译好的鉴别器模型进行训练。另外，<code class="eh mm mn mo mp b">self.r_alpha</code>是一个小浮点数，用于权衡两个发电机/R网络损耗的相对重要性。</p><figure class="lo lp lq lr fq iv"><div class="bz el l di"><div class="ls lt l"/></div><figcaption class="lu lv fg fe ff lw lx bd b be z ek">Construct and compile model</figcaption></figure><p id="ffbd" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">随着模型的构建和编译，我们可以开始训练。</p><p id="bb1d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">首先，仅提取MNIST训练集中的“1 ”,将统计噪声应用于发电机/ R输入的“1”的副本。</p><p id="1d85" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">下面是训练一批数据的代码。首先在具有不同输出标签的真实和生成的图像上训练3d网络。</p><p id="7a3d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">然后R网络对同一批有噪数据进行两次训练，使其损失最小。</p><figure class="lo lp lq lr fq iv"><div class="bz el l di"><div class="ls lt l"/></div><figcaption class="lu lv fg fe ff lw lx bd b be z ek">Train one batch</figcaption></figure><p id="ec45" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">对于输出<code class="eh mm mn mo mp b">g_loss</code>变量的最后一个提示，因为组合的<code class="eh mm mn mo mp b">adversarial_model</code>是具有两个损失函数且没有附加度量的<code class="eh mm mn mo mp b">compiled</code>，所以<code class="eh mm mn mo mp b">g_loss</code>将是3个数字的列表，<code class="eh mm mn mo mp b">[total_weighted_loss, loss_1, loss_2]</code>，其中<code class="eh mm mn mo mp b">loss_1</code>是重建损失，<code class="eh mm mn mo mp b">loss_2</code>是“愚弄R网络损失”。训练GAN网络的时间越长，通常会产生更好的结果，而在我们的情况下，过早停止训练会导致学习到的网络权重不成熟，而过度训练网络会使网络混乱，并产生不期望的输出。我们必须定义一个合适的训练停止标准。</p><p id="7dc7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">作者提出，当R能够以最小误差重构其输入时，训练过程停止，这可以通过跟踪<code class="eh mm mn mo mp b">loss_1</code>/重构损失来监控。</p><h1 id="4774" class="kw kc hu bd kd kx ky kz kh la lb lc kl ld le lf ko lg lh li kr lj lk ll ku lm dt translated">新颖性检测</h1><p id="fba8" class="pw-post-body-paragraph jc jd hu je b jf mq jh ji jj mr jl jm jn ms jp jq jr mt jt ju jv mu jx jy jz hn dt translated">下图显示了在5个时段的训练阶段期间的R网络重建损失，看起来重建损失在时段3结束时达到其最小值，因此让我们使用在时段3之后保存的模型权重来进行我们的新颖性检测。您可以从我的GitHub资源库下载并运行测试阶段Jupyter notebook<strong class="je hv">test . ipynb</strong>。</p><figure class="lo lp lq lr fq iv fe ff paragraph-image"><div class="fe ff mv"><img src="../Images/b553769de5a27ba896e8eb6b0fca02b5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/format:webp/0*wWSPxkq092SQJxVU.png"/></div><figcaption class="lu lv fg fe ff lw lx bd b be z ek">R network reconstruction loss</figcaption></figure><p id="ba23" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们可以测试重建损耗和鉴频器输出。新/异常图像具有较大的重建损失和较小的鉴别器输出值，如下所示。其中手写“1”的图像为目标，其他数字为新奇/异常情况。</p><figure class="lo lp lq lr fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mw"><img src="../Images/2b3412c077121e347692b97e5fd0c5cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/0*8fjAZIdgbrxWGqEn.png"/></div></div><figcaption class="lu lv fg fe ff lw lx bd b be z ek">Reconstruction loss and discriminator output</figcaption></figure><h1 id="6f15" class="kw kc hu bd kd kx ky kz kh la lb lc kl ld le lf ko lg lh li kr lj lk ll ku lm dt translated">结论和进一步阅读</h1><p id="0673" class="pw-post-body-paragraph jc jd hu je b jf mq jh ji jj mr jl jm jn ms jp jq jr mt jt ju jv mu jx jy jz hn dt translated">我们介绍了如何利用生成对抗网络和编解码网络在Keras中建立一个新颖的检测ALOCC模型。</p><p id="ca32" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">查看原文:<a class="ae ka" href="https://arxiv.org/abs/1802.09088" rel="noopener ugc nofollow" target="_blank">https://arxiv.org/abs/1802.09088</a>。</p><p id="96a1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这里是<a class="ae ka" href="http://qr.ae/TUGryT" rel="noopener ugc nofollow" target="_blank">在Quora </a>上的一个有趣的问题，关于GAN是否可以做异常/新奇检测，由GAN的创造者Ian Goodfellow回答。</p><h2 id="a213" class="kb kc hu bd kd ke kf kg kh ki kj kk kl jn km kn ko jr kp kq kr jv ks kt ku kv dt translated">别忘了从<a class="ae ka" href="https://github.com/Tony607/ALOCC_Keras" rel="noopener ugc nofollow" target="_blank"> my GitHub </a>下载源代码。</h2><p id="0147" class="pw-post-body-paragraph jc jd hu je b jf mq jh ji jj mr jl jm jn ms jp jq jr mt jt ju jv mu jx jy jz hn dt translated"><a class="ae ka" href="https://twitter.com/intent/tweet?url=https%3A//www.dlology.com/blog/how-to-do-novelty-detection-in-keras-with-generative-adversarial-network-part-2/&amp;text=How%20to%20do%20Novelty%20Detection%20in%20Keras%20with%20Generative%20Adversarial%20Network%20%28Part%202%29" rel="noopener ugc nofollow" target="_blank">在Twitter上分享</a> <a class="ae ka" href="https://www.facebook.com/sharer/sharer.php?u=https://www.dlology.com/blog/how-to-do-novelty-detection-in-keras-with-generative-adversarial-network-part-2/" rel="noopener ugc nofollow" target="_blank">在脸书分享</a></p></div><div class="ab cl mx my hc mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="hn ho hp hq hr"><p id="ab74" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><em class="ne">原载于</em><a class="ae ka" href="https://www.dlology.com/blog/how-to-do-novelty-detection-in-keras-with-generative-adversarial-network-part-2/" rel="noopener ugc nofollow" target="_blank"><em class="ne">www.dlology.com</em></a><em class="ne">。</em></p></div></div>    
</body>
</html>