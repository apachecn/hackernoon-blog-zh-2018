<html>
<head>
<title>What is a Decision Tree in Machine Learning?</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">什么是机器学习中的决策树？</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/what-is-a-decision-tree-in-machine-learning-15ce51dc445d?source=collection_archive---------1-----------------------#2018-10-22">https://medium.com/hackernoon/what-is-a-decision-tree-in-machine-learning-15ce51dc445d?source=collection_archive---------1-----------------------#2018-10-22</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><figure class="fi fk is it iu iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ir"><img src="../Images/d4193627b2c0c71f4431249f759011a7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ofMfrqFMfpaTH_RMvI_RQA.jpeg"/></div></div></figure><p id="05b3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">决策树，最简单也是最有用的机器学习结构之一。决策树，顾名思义，就是决策的<a class="ae ka" rel="noopener" href="/brandons-computer-science-notes/trees-the-data-structure-e3cb5aabfee9">树</a>。</p><p id="b917" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">这篇文章的更新版本可以在这里找到:</strong></p><div class="kb kc fm fo kd ke"><a href="https://skerritt.blog/what-is-a-decision-tree-in-machine-learning/" rel="noopener  ugc nofollow" target="_blank"><div class="kf ab ej"><div class="kg ab kh cl cj ki"><h2 class="bd hv fv z el kj eo ep kk er et ht dt translated">什么是机器学习中的决策树？</h2><div class="kl l"><h3 class="bd b fv z el kj eo ep kk er et ek translated">决策树，最简单也是最有用的机器学习结构之一。决策树，顾名思义…</h3></div><div class="km l"><p class="bd b gc z el kj eo ep kk er et ek translated">skerritt.blog</p></div></div></div></a></div><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="ab fr cl kr"><img src="../Images/121f313716b15922c3e17c48f3ab317c.png" data-original-src="https://miro.medium.com/v2/format:webp/0*Yclq0kqMAwCQcIV_.jpg"/></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">Taken from <a class="ae ka" href="https://becominghuman.ai/understanding-decision-trees-43032111380f" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="f4ef" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你有一个问题，通常是一个是或不是(二进制；2个选项)从树中引出两个分支(是和否)的问题。您可以获得两个以上的选项，但是对于本文，我们只使用两个选项。</p><p id="a34e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">树在计算机科学中是怪异的。它们不是从根部向上生长，而是向下生长。把它想象成一棵倒挂的树。</p><p id="3c51" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在这个例子中，最上面的项目是“我饿了吗？”被称为<strong class="je hv">的<em class="kw">根</em>的</strong>。这是一切开始的地方。<strong class="je hv"> <em class="kw">分支</em> </strong>就是我们所说的各条线。一片<strong class="je hv"> <em class="kw">叶</em> </strong>是除了根或分支以外的一切。</p><p id="8cb8" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">树在机器学习中很重要，因为它们不仅让我们可视化算法，而且是机器学习的一种类型。以这个算法为例。</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff kx"><img src="../Images/2a32e9479404d2e33afe14df60bdb9ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/0*LFepwBvXOWkxezDX"/></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">Taken from <a class="ae ka" href="https://www.wikiwand.com/en/Decision_tree_learning" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="628a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这个算法预测了一名乘客在泰坦尼克号上幸存的概率。</p><p id="d28f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">"<em class="kw"> sibsp </em>"是船上配偶或兄弟姐妹的数量。每片叶子下面的数字显示了存活的可能性。</p><p id="1ca0" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">对于机器学习树，粗体文本是一个条件。不是数据，是问题。树枝还是叫树枝。叶子是“<strong class="je hv"> <em class="kw">决定</em> </strong>”。这棵树决定了一个人的生死。</p><p id="4858" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这种类型的树是<strong class="je hv">分类</strong>树。我在这里多讲讲分类<a class="ae ka" href="https://hackernoon.com/absolute-fundamentals-of-machine-learning-dca5deee78df" rel="noopener ugc nofollow" target="_blank"/>。简而言之；我们想把船上的每个人归类为更有可能死亡或幸存的人。</p><p id="1594" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在现实生活中，决策树并不总是那么容易。看看这张照片，振作起来。我会尽可能多地描述它。</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ky"><img src="../Images/301ff7aefa85ffa16c9e1973d7f48f8c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*e_2uJcDN5hKQM9V2InylVA.png"/></div></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">😴 — Me when I have to look at this image</figcaption></figure><p id="8e7b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这是一棵决策树。它想回答“我能吃这个蘑菇吗？”</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff kz"><img src="../Images/3a02dd15dbb962c8b156543dbb31831f.png" data-original-src="https://miro.medium.com/v2/resize:fit:1280/0*eYlru012PubUH5qD.JPG"/></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">Taken from <a class="ae ka" href="https://www.wikiwand.com/en/Mushroom" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="c74a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">给定一个蘑菇的图像(如左图),我们想知道它是否可以食用。</p><p id="31db" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你看到顶部那些看起来像变量赋值的东西了吗？那些是if语句。让我们来看看其中的一个。</p><p id="5fae" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><em class="kw">“气味= a:e(400.0)”</em></p><p id="a333" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果蘑菇的气味(<em class="kw">气味</em>)是杏仁的<em class="kw"> a </em>，那么它是可食用的(<em class="kw"> e </em>)，我们有<em class="kw"> 400.0 </em>点信心它是可食用的。这些语句中的每一条都是<strong class="je hv">的一个特性</strong>。</p><p id="c6b1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">特征只是对象的属性。自行车的特点是:它有轮子，有把手等等。</p><p id="92c1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们继续这样做，直到我们到达气味中性的点(<em class="kw"> n </em>)，在这一点上，我们开始检查蘑菇的更多<strong class="je hv">特征</strong>。</p></div><div class="ab cl la lb hc lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hn ho hp hq hr"><h1 id="65e0" class="lh li hu bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me dt translated">使用正式语言制作决策树</h1><p id="1255" class="pw-post-body-paragraph jc jd hu je b jf mf jh ji jj mg jl jm jn mh jp jq jr mi jt ju jv mj jx jy jz hn dt translated">好吧，我们可以画出来，但是我们怎么写决策树呢？对此有一个很好的注释。</p><p id="ae85" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">让我们直接看一个例子。</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff mk"><img src="../Images/161c129e8b0a2e1f29cacab95c057a26.png" data-original-src="https://miro.medium.com/v2/resize:fit:1270/format:webp/1*eyHyrMqFuaJCEbFiuzGIdg.png"/></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">Sorry for the blurry formula. It’s a problem with screen shotting LaTeX 😢</figcaption></figure><p id="aac1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">花里胡哨的小“<strong class="je hv"><em class="kw">”^</em></strong>的意思是“<em class="kw">和</em>”。这是一些奇特的数学符号。更多类似的注释，请查看我写的另一篇文章。在这个符号中，当我们看不到连接两个项目的任何东西(如<em class="kw"> x2 </em>和<em class="kw"> x5 </em>)时，我们假设它是“<em class="kw">和</em>”。我们想要一个当<em class="kw"> x2 </em>和<em class="kw"> x5 </em>都为真时返回<strong class="je hv">真</strong>的决策树。</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff ml"><img src="../Images/935e632dde416aa02d3fea307f6474d1.png" data-original-src="https://miro.medium.com/v2/resize:fit:1222/format:webp/1*TMJZmOcSn53PReeaxfeBGw.png"/></div></figure><p id="42b2" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">好吧，让我们看看另一个。</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff mm"><img src="../Images/c5f0c0dbe15e78bfa5e31f457fef8823.png" data-original-src="https://miro.medium.com/v2/resize:fit:898/format:webp/1*LtuzvXS1JjJ0Ab8e5KT7GQ.png"/></div></figure><p id="768e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这个有更多的逻辑符号。你可能想看看我写的这篇文章。好的，“∨”符号的意思是“<em class="kw">或</em>”，“的意思是“<em class="kw">而不是</em>”。</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff mn"><img src="../Images/df5e72e99d68e816338fe36acc4723d4.png" data-original-src="https://miro.medium.com/v2/resize:fit:658/format:webp/1*DS4VcU4U3SDkUomS5jknmA.png"/></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">Notice how the X1 decision becomes True if X1 is <strong class="bd mo">not </strong>true. This is because of the “not” symbol before it in the formal notation.</figcaption></figure></div><div class="ab cl la lb hc lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hn ho hp hq hr"><h1 id="73e8" class="lh li hu bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me dt translated">在树中拆分候选人</h1><p id="ec9a" class="pw-post-body-paragraph jc jd hu je b jf mf jh ji jj mg jl jm jn mh jp jq jr mi jt ju jv mj jx jy jz hn dt translated">决策树是通过从根节点获取数据并将数据分割成多个部分来制作的。</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff kx"><img src="../Images/2a32e9479404d2e33afe14df60bdb9ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:720/0*LFepwBvXOWkxezDX"/></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">Taken from <a class="ae ka" href="https://www.wikiwand.com/en/Decision_tree_learning" rel="noopener ugc nofollow" target="_blank">here</a></figcaption></figure><p id="22bb" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">以之前的泰坦尼克号为例，我们分割数据，使其最有意义，并与我们现有的数据保持一致。</p><p id="5d9d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">决策树的一个问题是“<em class="kw">分割数据的最佳方式是什么？有时你会本能地知道，有时你需要算法</em></p><p id="a322" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们希望设计一个函数，当给定一个数据集时，它将相应地拆分数据。</p><p id="96f7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果我们有数字特征，我们可以根据我们看到的数据来分割它。有许多不同的拆分方式。我们可以对数据集中的所有值进行排序，并决定不同类的实例之间的分割阈值。我们也可以直接从中间切开。分裂算法太多，这里不讨论了。所以我们将通过一个简单的算法。</p><pre class="kn ko kp kq fq mp mq mr ms aw mt dt"><span id="6447" class="mu li hu mq b fv mv mw l mx my">(1, a), (2, b), (1, c), (0, b), (3, b)</span></pre><p id="3fcb" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">所以我们有3个班级(a，b，c)。我们做的第一件事是把它们分成不同的类别。</p><pre class="kn ko kp kq fq mp mq mr ms aw mt dt"><span id="5201" class="mu li hu mq b fv mv mw l mx my">{(0, b)}, {(1, a), (1, c)}, {(2, b)}, {(3, b)}</span></pre><p id="a870" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在我们有4套不同的<em class="kw">电视机</em>。关于集合论的更多内容，点击这里。</p><p id="7f7b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">让我们在这里选择一些任意的数字。我们会像这样把它们分开:</p><pre class="kn ko kp kq fq mp mq mr ms aw mt dt"><span id="9b9d" class="mu li hu mq b fv mv mw l mx my">Split 1 &lt;= 0.5<br/>Split 2 &lt;= 1.5 but &gt; 0.5<br/>Split 3 &gt; 1.5</span></pre><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff mz"><img src="../Images/0fd266f62bb62a8654d17076e231c655.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6imRsG1-PADkjrYaYtzBgg.png"/></div></div></figure><p id="0bdf" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们现在有一个分离的决策树。如果我们不分割数据，树看起来就不太像树。想象一下，如果我们的分割是“<em class="kw">所有数据小于3 </em>”，那么树会是什么样子。一切都会在那里！它不会很像树。</p></div><div class="ab cl la lb hc lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hn ho hp hq hr"><h1 id="7dce" class="lh li hu bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me dt translated">奥卡姆剃刀</h1><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff na"><img src="../Images/cdfaf00f76b87896a30025257bef16cf.png" data-original-src="https://miro.medium.com/v2/resize:fit:1276/format:webp/0*hmAFTUepd_9u3P4x.jpeg"/></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">Image of William of Ockham, from <a class="ae ka" href="https://www.wikiwand.com/en/William_of_Ockham" rel="noopener ugc nofollow" target="_blank">here</a>.</figcaption></figure><p id="d99d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">奥卡姆剃刀是14世纪奥卡姆的威廉提出的一种哲学。简而言之，引用的是:</p><blockquote class="nb nc nd"><p id="dd6e" class="jc jd kw je b jf jg jh ji jj jk jl jm ne jo jp jq nf js jt ju ng jw jx jy jz hn dt translated">“当你有两个相互竞争的理论做出完全相同的预测时，简单的那个更好。”</p></blockquote><p id="3a53" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们可以在机器学习中使用这个原则，特别是在决定何时拆分决策树的时候。</p><blockquote class="nh"><p id="e767" class="ni nj hu bd nk nl nm nn no np nq jz ek translated">"对训练实例进行精确分类的最简单的树将在以前看不见的实例上很好地工作."</p></blockquote><p id="0109" class="pw-post-body-paragraph jc jd hu je b jf nr jh ji jj ns jl jm jn nt jp jq jr nu jt ju jv nv jx jy jz hn dt translated">最简单的树往往是最好的树，只要所有其他可能的树产生相同的结果。</p></div><div class="ab cl la lb hc lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hn ho hp hq hr"><h1 id="74cb" class="lh li hu bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me dt translated">寻找最佳分割</h1><figure class="kn ko kp kq fq iv"><div class="bz el l di"><div class="nw nx l"/></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">Gif from <a class="ae ka" href="https://giphy.com/gifs/rupaulsdragrace-episode-10-rupauls-drag-race-E0Z06zqqlm7jSG6hV2" rel="noopener ugc nofollow" target="_blank">Giphy</a>. Sometimes, the subject you’re teaching is just plain old boring. Gif provided to try to alleviate the boredom.</figcaption></figure><p id="eb7a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">试图找到并返回对训练集进行准确分类的最小可能决策树是非常非常困难的。事实上，这是一个<a class="ae ka" href="https://www.wikiwand.com/en/NP-hardness" rel="noopener ugc nofollow" target="_blank"> NP-hard </a>问题。</p><p id="9a7b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">相反，我们将试图接近最佳结果，而不是得到最佳结果。我们会讲很多概率和统计，如果你想了解更多概率和统计<a class="ae ka" rel="noopener" href="/brandons-computer-science-notes/an-introduction-to-probability-statistics-3f5630824411">点击这里</a>。</p><p id="4eb5" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们想要的是明确地将数据一分为二的信息。我们不想要既包含男性又包含女性的东西，我们想要纯洁。每次拆分一个单独的类。</p><p id="1bc4" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这种纯度的度量被称为信息。它表示指定一个新实例应该被分类为左拆分还是右拆分所需的预期信息量。</p><p id="01dd" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">为了找到最好的劈叉，我们必须先了解一些有趣的事情。</p></div><div class="ab cl la lb hc lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hn ho hp hq hr"><h1 id="3b0a" class="lh li hu bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me dt translated">预期值</h1><p id="5212" class="pw-post-body-paragraph jc jd hu je b jf mf jh ji jj mg jl jm jn mh jp jq jr mi jt ju jv mj jx jy jz hn dt translated">这部分讲的是随机变量。关于随机变量的更多信息，请查看我写的这篇关于统计概率的文章。</p><p id="56dc" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">期望值就是它听起来的样子，你期望的值是什么？你可以用它来计算6次掷骰子的平均分，或者任何与概率相关的有价值的属性。</p><p id="05c9" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">假设我们正在计算自行车的种类，我们有4辆自行车。我们给每辆自行车分配一个代码，如下所示:</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff ny"><img src="../Images/102cede7cae9d43c94b3ba39e3e3e404.png" data-original-src="https://miro.medium.com/v2/resize:fit:782/format:webp/1*abbFixm6lr_ENDq5OuVFsw.png"/></div></figure><p id="27f4" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">对于每辆自行车，我们都给它一个号码。对于每个编码，我们可以看到我们使用2位。不是0就是1。对于期望值，我们不仅需要变量的值，还需要概率。每辆自行车都有相等的概率。所以每辆自行车都有25%的几率出现。</p><p id="20b1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">计算期望值时，我们将概率乘以2位，得到:</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff nz"><img src="../Images/d150c2e73df8cb12b501123b526d67fb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1248/format:webp/1*COX5CcPoUAawmFXqd_27WQ.png"/></div></figure><p id="ff09" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果概率不相等呢？</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff oa"><img src="../Images/cec6c5292e4e513ae904d123602b8ea5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*2BN_KfFV2guDUfs89gBSLA.png"/></div></div></figure><p id="4709" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们需要做的是用概率乘以位数</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ob"><img src="../Images/c3be5d8656780ad77b276e3c8e2a6280.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*wHvOPbsGOQYbRuMh-A_Ybg.png"/></div></div></figure></div><div class="ab cl la lb hc lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hn ho hp hq hr"><h1 id="1899" class="lh li hu bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me dt translated">熵</h1><p id="6442" class="pw-post-body-paragraph jc jd hu je b jf mf jh ji jj mg jl jm jn mh jp jq jr mi jt ju jv mj jx jy jz hn dt translated">这种对<em class="kw">纯度</em>的度量被称为<a class="ae ka" href="https://en.wikipedia.org/wiki/Information_theory" rel="noopener ugc nofollow" target="_blank"> <strong class="je hv">信息</strong> </a>。它表示<a class="ae ka" href="https://en.wikipedia.org/wiki/Expected_value" rel="noopener ugc nofollow" target="_blank">预期的</a>数量的<a class="ae ka" href="https://en.wikipedia.org/wiki/Self-information" rel="noopener ugc nofollow" target="_blank">信息</a>，在给定到达节点的示例的情况下，需要这些信息来指定一个新实例(名字)应该被分类为男性还是女性。我们根据节点上的男女类数量来计算。</p><p id="a3f1" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">还记得之前我们谈到的纯洁吗？熵是杂质的量度。而是事情有多不确定。熵的公式是:</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff oc"><img src="../Images/db4912b9bba8c7f994c4bd171641dadb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1260/format:webp/1*c_3RiTHigg36ry1XOTiQwg.png"/></div></figure><p id="2b1a" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">熵试图给事物的不确定性一个数字。</p><p id="187d" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">你也可以有条件熵，看起来像这样:</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff od"><img src="../Images/10f7bf6f9979030ffcc67895ef1b0aad.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*GJo4JB5Jv8i5OWKct9OJZA.png"/></div></figure><h2 id="b52d" class="mu li hu bd lj oe of og ln oh oi oj lr jn ok ol lv jr om on lz jv oo op md oq dt translated">信息增益示例</h2><p id="4302" class="pw-post-body-paragraph jc jd hu je b jf mf jh ji jj mg jl jm jn mh jp jq jr mi jt ju jv mj jx jy jz hn dt translated">让我们用一个例子来说明这一点。</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff or"><img src="../Images/0368552ce605d9f470b5a96fe3cf1ac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uMkQDAal44EIn2257ypZUw.png"/></div></div></figure><p id="5271" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在湿度上分裂的信息增益是多少？</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff os"><img src="../Images/80c6f3723dab1c1249d752e115e05b55.png" data-original-src="https://miro.medium.com/v2/resize:fit:748/format:webp/1*kppGR115DWCB7CGCNG2k0A.png"/></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">An example of splitting on humidity</figcaption></figure><p id="fbd9" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们有9+和5-。那是什么意思？这意味着在表中，我们有9个数据为正的特征和5个数据为否的特征。因此，在PlayTennis表中，计数9次为正(是)和5次为负(否)。</p><p id="6b80" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在我们想找出湿度的信息增益。如果湿度很高，我们会查看数据，并计算有多少人认为湿度很高。所以当湿度高时，我们有3+和4-。3正4负。</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ot"><img src="../Images/8dcbfde2232bc81a5388e48545d0fb58.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FP039Ozp4LvQISAfgF1Rmw.png"/></div></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">D indicates the specific sample, D.</figcaption></figure><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff or"><img src="../Images/0368552ce605d9f470b5a96fe3cf1ac0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uMkQDAal44EIn2257ypZUw.png"/></div></div></figure><p id="7675" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">信息增益是不确定性之间的差距。我们总共有14组数据，分母总是14。现在我们用公式来计算它们。湿度大时打网球(是)的信息增益为:</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ou"><img src="../Images/05e57074e7faa5fef51554ff3580c40b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*7exXE5m7ACI5wWMGv4OKug.png"/></div></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">3 yes’s and 4 no’s</figcaption></figure><p id="320e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">而湿度正常时打网球的信息增益是:</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ov"><img src="../Images/acc0582acce7a8fba0642f3d167dda56.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*0SACBDQmRdlC64HO8wYjAg.png"/></div></div><figcaption class="ks kt fg fe ff ku kv bd b be z ek">6 yes’s and 1 no.</figcaption></figure><p id="7a95" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">这不是某件事发生的可能性有多大，而是我们从中获得了多少信息。当我们想要分割某物时，我们使用信息增益。在下面的例子中，我们想知道是按湿度还是按风力来划分更好。</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff ow"><img src="../Images/4ff18aee4ac72d43653bdcc3a74f2d12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*j3b8QX69jtM7fTfsniP1ow.png"/></div></div></figure><p id="2b04" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">现在我们知道了每次分裂的信息增益是多少，我们应用信息增益公式。</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff ox"><img src="../Images/73fbe578b5ae8f8c2ed2dd86fd28e4d8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1178/format:webp/1*f6WKkGsiJVULpmGWmRTTmQ.png"/></div></figure><p id="442f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">在我们的样本中，湿度分裂的信息增益D是0.151。</p><p id="4294" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果我们在风的部分使用相同的熵公式，我们得到这些结果:</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff oy"><img src="../Images/6f40bbc24e44692e53da53e2659b8cbb.png" data-original-src="https://miro.medium.com/v2/resize:fit:944/format:webp/1*rNuDYRWkgn5QbKD27rDDLQ.png"/></div></figure><p id="213f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果我们把它们放入信息增益公式，我们得到:</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff oz"><img src="../Images/31698241f6e7555973fef7ced9ef49aa.png" data-original-src="https://miro.medium.com/v2/resize:fit:1048/format:webp/1*fs8BNCd10a-3d90E8AiYuQ.png"/></div></figure><p id="e08e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">由于湿度具有更高的信息增益，因此最好根据湿度而不是风来分割。</p></div><div class="ab cl la lb hc lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hn ho hp hq hr"><h1 id="1c05" class="lh li hu bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me dt translated">精确度的定义</h1><p id="d570" class="pw-post-body-paragraph jc jd hu je b jf mf jh ji jj mg jl jm jn mh jp jq jr mi jt ju jv mj jx jy jz hn dt translated">我们想做的是检验一个机器学习模型的准确度。</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff pa"><img src="../Images/80fdf7e98de44ce8c245c23b7c063cf7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*nQGqgAMF-PfSxHchOoTIWQ.png"/></div></div></figure><p id="6819" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">M(x)表示给定一个样本，X，我们给出预测的分类。标签。lx其实才是真正的标签。这个样本已经被贴上标签，所以我们知道真正的标签。这组样本表明这些标签是正确的。</p><p id="6ca6" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们所做的是向算法提供一个样本集，其中我们已经知道该样本集中每一项的分类。然后，我们测量机器学习算法正确的次数。</p></div><div class="ab cl la lb hc lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hn ho hp hq hr"><h1 id="7673" class="lh li hu bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me dt translated">用噪声数据过度拟合</h1><p id="6801" class="pw-post-body-paragraph jc jd hu je b jf mf jh ji jj mg jl jm jn mh jp jq jr mi jt ju jv mj jx jy jz hn dt translated">看下面的例子。我们有这个公式和嘈杂的数据。</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff pb"><img src="../Images/6838b060c24c4232468a049ebfa015a0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YfenrQToBs03KizsRUDm4A.png"/></div></div></figure><p id="712b" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">有噪声的数据意味着数据不正确。我们的公式是X1，X2 =真。我们嘈杂的数据是真的假的=真的，这是错的。</p><p id="48ac" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">x3、x4、x5都是附加功能。我们不关心它们，但这只是一个例子，表明有时我们在机器学习模型中有许多我们不关心的附加功能。</p><p id="f1df" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">我们建立一个决策树，可以完美匹配训练数据。</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff pc"><img src="../Images/c2a183182b090b36e9248238ccd92872.png" data-original-src="https://miro.medium.com/v2/resize:fit:768/format:webp/1*X7wC32mD2NEODDl0ME2jzw.png"/></div></figure><p id="af7e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">精确度是</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff pd"><img src="../Images/f44621225c6db33917e1fae4cd2f3aac.png" data-original-src="https://miro.medium.com/v2/resize:fit:1050/format:webp/1*BIzo-gvZI24GTCCCj0sT1w.png"/></div></figure><p id="e75f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">问题是它与训练数据完全匹配，100%，但由于噪音数据，它在真实数据上的表现不是很好。这一个小错误会形成一个更大的决策树，并导致它在现实世界中表现不佳。</p><p id="abf3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">如果我们建立一个能够很好地处理真实数据的决策树，我们会得到这样的结果:</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff pe"><img src="../Images/4a1e15c9aa3b1b4cd3b15c28892c7f7d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QrPJtfJ1LIJttuCa42itWg.png"/></div></div></figure><p id="1d70" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">尽管它在训练集中表现较差，但由于不用担心噪声数据，它在真实世界数据中表现完美。</p><p id="1fa7" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">让我们来看另一个过度拟合的例子。</p></div><div class="ab cl la lb hc lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hn ho hp hq hr"><h1 id="cabc" class="lh li hu bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me dt translated">用无噪声数据过度拟合</h1><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div role="button" tabindex="0" class="iw ix di iy bf iz"><div class="fe ff pf"><img src="../Images/45cd5b5fbb8271063d488c93f0d8695b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*_CtD1GdnMkecKDPLe6_LEQ.png"/></div></div></figure><p id="21d6" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">以下是每种情况的概率:</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff pg"><img src="../Images/7d9b84f552e267351daf49db57301925.png" data-original-src="https://miro.medium.com/v2/resize:fit:614/format:webp/1*n-B1Cz6fO01G7zbVg2X9vw.png"/></div></figure><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff ph"><img src="../Images/41479a6626bb508977e4904394fe8204.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*1AylUEp77wSf-Y_ohZqskw.png"/></div></figure><p id="260e" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">有50%的可能性，结果<em class="kw"> x3 </em>为真。有0.66%的可能性，结果<em class="kw"> Y </em>为真。</p><p id="b6cf" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">对于我们的第一个模型，让我们快速浏览一下。</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff pi"><img src="../Images/d5e540d7cb8af7f480ae07abc740649a.png" data-original-src="https://miro.medium.com/v2/resize:fit:758/format:webp/1*Vs0Dbag9ScC1uYApUqdFBw.png"/></div></figure><p id="d410" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">精确度为:</p><figure class="kn ko kp kq fq iv fe ff paragraph-image"><div class="fe ff od"><img src="../Images/9b85c75ea8214770740cf60c84debb03.png" data-original-src="https://miro.medium.com/v2/resize:fit:1096/format:webp/1*c4hLm7KbonQorvCDSweTUg.png"/></div></figure><p id="a318" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">它在训练数据上表现很好，但在真实世界数据(D_true)上表现不佳。由此可知，过度拟合已经发生。</p></div><div class="ab cl la lb hc lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hn ho hp hq hr"><h1 id="e9d7" class="lh li hu bd lj lk ll lm ln lo lp lq lr ls lt lu lv lw lx ly lz ma mb mc md me dt translated">防止过度拟合</h1><p id="99c7" class="pw-post-body-paragraph jc jd hu je b jf mf jh ji jj mg jl jm jn mh jp jq jr mi jt ju jv mj jx jy jz hn dt translated">过度拟合的原因是因为训练模型试图尽可能好地拟合训练数据，即使数据中有噪声。第一个建议是尽量减少数据中的噪音。</p><p id="6c89" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">另一种可能性是没有噪声，但是训练数据很小，导致与真实样本的差异。更多的数据会起作用。</p><p id="0d5f" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">很难给出如何防止过度拟合的确切想法，因为每个型号都不相同。</p></div><div class="ab cl la lb hc lc" role="separator"><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf lg"/><span class="ld bw bk le lf"/></div><div class="hn ho hp hq hr"><h2 id="b6c8" class="mu li hu bd lj oe of og ln oh oi oj lr jn ok ol lv jr om on lz jv oo op md oq dt translated">你喜欢这篇文章吗？在社交媒体上与我联系，讨论所有与计算机科学相关的事情😁</h2><p id="84d2" class="pw-post-body-paragraph jc jd hu je b jf mf jh ji jj mg jl jm jn mh jp jq jr mi jt ju jv mj jx jy jz hn dt translated"><a class="ae ka" href="https://twitter.com/brandon_skerrit" rel="noopener ugc nofollow" target="_blank">推特</a>|<a class="ae ka" href="http://instagram.com/brandon.codes" rel="noopener ugc nofollow" target="_blank">insta gram</a>|<a class="ae ka" href="https://www.linkedin.com/in/brandonls/" rel="noopener ugc nofollow" target="_blank">LinkedIn</a></p><p id="4370" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated">别忘了点击那个👏拍手声👏按钮，以示感谢！</p><figure class="kn ko kp kq fq iv"><div class="bz el l di"><div class="pj nx l"/></div></figure><p id="c2a3" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jz hn dt translated"><strong class="je hv">我写这篇文章没有得到报酬。如果你想支持我或喜欢这篇文章，请随时给我买杯茶或下面的东西😍✨ </strong></p><div class="kb kc fm fo kd ke"><a href="https://www.paypal.me/brandonskerritt" rel="noopener  ugc nofollow" target="_blank"><div class="kf ab ej"><div class="kg ab kh cl cj ki"><h2 class="bd hv fv z el kj eo ep kk er et ht dt translated">用贝宝支付布兰登·斯凯里特。我</h2><div class="kl l"><h3 class="bd b fv z el kj eo ep kk er et ek translated">去paypal.me/BrandonSkerritt输入金额。既然是PayPal，那就简单又安全。没有PayPal…</h3></div><div class="km l"><p class="bd b gc z el kj eo ep kk er et ek translated">www.paypal.me</p></div></div><div class="pk l"><div class="pl l pm pn po pk pp ja ke"/></div></div></a></div><div class="kb kc fm fo kd ke"><a href="https://monzo.me/brandonskerritt" rel="noopener  ugc nofollow" target="_blank"><div class="kf ab ej"><div class="kg ab kh cl cj ki"><h2 class="bd hv fv z el kj eo ep kk er et ht dt translated">通过Monzo.me即时支付Brandon</h2><div class="kl l"><h3 class="bd b fv z el kj eo ep kk er et ek translated">点击链接向布兰登付款。你不需要创建一个账户，而且完全免费。</h3></div><div class="km l"><p class="bd b gc z el kj eo ep kk er et ek translated">monzo.me</p></div></div><div class="pk l"><div class="pq l pm pn po pk pp ja ke"/></div></div></a></div></div></div>    
</body>
</html>