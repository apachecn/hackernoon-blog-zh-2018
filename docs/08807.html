<html>
<head>
<title>Tech Regulation Must Look Forward</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">技术监管必须向前看</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/tech-regulation-must-look-forward-885ce6bb3b7e?source=collection_archive---------33-----------------------#2018-10-23">https://medium.com/hackernoon/tech-regulation-must-look-forward-885ce6bb3b7e?source=collection_archive---------33-----------------------#2018-10-23</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="f76c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在洛杉矶，以前安静的住宅区在持续的高峰时间交通噪音下突然变得嘈杂。居民们愤怒了，他们抗议说他们的房子贬值了，他们的孩子再也不能安全地在户外玩耍了。与此同时，司机们也松了一口气，因为他们可以从城市臭名昭著的拥堵的高速公路上节省十分钟的通勤时间。罪魁祸首，或救世主，取决于你问谁，是智能手机应用Waze的智能路由算法。根据实时交通数据，Waze将司机派到非常规路线上，以避免拥堵。正如许多应用人工智能的案例一样，算法优化了特定的变量，使某些人受益匪浅，而不可预见的成本则由其他人承担。减轻智能系统的不利后果，同时将它们的好处扩大到更多人，将是未来几年的巨大挑战之一。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff jp"><img src="../Images/d10f587a6a2f441d4bd30deb0ffd88e0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*xTrsX-3InYNMK6s6eB-QoA.jpeg"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek">Traffic in LA is, like, not the most chill, ya know? <a class="ae kf" href="https://www.flickr.com/photos/respres/2544979655" rel="noopener ugc nofollow" target="_blank">“Los Angeles Traffic — The Newhall Pass”</a> by <a class="ae kf" href="https://www.flickr.com/people/respres/" rel="noopener ugc nofollow" target="_blank">Jeff Turner</a>is licensed under <a class="ae kf" href="https://creativecommons.org/licenses/by/2.0" rel="noopener ugc nofollow" target="_blank">CC BY 2.0</a></figcaption></figure><p id="d0d4" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">让我们回顾一下T2技术优势力量的一个更极端的例子。在西欧的发现时代，皇家制图员将可疑的收集数据合成为当时最先进的专有信息系统:地图。这种地图富含资源丰富、开发条件成熟的地区的信息(而被认为潜在利润较低的地区则严重缺乏细节)，有助于获取新大陆的财富。它的居民屈从于那些创造和控制这些新的大众信息系统的人是理所当然的。</p><p id="7c6a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们今天面临的风险也来自于现代信息科学在一个准备不足和无保护的社会上的无限制应用。这些风险中最大的一个是，在一个已经高度不平等和分散的世界中，人工智能加剧了不平等并使其自动化。这并不是一个保证——通过适当的远见和深思熟虑的先发制人政策，即将到来的普及人工智能时代的好处可以更均匀地分散，这些风险可以降低。人工智能有潜力成为解决许多世界问题的独特而强大的工具:我们可以更好地识别和控制疾病，使交通更加安全，并优化资源和利益向最需要的人的分配。但人工智能完全掌握在那些有权访问和知道如何设计和实施此类系统的人手中，它对数据如饥似渴，对那些最容易受到其流程影响的人来说难以理解和无法挑战，并且一心一意地专注于优化变量以巩固现状。</p><p id="7062" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">工作自动化被普遍认为是人工智能的最大威胁之一，虽然还不完全清楚人们何时会开始被机器集体取代，但导致这一结果的过程肯定已经开始。显而易见的是，并非所有的工作都面临自动化的风险，那些不成比例地属于行政、“低技能”或重复性工作的工作。虽然相当一部分白领职位将会减少(或者至少他们的职责会有所改变)，但大量蓝领工作面临风险。低收入工作岗位的减少本身就是一个重大问题，但随之而来的是提供人工智能服务的公司及其上层员工的财富大幅增加。通常情况下，这些大型科技公司已经在信息时代的前几个周期中丰富了自己，利用他们积累的大量用户数据来训练他们新生的人工智能程序。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff kg"><img src="../Images/048b8b3368225810daae44aea93b21b8.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*1LnZkkfRivJA_ijH"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek">In the worst future, workers will be displaced by cutting edge industrial AI and then have their unemployment benefits distributed by some horrendously designed government services AI. Photo by <a class="ae kf" href="https://unsplash.com/@abiismail?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">abi ismail</a> on <a class="ae kf" href="https://unsplash.com?utm_source=medium&amp;utm_medium=referral" rel="noopener ugc nofollow" target="_blank">Unsplash</a></figcaption></figure><p id="118c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">但人工智能也可能以其他方式增加社会不平等。削减成本的政府往往寻求更有效地分配有限的福利，今天，社会服务的分配往往是一项部分由算法提供信息的任务。随着人工智能服务变得越来越便宜，并专门针对这项工作进行营销，穷人将更频繁地发现自己受到这些扩展系统的唯一摆布，很少求助于个案工作者的伴随和主动判断。信用评分系统的扩展也是可能的，特别是在人工智能发展明确优先考虑的国家，如中国。边缘化人群、低收入工人和其他不完全符合算法分类逻辑的人将遭受公共和私人对这些人工智能服务的更大依赖，特别是在没有前瞻性法律保护的情况下。</p><p id="067e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">出于这些原因，针对人工智能实践的先发制人的具体政策是必要的。但是具体从哪里开始呢？随着人工智能无处不在时代的到来，任何事情都具有变革性和利润，监管需要得到仔细定义和深思熟虑的应用，以平衡人工智能开发者和他们的工作将影响其生活的公民的利益。只有有了这样的政策，人工智能的好处才有机会抵消这项技术给社会带来的无数风险。如果没有监管远见，人工智能的最大收益将由那些已经足够富裕、能够对支撑人工智能的研究和技术进行大规模投资的公司获得。如前所述，这只会加剧已经令人担忧的技术和经济不平等。</p><p id="149f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为公平的人工智能社会建立规范、规则和具体目标的时间是在技术发挥其全部潜力之前。具有前瞻性思维的研究人员和决策者已经朝着这个方向迈出了充满希望的步伐。然而，对经济和法律规划的投资尚未与人工智能给社会带来巨大变化的潜力相匹配。美国和中国这两个世界上最大的经济体中最富有和最强大的公司已经将他们的未来押在了人工智能的商业化上。因此，民主政府和国际机构必须跟上步伐，以有益于公民和企业的方式引导发展。</p><p id="84eb" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">人工智能最令人烦恼但也最有价值的元素之一是其计算固有的“黑箱”性质。机器学习算法是有价值和有效的，因为它们可以对人类分析师永远无法识别的数据模式采取行动；这也是他们的结果难以预测和管理的原因，洛杉矶以前安静的街区居民可以证明这一点。由于这个原因，越来越多的关注于研究这些潜在的突发效应必须成为人工智能发展的核心部分，如果必要的话，这项任务可能是强制性的。这种“完全不同的影响测试”应该完全整合到公司的常规流程中，不仅在初始开发阶段，而且作为常规内部审计的一部分，以确保系统正常运行。</p><p id="1e7a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">人工智能服务需要大量的数据(在机器学习的说法中称为“训练集”)，以便识别细微的模式，并不断完善它们的预测逻辑。这是最大的科技公司在人工智能研发方面占据如此领先地位的一个原因，而相比之下，更灵活的初创公司没有机会收集和存储数十亿用户的多年数据。个人数据最近在公共讨论中有点像避雷针，主要是由于脸书的剑桥分析丑闻。随着用户数据对蓬勃发展的人工智能公司的价值越来越大，那些无意中提供数据的人越来越清楚，这可能会成为一个更大的公共问题。换句话说，脸书昨天缺乏适当的数据管理造成了损害，今天与人工智能时代滥用数据的后果相比，这种损害很容易相形见绌。</p><p id="f449" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这需要一套更强有力的、全球强制执行的个人数据权利规则。欧洲新的通用数据保护条例(GDPR)朝着这个解决方案迈出了明确的一步，但问题仍然存在:欧盟有能力严格监管像数字广告拍卖这样不透明领域的违法者吗？它会修补法律的一些主要漏洞吗？这些漏洞允许公司在没有获得用户同意的情况下，基于商业的“合法利益”收集和处理数据？热衷于不输掉与中国的“人工智能竞赛”的美国会对其最具竞争力的科技公司实施类似的监管吗？为了最好地保护公民数据免受设计不良的人工智能系统的潜在灾难性滥用，这些问题的答案都必须是肯定的。</p><p id="1857" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果这些监管目标能够实现，人工智能的好处将值得这些风险。这是一项艰巨的任务，需要国家政府、国际机构和技术公司在全球范围内进行协调和执行，而它们的利益往往并不完全一致。但如果在真正的人工智能无处不在的时代到来之前不尽快采取行动，我们将失去确保更公正和公平的数字社会的机会。历史一次又一次地表明了任何规模的巨大技术失衡的危险，从非人化的欧洲对美洲的征服，到改变洛杉矶交通路线的更平凡的风险。当我们为人工智能必须为人类提供的非凡好处做准备时，我们必须认识到巨大的后果风险比比皆是，今天是我们塑造我们即将生活的人工智能未来的唯一机会。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><a href="https://medium.com/swlh"><div class="fe ff kh"><img src="../Images/308a8d84fb9b2fab43d66c117fcc4bb4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*YqDjlKFwScoQYQ62DWEdig.png"/></div></a></figure><h2 id="c148" class="ki kj hu bd kk kl km kn ko kp kq kr ks jc kt ku kv jg kw kx ky jk kz la lb lc dt translated">这篇文章发表在<a class="ae kf" href="https://medium.com/swlh" rel="noopener"> The Startup </a>上，这是Medium最大的创业刊物，有+ 381，088人关注。</h2><h2 id="869c" class="ki kj hu bd kk kl km kn ko kp kq kr ks jc kt ku kv jg kw kx ky jk kz la lb lc dt translated">订阅接收<a class="ae kf" href="http://growthsupply.com/the-startup-newsletter/" rel="noopener ugc nofollow" target="_blank">我们的头条</a>。</h2><figure class="jq jr js jt fq ju fe ff paragraph-image"><a href="https://medium.com/swlh"><div class="fe ff kh"><img src="../Images/b0164736ea17a63403e660de5dedf91a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*ouK9XR4xuNWtCes-TIUNAw.png"/></div></a></figure><figure class="jq jr js jt fq ju"><div class="bz el l di"><div class="ld le l"/></div></figure></div></div>    
</body>
</html>