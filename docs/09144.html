<html>
<head>
<title>Flink or Flunk? Why Ele.me Is Developing a Taste for Apache Flink</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">Flink还是unk？为什么Ele.me喜欢上了Apache Flink</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/flink-or-flunk-why-ele-me-is-developing-a-taste-for-apache-flink-7d2a74e4d6c0?source=collection_archive---------6-----------------------#2018-11-06">https://medium.com/hackernoon/flink-or-flunk-why-ele-me-is-developing-a-taste-for-apache-flink-7d2a74e4d6c0?source=collection_archive---------6-----------------------#2018-11-06</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><div class=""><h2 id="f6a6" class="pw-subtitle-paragraph ir ht hu bd b is it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji ek translated">Flink的独特之处是什么，它与Storm和Spark的区别是什么？</h2></div><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff jk"><img src="../Images/5352386026b8b7b4f05564a39e7f0d12.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*cdPUrL7L8bpK2a_WQHdjpQ.jpeg"/></div></div></figure><p id="f42a" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><em class="ks">本文是</em> <a class="ae kt" rel="noopener" href="/@alitech_2017/a-flink-series-from-the-alibaba-tech-team-b8b5539fdc70"> <strong class="jy hv"> <em class="ks">阿里巴巴旗下Flink系列</em> </strong> </a> <em class="ks">的一部分。</em></p><p id="d61e" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt">Engineers at Alibaba’s food delivery app Ele.me(饿了吗) are finding themselves increasingly reliant on Apache Flink, an open source stream processing framework released in 2018.</p><p id="0ebc" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">Flink的独特之处是什么，它与Storm和Spark的区别是什么？本文调查了Ele.me的大数据平台如何在实时计算方面运行，并评估了Flink的各种优势和劣势。</p><h1 id="1c2f" class="ku kv hu bd kw kx ky kz la lb lc ld le ja lf jb lg jd lh je li jg lj jh lk ll dt translated">Ele.me今日平台</h1><p id="7f9b" class="pw-post-body-paragraph jw jx hu jy b jz lm iv kb kc ln iy ke kf lo kh ki kj lp kl km kn lq kp kq kr hn dt translated">下图说明了Ele.me平台的当前架构。</p><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff lr"><img src="../Images/700d0db73f80de5fde3827f1246a43e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S4cIaEyShDuy0Rw_nfsNng.jpeg"/></div></div><figcaption class="ls lt fg fe ff lu lv bd b be z ek">Current platform architecture</figcaption></figure><p id="687f" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">在Ele.me目前的平台上，来自多个来源的数据首先被写入Apache Kafka。用于此的主要计算框架是Storm、Spark和Flink。来自这些框架的数据结果随后被存放到各种类型的存储器中。</p><p id="cb91" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">目前在Storm中有超过100个任务，在Spark中大约有50个，在Flink中数量更少。</p><p id="2d7a" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">当前的集群规模为每天60TB的数据、10亿次计算和400个节点。这里需要注意的一点是，Spark和Flink都是靠纱线运行的。虽然Flink on YARN主要用作任务之间的作业管理器隔离，但Storm on YARN处于独立模式。</p><p id="c378" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">本文将主要关注五个方面——一致语义、Apache Storm、Apache Spark的Spark流和结构化流，以及Apache Flink。</strong></p><h1 id="deb3" class="ku kv hu bd kw kx ky kz la lb lc ld le ja lf jb lg jd lh je li jg lj jh lk ll dt translated">一致语义</h1><p id="cdea" class="pw-post-body-paragraph jw jx hu jy b jz lm iv kb kc ln iy ke kf lo kh ki kj lp kl km kn lq kp kq kr hn dt translated">这里值得强调的是，维护以下语义的一致性至关重要。</p><p id="aece" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">最多一次(或一劳永逸)</strong>:通常，在编写Java应用程序时，会使用简单的“最多一次”语义，而不考虑源代码的偏移量管理和下游幂等性。当数据传入时，无论是中间状态还是写入数据状态，都没有ACK机制。</p><p id="7c08" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">至少一次</strong>:重传数据的重传机制，保证每一段至少处理一次。</p><p id="c563" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">恰好一次</strong>:这是通过粗检查点粒度控制实现的。大多数精确一次语义指的是计算框架中的那些，或者换句话说，每一步的操作符内部的状态是否可以重放，如果最后一个作业失败了，是否可以从之前的状态顺利恢复。这不涉及输出到sink的幂等性。</p><p id="1ab8" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">幂等性+至少一次=恰好一次</strong>:如果能保证下游有基于MySQL的“关于重复密钥更新”等幂等操作，或者使用ES/Cassandra等。，您可以使用主键来实现“颠覆”语义。如果在确保至少一次的情况下将幂等性加入到混合中，那么结果正好是一次。</p><h1 id="dd67" class="ku kv hu bd kw kx ky kz la lb lc ld le ja lf jb lg jd lh je li jg lj jh lk ll dt translated">阿帕奇风暴</h1><p id="c907" class="pw-post-body-paragraph jw jx hu jy b jz lm iv kb kc ln iy ke kf lo kh ki kj lp kl km kn lq kp kq kr hn dt translated">虽然Spark流媒体和结构化流媒体直到2017年才完全投入实践，但Ele.me从2016年之前就开始使用Apache Storm了。Storm拥有以下特点。</p><p id="250e" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">数据是基于元组的</p><p id="5bd8" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">延迟是毫秒级的</p><p id="ddde" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">一开始支持Java，但是现在使用了Apache Beam，Python和Go也支持了</p><p id="3d27" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">SQL函数不完整。Typhon已经内部封装，用户只需要扩展我们的一些接口就可以使用众多的主要功能。通量也是风暴的好工具。有了它，要描述一个风暴任务，你只需要写一个YAML文件。这在一定程度上满足了需求，但是用户仍然需要在工程师级别编写Java，这意味着数据分析师经常不能使用它。</p><h2 id="973c" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">摘要</h2><p id="6f58" class="pw-post-body-paragraph jw jx hu jy b jz lm iv kb kc ln iy ke kf lo kh ki kj lp kl km kn lq kp kq kr hn dt translated">综上所述，Storm主要有以下三大优势。</p><p id="f89d" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">易用性</strong>:因为门槛高，所以推广受限。</p><p id="ea52" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv"> State Backend </strong>:它需要更多的外部存储，包括Redis这样的键值存储数据库。</p><p id="d041" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">资源分配</strong>:预设工人和槽位。吞吐量非常低，因为只执行了少量的优化。</p><h1 id="24c3" class="ku kv hu bd kw kx ky kz la lb lc ld le ja lf jb lg jd lh je li jg lj jh lk ll dt translated">阿帕奇火花:火花流</h1><p id="2c61" class="pw-post-body-paragraph jw jx hu jy b jz lm iv kb kc ln iy ke kf lo kh ki kj lp kl km kn lq kp kq kr hn dt translated">有一次，Ele.me团队被问到是否可以编写一个SQL，在几分钟内发布一个实时计算任务。为此，该团队开始使用Apache Spark流，其主要概念如下。</p><p id="f639" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">微批处理:您必须预设一个窗口，并在该窗口中处理数据。</p><p id="e0af" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">延迟在第二级，通常在500毫秒左右。</p><p id="86d7" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">开发语言包括Java和Scala。</p><p id="94c7" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">流式SQL:ele . me技术团队希望在不久的将来为流式SQL提供一个平台。</p><h2 id="b468" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">关键特征</h2><p id="2cc2" class="pw-post-body-paragraph jw jx hu jy b jz lm iv kb kc ln iy ke kf lo kh ki kj lp kl km kn lq kp kq kr hn dt translated">Spark生态系统和SparkSQL <br/>这代表了Spark的一大优势。技术栈是统一的，SQL、图形计算和机器学习包都是可互操作的。与Flink不同，使用Spark时，先进行批处理，这意味着它的实时和离线API是统一的。</p><p id="07c0" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">HDFS检查站</p><p id="42a4" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">运行在YARN上<br/> Spark属于Hadoop生态系统，与YARN高度集成。</p><p id="a111" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">高通量<br/>由于它是一种微量配料的方式，因此通量相对较高。</p><p id="bd7d" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">下图是Ele.me平台上的操作页面，显示了用户发布实时任务时所需的步骤。</p><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff mk"><img src="../Images/adbfc9647d07fffa056367b0417110d5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*95hZoaAJ26XHpDjqh7T9WA.jpeg"/></div></div></figure><p id="30bc" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">在页面上，有许多用户必须选择的必要参数。首先，用户必须为每个分区选择Kafka集群和最大消耗率。默认情况下，背压启用。对于购物位置，用户每次都必须指定。用户可以在下一次重写实时任务时，根据他们的要求选择一个偏移购物点。</p><p id="e58f" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">在中间，用户可以描述管道。SQL是多个卡夫卡主题。当您选择一个输出表时，SQL将购物的Kafka DStream注册为一个表，然后写入一个管道字符串。最后，为用户封装了一些外部接收器。支持提到的所有存储类型。如果存储可以实现upsert语义，则它是受支持的。</p><h2 id="38b2" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">多流连接</h2><p id="752a" class="pw-post-body-paragraph jw jx hu jy b jz lm iv kb kc ln iy ke kf lo kh ki kj lp kl km kn lq kp kq kr hn dt translated">一些用户可能仍然想知道如何执行多流连接。对于Spark 1.5，请参考Spark流SQL。在这个开源项目中，DStream被注册为一个表，连接操作是在表上完成的。但该操作仅在1.5之前的版本中受支持。在Spark 2.0中引入结构化流之后，该项目被放弃了。方法很棘手:</p><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff ml"><img src="../Images/91bf7cc80010358ad4ef4ad947aa9867.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*PvPO6KXHrDluG1clCf11ag.png"/></div></div><figcaption class="ls lt fg fe ff lu lv bd b be z ek">Unique method</figcaption></figure><p id="6c4f" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">当允许Spark Streaming购买多个主题时，购物数据流中的每批rdd都被转换为数据帧，以便数据帧可以注册为表。然后将表一分为二，这样就可以进行连接。这个加入完全依赖于这个购物的数据，加入的条件是不可控的。这就是为什么这种方法很棘手。</p><p id="dff7" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">以下面这个案例为例。购买了两个主题。在filer条件下，表被一分为二。然后可以对这两个表进行连接。然而，它本质上是一个流。</p><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff mm"><img src="../Images/c9c217cc8aa7d7a532193f601bb0e18b.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*k_64df1l7vXuUgzyxS0rzw.jpeg"/></div></div></figure><h2 id="9b18" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">恰好一次语义</h2><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff mn"><img src="../Images/6330bc5d821fefaff256b8950dcb5e3c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*MXb7cVB5f8cPRekMYCIvnA.jpeg"/></div></div></figure><p id="cbc5" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">对于恰好一次，需要注意的是，在偏移量提交之前，必须要求数据接收到外部存储。无论数据是传到ZK还是MySQL，确保它在事务中是很重要的。在源驱动程序生成卡夫卡RDD和执行器消费数据之前，还需要将其输出到外部存储。如果满足这些条件，就可以实现端到端的一次性语义。这是一个大前提。</p><h2 id="0d2f" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">摘要</h2><p id="04fd" class="pw-post-body-paragraph jw jx hu jy b jz lm iv kb kc ln iy ke kf lo kh ki kj lp kl km kn lq kp kq kr hn dt translated"><strong class="jy hv">有状态处理SQL ( &lt; 2.x mapWithState，updateStateByKey) </strong>:如果想用1。x版本，通过这两个接口来做。您仍然需要将此状态保存到HDFS或外部存储器。因此，实现有点复杂。</p><p id="2235" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">真正的多流连接</strong>:真正的多流连接语义是无法实现的。</p><p id="3000" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">端到端恰好一次语义</strong>:这些很难实现。您必须将它们接收到外部存储，然后在事务中手动提交偏移量。</p><h1 id="b892" class="ku kv hu bd kw kx ky kz la lb lc ld le ja lf jb lg jd lh je li jg lj jh lk ll dt translated">Apache Spark:结构化流</h1><p id="807a" class="pw-post-body-paragraph jw jx hu jy b jz lm iv kb kc ln iy ke kf lo kh ki kj lp kl km kn lq kp kq kr hn dt translated">在Spark 2之后的版本中。x，使用增量有状态计算。下图来自官网。</p><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff mo"><img src="../Images/6c70a3d01637e6ff15257ff73a6ccd18.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*tVX5BFXVAllvnSNXO-OoxQ.png"/></div></div></figure><p id="b216" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">这里所有的流计算指的是谷歌的数据流，它有一个重要的概念——事件发生的时间和数据被处理的时间之间的间隔。StreamCompute领域有一个水印，可以指定延时的范围。可以丢弃延迟窗口之外的数据。</p><p id="f1fd" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">下图说明了结构化流的体系结构。</p><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff mp"><img src="../Images/94d8538a99530575b921e751cb04159d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kC1PhkxTzX9Rbw2fIosG0w.png"/></div></div></figure><p id="b37f" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">在该图中，实现了恰好一次语义的步骤1、2和3。本质上，实现使用批处理方法。使用这种方法，偏移量保持不变，HDFS用于状态存储。外部接收器不会运行类似的幂等运算，也不会在写入后提交偏移量。该实现实现了内部引擎的恰好一次性，同时保证了容错性。</p><h2 id="774b" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">关键特征</h2><p id="76c9" class="pw-post-body-paragraph jw jx hu jy b jz lm iv kb kc ln iy ke kf lo kh ki kj lp kl km kn lq kp kq kr hn dt translated"><strong class="jy hv">有状态处理SQL和DSL </strong>:这个可以满足有状态流计算。</p><p id="e636" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">真正的多流连接</strong>:多流连接可以通过Spark 2.3实现。实现方法与Flink类似。你要定义两个流的条件(这主要涉及到定义时间为条件)。例如，两个主题流入，您通过特定模式中的字段(通常是事件时间)限制需要缓冲的数据。通过这样做，你就把这两股流合在一起了。</p><p id="bd44" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">更容易实现端到端恰好一次语义</strong>。为了支持幂等运算，您只需要扩展sink接口，这将产生恰好一次语义。</p><p id="5ae6" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">结构化流与本地流API的最大区别在于，当结构化流创建表的数据帧时，必须指定表的模式。这意味着您必须提前指定模式。</p><p id="42ba" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">另外，它的水印不支持SQL。在Ele.me，技术团队添加了一个扩展来实现完整的SQL写入和从左到右的转换(如下图所示)。希望这不仅适用于程序员，也适用于不知道如何编程的数据分析师。</p><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div class="fe ff mq"><img src="../Images/bf7d13d5a3ebfb52b6d7a0f996e67b81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1364/format:webp/1*l3PdDi5AmBQnR5pC4MSAUw.jpeg"/></div></figure><h2 id="bb1e" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">摘要</h2><p id="999b" class="pw-post-body-paragraph jw jx hu jy b jz lm iv kb kc ln iy ke kf lo kh ki kj lp kl km kn lq kp kq kr hn dt translated"><strong class="jy hv">触发器</strong>:在2.3版本之前，结构化流主要基于处理时间。这样，每一批数据处理的完成都会触发下一批的计算。版本2.3引入了连续处理的触发功能，逐个记录。</p><p id="e73a" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">连续处理</strong>:目前只支持类似map的操作，对SQL的支持也有限。</p><p id="e25b" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">低端到端延迟，保证一次到位</strong>:端到端一次到位语义的保证需要额外的扩展。Ele.me tech团队发现Kafka版本提供了事务性功能，在此基础上我们可以考虑实现从源到引擎和sink的端到端恰好一次语义。</p><p id="94af" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv"> CEP (Drools) </strong>:对于需要CEP等函数处理复杂事件的用户，Drools规则引擎可以在每个执行器上运行。</p><p id="c1d2" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">考虑到Apache Spark在结构化流方面的上述缺点，Ele.me的工程师们决定开始使用Flink。</p><h1 id="5cc7" class="ku kv hu bd kw kx ky kz la lb lc ld le ja lf jb lg jd lh je li jg lj jh lk ll dt translated">阿帕奇弗林克</h1><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff mr"><img src="../Images/67391f11113ae9cd70d51f942f4aad81.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*M_cOKU47TS17KfBimg0aRw.png"/></div></div></figure><p id="1f7d" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">开源流处理框架Flink是流媒体领域的领导者。它拥有出色的图形计算和机器学习功能，其底层支持YARN、Tez等。</p><h2 id="03da" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">弗林克框架</h2><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff ms"><img src="../Images/df0037927f2f806ece701607886c6a66.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*NpdFL9s-7pEAEqTY7pHTkw.png"/></div></div></figure><p id="2c44" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">Flink中的JobManager类似于Spark中的driver，TaskManager类似于executor，两者中的任务是相同的。不过Flink用的RPC是Akka，Flink内核定制内存的序列化框架。此外，Flink中的任务不需要像Spark的每个阶段的任务那样等待对方，而是在处理后将数据发送到下游。</p><h2 id="74af" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">弗林克二进制数据处理算子</h2><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff mt"><img src="../Images/9c7c3061b87d8355392ce15c2d78573e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*rZDAikaAaa3VoYNLHNUEgA.png"/></div></div></figure><p id="5204" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">对于Spark中的序列化，用户通常使用默认的Kryo或Java序列化。钨项目还为Spark程序优化了JVM层和代码生成。与此同时，Flink实现了一个基于内存的序列化框架，该框架维护了键和指针的概念。它的关键是连续存储，并在CPU级别进行了优化。高速缓存未命中的概率极低。在对数据进行比较和排序时，您不是在比较真实的数据，而是首先比较键。只有当结果相等时，数据才会从内存中反序列化。此时，可以对比一下具体的数据。这代表了可靠的性能优化。</p><h2 id="5548" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">弗林克的任务链</h2><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff mu"><img src="../Images/56920fd629c2deed49a55d777c8e2d06.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*FaWD0__KQt_PO7ViZI17-A.png"/></div></div></figure><p id="27bc" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">有了OperatorChain，如果上下游的数据分布不需要重新洗牌，那么后面的地图只是一个简单的数据过滤器。如果我们把它放在一个线程中，线程上下文切换的开销就可以降低。</p><h2 id="bc85" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">平行的概念</h2><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff mv"><img src="../Images/e97fba111746631437f73daab661d0c0.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3mNVQamuoENMfXrYe26OUg.png"/></div></div></figure><p id="7235" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">为了说明这个概念，假设五个任务需要多个并发线程来运行。如果任务被链接，它们可以在一个线程中运行，这提高了数据传输性能。使用Spark，操作者不能设置他们的并发度，而使用Flink，他们可以，这使得Flink更加灵活，资源利用更加有效。</p><p id="2359" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">Spark一般通过Spark.default.parallelism来调整并行度，在shuffle操作过程中，一般通过Spark.sql.shuffle.partitions参数来调整并行度。在实时计算中，该参数应设置为较小的值。例如，在生产中，Kafka和partition参数被设置为几乎相同，而batch被调整为稍大的值。在左图中，Ele.me工程师将并发性设置为2(最多10)。然后，他们运行两个并发批处理，并根据密钥组成一个组(最多10个)。这样，数据可以尽可能分散。</p><h2 id="3635" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">州和检查站</h2><p id="a483" class="pw-post-body-paragraph jw jx hu jy b jz lm iv kb kc ln iy ke kf lo kh ki kj lp kl km kn lq kp kq kr hn dt translated">Flink逐段处理数据，每一段处理完后，立即发送到下游。相比之下，Spark中的数据必须等到操作员所在阶段的所有任务都完成之后。</p><p id="fdbd" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">Flink有一个粗粒度的检查点机制，以较低的成本给每个元素一个快照。只有当属于该快照的所有数据都进入时，计算才会被触发。在计算之后，缓冲数据被发送到下游。目前，Flink SQL不提供控制缓冲超时的接口，换句话说，就是数据缓冲需要多长时间。当构造Flink上下文时，可以将缓冲区超时指定为0，这样数据在处理后将立即发送。您不需要等到达到某个阈值后再发送它。</p><p id="c9ef" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">默认情况下，后端保存在JobManager内存中。每个操作员的状态被写入RocksDB，异步周期被增量同步到外部存储。</p><h2 id="b315" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">误差容限</h2><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff mw"><img src="../Images/d69acf90e2a1435763953d2cc6f9487a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*E_TecE-s_EpQsDNOYnYdyg.png"/></div></div></figure><p id="a69b" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">图表左侧的红色节点有一个故障转移。如果至少有一次，那么在最上游重新传输数据可以纠正错误。然而，如果它是精确的一次，每个计算节点必须从最后一个错误的时间回放。</p><h2 id="a15b" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">恰好一次两阶段提交</h2><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff mx"><img src="../Images/f7671f50605c70a63cbea086026dbc9c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*kIaG8tFyzDtp8uysp-SPpw.png"/></div></div></figure><p id="cd91" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">在Flink 1.4之后，引入了两阶段提交协议来支持恰好一次提交。从上游Kafka消费数据后，每一步都会发起投票来记录状态，标记通过检查点关卡处理。状态只写到结尾的Kafka(这只适用于Kafka 0.11或更高版本)。只有在最终完成后，每一步的状态才会被通知给JobManager中的协调器并被固化，从而实现恰好一次。</p><h2 id="28cd" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">保存点</h2><figure class="jl jm jn jo fq jp fe ff paragraph-image"><div role="button" tabindex="0" class="jq jr di js bf jt"><div class="fe ff my"><img src="../Images/73075375b74f7a1a79cba4f1529d56c2.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*iEqTT5KtxZYswp1sCyvr2w.png"/></div></div></figure><p id="0cd8" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">Flink的另一个优点是可以利用Flink的检查点实现保存点功能。保存点不仅是数据恢复的一种方式，也是恢复计算状态的一种方式。</p><h2 id="59d2" class="lw kv hu bd kw lx ly lz la ma mb mc le kf md me lg kj mf mg li kn mh mi lk mj dt translated">最终分析:Flink的优点与缺点</h2><p id="24b1" class="pw-post-body-paragraph jw jx hu jy b jz lm iv kb kc ln iy ke kf lo kh ki kj lp kl km kn lq kp kq kr hn dt translated">Flink的优势可以总结为以下几个主要特点:</p><p id="467a" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv"> Trigger </strong>:与Spark相反，Flink支持更丰富的流语义，包括处理时间、事件时间和摄取时间。</p><p id="07f2" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">连续处理&amp; windows </strong> : Flink支持连续处理，在windows上的表现比Spark好。</p><p id="79e5" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">低端到端延迟，保证一次到位</strong>:通过两阶段提交协议，用户可以根据业务需求选择牺牲吞吐量来调整和确保端到端一次到位语义。</p><p id="3b69" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">文化教育</strong></p><p id="a81e" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><strong class="jy hv">保存点</strong>:用户可以根据自己的业务需求进行版本控制。</p><p id="e001" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">然而，在以下方面也有一些不足之处:</p><p id="7cbc" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">1.<strong class="jy hv">SQL</strong>:SQL特性不完整。大部分用户都是从Hive迁移过来的，那里Spark的覆盖率超过99%。目前，不支持SQL函数，也不支持为单个操作符设置并行度。</p><p id="0ed4" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated">2.<strong class="jy hv">机器学习，图形计算</strong> : Flink在这里的表现弱于Spark，但是社区正在努力在这些方面进行改进。</p></div><div class="ab cl mz na hc nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="hn ho hp hq hr"><p id="f569" class="pw-post-body-paragraph jw jx hu jy b jz ka iv kb kc kd iy ke kf kg kh ki kj kk kl km kn ko kp kq kr hn dt translated"><em class="ks">本文是</em> <a class="ae kt" rel="noopener" href="/@alitech_2017/a-flink-series-from-the-alibaba-tech-team-b8b5539fdc70"> <strong class="jy hv"> <em class="ks">阿里巴巴旗下Flink系列</em> </strong> </a> <em class="ks">的一部分。</em></p></div><div class="ab cl mz na hc nb" role="separator"><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne nf"/><span class="nc bw bk nd ne"/></div><div class="hn ho hp hq hr"><h1 id="c214" class="ku kv hu bd kw kx ng kz la lb nh ld le ja ni jb lg jd nj je li jg nk jh lk ll dt translated">阿里巴巴科技</h1><p id="01dc" class="pw-post-body-paragraph jw jx hu jy b jz lm iv kb kc ln iy ke kf lo kh ki kj lp kl km kn lq kp kq kr hn dt translated">关于阿里巴巴最新技术的第一手深度资料→脸书:<a class="ae kt" href="http://www.facebook.com/AlibabaTechnology" rel="noopener ugc nofollow" target="_blank"> <strong class="jy hv">【阿里巴巴科技】</strong> </a>。推特:<a class="ae kt" href="https://twitter.com/AliTech2017" rel="noopener ugc nofollow" target="_blank"><strong class="jy hv">【AlibabaTech】</strong></a>。</p></div></div>    
</body>
</html>