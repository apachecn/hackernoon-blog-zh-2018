<html>
<head>
<title>Multi-GPU training with Brain Builder and TensorFlow</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用Brain Builder和TensorFlow进行多GPU训练</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/multi-gpu-training-with-brain-builder-and-tensorflow-3b7aba2eb84b?source=collection_archive---------19-----------------------#2018-11-16">https://medium.com/hackernoon/multi-gpu-training-with-brain-builder-and-tensorflow-3b7aba2eb84b?source=collection_archive---------19-----------------------#2018-11-16</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="1d0d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">是的，造AI很难！数据注释、培训和部署的每一步都有其自身的挑战。这篇博文将尝试解决其中的前两个问题:</p><ul class=""><li id="3088" class="jp jq hu it b iu iv iy iz jc jr jg js jk jt jo ju jv jw jx dt translated">数据注释</li><li id="9d1c" class="jp jq hu it b iu jy iy jz jc ka jg kb jk kc jo ju jv jw jx dt translated">培养</li></ul><p id="0d3e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在过去的几年里，在Neurala公司，我们一直在开发高效的人工智能系统，目前已经部署在数百万台消费设备上！在这个过程中，我们开发了许多工具来简化我们的工作流程。我们最终决定通过公开我们的一些工具来弥合人工智能技能的差距。其中一个工具Brain Builder处理了前面提到的第一个问题:数据标注。</p><p id="2833" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><a class="ae kd" href="https://info.neurala.com/brain-builder" rel="noopener ugc nofollow" target="_blank"> Brain Builder </a>是一个人工智能辅助的注释工具，可以无缝地融入常用的框架，如<a class="ae kd" href="https://hackernoon.com/tagged/tensorflow" rel="noopener ugc nofollow" target="_blank"> TensorFlow </a>和Caffe。这篇文章将带你完成将大脑构建器整合到你的人工智能工作流程中的步骤。我们将使用Brain Builder标记的数据和使用TensorFlow和Keras编写的模型来建立语义分割网络。</p><p id="7cfc" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">语义分割是计算机视觉经常遇到的应用之一。它的任务是用<em class="ke">类</em>标记图像的每个像素。它广泛用于图像分析，并支持智能手机上的人像模式等应用。下面的教程将描述如何使用自己的数据创建语义细分模型来对人进行细分，并使用Brain Builder和TensorFlow在多个GPU上对其进行训练。</p><h1 id="4e6b" class="kf kg hu bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc dt translated">使用大脑构建器的数据注释</h1><p id="db69" class="pw-post-body-paragraph ir is hu it b iu ld iw ix iy le ja jb jc lf je jf jg lg ji jj jk lh jm jn jo hn dt translated">数据注释是构建人工智能系统最关键的一步，因为这是你的模型所要学习的。深度学习模型的好坏取决于它所输入的数据！Brain Builder可以帮助您管理高质量的数据集，并拥有人工智能辅助工具来加快数据管理步骤。</p><p id="2b70" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">Brain Builder最重要的功能之一是自动视频标记。人工智能辅助的视频标记可以让你在很短的时间内收集大量数据，方法是从以非常高的帧速率录制的视频中提取帧并标记帧。</p><p id="43e1" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">以下视频展示了使用brain builder为视频中的人添加标签的过程:</p><figure class="li lj lk ll fq lm"><div class="bz el l di"><div class="ln lo l"/></div><figcaption class="lp lq fg fe ff lr ls bd b be z ek">AI-assisted Video Tagging using Brain Builder</figcaption></figure><p id="2941" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">正如你所看到的，仅仅通过标记视频中的第一帧，你就在几分钟内积累了近500个标记的人物帧！完成标记和导出数据后，您将从Brain Builder获得一个压缩文件，其文件夹结构如下:</p><figure class="li lj lk ll fq lm fe ff paragraph-image"><div class="ab fr cl lt"><img src="../Images/3305bffc4b359c15fbad06833e868c62.png" data-original-src="https://miro.medium.com/v2/format:webp/1*5H4PvayHZT6AZyVFeFprtA.png"/></div><figcaption class="lp lq fg fe ff lr ls bd b be z ek">Brain Builder TensorFlow export folder structure</figcaption></figure><p id="b3ac" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">该文件夹包含TensorFlow读取和处理数据集所需的所有内容。所有地面实况图像都是<em class="ke">类索引标记的png</em>，其中图像中的每个像素对应一个类索引。文件<em class="ke"> class_dictionary.csv、classes.txt和palette.txt </em>为您提供了关于类索引到其后续R、G、B值的映射的详细信息，您可以稍后使用这些信息来可视化您的结果。</p><p id="7edf" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们现在将使用TensorFlow和Keras编写一个流行的语义分割架构，名为<a class="ae kd" href="https://arxiv.org/abs/1505.04597" rel="noopener ugc nofollow" target="_blank"> UNet </a>。使用估算器和TensorFlow数据集API，我们可以在多个GPU上进行训练，从而大幅减少训练时间！</p><p id="fb07" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">(请注意，我们在实现中稍微修改了UNet，以使实验速度更快！)</p><h1 id="85da" class="kf kg hu bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc dt translated">使用张量流估计器和数据集API的多GPU训练</h1><p id="ea42" class="pw-post-body-paragraph ir is hu it b iu ld iw ix iy le ja jb jc lf je jf jg lg ji jj jk lh jm jn jo hn dt translated">Keras与TensorFlow的端到端集成使得使用TensorFlow估算器和数据集API对Keras模型进行多GPU训练变得非常容易。</p><h2 id="cfb7" class="lw kg hu bd kh lx ly lz kl ma mb mc kp jc md me kt jg mf mg kx jk mh mi lb mj dt translated">张量流估计量</h2><p id="1751" class="pw-post-body-paragraph ir is hu it b iu ld iw ix iy le ja jb jc lf je jf jg lg ji jj jk lh jm jn jo hn dt translated"><strong class="it hv">估计器</strong>类代表一个模型，以及这个模型应该如何被训练和评估。使用估算器的一些主要优点是:</p><ul class=""><li id="7319" class="jp jq hu it b iu iv iy iz jc jr jg js jk jt jo ju jv jw jx dt translated">基于估算器的模型可以跨多个GPU运行，而无需更改模型代码；</li><li id="beb5" class="jp jq hu it b iu jy iy jz jc ka jg kb jk kc jo ju jv jw jx dt translated">评估者简化了开发人员之间模型实现的共享；</li><li id="d905" class="jp jq hu it b iu jy iy jz jc ka jg kb jk kc jo ju jv jw jx dt translated">评估人员为您构建图表，并消除了明确的(相当痛苦的)会议的需要。</li></ul><p id="d2b3" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">以下代码创建了一个Keras模型，对其进行编译，并将其转换为TensorFlow估算器:</p><pre class="li lj lk ll fq mk ml mm mn aw mo dt"><span id="c408" class="lw kg hu ml b fv mp mq l mr ms">dataset = TFDatasetLoader(data_dirpath, input_size, n_classes, batch_size, num_epochs)<br/>model = UNet(input_size, n_classes)<br/>model.compile(optimizer=tf.train.AdamOptimizer(learning_rate=0.01), loss='binary_crossentropy', metrics=['accuracy'])</span><span id="95ca" class="lw kg hu ml b fv mt mq l mr ms">strategy = tf.contrib.distribute.MirroredStrategy(num_gpus=num_gpus)<br/>config = tf.estimator.RunConfig(train_distribute=strategy)<br/>estimator = tf.keras.estimator.model_to_estimator(model, config=config)</span></pre><p id="efed" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">如果你熟悉Keras，你唯一会注意到的新东西是最后三行代码。我们用于多GPU训练的策略叫做<code class="eh mu mv mw ml b">MirroredStrategy</code>。在这种策略中，每个GPU都有一个图形副本，并获得一个数据子集，在此基础上计算局部梯度。一旦计算出局部梯度，每个GPU就会等待其他GPU以同步方式完成。当所有梯度都到达时，每个GPU对它们进行平均，并更新其参数，然后开始下一步。你可以在<a class="ae kd" href="https://www.youtube.com/watch?v=bRMGoPqsn20" rel="noopener ugc nofollow" target="_blank">这个</a>链接上了解更多关于分布式张量流训练的信息。</p><p id="0e1b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">既然已经定义了策略，我们就使用该策略创建一个<code class="eh mu mv mw ml b">RunConfig</code>对象，并使用它来调用<code class="eh mu mv mw ml b">model_to_estimator</code>函数，该函数将Keras模型转换成一个估计器对象。</p><p id="603b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">准备好估计器后，我们可以使用这两行代码简单地训练和评估它:</p><pre class="li lj lk ll fq mk ml mm mn aw mo dt"><span id="6089" class="lw kg hu ml b fv mp mq l mr ms">estimator.train(lambda:dataset.imgs_input_fn(mode="train"), hooks=[time_hist])<br/>estimator.evaluate(lambda:dataset.imgs_input_fn(mode="val"))</span></pre><p id="a327" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在这两个调用中需要注意的重要事情是<code class="eh mu mv mw ml b">dataset.imgs_input_fn</code>函数。该函数使用TensorFlow数据集API向模型提供数据。</p><h2 id="7d96" class="lw kg hu bd kh lx ly lz kl ma mb mc kp jc md me kt jg mf mg kx jk mh mi lb mj dt translated">张量流数据集API</h2><p id="82b5" class="pw-post-body-paragraph ir is hu it b iu ld iw ix iy le ja jb jc lf je jf jg lg ji jj jk lh jm jn jo hn dt translated">Dataset是一个高效的数据输入API，它与估算器和tf.Keras结合得很好。新输入管道的核心是<code class="eh mu mv mw ml b">Dataset</code>(也许还有<code class="eh mu mv mw ml b">Iterator</code>)。一个<code class="eh mu mv mw ml b">Dataset</code>是一个<code class="eh mu mv mw ml b">elements</code>的集合，每个都有相同的结构，其中一个元素可以是一个或多个张量。一个元素内部不同的张量叫做<code class="eh mu mv mw ml b">components</code>。每个组件都有特定的数据类型和形状，但是一个元素中的不同组件可以有不同的数据类型和形状。</p><p id="a9f7" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">下面的代码片段显示了如何创建可以提供给评估者的dataset对象:</p><pre class="li lj lk ll fq mk ml mm mn aw mo dt"><span id="798d" class="lw kg hu ml b fv mp mq l mr ms">dataset = tf.data.Dataset.from_tensor_slices((image_paths, gt_paths))<br/>dataset = dataset.map(lambda image, label: tuple(tf.py_func(<br/> self._one_hot_gt, [image, label], [tf.string, tf.uint8])))<br/>dataset = dataset.map(self._data_to_tensor)<br/>dataset = dataset.repeat(self.epochs)<br/>dataset = dataset.batch(self.batch_size)<br/>dataset = dataset.prefetch(self.batch_size)</span></pre><p id="70ba" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">需要注意的重要函数是<code class="eh mu mv mw ml b">map()</code>函数，它允许您读取数据并以任何方式处理数据(调整大小、一键代码等)。<code class="eh mu mv mw ml b">repeat()</code>让您指定想要迭代这个数据集的次数。<code class="eh mu mv mw ml b">batch()</code>根据用户提供的批次大小自动对数据进行批处理，并在处理当前批次时<code class="eh mu mv mw ml b">prefetch()</code>预取下一批次。</p><h1 id="34dc" class="kf kg hu bd kh ki kj kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc dt translated">训练结果和速度对比</h1><p id="fe1a" class="pw-post-body-paragraph ir is hu it b iu ld iw ix iy le ja jb jc lf je jf jg lg ji jj jk lh jm jn jo hn dt translated">我们在两个NVIDIA GTX1080 GPUs上训练我们的分段模型100个时期。该模型仅用大约4个小时的训练就达到了大约91%的像素精度。以下是我们测试中的一些比较:</p><figure class="li lj lk ll fq lm fe ff paragraph-image"><div class="ab fr cl lt"><img src="../Images/4be4bbac73c95c86d9cfcd0661ce989c.png" data-original-src="https://miro.medium.com/v2/format:webp/1*C1eaUWsjJRpq46ub1calkA.png"/></div></figure><figure class="li lj lk ll fq lm fe ff paragraph-image"><div class="ab fr cl lt"><img src="../Images/6e45dec9e63b318f868d4f0543e1be0d.png" data-original-src="https://miro.medium.com/v2/format:webp/1*h2N_pGK8GeVUym8Y11izVg.png"/></div></figure><p id="07ba" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">正如你所看到的，使用两个而不是一个GPU使我们的速度提高了近2倍，以达到相同的精度水平。</p></div><div class="ab cl mx my hc mz" role="separator"><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc nd"/><span class="na bw bk nb nc"/></div><div class="hn ho hp hq hr"><p id="b6ee" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我们希望本教程能够帮助您理解如何将Brain Builder集成到您的人工智能工作流中，以建立高效的数据准备和训练管道。我们欢迎来自社区的反馈，以便能够进一步改进Brain Builder！</p><p id="5a4b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><a class="ae kd" href="https://info.neurala.com/brain-builder" rel="noopener ugc nofollow" target="_blank">你可以在这里注册大脑建造者测试版</a>。请在下面留下您对教程和/或大脑构建器的反馈、功能需求或任何其他问题的评论。</p><p id="6623" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">你可以在<a class="ae kd" href="https://github.com/neurala/Neurala-Tutorials/tree/master/01_multi_gpu_tf_keras" rel="noopener ugc nofollow" target="_blank">这个链接</a>上找到本教程的代码。</p></div></div>    
</body>
</html>