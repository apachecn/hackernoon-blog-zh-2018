<html>
<head>
<title>Tackle High Bias and Other Problems/Solutions in Machine Learning Models</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">处理机器学习模型中的高偏差和其他问题/解决方案</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/tackle-bias-and-other-problems-solutions-in-machine-learning-models-f4274c5fe538?source=collection_archive---------1-----------------------#2018-12-16">https://medium.com/hackernoon/tackle-bias-and-other-problems-solutions-in-machine-learning-models-f4274c5fe538?source=collection_archive---------1-----------------------#2018-12-16</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="b3df" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">预测分析模型非常依赖于回归、分类和聚类方法。在分析预测模型的有效性时，预测越接近实际数据，就越好。本文希望成为主要问题及其最流行/有效的解决方案的一站式参考，而不是深入执行的细节。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff jp"><img src="../Images/e241362b73bc5a137dd3c99af8899bef.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*--mzAxz5byM270kB"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek"><em class="kf">A Linear Regression Plot</em></figcaption></figure><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff kg"><img src="../Images/fd6f48e9dd7d57d4c96b3830b21d1714.png" data-original-src="https://miro.medium.com/v2/resize:fit:858/0*Vl73230YH5Fj0Hak"/></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek"><em class="kf">A clustering algorithm plot</em></figcaption></figure><p id="fcaa" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">首先，数据选择和删减发生在数据准备阶段，在这一阶段，您首先要处理掉不良数据。此外，在训练过程中，数据及其与ML模型目标的相关性存在问题，算法的使用存在问题，数据中会出现错误。实际上，对模型进行了<a class="ae kh" href="http://bit.ly/EveryoneAI" rel="noopener ugc nofollow" target="_blank">偏差</a>、方差、自相关和许多在最终确定模型时可能出现的错误的测试。在最终确定模型之前，对数据执行一些已定义的测试——这些是检测此类错误的测试算法。</p><p id="3bf5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在运行这些测试之后，您返回到模型并做出那些修正，然后批准模型是合适的，或者“好的”。但是，行业中的佼佼者已经找到了在以后的迭代中避免这种错误的方法。可能会出现许多错误，但让我们用定义明确且最有效的测试和解决方案来探究其中的一些错误:</p><h1 id="fbac" class="ki kj hu bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">过度拟合和欠拟合</h1><p id="942e" class="pw-post-body-paragraph ir is hu it b iu lg iw ix iy lh ja jb jc li je jf jg lj ji jj jk lk jm jn jo hn dt translated"><strong class="it hv">过拟合和欠拟合问题可以用偏差-方差权衡属性来解释:</strong></p><p id="1d1f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">偏差是学习算法中的错误，此时学习算法从数据中学习的能力较弱。在高偏差的情况下，学习算法不能学习数据中的相关细节。因此，它在训练数据和测试数据集上都表现不佳。另一方面，当学习算法试图从数据集过度学习或试图尽可能接近地拟合训练数据时，方差是学习算法中的错误。在高方差的情况下，该算法在测试数据集上表现不佳，但在训练数据集上表现相当好。</p><p id="8a69" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">偏差-方差权衡是机器学习中的一个重要问题。这是一种你不能同时拥有低偏差和低方差的情况。但是你必须通过训练一个模型来进行权衡，这个模型可以捕捉数据中的规律，足够精确，并且可以推广到同一来源的不同点，具有最佳偏差和最佳方差。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff ll"><img src="../Images/02a19a26a8ea201a64b6b9e72707d0ac.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/0*7bkoOoww6B5ld2VO"/></div></figure><blockquote class="lm"><p id="0059" class="ln lo hu bd lp lq lr ls lt lu lv jo ek translated">偏差和方差是学习算法中总误差中的两个误差，如果你试图减少一个误差，另一个误差可能会增加。</p></blockquote><p id="c6ce" class="pw-post-body-paragraph ir is hu it b iu lw iw ix iy lx ja jb jc ly je jf jg lz ji jj jk ma jm jn jo hn dt translated"><strong class="it hv">偏差和方差是如何导致过度拟合和欠拟合的？</strong></p><p id="7a2e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">为了确定模型的最佳拟合，我们分析测试样本/数据点如何被考虑用于模型分析。当解析数百万行时，您可能会试图包含所有的数据点，不管它们是否相关，或者超出了前面提到的阈值。这里的关键是不要尽善尽美地包括每个数据点，也不要在试图拟合曲线时忽略数据点。</p><p id="359b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">当学习算法具有高偏差问题时，致力于减少偏差将导致方差上升，从而导致过拟合问题。并且，当学习算法遭受高方差问题时，致力于减小方差将导致偏差上升，从而导致欠拟合问题。这就是“权衡”一词的由来，因为仅仅减少偏差不会改善模型，反之亦然。“最佳点”是将数据点放在有最佳偏差和最佳方差的地方。基本上，找到一个模式不要走极端，以免影响准确性。大多数时候，规划和选择这些点是数据科学家和分析师面临的最大挑战。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff mb"><img src="../Images/f6bbdfb5ac1c704a923827c519f9e723.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*7xAFG32QA2nNEs6n"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek"><em class="kf">The best fit may not be the one that excludes outliers to the T, but is always a compromise</em></figcaption></figure><p id="7b30" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">但是，也有测试模型拟合度的方法。针对这些现象提供的一些解决方案有:</p><p id="6e20" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">偏差-方差权衡问题的答案:</p><p id="97fc" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="mc">建立更复杂的模型</em></p><p id="c0ec" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">对拟合不足问题的第一个也是最简单的解决方案是训练一个更复杂的模型来解决问题。对于过度拟合的模型，获取更多的数据。和正规化。</p><p id="5a3f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="mc">交叉验证</em></p><p id="ef59" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">在交叉验证中，所有可用或选择的数据都不会用于训练模型。通常有三个方面有助于执行交叉验证方法——训练数据、测试数据和验证数据集。您可以单独使用训练和测试数据的组合，或者使用所有三种数据折叠。</p><p id="7a90" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">[训练数据=用于模型训练</p><p id="d981" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">测试数据=用于模型超参数调整</p><p id="46f2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">验证数据=用于模型验证和准确性评估]</p><p id="d6e2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">有许多方法可以处理这些折叠，训练数据通常占总数据集的60%，测试数据集占20%，而验证数据集由剩余的20%组成。</p><p id="7145" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">通过首先仅使用训练数据训练模型，然后将该模型与用测试数据训练的模型进行比较，来测试训练模型的质量。通过这种方式，我们可以识别哪些数据点带来了更好的预测。交叉验证有多种形式:</p><p id="6393" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">坚持:数据分为测试数据和训练数据，然后进行比较。在保留方法中，我们只使用一组保留的训练数据。</p><p id="13e5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">100个样本，60个训练，20个测试，20个在验证数据集中。在训练期间，你计算模型的准确性。测试是对模型进行训练后测试精度。</p><p id="1c23" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">K-Fold交叉验证:这里数据被分成k个集合。则第一组或第一折叠是验证数据集，并且第一折叠从折叠总数中移除(其中，假设k=10)。对于每次迭代，我们取一个折叠进行验证(第9次，在第一次迭代(k-1)之后)，然后从现在剩余的折叠总数中减去它(现在k=9)。这种方法是有效的，但需要巨大的计算能力。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff md"><img src="../Images/4e5e4d9bfdf2e4265806e3e86d419bca.png" data-original-src="https://miro.medium.com/v2/resize:fit:970/0*dRkf7Qtx5l_k3n_y"/></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek"><em class="kf">Example for k-fold cross validation with 10 folds</em></figcaption></figure><p id="d74e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">留一个出来:这种方法比较麻烦，因为每次测试n个数据点时，一对一的数据会被剔除。</p><p id="5e9d" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="mc">辍学</em>:</p><p id="3fce" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">当在深度学习中使用<a class="ae kh" href="http://bit.ly/NeuralNets" rel="noopener ugc nofollow" target="_blank">神经网络</a>时，使用退出方法。Dropout是一种古老的技术，被证明有助于模型的准确性。这使得层中的一些激活被去激活(等于0)。我们可以从数据集中选择任意数量的数据来创建辍学层。通常，这在20%或30%的范围内。假设，如果我们使用30%的丢弃率，那么在那个特定层中随机30%的神经元的激活被去激活。去激活的神经元将不会传播到网络的下一层。我们这样做是为了避免过度拟合，因为更多的噪声会使模型更健壮。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff me"><img src="../Images/7344e15a496bcb73f13f7bca68c33602.png" data-original-src="https://miro.medium.com/v2/resize:fit:990/0*XQXW9XkX7zyTql5V"/></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek"><em class="kf">Dropout method: Here, some neurons have been deactivated( red colored, right). Suppose the activation is x, then in dropout it is equated to zero</em></figcaption></figure><p id="b690" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">直觉上，这迫使网络即使在缺乏某些信息的情况下也是准确的。去激活的阈值是较早决定的。</p><p id="ae1c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="mc">渐变噪声:</em></p><p id="f18e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这种方法包括在训练期间添加梯度噪声，这种方法被证明提高了模型的准确性。参考本文- <a class="ae kh" href="http://bit.ly/gradientNoise" rel="noopener ugc nofollow" target="_blank"> <em class="mc">加入梯度噪声提高了非常深度网络的学习</em> </a>)。</p><p id="a4bf" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">添加从高斯分布采样的噪声:</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff ll"><img src="../Images/e1a9bb042abb12f6926305e7672db9c9.png" data-original-src="https://miro.medium.com/v2/resize:fit:450/0*zAreThWeeoXp1V4l"/></div></div></figure><p id="10c8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="mc">规范化</em>:</p><p id="fa56" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">正则化只是另一种减少过度拟合现象的流行方法。该技术用于解决高方差问题，包括惩罚系数和权重，以获得训练数据和测试数据的更高精度。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff mf"><img src="../Images/a0ff36a7b2e9079a89417718f8c99a3a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*6OJuJuw_sJiPHLLL"/></div></div></figure><p id="7988" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="mc">这里，w是权重值，红框代表正则项，λ是正则化参数，在训练过程中得到优化。剩下的是计算最小平方的损失函数。</em></p><h1 id="76b8" class="ki kj hu bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">消失和爆炸渐变问题</h1><p id="df96" class="pw-post-body-paragraph ir is hu it b iu lg iw ix iy lh ja jb jc li je jf jg lj ji jj jk lk jm jn jo hn dt translated">当使用反向传播来训练深度神经网络时，可以向网络中添加新的和新的隐藏层。这最终会构建一个高度复杂的模型，但会影响训练速度。这里，当使用sigmoid激活函数或tanh激活函数时，会出现梯度消失的问题，这两个函数用于激发神经网络的神经元，确定梯度在通过层时的行为。</p><p id="c126" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">当计算权重矩阵的梯度，然后从完全相同的矩阵中减去时，会发生这种情况。然而，如果模型有许多层，最终一些梯度等于零，因此使其权重值不变，并且它们停止学习。然而，这带来了一个问题，因为模型没有从这些消失的梯度中学习，这没有实现任何东西。通常，这种降低梯度值的效果会随着您在层中反向传播而增强，从而使那些较早的层停止学习。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff mg"><img src="../Images/e82d0c0b2c3de42e7dc1e0a96005ed01.png" data-original-src="https://miro.medium.com/v2/resize:fit:570/0*dHuImDhyMgciCkYd"/></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek">Gradient Descent and Vanishing/Exploding Gradients</figcaption></figure><p id="f86c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">更清楚地说，当使用反向传播时，如果使用值在0和1之间的sigmoid激活函数。因此，如果产生一个高值(&gt; 1)，那么激活函数将激活该值为1，在反向传播期间，导数变为0，从而完全丢失更高的值，反之亦然(低值[&gt;0)，保持恒定在0。为了避免这种消失梯度，使用其他激活函数，如ReLU、PReLU、卢瑟和eLU。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff mb"><img src="../Images/187a36dc461b25832a9d5849488793a4.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*L7FePuJUfEtBz3dV"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek"><em class="kf">A Tanh function</em></figcaption></figure><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff mh"><img src="../Images/3d5dc412af05deff1cac5ba7dc7b4e4c.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*-Z9JQnkmk1A9PGkB"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek"><em class="kf">A sigmoid function. Notice that higher values beyond -6 and 6 remains constant, here</em></figcaption></figure><p id="6b75" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">消失和爆炸渐变问题的答案</p><p id="3f39" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="mc">激活功能— ReLU、PReLU、RReLU、ELU </em></p><p id="5e41" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">ReLU:(整流线性单位)为了使大于零的值不变为无效，ReLU将其标记为无穷大，从而生成一个线性函数。然而，ReLu的缺点是将小于零的值等同于零，这在某些情况下不是很好，因为它完全错过了这些值，但提高了速度。并且，当值的饱和度低于零时，ReLU实际上完全阻止了任何训练。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff mi"><img src="../Images/6280c8751be36958f132108a4d8ad0c7.png" data-original-src="https://miro.medium.com/v2/resize:fit:536/0*1FuuTN1iN9kXbApl"/></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek"><em class="kf">ReLu</em></figcaption></figure><p id="2799" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">PReLU(参数校正线性单位):比ReLU更好，PReLU不会使低于零的值无效，但会提高速度。它通过用参数<strong class="it hv">‘α’替换0.01的值来减轻饱和度。</strong></p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff mj"><img src="../Images/480f008134e4a0a0b2322340e5cfaaec.png" data-original-src="https://miro.medium.com/v2/resize:fit:584/0*iCWrr2Pds41pqCu3"/></div></figure><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff mk"><img src="../Images/1ff186bc828a3dfd6ead21d4ec19a75b.png" data-original-src="https://miro.medium.com/v2/resize:fit:528/0*92NoVQaR36ELbKP4"/></div></figure><p id="95a0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">RReLU(随机泄漏整流线性单元):RReLU据说击败了上述每一个激活函数。RReLU为负斜率分配随机值，因此不会影响速度或精度。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff ml"><img src="../Images/1995d88d421544c0a38f176e22cce6b7.png" data-original-src="https://miro.medium.com/v2/resize:fit:486/0*zpGMPMSP-gQTSksd"/></div></figure><p id="1699" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">ELU(指数线性单位):ELU通过将大于零的值等同于1来避免饱和。主要是为了提高分类的准确性，ELU加快了训练速度。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff mm"><img src="../Images/52c26f03e0ed6743cce41fea0ad69934.png" data-original-src="https://miro.medium.com/v2/resize:fit:562/0*Qs-yyJv39mjJ5X-x"/></div></figure><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff mn"><img src="../Images/2f6c56987309bbffdc45020731eaa02a.png" data-original-src="https://miro.medium.com/v2/resize:fit:740/0*4XK6NC0ZtEEqRgRx"/></div></figure><p id="6fa8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">参见文章<a class="ae kh" href="https://towardsdatascience.com/secret-sauce-behind-the-beauty-of-deep-learning-beginners-guide-to-activation-functions-a8e23a57d046" rel="noopener" target="_blank">此处</a>的方程和这些函数的详细解释。</p><p id="2307" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="mc">归一化:</em></p><p id="634e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">归一化解决了过度拟合、欠拟合和消失梯度问题。</p><p id="98cf" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">批量归一化:批量归一化技术用于提高反向传播的性能。它包括重新调整输入值的比例，以防止它们变得过大或过小。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff mo"><img src="../Images/242c7bc88a158acf0c93a14fe490272a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1012/0*7ncRFbWaUa6cTAr8"/></div></figure><p id="7759" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">实例规范化:实例规范化是一种只使用单个样本的规范化，而不是像批量规范化那样使用一批样本。</p><h1 id="b054" class="ki kj hu bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">多重共线性</h1><p id="8556" class="pw-post-body-paragraph ir is hu it b iu lg iw ix iy lh ja jb jc li je jf jg lj ji jj jk lk jm jn jo hn dt translated">当模型预测中的预测变量之间存在多重相关性时，就会出现多重共线性。这种现象是大多数人都熟悉的，在回归模型中也很常见。多重共线性问题仅在您需要知道特定预测发生的原因(即需要预测的原因)时才会出现。这可以为模型的任何预测带来解释。有时，一个高度相关的列看起来可能是某些结果的原因，但实际上它们只是相关的。</p><p id="fbe2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">发现数据集中的多重共线性可以防止对某些结果得出严重错误的结论，例如在患有哮喘的肺炎患者中，他们被认为对哮喘有更好的抵抗力，因为他们接受治疗的时间更早。然而，事实是，当哮喘患者同时患有肺炎时，他们得到了及时的治疗，因为如果不及时治疗，他们更容易发生致命的后果。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff mp"><img src="../Images/68ede219dac58cb47c1a3904e63b2b1d.png" data-original-src="https://miro.medium.com/v2/resize:fit:1000/0*Zqp3HgEefL042Wr6"/></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek"><em class="kf">Credits: creativewisdom.com</em></figcaption></figure><p id="b950" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">多重共线性的答案</p><p id="b883" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="mc">自相关&amp;部分自相关测试:</em>这些测试可以检测模型中的相关现象。它们通常用于时间序列分析和预测。通过这些测试，您可以检测哪里发生了相关，并删除高度相关的列。</p><p id="1bf6" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="mc">自相关:</em>检测数据中的相关性，或者重复信号的出现，多用于时间序列分析和预测。它可以发生在两个因变量x1和x2之间。</p><p id="a230" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="mc">主成分分析(PCA): </em></p><p id="5cbf" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">主成分分析用于校正相关误差。它只是保留一组新的预测变量，这些变量是高度相关的变量行为的组合。因此，这些新变量保留了那些循环和相关变量的行为，而不是放弃那些在模型中有自己角色的相关变量。它通过特征提取来工作。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff mq"><img src="../Images/4efeb01697a7dba046f4e5fbed058a75.png" data-original-src="https://miro.medium.com/v2/resize:fit:1182/0*C1gmaeCVYH86q_k4"/></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek"><em class="kf">Plot that analyses the Principal Components of a Dataset through Feature Extraction</em></figcaption></figure><p id="8b39" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="mc">通过特征提取分析数据集主要成分的图</em></p><p id="82fd" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="mc">线性判别分析(LDA): </em></p><p id="030a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">LDA用于预测分析问题。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff mr"><img src="../Images/b1df696296b82e76fb4760a0e09a08be.png" data-original-src="https://miro.medium.com/v2/resize:fit:1088/0*YJ7ZVxOpzCdgjRMZ"/></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek"><em class="kf">Logistic Regressions are Classification Algorithms</em></figcaption></figure><p id="06fe" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">它假设一组新输入将属于到目前为止收集的数据集中的类。当使用逻辑回归时，会出现某些限制，例如模型的不稳定性。相反，我们可以使用LDA进行线性回归。该算法还使用著名的贝叶斯定理来计算输入对输出的概率。</p><p id="449a" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">p(Y = X | X = X)=(PIk * fk(X))/sum(PIl * fl(X))</p><p id="9cbb" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="mc">皮尔逊相关系数:</em></p><p id="0430" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">皮尔逊系数用于计算两个变量X和y之间的相关性。它给出一个介于-1和1之间的值，表示负相关或正相关，如果该值为零，则不存在相关性。</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff ms"><img src="../Images/85b472c230b7fd2a94db3c27565e1b5a.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/0*Fdm2Jz3SuMEQ1IBF"/></div></div></figure><p id="9bb0" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated"><em class="mc">自相关&amp;偏自相关测试:</em></p><p id="487e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">自相关测试结果与变量的相关程度。自相关函数(ACF)用于计算时间序列中的相关性。时间序列预测的观测值与已经收集的时间序列观测值相关联。因此，这个名字叫做自相关。ACF的目的是使用值绘制具有滞后的所有相关性的图表。这里的滞后项是通过从以前的时间序列观测值中提取使序列平稳所需的值来计算的。</p></div><div class="ab cl mt mu hc mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="hn ho hp hq hr"><h1 id="f3a4" class="ki kj hu bd kk kl na kn ko kp nb kr ks kt nc kv kw kx nd kz la lb ne ld le lf dt translated">关于Mate Labs</h1><blockquote class="nf ng nh"><p id="2cf4" class="ir is mc it b iu iv iw ix iy iz ja jb ni jd je jf nj jh ji jj nk jl jm jn jo hn dt translated">在<a class="ae kh" href="http://www.matelabs.ai" rel="noopener ugc nofollow" target="_blank"> <em class="hu"> Mate Labs </em> </a> <em class="hu">我们</em>已经构建了<a class="ae kh" href="https://www.matelabs.ai" rel="noopener ugc nofollow" target="_blank"> Mateverse </a>，一个机器学习平台，在这里你可以在几分钟 s <strong class="it hv">内构建<strong class="it hv">定制的ML模型，而无需编写一行代码</strong>。我们利用专有技术、复杂管道、大数据支持、自动化数据预处理(使用ML模型的缺失值插补、异常值检测和格式化)、自动化超参数优化和<a class="ae kh" href="http://bit.ly/2UKMO2J" rel="noopener ugc nofollow" target="_blank">等等，让分析师和数据科学家的工作变得更加轻松。</a></strong></p><p id="1fdc" class="ir is mc it b iu iv iw ix iy iz ja jb ni jd je jf nj jh ji jj nk jl jm jn jo hn dt translated">为了帮助您的企业采用机器学习，而不会浪费您的团队在数据清理和创建有效数据模型方面的时间，请填写<a class="ae kh" href="https://matelabs.typeform.com/to/LIAau1" rel="noopener ugc nofollow" target="_blank">类型表单</a> <a class="ae kh" href="http://bit.ly/formcontactus" rel="noopener ugc nofollow" target="_blank"> <strong class="it hv">此处</strong> </a>，我们将与您联系。</p><p id="84e4" class="ir is mc it b iu iv iw ix iy iz ja jb ni jd je jf nj jh ji jj nk jl jm jn jo hn dt translated">阅读更多关于我们的<a class="ae kh" href="https://towardsdatascience.com/product-launch-announcement-mateverse-high-level-v-1-0-e51577dab05f" rel="noopener" target="_blank">产品</a>的信息。欢迎致电<a class="ae kh" href="mailto:mate@matelabs.in" rel="noopener ugc nofollow" target="_blank"><strong class="it hv">mate @ mate labs . in</strong></a>联系我们</p></blockquote><h1 id="a881" class="ki kj hu bd kk kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf dt translated">联系我们</h1><blockquote class="nf ng nh"><p id="46e4" class="ir is mc it b iu iv iw ix iy iz ja jb ni jd je jf nj jh ji jj nk jl jm jn jo hn dt translated">此外，要收到像这篇文章这样有用的文章，请关注我们的<a class="ae kh" rel="noopener" href="/@matelabs_ai">这里</a>，在Medium上<a class="ae kh" href="https://www.linkedin.com/company/mate-labs/" rel="noopener ugc nofollow" target="_blank">，LinkedIn </a>和Twitter 。</p></blockquote></div><div class="ab cl mt mu hc mv" role="separator"><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my mz"/><span class="mw bw bk mx my"/></div><div class="hn ho hp hq hr"><h1 id="137e" class="ki kj hu bd kk kl na kn ko kp nb kr ks kt nc kv kw kx nd kz la lb ne ld le lf dt translated">关于作者</h1><h2 id="0afb" class="nl kj hu bd kk nm nn no ko np nq nr ks jc ns nt kw jg nu nv la jk nw nx le ny dt translated"><a class="ae kh" rel="noopener" href="/me/stories/public">渡鸦的丹尼尔</a></h2><blockquote class="nf ng nh"><p id="374f" class="ir is mc it b iu iv iw ix iy iz ja jb ni jd je jf nj jh ji jj nk jl jm jn jo hn dt translated">在Medium上找到她，<a class="ae kh" rel="noopener" href="/@rayvensdan">这里</a>。在LinkedIn 上寻找更多行业话题和更新。</p></blockquote></div></div>    
</body>
</html>