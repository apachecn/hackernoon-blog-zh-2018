<html>
<head>
<title>Binary Image Classifier using PyTorch</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">使用PyTorch的二值图像分类器</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/binary-face-classifier-using-pytorch-2d835ccb7816?source=collection_archive---------0-----------------------#2018-12-24">https://medium.com/hackernoon/binary-face-classifier-using-pytorch-2d835ccb7816?source=collection_archive---------0-----------------------#2018-12-24</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><h1 id="b803" class="ir is hu bd it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo dt translated">基于PyTorch的虚拟图像分类</h1><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff jp"><img src="../Images/ff0167ce84c25da5d123ee178a5ba454.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*hBnlM0161Zyx-akt3uEb8w.png"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek"><a class="ae kf" href="https://cdn-images-1.medium.com/max/2000/1*LLVL8xUiUOBE8WHgzAuY-Q.png" rel="noopener">Source</a></figcaption></figure><figure class="jq jr js jt fq ju"><div class="bz el l di"><div class="kg kh l"/></div></figure><p id="ac05" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">脸书最近发布了名为PyTorch 1.0的深度学习库，这是该库的稳定版本，可用于生产级代码。</p><p id="d964" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">我是Udacity的PyTorch奖学金挑战项目的一部分，学到了很多关于PyTorch及其功能的知识。来自喀拉斯的PyTorch看起来没什么不同，需要时间来适应。</p><p id="bf7c" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">在本文中，我将指导您使用PyTorch中的卷积神经网络从头构建一个二值图像分类器。</p><p id="3ea6" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">整个过程分为以下步骤:</p><p id="0095" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">1.加载数据<br/> 2。定义一个卷积神经网络<br/> 3。训练模型<br/> 4。在数据集上评估我们的训练模型的性能</p><h1 id="c2c5" class="ir is hu bd it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo dt translated"><strong class="ak"> 1。加载数据</strong></h1><p id="8c96" class="pw-post-body-paragraph ki kj hu kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf hn dt translated">当加载/预处理数据时，PyTorch比其他库简单得多。然而，PyTorch有一个名为transforms的内置函数，使用它您可以一次执行所有的预处理任务，我们稍后会看到。</p><p id="b95b" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">对于数据集，我找不到一个正面标记的人脸，因此我手动制作了自己的数据集，将来自<a class="ae kf" href="http://vis-www.cs.umass.edu/lfw/" rel="noopener ugc nofollow" target="_blank"> LFW人脸数据集</a>的图像用于正面，并为负面添加了一些随机图像，包括车辆、动物、家具等图像。<br/>如果你愿意，你可以从这里下载数据集:<a class="ae kf" href="https://drive.google.com/file/d/1nt-Orxqh-5b1XwBcU3CHz4i0vEOGwt0J/view?usp=sharing" rel="noopener ugc nofollow" target="_blank">链接</a></p><p id="b956" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">在训练之前，需要在训练、测试和验证集中拆分数据。训练集将用于训练模型，验证集将用于在每个时期后验证模型，测试集将用于在模型被训练后评估模型。</p><p id="8d2a" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">首先，我们需要将数据集放入环境中，这可以通过:<br/> ( <em class="ll">注意:“face”是包含正面和负面faces例子的目录名</em>)</p><pre class="jq jr js jt fq lm ln lo lp aw lq dt"><span id="41ca" class="lr is hu ln b fv ls lt l lu lv">train_data = datasets.ImageFolder('face',transform=transform)</span></pre><p id="1116" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">我们还需要定义一个转换对象来执行预处理步骤。我们可以在对象中提到我们需要什么类型的处理。在下面的代码中，我定义了transform对象，该对象执行水平翻转、随机旋转，将图像数组转换为PyTorch(因为该库只处理张量，类似于numpy数组)，然后最终归一化图像。</p><pre class="jq jr js jt fq lm ln lo lp aw lq dt"><span id="3ec6" class="lr is hu ln b fv ls lt l lu lv">transform = transforms.Compose([<br/>    transforms.RandomHorizontalFlip(),<br/>    transforms.RandomRotation(20),<br/>    transforms.ToTensor(),<br/>    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))<br/>    ])</span></pre><p id="f653" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">一旦我们完成了数据集的加载和转换对象的定义，我们就可以像前面讨论的那样将数据集分成训练集、测试集和验证集。进行分割时:</p><pre class="jq jr js jt fq lm ln lo lp aw lq dt"><span id="ec0e" class="lr is hu ln b fv ls lt l lu lv">#For test<br/>num_data = len(train_data)<br/>indices_data = list(range(num_data))<br/>np.random.shuffle(indices_data)<br/>split_tt = int(np.floor(test_size * num_data))<br/>train_idx, test_idx = indices_data[split_tt:], indices_data[:split_tt]</span><span id="bca5" class="lr is hu ln b fv lw lt l lu lv">#For Valid<br/>num_train = len(train_idx)<br/>indices_train = list(range(num_train))<br/>np.random.shuffle(indices_train)<br/>split_tv = int(np.floor(valid_size * num_train))<br/>train_idx, valid_idx = indices_train[split_tv:],indices_train[:split_tv]</span><span id="ba0c" class="lr is hu ln b fv lw lt l lu lv"># define samplers for obtaining training and validation batches<br/>train_sampler = SubsetRandomSampler(train_idx)<br/>test_sampler = SubsetRandomSampler(test_idx)<br/>valid_sampler = SubsetRandomSampler(valid_idx)</span><span id="afb9" class="lr is hu ln b fv lw lt l lu lv">#Loaders contains the data in tuple format <br/># (Image in form of tensor, label)<br/>train_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=train_sampler, num_workers=1)</span><span id="7c2a" class="lr is hu ln b fv lw lt l lu lv">valid_loader = torch.utils.data.DataLoader(train_data, batch_size=batch_size, sampler=valid_sampler, num_workers=1)</span><span id="b62e" class="lr is hu ln b fv lw lt l lu lv">test_loader = torch.utils.data.DataLoader(train_data, sampler = test_sampler, batch_size=batch_size,num_workers=1)</span><span id="a8d5" class="lr is hu ln b fv lw lt l lu lv"># variable representing classes of the images<br/>classes = [0,1]</span></pre><p id="a35e" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">train_loader、test_loader和valid_loader将用于向模型传递输入。</p><p id="3e93" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">以下是应用变换(包括调整大小、随机旋转和归一化)后来自数据集的一些随机图像:</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff lx"><img src="../Images/b4cd76e1de2f3edf7d4143265fbe5520.png" data-original-src="https://miro.medium.com/v2/resize:fit:1144/format:webp/1*xydSVEV9sR4N2Idrhr6T7w.png"/></div></figure><h1 id="6702" class="ir is hu bd it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo dt translated"><strong class="ak"> 2。</strong>初始化卷积神经网络(CNN)</h1><figure class="jq jr js jt fq ju fe ff paragraph-image"><div class="fe ff ly"><img src="../Images/ad5f30e89c6c0df5157e19b601ee6d44.png" data-original-src="https://miro.medium.com/v2/resize:fit:600/format:webp/1*pNxGdMXltxDBi3-j4BTPOw.jpeg"/></div></figure><p id="66d5" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">PyTorch中的CNN定义如下:</p><pre class="jq jr js jt fq lm ln lo lp aw lq dt"><span id="d11a" class="lr is hu ln b fv ls lt l lu lv">torch.nn.Conv2D(Depth_of_input_image, Depth_of_filter, size_of_filter, padding, strides)</span></pre><p id="faac" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">输入图像的深度对于RGB通常为3，对于灰度通常为1。滤波器的深度由用户指定，用户通常提取低级特征，并且滤波器的大小是在整个图像上卷积的核的大小。</p><p id="42b4" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">为了计算新卷积层的维度，使用以下公式:<br/><em class="ll">dimension =<br/>(dimen _ of _ input _ image-Filter _ size(int)+(2 * padding))/stride _ value+1</em></p><p id="a572" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">现在是初始化模型的时候了:</p><pre class="jq jr js jt fq lm ln lo lp aw lq dt"><span id="9c31" class="lr is hu ln b fv ls lt l lu lv">class Net(nn.Module):<br/>    def __init__(self):<br/>        super(Net, self).__init__()<br/>        # convolutional layer<br/>        self.conv1 = nn.Conv2d(3, 16, 5)<br/>        # max pooling layer<br/>        self.pool = nn.MaxPool2d(2, 2)<br/>        self.conv2 = nn.Conv2d(16, 32, 5)<br/>        self.dropout = nn.Dropout(0.2)<br/>        self.fc1 = nn.Linear(32*53*53, 256)<br/>        self.fc2 = nn.Linear(256, 84)<br/>        self.fc3 = nn.Linear(84, 2)<br/>        self.softmax = nn.LogSoftmax(dim=1)<br/>        <br/>    def forward(self, x):<br/>        # add sequence of convolutional and max pooling layers<br/>        x = self.pool(F.relu(self.conv1(x)))<br/>        x = self.pool(F.relu(self.conv2(x)))<br/>        x = self.dropout(x)<br/>        x = x.view(-1, 32 * 53 * 53)<br/>        x = F.relu(self.fc1(x))<br/>        x = self.dropout(F.relu(self.fc2(x)))<br/>        x = self.softmax(self.fc3(x))<br/>        return x</span><span id="60d8" class="lr is hu ln b fv lw lt l lu lv"># create a complete CNN<br/>model = Net()</span></pre><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff lz"><img src="../Images/2bd8d4ab447b4c80c4493561c6ca3ed6.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*x7Ecf5kbqm7GiGnvKHXoKA.png"/></div></div><figcaption class="kb kc fg fe ff kd ke bd b be z ek">Model Architecture</figcaption></figure><p id="5099" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">我们还需要初始化我们的损失函数和一个优化器。损失函数将帮助我们通过比较预测和原始标签来计算损失。优化器将通过在每个时期之后更新模型的参数来最小化损失。它们可以通过以下方式初始化:</p><pre class="jq jr js jt fq lm ln lo lp aw lq dt"><span id="a1a1" class="lr is hu ln b fv ls lt l lu lv"># Loss function<br/>criterion = torch.nn.CrossEntropyLoss()</span><span id="18dc" class="lr is hu ln b fv lw lt l lu lv"># Optimizer<br/>optimizer = torch.optim.SGD(model.parameters(), lr = 0.003, momentum= 0.9)</span></pre><h1 id="6f4a" class="ir is hu bd it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo dt translated"><strong class="ak"> 3。训练模型</strong></h1><p id="0f59" class="pw-post-body-paragraph ki kj hu kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf hn dt translated">是时候训练模型了！</p><figure class="jq jr js jt fq ju fe ff paragraph-image"><div role="button" tabindex="0" class="jv jw di jx bf jy"><div class="fe ff ma"><img src="../Images/29c3ea8623381ab98348e2cf0e5cb222.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*3tX5wuhfLPeinWsdEemi3Q.jpeg"/></div></div></figure><p id="b679" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">训练模型需要我们遵循以下步骤:</p><ol class=""><li id="b713" class="mb mc hu kk b kl km kp kq kt md kx me lb mf lf mg mh mi mj dt translated"><strong class="kk hv">清除所有优化变量的梯度:<br/> </strong>可能存在以前批次的梯度，因此有必要在每个时期后清除梯度</li><li id="72c9" class="mb mc hu kk b kl mk kp ml kt mm kx mn lb mo lf mg mh mi mj dt translated"><strong class="kk hv">正向传递</strong> : <br/>该步骤通过将输入传递给卷积神经网络模型来计算预测输出</li><li id="f7d7" class="mb mc hu kk b kl mk kp ml kt mm kx mn lb mo lf mg mh mi mj dt translated"><strong class="kk hv">计算损失:<br/> </strong>当模型训练时，损失函数在每个时期后计算损失，然后被优化器使用。</li><li id="ea5a" class="mb mc hu kk b kl mk kp ml kt mm kx mn lb mo lf mg mh mi mj dt translated"><strong class="kk hv">反向传递:</strong> <br/>该步骤计算相对于模型参数的损失梯度</li><li id="a0ea" class="mb mc hu kk b kl mk kp ml kt mm kx mn lb mo lf mg mh mi mj dt translated"><strong class="kk hv">优化</strong> <br/>这为模型执行单个优化步骤/参数更新</li><li id="1c53" class="mb mc hu kk b kl mk kp ml kt mm kx mn lb mo lf mg mh mi mj dt translated"><strong class="kk hv">更新平均培训损失</strong></li></ol><p id="06eb" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">以下是训练模型的代码(<em class="ll">这是针对单个时期的</em></p><figure class="jq jr js jt fq ju"><div class="bz el l di"><div class="mp kh l"/></div></figure><h1 id="4096" class="ir is hu bd it iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo dt translated"><strong class="ak"> 4。模型评估</strong></h1><p id="e833" class="pw-post-body-paragraph ki kj hu kk b kl lg kn ko kp lh kr ks kt li kv kw kx lj kz la lb lk ld le lf hn dt translated">为了评估模型，应该将它从model.train()更改为model.eval()</p><pre class="jq jr js jt fq lm ln lo lp aw lq dt"><span id="eb37" class="lr is hu ln b fv ls lt l lu lv">model.eval()<br/># iterate over test data<br/>len(test_loader)<br/>for data, target in test_loader:<br/>    # move tensors to GPU if CUDA is available<br/>    if train_on_gpu:<br/>        data, target = data.cuda(), target.cuda()<br/>    # forward pass<br/>    output = model(data)<br/>    # calculate the batch loss<br/>    loss = criterion(output, target)<br/>    # update test loss <br/>    test_loss += loss.item()*data.size(0)<br/>    # convert output probabilities to predicted class<br/>    _, pred = torch.max(output, 1)    <br/>    # compare predictions to true label<br/>    correct_tensor = pred.eq(target.data.view_as(pred))<br/>    correct = np.squeeze(correct_tensor.numpy()) if not train_on_gpu else np.squeeze(correct_tensor.cpu().numpy())<br/>    # calculate test accuracy for each object class<br/>    for i in range(batch_size):       <br/>        label = target.data[i]<br/>        class_correct[label] += correct[i].item()<br/>        class_total[label] += 1</span><span id="b50c" class="lr is hu ln b fv lw lt l lu lv"># average test loss<br/>test_loss = test_loss/len(test_loader.dataset)<br/>print('Test Loss: {:.6f}\n'.format(test_loss))</span><span id="7769" class="lr is hu ln b fv lw lt l lu lv">for i in range(2):<br/>    if class_total[i] &gt; 0:<br/>        print('Test Accuracy of %5s: %2d%% (%2d/%2d)' % (<br/>            classes[i], 100 * class_correct[i] / class_total[i],<br/>            np.sum(class_correct[i]), np.sum(class_total[i])))<br/>    else:<br/>        print('Test Accuracy of %5s: N/A (no training examples)' % (classes[i]))</span><span id="608d" class="lr is hu ln b fv lw lt l lu lv">print('\nTest Accuracy (Overall): %2d%% (%2d/%2d)' % (<br/>    100. * np.sum(class_correct) / np.sum(class_total),<br/>    np.sum(class_correct), np.sum(class_total)))</span></pre><p id="0d14" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">经过评估，我们发现以下结果:</p><pre class="jq jr js jt fq lm ln lo lp aw lq dt"><span id="dbe8" class="lr is hu ln b fv ls lt l lu lv">Test Loss: 0.006558</span><span id="0019" class="lr is hu ln b fv lw lt l lu lv">Test Accuracy of     0: 99% (805/807) <br/>Test Accuracy of     1: 98% (910/921)</span><span id="9ca6" class="lr is hu ln b fv lw lt l lu lv">Test Accuracy (Overall): 99% (1715/1728)</span></pre><p id="3b35" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">我们得到的结果是仅使用2个卷积层，尽管研究人员正在使用可以提取更多细节特征的更深层次的网络。</p><p id="606f" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">由于这个模型已经学会了提取面部特征，这可以进一步用于面部识别，其中你可以在你自己的图像上训练这个面部分类器，并使用迁移学习创建面部识别系统。</p><p id="54a7" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">此外，编辑其中的几行代码将生成另一个带有适量数据和标签的图像分类器。可能性是无限的，你只需要实践它，并将其应用于任何你想要的问题！</p><blockquote class="mq mr ms"><p id="e606" class="ki kj ll kk b kl km kn ko kp kq kr ks mt ku kv kw mu ky kz la mv lc ld le lf hn dt translated">快乐学习！</p></blockquote><p id="b81d" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">GitHub回购:<a class="ae kf" href="https://github.com/jayrodge/Binary-Image-Classifier-PyTorch" rel="noopener ugc nofollow" target="_blank">https://github.com/jayrodge/Binary-Image-Classifier-PyTorch</a></p></div><div class="ab cl mw mx hc my" role="separator"><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb nc"/><span class="mz bw bk na nb"/></div><div class="hn ho hp hq hr"><p id="8287" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">我们上<a class="ae kf" href="https://linkedin.com/in/jayrodge" rel="noopener ugc nofollow" target="_blank"> LinkedIn连线吧！</a></p><p id="3de7" class="pw-post-body-paragraph ki kj hu kk b kl km kn ko kp kq kr ks kt ku kv kw kx ky kz la lb lc ld le lf hn dt translated">了解更多关于我的<a class="ae kf" href="https://about.me/jayrodge" rel="noopener ugc nofollow" target="_blank"/>。</p></div></div>    
</body>
</html>