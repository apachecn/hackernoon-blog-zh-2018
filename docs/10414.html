<html>
<head>
<title>Deep Dream with TensorFlow: A Practical guide to build your first Deep Dream Experience</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">TensorFlowæ·±åº¦æ¢¦å¢ƒ:å»ºç«‹ä½ çš„ç¬¬ä¸€æ¬¡æ·±åº¦æ¢¦å¢ƒä½“éªŒçš„å®ç”¨æŒ‡å—</h1>
<blockquote>åŸæ–‡ï¼š<a href="https://medium.com/hackernoon/deep-dream-with-tensorflow-a-practical-guide-to-build-your-first-deep-dream-experience-f91df601f479?source=collection_archive---------1-----------------------#2018-12-29">https://medium.com/hackernoon/deep-dream-with-tensorflow-a-practical-guide-to-build-your-first-deep-dream-experience-f91df601f479?source=collection_archive---------1-----------------------#2018-12-29</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><blockquote class="ir"><p id="3e87" class="is it hu bd iu iv iw ix iy iz ja jb ek translated">æƒ³è±¡åŠ›æ¯”çŸ¥è¯†æ›´é‡è¦ã€‚å› ä¸º<strong class="ak">çš„çŸ¥è¯†</strong>æ˜¯æœ‰é™çš„ï¼Œè€Œ<strong class="ak">çš„æƒ³è±¡åŠ›</strong>åŒ…å®¹äº†æ•´ä¸ªä¸–ç•Œï¼Œåˆºæ¿€äº†è¿›æ­¥ï¼Œå‚¬ç”Ÿäº†è¿›åŒ–ã€‚â€</p></blockquote><p id="6635" class="pw-post-body-paragraph jc jd hu je b jf jg jh ji jj jk jl jm jn jo jp jq jr js jt ju jv jw jx jy jb hn dt jz translated">æ— è®ºæ˜¯æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆï¼Œè¿˜æ˜¯æ·±åº¦å­¦ä¹ ä¸“ä¸šäººå£«ï¼Œéƒ½ä¼šèšé›†åœ¨ä¸€äº›èšä¼šæˆ–ä¼šè®®ä¸Šï¼Œä»–ä»¬è®¨è®ºçš„æ·±åº¦å­¦ä¹ æœ€å¸¸è§çš„åº”ç”¨èŒƒå›´ä»å¯¹è±¡æ£€æµ‹ï¼Œäººè„¸è¯†åˆ«ï¼Œè‡ªç„¶è¯­è¨€å¤„ç†å’Œè¯­éŸ³è¯†åˆ«ï¼Œä¸»è¦æ˜¯ç”±äºè‡ªåŠ¨é©¾é©¶æ±½è½¦ï¼Œäºšé©¬é€Š-Alexaæˆ–èŠå¤©æœºå™¨äººï¼Œä½†è¿˜æœ‰å…¶ä»–ç±»å‹çš„åº”ç”¨ä¸åŒäºè¿™äº›æ ‡å‡†åº”ç”¨ï¼Œè¿™äº›åº”ç”¨ä¸ä»…åœ¨äººå·¥æ™ºèƒ½é¢†åŸŸï¼Œä¹Ÿåœ¨è‰ºæœ¯é¢†åŸŸå¼•èµ·äº†å·¨å¤§çš„è½°åŠ¨ã€‚</p><p id="9f25" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">ä¸€ä¸ªè¿™æ ·çš„åº”ç”¨æ˜¯â€œ<strong class="je hv">æ·±æ¢¦â€</strong>ï¼Œå®ƒèµ‹äºˆäº†è‰ºæœ¯å®¶åŠ›é‡ï¼Œåè¿‡æ¥å¢å¼ºäº†æˆ‘ä»¬çš„åˆ›é€ æ€§å¯ç¤ºï¼Œæ‰©å¤§äº†æˆ‘ä»¬å¯ä»¥æƒ³è±¡çš„ç©ºé—´ã€‚</p><p id="c1e1" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated"><strong class="je hv">æ·±æ¢¦</strong>æ˜¯ä¸€ä¸ª<a class="ae kn" href="https://en.wikipedia.org/wiki/Computer_vision" rel="noopener ugc nofollow" target="_blank">è®¡ç®—æœºè§†è§‰</a>ç¨‹åºï¼Œç”±<a class="ae kn" href="https://en.wikipedia.org/wiki/Google" rel="noopener ugc nofollow" target="_blank">è°·æ­Œ</a>å·¥ç¨‹å¸ˆ<a class="ae kn" href="https://twitter.com/zzznah" rel="noopener ugc nofollow" target="_blank"> Alex Mordvintsev </a>åˆ›å»ºï¼Œå®ƒä½¿ç”¨<a class="ae kn" href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="noopener ugc nofollow" target="_blank">å·ç§¯ç¥ç»ç½‘ç»œ</a>é€šè¿‡<a class="ae kn" href="https://en.wikipedia.org/wiki/Algorithm" rel="noopener ugc nofollow" target="_blank">ç®—æ³•</a> <a class="ae kn" href="https://en.wikipedia.org/wiki/Pareidolia" rel="noopener ugc nofollow" target="_blank">å¹»è§‰</a>åœ¨çš„<a class="ae kn" href="https://en.wikipedia.org/wiki/Image" rel="noopener ugc nofollow" target="_blank">å›¾åƒä¸­å¯»æ‰¾å¹¶å¢å¼ºæ¨¡å¼ï¼Œä»è€Œåœ¨å›¾åƒä¸­åˆ›å»ºä¸€ä¸ªç±»ä¼¼äº</a>çš„<a class="ae kn" href="https://en.wikipedia.org/wiki/Hallucinogenic" rel="noopener ugc nofollow" target="_blank">è‡´å¹»</a>å¤–è§‚</p><p id="e6f6" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">è°·æ­Œçš„è®¡åˆ’æ¨å¹¿äº†æœ¯è¯­(æ·±åº¦)â€œåšæ¢¦â€ï¼ŒæŒ‡çš„æ˜¯åœ¨ç»è¿‡è®­ç»ƒçš„<a class="ae kn" href="https://en.wikipedia.org/wiki/Deep_neural_network" rel="noopener ugc nofollow" target="_blank">æ·±åº¦ç½‘ç»œ</a>ä¸­äº§ç”ŸæœŸæœ›çš„<a class="ae kn" href="https://en.wikipedia.org/wiki/Activation_(neural_network)" rel="noopener ugc nofollow" target="_blank">æ¿€æ´»</a>çš„å›¾åƒç”Ÿæˆï¼Œè¯¥æœ¯è¯­ç°åœ¨æŒ‡çš„æ˜¯ç›¸å…³æ–¹æ³•çš„é›†åˆã€‚</p><h2 id="17e4" class="ko kp hu bd kq kr ks kt ku kv kw kx ky jn kz la lb jr lc ld le jv lf lg lh li dt translated"><strong class="ak">ä»ç†è®ºåˆ°å®è·µ</strong></h2><p id="2a29" class="pw-post-body-paragraph jc jd hu je b jf lj jh ji jj lk jl jm jn ll jp jq jr lm jt ju jv ln jx jy jb hn dt translated">æ¥ä¸‹æ¥æ˜¯æˆ‘æœ€å–œæ¬¢çš„éƒ¨åˆ†ï¼Œåœ¨è‡ªå­¦äº†<a class="ae kn" href="https://en.wikipedia.org/wiki/Google" rel="noopener ugc nofollow" target="_blank">è°·æ­Œ</a>æ·±åº¦æ¢¦ä¹‹åï¼Œæ˜¯æ—¶å€™ä»<strong class="je hv">é˜…è¯»å™¨</strong>æ¨¡å¼åˆ‡æ¢åˆ°<strong class="je hv">ç¼–ç å™¨</strong>æ¨¡å¼ï¼Œå› ä¸ºä»è¿™ä¸€ç‚¹å¼€å§‹ï¼Œæˆ‘å°†åªè°ˆè®ºä»£ç ï¼Œè¿™ä¸äº†è§£ä»»ä½•æ·±åº¦å­¦ä¹ åº”ç”¨èƒŒåçš„æ¦‚å¿µåŒç­‰é‡è¦ã€‚</p><p id="6a82" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">éµå¾ªè¿™ä¸ªä¸€æ­¥ä¸€æ­¥çš„å®è·µæŒ‡å—æ¥åˆ›å»ºä½ çš„ç¬¬ä¸€ä¸ªæ·±åº¦æ¢¦ä½“éªŒï¼Œä½†æ˜¯åœ¨å¼€å§‹æˆ‘çš„ç¼–ç ä¹‹æ—…ä¹‹å‰ï¼Œå…ˆçœ‹çœ‹æˆ‘çš„æ·±åº¦æ¢¦å›¾åƒï¼Œè¿™äº›å›¾åƒéå¸¸è¿·å¹»ã€‚</p><figure class="lp lq lr ls fq lt fe ff paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="fe ff lo"><img src="../Images/73d8290c57d68118dcff184099ab75ec.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*h1DL2aTZd9xJb-AhviX0gg.png"/></div></div><figcaption class="ma mb fg fe ff mc md bd b be z ek">Image 1: Welcome to the trippy world of hallucinogenic images</figcaption></figure><p id="085e" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated"><strong class="je hv">å…è´£å£°æ˜</strong>:åœ¨å¼€å§‹æœ¬ç¼–ç æ•™ç¨‹ä¹‹å‰ï¼Œè¯·ç¡®ä¿æ‚¨åœ¨ä¸€ä¸ªæ–‡ä»¶å¤¹ä¸­æœ‰ä¸¤ä¸ªpythonæ–‡ä»¶ï¼Œå³download.pyå’Œinception5h.pyï¼Œæ‚¨å¯ä»¥ä»æˆ‘åœ¨å‚è€ƒèµ„æ–™éƒ¨åˆ†æåˆ°çš„GitHubèµ„æºåº“ä¸­è·å¾—ï¼Œå¦åˆ™æ‚¨ä¼šå‘ç°è‡ªå·±è¢«â€œæ²¡æœ‰æ‰¾åˆ°æ¨¡å—â€é”™è¯¯æ‰€å›°æ‰°ï¼Œè¿™æ— ç–‘æ˜¯ä¸€ç§ç—›è‹¦</p><p id="1d4a" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">é‚£ä¹ˆï¼Œè®©æˆ‘ä»¬å¼€å§‹å§</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="ea63" class="ko kp hu mf b fv mj mk l ml mm">#This was developed using Python 3.6.3 (Anaconda) <br/>#Important library to import</span><span id="13b0" class="ko kp hu mf b fv mn mk l ml mm">%matplotlib inline<br/>import matplotlib.pyplot as plt<br/>import tensorflow as tf<br/>import numpy as np<br/>import random<br/>import math</span><span id="408e" class="ko kp hu mf b fv mn mk l ml mm"># Image manipulation.<br/>from PIL import Image<br/>from scipy.ndimage.filters import gaussian_filter</span></pre><h1 id="9cf7" class="mo kp hu bd kq mp mq mr ku ms mt mu ky mv mw mx lb my mz na le nb nc nd lh ne dt translated">åˆå§‹æ¨¡å‹</h1><p id="9bd7" class="pw-post-body-paragraph jc jd hu je b jf lj jh ji jj lk jl jm jn ll jp jq jr lm jt ju jv ln jx jy jb hn dt translated">ä½¿ç”¨Inception 5hæ¨¡å‹æ˜¯å› ä¸ºå®ƒæ›´å®¹æ˜“ä½¿ç”¨:å®ƒæ¥å—ä»»ä½•å¤§å°çš„è¾“å…¥å›¾åƒï¼Œå¹¶ä¸”å®ƒä¼¼ä¹æ¯”Inception v3æ¨¡å‹åˆ›å»ºäº†æ›´æ¼‚äº®çš„å›¾ç‰‡ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="aeb9" class="ko kp hu mf b fv mj mk l ml mm">import inception5h</span></pre><p id="492a" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">ä¸‹è½½åˆå§‹æ¨¡å‹çš„æ•°æ®ã€‚å®ƒçš„å¤§å°æ˜¯50å…†å­—èŠ‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="849e" class="ko kp hu mf b fv mj mk l ml mm">inception5h.maybe_download()</span><span id="9ab1" class="ko kp hu mf b fv mn mk l ml mm">Downloading Inception 5h Model ...<br/>Data has apparently already been downloaded and unpacked.</span></pre><p id="eb0a" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">åŠ è½½å…ˆå¯æ¨¡å‹ï¼Œè¿™æ ·å®ƒå°±å¯ä»¥ä½¿ç”¨äº†ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="b432" class="ko kp hu mf b fv mj mk l ml mm">model = inception5h.Inception5h()</span></pre><p id="1241" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">Inception 5hæ¨¡å‹æœ‰è®¸å¤šå±‚ï¼Œå¯ä»¥ç”¨äºæ·±åº¦åšæ¢¦ã€‚ä½†æ˜¯ä¸ºäº†ä¾¿äºå‚è€ƒï¼Œæˆ‘ä»¬å°†åªä½¿ç”¨12ä¸ªæœ€å¸¸ç”¨çš„å±‚ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="4eab" class="ko kp hu mf b fv mj mk l ml mm">len(model.layer_tensors)</span></pre><p id="359a" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">è¦äº†è§£inception 5hæ¨¡å‹ä¸­çš„ä¸åŒå±‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="12d8" class="ko kp hu mf b fv mj mk l ml mm">def printTensors(pb_file):</span><span id="6946" class="ko kp hu mf b fv mn mk l ml mm"># read pb into graph_def<br/>    with tf.gfile.GFile(pb_file, "rb") as f:<br/>        graph_def = tf.GraphDef()<br/>        graph_def.ParseFromString(f.read())</span><span id="8de7" class="ko kp hu mf b fv mn mk l ml mm"># import graph_def<br/>    with tf.Graph().as_default() as graph:<br/>        tf.import_graph_def(graph_def)</span><span id="1346" class="ko kp hu mf b fv mn mk l ml mm"># print operations<br/>    for op in graph.get_operations():<br/>        print(op.name)</span><span id="ee7c" class="ko kp hu mf b fv mn mk l ml mm">printTensors("inception/5h/tensorflow_inception_graph.pb")</span></pre><h1 id="6504" class="mo kp hu bd kq mp mq mr ku ms mt mu ky mv mw mx lb my mz na le nb nc nd lh ne dt translated">å›¾åƒå¤„ç†çš„è¾…åŠ©åŠŸèƒ½</h1><p id="234f" class="pw-post-body-paragraph jc jd hu je b jf lj jh ji jj lk jl jm jn ll jp jq jr lm jt ju jv ln jx jy jb hn dt translated">è¿™ä¸ªå‡½æ•°åŠ è½½ä¸€ä¸ªå›¾åƒï¼Œå¹¶ä»¥æµ®ç‚¹numpyæ•°ç»„çš„å½¢å¼è¿”å›ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="21f7" class="ko kp hu mf b fv mj mk l ml mm">def load_image(filename):<br/>    try:<br/>        original = Image.open(filename)<br/>        print("the size of the image is :")<br/>        print(original.format,original.size)<br/>    except:<br/>        print ("Unable to load image")</span><span id="020d" class="ko kp hu mf b fv mn mk l ml mm">return np.float32(original)</span></pre><p id="07af" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">å°†å›¾åƒä¿å­˜ä¸ºjpegæ–‡ä»¶ã€‚å›¾åƒä»¥numpyæ•°ç»„çš„å½¢å¼ç»™å‡ºï¼Œåƒç´ å€¼åœ¨0åˆ°255ä¹‹é—´ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="001d" class="ko kp hu mf b fv mj mk l ml mm">def save_image(image, filename):<br/>    # Ensure the pixel-values are between 0 and 255.<br/>    image = np.clip(image, 0.0, 255.0)<br/>    <br/>    # Convert to bytes.<br/>    image = image.astype(np.uint8)<br/>    <br/>    # Write the image-file in jpeg-format.<br/>    with open(filename, 'wb') as file:<br/>        Image.fromarray(image).save(file, 'jpeg')</span></pre><p id="8d0a" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">è¯¥å‡½æ•°ç»˜åˆ¶å›¾åƒã€‚ä½¿ç”¨matplotlibä¼šäº§ç”Ÿä½åˆ†è¾¨ç‡å›¾åƒã€‚ä½¿ç”¨PILç»™å‡ºäº†æ¼‚äº®çš„å›¾ç‰‡ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="bd34" class="ko kp hu mf b fv mj mk l ml mm">def plot_image(image):<br/>    # Assume the pixel-values are scaled between 0 and 255.<br/>    <br/>    if False:<br/>        # Convert the pixel-values to the range between 0.0 and 1.0<br/>        image = np.clip(image/255.0, 0.0, 1.0)<br/>        <br/>        # Plot using matplotlib.<br/>        plt.imshow(image, interpolation='lanczos')<br/>        plt.show()<br/>    else:<br/>        # Ensure the pixel-values are between 0 and 255.<br/>        image = np.clip(image, 0.0, 255.0)<br/>        <br/>        # Convert pixels to bytes.<br/>        image = image.astype(np.uint8)</span><span id="5c2d" class="ko kp hu mf b fv mn mk l ml mm"># Convert to a PIL-image and display it.<br/>        display(Image.fromarray(image))</span></pre><p id="f52b" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">å½’ä¸€åŒ–å›¾åƒï¼Œä½¿å…¶å€¼ä»‹äº0.0å’Œ1.0ä¹‹é—´ã€‚è¿™å¯¹äºç»˜åˆ¶æ¢¯åº¦å¾ˆæœ‰ç”¨ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="9ad6" class="ko kp hu mf b fv mj mk l ml mm">def normalize_image(x):<br/>    # Get the min and max values for all pixels in the input.<br/>    x_min = x.min()<br/>    x_max = x.max()</span><span id="1db2" class="ko kp hu mf b fv mn mk l ml mm"># Normalize so all values are between 0.0 and 1.0<br/>    x_norm = (x - x_min) / (x_max - x_min)<br/>    <br/>    return x_norm</span></pre><p id="c745" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">è¯¥å‡½æ•°ç»˜åˆ¶å½’ä¸€åŒ–åçš„æ¢¯åº¦</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="1727" class="ko kp hu mf b fv mj mk l ml mm">def plot_gradient(gradient):<br/>    # Normalize the gradient so it is between 0.0 and 1.0<br/>    gradient_normalized = normalize_image(gradient)<br/>    <br/>    # Plot the normalized gradient.<br/>    plt.imshow(gradient_normalized, interpolation='bilinear')<br/>    plt.show()</span></pre><p id="241c" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">è¿™ä¸ªå‡½æ•°è°ƒæ•´å›¾åƒçš„å¤§å°ã€‚å®ƒå¯ä»¥æ¥å—ä¸€ä¸ªå¤§å°å‚æ•°ï¼Œä½ å¯ä»¥ç»™å®ƒä½ æƒ³è¦çš„å›¾åƒçš„åƒç´ å¤§å°ï¼Œä¾‹å¦‚(100ï¼Œ200)ã€‚æˆ–è€…å®ƒå¯ä»¥å¸¦ä¸€ä¸ªå› å­å‚æ•°ï¼Œä½ å¯ä»¥ç»™å®ƒä¸€ä¸ªä½ æƒ³è¦çš„ç¼©æ”¾å› å­ï¼Œæ¯”å¦‚0.5ï¼Œç”¨æ¥åœ¨æ¯ä¸ªç»´åº¦ä¸ŠæŠŠå›¾åƒçš„å¤§å°å‡åŠã€‚</p><p id="5134" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">è¿™æ˜¯ç”¨PILå®ç°çš„ï¼Œæœ‰ç‚¹é•¿ï¼Œå› ä¸ºæˆ‘ä»¬å¤„ç†çš„æ˜¯åƒç´ æ˜¯æµ®ç‚¹å€¼çš„numpyæ•°ç»„ã€‚PILä¸æ”¯æŒè¿™ä¸€ç‚¹ï¼Œå› æ­¤å¿…é¡»å°†å›¾åƒè½¬æ¢ä¸º8ä½å­—èŠ‚ï¼ŒåŒæ—¶ç¡®ä¿åƒç´ å€¼åœ¨é€‚å½“çš„èŒƒå›´å†…ã€‚ç„¶åè°ƒæ•´å›¾åƒçš„å¤§å°å¹¶è½¬æ¢å›æµ®ç‚¹å€¼ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="6176" class="ko kp hu mf b fv mj mk l ml mm">def resize_image(image, size=None, factor=None):<br/>    # If a rescaling-factor is provided then use it.<br/>    if factor is not None:<br/>        # Scale the numpy array's shape for height and width.<br/>        size = np.array(image.shape[0:2]) * factor<br/>        <br/>        # The size is floating-point because it was scaled.<br/>        # PIL requires the size to be integers.<br/>        size = size.astype(int)<br/>    else:<br/>        # Ensure the size has length 2.<br/>        size = size[0:2]<br/>    <br/>    # The height and width is reversed in numpy vs. PIL.<br/>    size = tuple(reversed(size))</span><span id="1d27" class="ko kp hu mf b fv mn mk l ml mm"># Ensure the pixel-values are between 0 and 255.<br/>    img = np.clip(image, 0.0, 255.0)<br/>    <br/>    # Convert the pixels to 8-bit bytes.<br/>    img = img.astype(np.uint8)<br/>    <br/>    # Create PIL-object from numpy array.<br/>    img = Image.fromarray(img)<br/>    <br/>    # Resize the image.<br/>    img_resized = img.resize(size, Image.LANCZOS)<br/>    <br/>    # Convert 8-bit pixel values back to floating-point.<br/>    img_resized = np.float32(img_resized)</span><span id="9c04" class="ko kp hu mf b fv mn mk l ml mm">return img_resized</span></pre><h1 id="9fe9" class="mo kp hu bd kq mp mq mr ku ms mt mu ky mv mw mx lb my mz na le nb nc nd lh ne dt translated">DeepDreamç®—æ³•</h1><h1 id="b0d3" class="mo kp hu bd kq mp mq mr ku ms mt mu ky mv mw mx lb my mz na le nb nc nd lh ne dt translated">æ¢¯åº¦</h1><p id="bd0a" class="pw-post-body-paragraph jc jd hu je b jf lj jh ji jj lk jl jm jn ll jp jq jr lm jt ju jv ln jx jy jb hn dt translated">ä»¥ä¸‹è¾…åŠ©å‡½æ•°è®¡ç®—è¾“å…¥å›¾åƒçš„æ¸å˜ï¼Œç”¨äºDeepDreamç®—æ³•ã€‚Inception 5hæ¨¡å‹å¯ä»¥æ¥å—ä»»ä½•å¤§å°çš„å›¾åƒï¼Œä½†æ˜¯éå¸¸å¤§çš„å›¾åƒå¯èƒ½ä¼šä½¿ç”¨è®¸å¤šåƒå…†å­—èŠ‚çš„RAMã€‚ä¸ºäº†ä¿æŒè¾ƒä½çš„RAMä½¿ç”¨ç‡ï¼Œæˆ‘ä»¬å°†æŠŠè¾“å…¥å›¾åƒåˆ†å‰²æˆè¾ƒå°çš„å›¾åƒå—ï¼Œå¹¶è®¡ç®—æ¯ä¸ªå›¾åƒå—çš„æ¢¯åº¦ã€‚</p><p id="9a01" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">ä½†æ˜¯ï¼Œè¿™å¯èƒ½ä¼šå¯¼è‡´DeepDreamç®—æ³•ç”Ÿæˆçš„æœ€ç»ˆå›¾åƒä¸­å‡ºç°å¯è§çº¿æ¡ã€‚å› æ­¤ï¼Œæˆ‘ä»¬éšæœºé€‰æ‹©ç“·ç –ï¼Œæ‰€ä»¥ç“·ç –çš„ä½ç½®æ€»æ˜¯ä¸åŒçš„ã€‚è¿™ä½¿å¾—ç“·ç –ä¹‹é—´çš„æ¥ç¼åœ¨æœ€ç»ˆçš„DeepDreamå›¾åƒä¸­ä¸å¯è§ã€‚</p><p id="f1e9" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">è¿™æ˜¯ä¸€ä¸ªå¸®åŠ©å‡½æ•°ï¼Œç”¨äºç¡®å®šåˆé€‚çš„å›¾å—å¤§å°ã€‚æœŸæœ›çš„å›¾å—å°ºå¯¸ä¾‹å¦‚æ˜¯400Ã—400åƒç´ ï¼Œä½†æ˜¯å®é™…çš„å›¾å—å°ºå¯¸å°†å–å†³äºå›¾åƒå°ºå¯¸ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="0383" class="ko kp hu mf b fv mj mk l ml mm">def get_tile_size(num_pixels, tile_size=400):<br/>    """<br/>    num_pixels is the number of pixels in a dimension of the image.<br/>    tile_size is the desired tile-size.<br/>    """</span><span id="1a90" class="ko kp hu mf b fv mn mk l ml mm"># How many times can we repeat a tile of the desired size.<br/>    num_tiles = int(round(num_pixels / tile_size))<br/>    <br/>    # Ensure that there is at least 1 tile.<br/>    num_tiles = max(1, num_tiles)<br/>    <br/>    # The actual tile-size.<br/>    actual_tile_size = math.ceil(num_pixels / num_tiles)<br/>    <br/>    return actual_tile_size</span></pre><p id="7021" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">è¿™ä¸ªè¾…åŠ©å‡½æ•°è®¡ç®—è¾“å…¥å›¾åƒçš„æ¢¯åº¦ã€‚å°†å›¾åƒåˆ†å‰²æˆå°å—ï¼Œå¹¶è®¡ç®—æ¯ä¸ªå°å—çš„æ¢¯åº¦ã€‚ç“·ç –æ˜¯éšæœºé€‰æ‹©çš„ï¼Œä»¥é¿å…åœ¨æœ€ç»ˆçš„DeepDreamå›¾åƒä¸­å‡ºç°å¯è§çš„æ¥ç¼/çº¿æ¡ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="5cd8" class="ko kp hu mf b fv mj mk l ml mm">def tiled_gradient(gradient, image, tile_size=400):<br/>    # Allocate an array for the gradient of the entire image.<br/>    grad = np.zeros_like(image)</span><span id="9210" class="ko kp hu mf b fv mn mk l ml mm"># Number of pixels for the x- and y-axes.<br/>    x_max, y_max, _ = image.shape</span><span id="2d5f" class="ko kp hu mf b fv mn mk l ml mm"># Tile-size for the x-axis.<br/>    x_tile_size = get_tile_size(num_pixels=x_max, tile_size=tile_size)<br/>    # 1/4 of the tile-size.<br/>    x_tile_size4 = x_tile_size // 4</span><span id="0f3d" class="ko kp hu mf b fv mn mk l ml mm"># Tile-size for the y-axis.<br/>    y_tile_size = get_tile_size(num_pixels=y_max, tile_size=tile_size)<br/>    # 1/4 of the tile-size<br/>    y_tile_size4 = y_tile_size // 4</span><span id="8b1f" class="ko kp hu mf b fv mn mk l ml mm"># Random start-position for the tiles on the x-axis.<br/>    # The random value is between -3/4 and -1/4 of the tile-size.<br/>    # This is so the border-tiles are at least 1/4 of the tile-size,<br/>    # otherwise the tiles may be too small which creates noisy gradients.<br/>    x_start = random.randint(-3*x_tile_size4, -x_tile_size4)</span><span id="e44c" class="ko kp hu mf b fv mn mk l ml mm">while x_start &lt; x_max:<br/>        # End-position for the current tile.<br/>        x_end = x_start + x_tile_size<br/>        <br/>        # Ensure the tile's start- and end-positions are valid.<br/>        x_start_lim = max(x_start, 0)<br/>        x_end_lim = min(x_end, x_max)</span><span id="d8bc" class="ko kp hu mf b fv mn mk l ml mm"># Random start-position for the tiles on the y-axis.<br/>        # The random value is between -3/4 and -1/4 of the tile-size.<br/>        y_start = random.randint(-3*y_tile_size4, -y_tile_size4)</span><span id="7adf" class="ko kp hu mf b fv mn mk l ml mm">while y_start &lt; y_max:<br/>            # End-position for the current tile.<br/>            y_end = y_start + y_tile_size</span><span id="2b31" class="ko kp hu mf b fv mn mk l ml mm"># Ensure the tile's start- and end-positions are valid.<br/>            y_start_lim = max(y_start, 0)<br/>            y_end_lim = min(y_end, y_max)</span><span id="7075" class="ko kp hu mf b fv mn mk l ml mm"># Get the image-tile.<br/>            img_tile = image[x_start_lim:x_end_lim,<br/>                             y_start_lim:y_end_lim, :]</span><span id="f572" class="ko kp hu mf b fv mn mk l ml mm"># Create a feed-dict with the image-tile.<br/>            feed_dict = model.create_feed_dict(image=img_tile)</span><span id="b8cd" class="ko kp hu mf b fv mn mk l ml mm"># Use TensorFlow to calculate the gradient-value.<br/>            g = session.run(gradient, feed_dict=feed_dict)</span><span id="b1a4" class="ko kp hu mf b fv mn mk l ml mm"># Normalize the gradient for the tile. This is<br/>            # necessary because the tiles may have very different<br/>            # values. Normalizing gives a more coherent gradient.<br/>            g /= (np.std(g) + 1e-8)</span><span id="3f80" class="ko kp hu mf b fv mn mk l ml mm"># Store the tile's gradient at the appropriate location.<br/>            grad[x_start_lim:x_end_lim,<br/>                 y_start_lim:y_end_lim, :] = g<br/>            <br/>            # Advance the start-position for the y-axis.<br/>            y_start = y_end</span><span id="97af" class="ko kp hu mf b fv mn mk l ml mm"># Advance the start-position for the x-axis.<br/>        x_start = x_end</span><span id="99a0" class="ko kp hu mf b fv mn mk l ml mm">return grad</span></pre><h1 id="0efb" class="mo kp hu bd kq mp mq mr ku ms mt mu ky mv mw mx lb my mz na le nb nc nd lh ne dt translated">ä¼˜åŒ–å›¾åƒ</h1><p id="4afa" class="pw-post-body-paragraph jc jd hu je b jf lj jh ji jj lk jl jm jn ll jp jq jr lm jt ju jv ln jx jy jb hn dt translated">è¿™ä¸ªå‡½æ•°æ˜¯DeepDreamç®—æ³•çš„ä¸»è¦ä¼˜åŒ–å¾ªç¯ã€‚å®ƒè®¡ç®—åˆå§‹æ¨¡å‹çš„ç»™å®šå±‚ç›¸å¯¹äºè¾“å…¥å›¾åƒçš„æ¢¯åº¦ã€‚ç„¶åå°†æ¢¯åº¦æ·»åŠ åˆ°è¾“å…¥å›¾åƒï¼Œä»è€Œå¢åŠ å±‚å¼ é‡çš„å¹³å‡å€¼ã€‚è¿™ä¸ªè¿‡ç¨‹è¢«é‡å¤å¤šæ¬¡ï¼Œå¹¶ä¸”æ”¾å¤§äº†åˆå§‹æ¨¡å‹åœ¨è¾“å…¥å›¾åƒä¸­çœ‹åˆ°çš„ä»»ä½•æ¨¡å¼ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="03c3" class="ko kp hu mf b fv mj mk l ml mm"><strong class="mf hv">def</strong> optimize_image(layer_tensor, image,<br/>                   num_iterations=10, step_size=3.0, tile_size=400,<br/>                   show_gradient=<strong class="mf hv">False</strong>):<br/>    <em class="nf">"""</em><br/><em class="nf">    Use gradient ascent to optimize an image so it maximizes the</em><br/><em class="nf">    mean value of the given layer_tensor.</em><br/><em class="nf">    </em><br/><em class="nf">    Parameters:</em><br/><em class="nf">    layer_tensor: Reference to a tensor that will be maximized.</em><br/><em class="nf">    image: Input image used as the starting point.</em><br/><em class="nf">    num_iterations: Number of optimization iterations to perform.</em><br/><em class="nf">    step_size: Scale for each step of the gradient ascent.</em><br/><em class="nf">    tile_size: Size of the tiles when calculating the gradient.</em><br/><em class="nf">    show_gradient: Plot the gradient in each iteration.</em><br/><em class="nf">    """</em><br/><br/>    <em class="nf"># Copy the image so we don't overwrite the original image.</em><br/>    img = image.copy()<br/>    <br/>    print("Image before:")<br/>    plot_image(img)<br/><br/>    print("Processing image: ", end="")<br/><br/>    <em class="nf"># Use TensorFlow to get the mathematical function for the</em><br/>    <em class="nf"># gradient of the given layer-tensor with regard to the</em><br/>    <em class="nf"># input image. This may cause TensorFlow to add the same</em><br/>    <em class="nf"># math-expressions to the graph each time this function is called.</em><br/>    <em class="nf"># It may use a lot of RAM and could be moved outside the function.</em><br/>    gradient = model.get_gradient(layer_tensor)<br/>    <br/>    <strong class="mf hv">for</strong> i <strong class="mf hv">in</strong> range(num_iterations):<br/>        <em class="nf"># Calculate the value of the gradient.</em><br/>        <em class="nf"># This tells us how to change the image so as to</em><br/>        <em class="nf"># maximize the mean of the given layer-tensor.</em><br/>        grad = tiled_gradient(gradient=gradient, image=img)<br/>        <br/>        <em class="nf"># Blur the gradient with different amounts and add</em><br/>        <em class="nf"># them together. The blur amount is also increased</em><br/>        <em class="nf"># during the optimization. This was found to give</em><br/>        <em class="nf"># nice, smooth images. You can try and change the formulas.</em><br/>        <em class="nf"># The blur-amount is called sigma (0=no blur, 1=low blur, etc.)</em><br/>        <em class="nf"># We could call gaussian_filter(grad, sigma=(sigma, sigma, 0.0))</em><br/>        <em class="nf"># which would not blur the colour-channel. This tends to</em><br/>        <em class="nf"># give psychadelic / pastel colours in the resulting images.</em><br/>        <em class="nf"># When the colour-channel is also blurred the colours of the</em><br/>        <em class="nf"># input image are mostly retained in the output image.</em><br/>        sigma = (i * 4.0) / num_iterations + 0.5<br/>        grad_smooth1 = gaussian_filter(grad, sigma=sigma)<br/>        grad_smooth2 = gaussian_filter(grad, sigma=sigma*2)<br/>        grad_smooth3 = gaussian_filter(grad, sigma=sigma*0.5)<br/>        grad = (grad_smooth1 + grad_smooth2 + grad_smooth3)<br/><br/>        <em class="nf"># Scale the step-size according to the gradient-values.</em><br/>        <em class="nf"># This may not be necessary because the tiled-gradient</em><br/>        <em class="nf"># is already normalized.</em><br/>        step_size_scaled = step_size / (np.std(grad) + 1e-8)<br/><br/>        <em class="nf"># Update the image by following the gradient.</em><br/>        img += grad * step_size_scaled<br/><br/>        <strong class="mf hv">if</strong> show_gradient:<br/>            <em class="nf"># Print statistics for the gradient.</em><br/>            msg = "Gradient min: <strong class="mf hv">{0:&gt;9.6f}</strong>, max: <strong class="mf hv">{1:&gt;9.6f}</strong>, stepsize: <strong class="mf hv">{2:&gt;9.2f}</strong>"<br/>            print(msg.format(grad.min(), grad.max(), step_size_scaled))<br/><br/>            <em class="nf"># Plot the gradient.</em><br/>            plot_gradient(grad)<br/>        <strong class="mf hv">else</strong>:<br/>            <em class="nf"># Otherwise show a little progress-indicator.</em><br/>            print(". ", end="")<br/><br/>    print()<br/>    print("Image after:")<br/>    plot_image(img)<br/>    <br/>    <strong class="mf hv">return</strong> img</span></pre><h1 id="37c1" class="mo kp hu bd kq mp mq mr ku ms mt mu ky mv mw mx lb my mz na le nb nc nd lh ne dt translated">é€’å½’å›¾åƒä¼˜åŒ–</h1><p id="9f47" class="pw-post-body-paragraph jc jd hu je b jf lj jh ji jj lk jl jm jn ll jp jq jr lm jt ju jv ln jx jy jb hn dt translated">åˆå§‹æ¨¡å‹æ˜¯åœ¨ç›¸å½“å°çš„å›¾åƒä¸Šè®­ç»ƒçš„ã€‚ç¡®åˆ‡çš„å¤§å°è¿˜ä¸æ¸…æ¥šï¼Œä½†æ¯ä¸ªç»´åº¦å¯èƒ½æœ‰200-300ä¸ªåƒç´ ã€‚å¦‚æœæˆ‘ä»¬ä½¿ç”¨æ›´å¤§çš„å›¾åƒï¼Œæ¯”å¦‚1920x1080åƒç´ ï¼Œé‚£ä¹ˆä¸Šé¢çš„<code class="eh ng nh ni mf b">optimize_image()</code>å‡½æ•°ä¼šç»™å›¾åƒæ·»åŠ è®¸å¤šå°å›¾æ¡ˆã€‚</p><p id="9048" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">è¿™ä¸ªè¾…åŠ©å‡½æ•°å°†è¾“å…¥å›¾åƒç¼©å°å‡ æ¬¡ï¼Œå¹¶é€šè¿‡ä¸Šé¢çš„<code class="eh ng nh ni mf b">optimize_image()</code>å‡½æ•°è¿è¡Œæ¯ä¸ªç¼©å°çš„ç‰ˆæœ¬ã€‚è¿™å¯¼è‡´æœ€ç»ˆå›¾åƒä¸­çš„å›¾æ¡ˆæ›´å¤§ã€‚è¿™ä¹ŸåŠ å¿«äº†è®¡ç®—é€Ÿåº¦ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="169a" class="ko kp hu mf b fv mj mk l ml mm">def recursive_optimize(layer_tensor, image,<br/>                       num_repeats=4, rescale_factor=0.7, blend=0.2,<br/>                       num_iterations=10, step_size=3.0,<br/>                       tile_size=400):<br/>    """<br/>    Recursively blur and downscale the input image.<br/>    Each downscaled image is run through the optimize_image()<br/>    function to amplify the patterns that the Inception model sees.</span><span id="90ea" class="ko kp hu mf b fv mn mk l ml mm">Parameters:<br/>    image: Input image used as the starting point.<br/>    rescale_factor: Downscaling factor for the image.<br/>    num_repeats: Number of times to downscale the image.<br/>    blend: Factor for blending the original and processed images.</span><span id="1b96" class="ko kp hu mf b fv mn mk l ml mm">Parameters passed to optimize_image():<br/>    layer_tensor: Reference to a tensor that will be maximized.<br/>    num_iterations: Number of optimization iterations to perform.<br/>    step_size: Scale for each step of the gradient ascent.<br/>    tile_size: Size of the tiles when calculating the gradient.<br/>    """</span><span id="3c14" class="ko kp hu mf b fv mn mk l ml mm"># Do a recursive step?<br/>    if num_repeats&gt;0:<br/>        # Blur the input image to prevent artifacts when downscaling.<br/>        # The blur amount is controlled by sigma. Note that the<br/>        # colour-channel is not blurred as it would make the image gray.<br/>        sigma = 0.5<br/>        img_blur = gaussian_filter(image, sigma=(sigma, sigma, 0.0))</span><span id="bd45" class="ko kp hu mf b fv mn mk l ml mm"># Downscale the image.<br/>        img_downscaled = resize_image(image=img_blur,<br/>                                      factor=rescale_factor)<br/>            <br/>        # Recursive call to this function.<br/>        # Subtract one from num_repeats and use the downscaled image.<br/>        img_result = recursive_optimize(layer_tensor=layer_tensor,<br/>                                        image=img_downscaled,<br/>                                        num_repeats=num_repeats-1,<br/>                                        rescale_factor=rescale_factor,<br/>                                        blend=blend,<br/>                                        num_iterations=num_iterations,<br/>                                        step_size=step_size,<br/>                                        tile_size=tile_size)<br/>        <br/>        # Upscale the resulting image back to its original size.<br/>        img_upscaled = resize_image(image=img_result, size=image.shape)</span><span id="a8c9" class="ko kp hu mf b fv mn mk l ml mm"># Blend the original and processed images.<br/>        image = blend * image + (1.0 - blend) * img_upscaled</span><span id="b13a" class="ko kp hu mf b fv mn mk l ml mm">print("Recursive level:", num_repeats)</span><span id="8326" class="ko kp hu mf b fv mn mk l ml mm"># Process the image using the DeepDream algorithm.<br/>    img_result = optimize_image(layer_tensor=layer_tensor,<br/>                                image=image,<br/>                                num_iterations=num_iterations,<br/>                                step_size=step_size,<br/>                                tile_size=tile_size)<br/>    <br/>    return img_result</span></pre><h1 id="433a" class="mo kp hu bd kq mp mq mr ku ms mt mu ky mv mw mx lb my mz na le nb nc nd lh ne dt translated">å¼ é‡æµä¼šè¯</h1><p id="5298" class="pw-post-body-paragraph jc jd hu je b jf lj jh ji jj lk jl jm jn ll jp jq jr lm jt ju jv ln jx jy jb hn dt translated">æˆ‘ä»¬éœ€è¦ä¸€ä¸ªTensorFlowä¼šè¯æ¥æ‰§è¡Œå›¾è¡¨ã€‚è¿™æ˜¯ä¸€ä¸ªäº’åŠ¨çš„ä¼šè®®ï¼Œæ‰€ä»¥æˆ‘ä»¬å¯ä»¥ç»§ç»­æ·»åŠ æ¢¯åº¦å‡½æ•°åˆ°è®¡ç®—å›¾ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="ab62" class="ko kp hu mf b fv mj mk l ml mm">session = tf.InteractiveSession(graph=model.graph)</span></pre><p id="bf21" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">æ˜¯æ—¶å€™è¿è¡Œç®—æ³•äº†</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="87b5" class="ko kp hu mf b fv mj mk l ml mm">#load the image which you want to process<br/>image=load_image(filename='test_output/test_output_11.jpg')<br/>plot_image(image)</span><span id="7b86" class="ko kp hu mf b fv mn mk l ml mm"># the size of the image is :<br/># JPEG (780, 1040)</span></pre><figure class="lp lq lr ls fq lt fe ff paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="fe ff nj"><img src="../Images/50067c29dc5b4fae95eeb0bd8f676064.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*333UZR6Lmc_-xjnBSVtf1A.jpeg"/></div></div><figcaption class="ma mb fg fe ff mc md bd b be z ek">Image 2 : Thatâ€™s me few years back</figcaption></figure><p id="f838" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">é¦–å…ˆï¼Œæˆ‘ä»¬éœ€è¦åœ¨ç›—æ¢¦æ¨¡å‹ä¸­å¼•ç”¨å¼ é‡ï¼Œæˆ‘ä»¬å°†åœ¨DeepDreamä¼˜åŒ–ç®—æ³•ä¸­æœ€å¤§åŒ–å®ƒã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬é€‰æ‹©åˆå§‹æ¨¡å‹çš„æ•´ä¸ªç¬¬ä¸‰å±‚(å±‚ç´¢å¼•2)ã€‚å®ƒæœ‰192ä¸ªé¢‘é“ï¼Œæˆ‘ä»¬å°†å°è¯•æœ€å¤§åŒ–æ‰€æœ‰è¿™äº›é¢‘é“çš„å¹³å‡å€¼ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="1334" class="ko kp hu mf b fv mj mk l ml mm">layer_tensor = model.layer_tensors[2]<br/>layer_tensor</span><span id="bd73" class="ko kp hu mf b fv mn mk l ml mm"># &lt;tf.Tensor 'conv2d2:0' shape=(?, ?, ?, 192) dtype=float32&gt;</span></pre><p id="e404" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">é€’å½’åº”ç”¨æ·±åº¦æ¢¦ç®—æ³•ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="8d36" class="ko kp hu mf b fv mj mk l ml mm">img_result = recursive_optimize(layer_tensor=layer_tensor, image=image,<br/>                 num_iterations=10, step_size=3.0, rescale_factor=0.7,<br/>                 num_repeats=4, blend=0.2)</span></pre><figure class="lp lq lr ls fq lt fe ff paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="fe ff nj"><img src="../Images/a75eb4b99a85984fe5d8879b7c74f6e7.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*6V_LrSlnSrbQKTv-dxrQFw.jpeg"/></div></div><figcaption class="ma mb fg fe ff mc md bd b be z ek">Image 3: After applying Deep Dream to my image</figcaption></figure><p id="7876" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">ç°åœ¨æˆ‘ä»¬å°†åœ¨åˆå§‹æ¨¡å‹ä¸­æœ€å¤§åŒ–ä¸€ä¸ªæ›´é«˜å±‚ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œå®ƒæ˜¯ç¬¬7å±‚(ç´¢å¼•6)ã€‚è¯¥å±‚è¯†åˆ«è¾“å…¥å›¾åƒä¸­æ›´å¤æ‚çš„å½¢çŠ¶ï¼Œå› æ­¤DeepDreamç®—æ³•å°†äº§ç”Ÿæ›´å¤æ‚çš„å›¾åƒã€‚è¿™ä¸€å±‚ä¼¼ä¹åœ¨è¯†åˆ«ç‹—è„¸å’Œçš®æ¯›ï¼Œå› æ­¤DeepDreamç®—æ³•å°†å®ƒä»¬æ·»åŠ åˆ°äº†å›¾åƒä¸­ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="d515" class="ko kp hu mf b fv mj mk l ml mm">layer_tensor = model.layer_tensors[6]<br/>img_result = recursive_optimize(layer_tensor=layer_tensor, image=image,<br/>                 num_iterations=10, step_size=3.0, rescale_factor=0.7,<br/>                 num_repeats=4, blend=0.2)</span></pre><figure class="lp lq lr ls fq lt fe ff paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="fe ff nk"><img src="../Images/2352cba9b1de53152364cd1c56dfa5eb.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*yIvD7-4rYPa5uxGovtpGFw.jpeg"/></div></div><figcaption class="ma mb fg fe ff mc md bd b be z ek">Image 4: After applying Deep Dream Algorithm</figcaption></figure><p id="9934" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">è¿™æ˜¯ä¸€ä¸ªä½¿ç”¨DeepDreamç®—æ³•ä»…æœ€å¤§åŒ–å›¾å±‚è¦ç´ é€šé“å­é›†çš„ç¤ºä¾‹ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œç´¢å¼•ä¸º10çš„å±‚å’Œåªæœ‰å…¶å‰3ä¸ªç‰¹å¾é€šé“è¢«æœ€å¤§åŒ–ã€‚</p><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="1916" class="ko kp hu mf b fv mj mk l ml mm">layer_tensor = model.layer_tensors[10][:,:,:,0:3]<br/>img_result = recursive_optimize(layer_tensor=layer_tensor, image=image,<br/>                 num_iterations=10, step_size=3.0, rescale_factor=0.7,<br/>                 num_repeats=4, blend=0.2)</span></pre><figure class="lp lq lr ls fq lt fe ff paragraph-image"><div class="fe ff nl"><img src="../Images/7c2276d69d28aa978cd966e0bd6e28f3.png" data-original-src="https://miro.medium.com/v2/resize:fit:1320/format:webp/1*IwugQk8YCw5ynt5lOC_Zuw.jpeg"/></div><figcaption class="ma mb fg fe ff mc md bd b be z ek">Image 5: After applying Deep Dream Algorithm</figcaption></figure><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="ff6a" class="ko kp hu mf b fv mj mk l ml mm">layer_tensor = model.layer_tensors[4]<br/>img_result = recursive_optimize(layer_tensor=layer_tensor, image=image,<br/>                 num_iterations=10, step_size=3.0, rescale_factor=0.7,<br/>                 num_repeats=4, blend=0.2)</span></pre><figure class="lp lq lr ls fq lt fe ff paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="fe ff nm"><img src="../Images/78fa52338713d33d44f2d4aa65795887.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*QcvBkMFn-IO2yZvwwiw64w.jpeg"/></div></div><figcaption class="ma mb fg fe ff mc md bd b be z ek">Image 6: After applying Deep Dream Algorithm</figcaption></figure><pre class="lp lq lr ls fq me mf mg mh aw mi dt"><span id="278a" class="ko kp hu mf b fv mj mk l ml mm"># To save the final Output</span><span id="fca9" class="ko kp hu mf b fv mn mk l ml mm">image_save=save_image(img_result,"test_output/test_output_12.jpg")</span></pre><p id="87bd" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">å¦‚æœè¿™è¿˜ä¸å¤Ÿï¼Œæˆ‘åœ¨YouTubeä¸Šä¸Šä¼ äº†ä¸€ä¸ªè§†é¢‘ï¼Œå®ƒå°†è¿›ä¸€æ­¥æ‰©å±•ä½ çš„è¿·å¹»ä½“éªŒã€‚</p><figure class="lp lq lr ls fq lt"><div class="bz el l di"><div class="nn no l"/></div></figure><p id="533d" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">ç»“è®º:å°±æ˜¯è¿™æ ·ï¼Œè¿™ç¯‡æ–‡ç« å‘ä½ å±•ç¤ºäº†å¦‚ä½•ä½¿ç”¨å¼ é‡æµå’Œä¸€äº›æ¦‚å¿µï¼Œä½ ä¹Ÿå¯ä»¥è‡ªå·±åˆ›é€ ä¸€ä¸ªæ·±åˆ»çš„æ¢¦å¢ƒä½“éªŒã€‚</p><p id="9eaf" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">ç‰¹åˆ«è¯´æ˜:å¦‚æœæ²¡æœ‰Magnus Erik Hvass Pedersené€šè¿‡ä»–è‘—åçš„TensorFlowæ•™ç¨‹ç»™å‡ºçš„æŒ‡å¯¼ï¼Œè¿™ç¯‡æ–‡ç« æ˜¯ä¸å¯èƒ½å®Œæˆçš„ã€‚GitHubåº“å¯ä»¥åœ¨è¿™é‡Œæ‰¾åˆ°<a class="ae kn" href="https://github.com/Hvass-Labs" rel="noopener ugc nofollow" target="_blank"/>ã€‚</p><p id="498f" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">èµ„æº:</p><ol class=""><li id="83c2" class="np nq hu je b jf ki jj kj jn nr jr ns jv nt jb nu nv nw nx dt translated">å¯¹äº<strong class="je hv"> GitHub </strong>åº“ç‚¹å‡»<a class="ae kn" href="https://github.com/ElephantHunters/Deep-Dream-using-Tensorflow" rel="noopener ugc nofollow" target="_blank">è¿™é‡Œ</a>ã€‚</li><li id="1be4" class="np nq hu je b jf ny jj nz jn oa jr ob jv oc jb nu nv nw nx dt translated">ä¸ºäº†å¢åŠ å¯¹æ·±å±‚æ¢¦æƒ³çš„ç†è§£ï¼Œè¯·é˜…è¯»è°·æ­Œç ”ç©¶åšå®¢æ–‡ç« ã€‚</li></ol><figure class="lp lq lr ls fq lt fe ff paragraph-image"><div role="button" tabindex="0" class="lu lv di lw bf lx"><div class="fe ff od"><img src="../Images/4f3fa3da2f3b53eea7f6967651ff8176.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*S0Yy7saEymxsZADJsrhBVw.jpeg"/></div></div></figure><p id="26ca" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated"><strong class="je hv">æ„Ÿè°¢æ‚¨çš„å…³æ³¨</strong></p><p id="4bda" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">ä½ ç”¨<em class="nf">ä½ çš„</em>æ—¶é—´æ¥é˜…è¯»<em class="nf">æˆ‘çš„</em>å·¥ä½œå¯¹æˆ‘æ¥è¯´æ„å‘³ç€ä¸€åˆ‡ã€‚æˆ‘å®Œå…¨æ˜¯è¿™ä¸ªæ„æ€ã€‚</p><p id="89c9" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">å¦‚æœä½ å–œæ¬¢è¿™ä¸ªæ•…äº‹ï¼Œç–¯ç‹‚é¼“æŒå§ğŸ‘<strong class="je hv"> ) </strong>æŒ‰é’®ï¼è¿™å°†æœ‰åŠ©äºå…¶ä»–äººæ‰¾åˆ°æˆ‘çš„å·¥ä½œã€‚</p><p id="5f85" class="pw-post-body-paragraph jc jd hu je b jf ki jh ji jj kj jl jm jn kk jp jq jr kl jt ju jv km jx jy jb hn dt translated">æ­¤å¤–ï¼Œå¦‚æœä½ æ„¿æ„ï¼Œå¯ä»¥åœ¨Mediumã€LinkedInæˆ–Twitterä¸Šå…³æ³¨æˆ‘ï¼æˆ‘å¾ˆä¹æ„ã€‚</p><div class="oe of fm fo og oh"><a rel="noopener follow" target="_blank" href="/@naveenmanwani"><div class="oi ab ej"><div class="oj ab ok cl cj ol"><h2 class="bd hv fv z el om eo ep on er et ht dt translated">çº³æ–‡Â·æ›¼ç“¦å°¼åŸ¹å…»åŸº</h2><div class="oo l"><h3 class="bd b fv z el om eo ep on er et ek translated">é˜…è¯»çº³æ–‡Â·æ›¼ç“¦å°¼åœ¨åª’ä»‹ä¸Šçš„ä½œå“ã€‚ä¸€ä¸ªæœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆï¼Œä¸€ä¸ªæ·±åº¦å­¦ä¹ çˆ±å¥½è€…|è°·æ­Œå°åº¦â€¦</h3></div><div class="op l"><p class="bd b gc z el om eo ep on er et ek translated">medium.com</p></div></div><div class="oq l"><div class="or l os ot ou oq ov ly oh"/></div></div></a></div><div class="oe of fm fo og oh"><a href="https://www.linkedin.com/in/naveen-manwani-65491678/" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab ej"><div class="oj ab ok cl cj ol"><h2 class="bd hv fv z el om eo ep on er et ht dt translated">Naveen Manwani -æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ- AIMonk Labs Private Ltd | LinkedIn</h2><div class="oo l"><h3 class="bd b fv z el om eo ep on er et ek translated">æŸ¥çœ‹çº³æ–‡Â·æ›¼ç“¦å°¼åœ¨å…¨çƒæœ€å¤§çš„èŒä¸šç¤¾åŒºLinkedInä¸Šçš„ä¸ªäººèµ„æ–™ã€‚Naveenæœ‰ä¸€ä»½å·¥ä½œåˆ—åœ¨ä»–ä»¬çš„â€¦</h3></div><div class="op l"><p class="bd b gc z el om eo ep on er et ek translated">www.linkedin.com</p></div></div><div class="oq l"><div class="ow l os ot ou oq ov ly oh"/></div></div></a></div><div class="oe of fm fo og oh"><a href="https://twitter.com/NaveenManwani17" rel="noopener  ugc nofollow" target="_blank"><div class="oi ab ej"><div class="oj ab ok cl cj ol"><h2 class="bd hv fv z el om eo ep on er et ht dt translated">çº³æ–‡Â·æ›¼ç“¦å°¼(@çº³æ–‡Â·æ›¼ç“¦å°¼17) |æ¨ç‰¹</h2><div class="oo l"><h3 class="bd b fv z el om eo ep on er et ek translated">çº³æ–‡Â·æ›¼ç“¦å°¼çš„æœ€æ–°æ¨æ–‡(@çº³æ–‡Â·æ›¼ç“¦å°¼17)ã€‚æœºå™¨å­¦ä¹ å·¥ç¨‹å¸ˆ@ AIMONK Labs Pvt ltdï¼Œæ·±â€¦</h3></div><div class="op l"><p class="bd b gc z el om eo ep on er et ek translated">twitter.com</p></div></div><div class="oq l"><div class="ox l os ot ou oq ov ly oh"/></div></div></a></div></div></div>    
</body>
</html>