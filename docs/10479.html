<html>
<head>
<title>Traffic Sign Classification</title>
<link href="../Styles/Style.css" type="text/css" rel="stylesheet"/>
</head>
<body>
<h1 class="translated">交通标志分类</h1>
<blockquote>原文：<a href="https://medium.com/hackernoon/traffic-sign-classification-6e7113d9c4d5?source=collection_archive---------20-----------------------#2018-12-31">https://medium.com/hackernoon/traffic-sign-classification-6e7113d9c4d5?source=collection_archive---------20-----------------------#2018-12-31</a></blockquote><div><div class="ef hi hj hk hl hm"/><div class="hn ho hp hq hr"><div class=""/><p id="f561" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">刚刚结束在NYU的一个学期，我想我应该分享我的一个更有趣的家庭作业的结果。顾名思义，这将是在<a class="ae jp" href="http://benchmark.ini.rub.de/" rel="noopener ugc nofollow" target="_blank">http://benchmark.ini.rub.de/</a>发现的又一个关于交通标志分类比赛的帖子。</p><p id="f78f" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">关于背景，我目前正在NYU大学攻读硕士学位。像那里的许多其他学生一样，我抓住机会参加了由著名教授Rob Fergus讲授的计算机视觉课程。</p><p id="2866" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">酷，但是是什么让这个作业比其他教授的作业更有趣呢？这项家庭作业是以卡格尔竞赛的形式进行的。你在私人排行榜上的排名越高，你的等级就越高。</p><p id="57ae" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">对于那些不知道Kaggle上的私人排行榜是什么的人来说，Kaggle比赛中有两个不同的排行榜。公共排行榜和私人排行榜。比赛开始时，所有提交的作品都会显示在公共排行榜上。这个排名是基于你在50%的测试数据中的得分。比赛结束后，将根据另外50%的测试数据计算出您的分数，并在私人排行榜上对您进行排名。很明显，你没有被告知哪个排行榜用的是什么数据。这是为了防止您过度拟合测试数据。</p><p id="0ac8" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">获得及格分数的要求是测试数据的准确率至少达到90%。为了实现这个里程碑，我从一个简单的卷积神经网络和一个天真选择的验证集开始。每个交通标志都有不同的图像，拍摄位置不同，光线也不同。我为每个交通标志取了前三种类型的图像，并将它们移动到不同的目录中作为验证集。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff jq"><img src="../Images/afbe239884380e1994ce91af6580b9a5.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*GS__aSMeD-pPTYKXbOCb_g.png"/></div></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">Representation of CNN architecture used. 2 conv layers followed by 2 linear layers. Not sure how people draw their beautiful network architecture diagrams… I used <a class="ae jp" href="http://alexlenail.me/NN-SVG/LeNet.html" rel="noopener ugc nofollow" target="_blank">http://alexlenail.me/NN-SVG/LeNet.html</a>.</figcaption></figure><pre class="jr js jt ju fq kg kh ki kj aw kk dt"><span id="9577" class="kl km hu kh b fv kn ko l kp kq">nclasses = 43</span><span id="33dd" class="kl km hu kh b fv kr ko l kp kq">class BaseNet(nn.Module):<br/>    def __init__(self):<br/>        super(BaseNet, self).__init__()<br/>        self.conv1 = nn.Conv2d(3, 10, kernel_size=5)<br/>        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)<br/>        self.conv2_drop = nn.Dropout2d()</span><span id="c7df" class="kl km hu kh b fv kr ko l kp kq">        self.fc1 = nn.Linear(500, 50)<br/>        self.fc2 = nn.Linear(50, nclasses)</span><span id="a503" class="kl km hu kh b fv kr ko l kp kq">    def forward(self, x):<br/>        x = F.relu(F.max_pool2d(self.conv1(x), 2))<br/>        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))</span><span id="1e92" class="kl km hu kh b fv kr ko l kp kq">        x = x.view(-1, 500)<br/>        x = F.relu(self.fc1(x))<br/>        x = F.dropout(x, training=self.training)</span><span id="ab1b" class="kl km hu kh b fv kr ko l kp kq">        x = self.fc2(x)<br/>        return F.log_softmax(x)</span></pre><p id="ea88" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">第一个网络由两个卷积层和两个线性层组成。我使用了一个步长调度器，在每5个周期后将学习速率衰减0.1。这个简单的模型令人惊讶地能够在25个时期后达到89%的准确度。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff ks"><img src="../Images/25b9e9d97857d7c4c2bb6c64f19da6d6.png" data-original-src="https://miro.medium.com/v2/resize:fit:642/format:webp/1*ZPgud9sbF1FEtjyHCOn_lQ.png"/></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">Validation accuracy values after running for 25 epochs.</figcaption></figure><p id="2884" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">不幸的是，为更多的时期训练该模型看起来不会有任何好处，因为我们可以从验证损失值的图表中看到，损失值已经稳定下来。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff kt"><img src="../Images/a5d286b222d9bf069598fcb3cf466c6d.png" data-original-src="https://miro.medium.com/v2/resize:fit:618/format:webp/1*qKp8uXsfz_Oc5iLqBdAtlw.png"/></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">Validation losses for a 25 epoch run on the simple CNN model.</figcaption></figure><p id="52e5" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">由于这只是害羞的90%的准确性目标，我想为什么不增加几个卷积层和另一个线性层。见鬼，让我们扔在一些批处理规范化和辍学层，以防止任何过度拟合问题在这个游戏早期。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff ku"><img src="../Images/a7260e09fa01558e4288c58173e8f5ca.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*IN1K7SDIKdOtPjuJcQ9iTw.png"/></div></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">New CNN model with batch normalization and dropouts added between conv layers.</figcaption></figure><p id="8be2" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">我添加了2个conv层和1个线性层。我还在第二层和第四层conv图层后添加了批量归一化和剔除。在第一个和第二个线性图层之后也插入了批量标准化。</p><pre class="jr js jt ju fq kg kh ki kj aw kk dt"><span id="249b" class="kl km hu kh b fv kn ko l kp kq">nclasses = 43</span><span id="5ba2" class="kl km hu kh b fv kr ko l kp kq">class DeepNet(nn.Module):    <br/>    def __init__(self):        <br/>        super(DeepNet, self).__init__()        <br/>        self.conv1 = nn.Conv2d(3, 32, kernel_size=3)           <br/>        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)        <br/>        self.conv_bn1 = nn.BatchNorm2d(64)        <br/>        self.conv2_drop = nn.Dropout2d()<br/>         <br/>        self.conv3 = nn.Conv2d(64, 128, kernel_size=3)        <br/>        self.conv4 = nn.Conv2d(128, 256, kernel_size=3)        <br/>        self.conv_bn2 = nn.BatchNorm2d(256)        <br/>        self.conv4_drop = nn.Dropout2d()<br/>         <br/>        self.fc1 = nn.Linear(6400, 512)        <br/>        self.fc1_bn = nn.BatchNorm1d(512)<br/>         <br/>        self.fc2 = nn.Linear(512, 512)        <br/>        self.fc2_bn = nn.BatchNorm1d(512)<br/>         <br/>        self.fc3 = nn.Linear(512, nclasses)     </span><span id="0f64" class="kl km hu kh b fv kr ko l kp kq">    def forward(self, x):        <br/>        x = self.conv1(x)        <br/>        x = F.relu(F.max_pool2d(<br/>                  self.conv2_drop(self.conv_bn1(self.conv2(x))), 2))<br/>         <br/>        x = self.conv3(x)        <br/>        x = F.relu(F.max_pool2d(self.conv4_drop(            <br/>                                self.conv_bn2(self.conv4(x))), 2))<br/>         <br/>        x = x.view(-1, self.num_flat_features(x))<br/>         <br/>        x = F.relu(self.fc1_bn(self.fc1(x)))        <br/>        x = F.dropout(x, training=self.training)<br/>         <br/>        x = F.relu(self.fc2_bn(self.fc2(x)))        <br/>        x = F.dropout(x, training=self.training)<br/>         <br/>        x = self.fc3(x)        <br/>        return F.log_softmax(x)     </span><span id="ec31" class="kl km hu kh b fv kr ko l kp kq">    def num_flat_features(self, x):        <br/>        size = x.size()[1:]        <br/>        num_features = 1        <br/>        for s in size:            <br/>            num_features *= s        <br/>        return num_features</span></pre><p id="b85b" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">运行这个模型25个时期，然后让我达到96%的验证准确率！这只是一个由一堆卷积层和线性层拼凑而成的模型。它应该让你想知道在网络上可以实现的性能，这些网络已经被证明在像ImageNet这样复杂得多的数据集上表现良好。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff kv"><img src="../Images/ef4cbb8cb98d0295edc2ca9f0d595d02.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*FLQwOelqZ4ZkpTLMM5PZHQ.png"/></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">Validation accuracy after 25 epochs with deeper CNN.</figcaption></figure><p id="9e2e" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">现在是拿出大枪的时候了。由于我能够用这样一个简单的网络达到96%的准确率，我认为没有必要使用像ResNet152这样的东西。事实上，我很确定这样规模的网络会有严重的过度拟合问题。我选择了较小的ResNet18。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div role="button" tabindex="0" class="jw jx di jy bf jz"><div class="fe ff kw"><img src="../Images/ee86344500603600c3d5a03384b0fc7e.png" data-original-src="https://miro.medium.com/v2/resize:fit:1400/format:webp/1*uJ0IrP9JXYE2hHAzMjorQA.png"/></div></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">ResNet18, image found on Google images.</figcaption></figure><pre class="jr js jt ju fq kg kh ki kj aw kk dt"><span id="15c4" class="kl km hu kh b fv kn ko l kp kq">nclasses = 43</span><span id="67f1" class="kl km hu kh b fv kr ko l kp kq">class ResNet(nn.Module):    <br/>    def __init__(self):        <br/>        super(ResNet, self).__init__()        <br/>        self.resnet = resnet18()        <br/>        self.resnet.fc = nn.Linear(512, nclasses)     </span><span id="9471" class="kl km hu kh b fv kr ko l kp kq">    def forward(self, x):        <br/>        x = self.resnet(x)        <br/>        return F.log_softmax(x)</span></pre><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff kx"><img src="../Images/31724706cf2a21988f1bf3c3c878d845.png" data-original-src="https://miro.medium.com/v2/resize:fit:626/format:webp/1*dLQQXBhZse8H4T9nBXpTBw.png"/></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">Training accuracy using ResNet18.</figcaption></figure><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff kv"><img src="../Images/9e8dc6800a8f851182309509c639f46f.png" data-original-src="https://miro.medium.com/v2/resize:fit:644/format:webp/1*r0NbdaoPWF4hrO-wRPNScA.png"/></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">Validation accuracy using ResNet18.</figcaption></figure><p id="6469" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">这使我在运行25个时期后，对3870个交通标志中的3798个交通标志进行了98%的正确分类。正如我们从图表中看到的，训练精度为100%,因此即使我们运行它更多的时期，我们也可能不会从该模型中获得更多的精度。</p><p id="7082" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">由于训练精度为100%，因此可以安全地假设模型过度拟合了训练集，因此没有达到更高的验证精度。在这一点上，有必要看一看一些被模型错误分类的图片。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff ky"><img src="../Images/e4ea398e7b8ff9ea009595fa762ee93c.png" data-original-src="https://miro.medium.com/v2/resize:fit:578/format:webp/1*UF91AtmJ4QeiTQyf34iR-A.png"/></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">Incorrectly classified images in the validation set.</figcaption></figure><p id="d635" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">模型最难处理的图像是光线不好或不一致的图像。我决定使用色彩抖动来随机化训练图像中的亮度。一些分类不正确的图像看起来也偏离了中心，所以我也使用RandomAffine将随机旋转、缩放和平移添加到训练图像中。这促使我使用以下转换进行数据扩充:</p><pre class="jr js jt ju fq kg kh ki kj aw kk dt"><span id="c00b" class="kl km hu kh b fv kn ko l kp kq">data_transforms = transforms.Compose([    <br/>    transforms.Resize((224, 224)),    <br/>    transforms.ColorJitter(0.8, contrast=0.4),     <br/>    transforms.RandomAffine(15, <br/>                            scale=(0.8, 1.2), <br/>                            translate=(0.2, 0.2)),    <br/>    transforms.ToTensor(),    <br/>    transforms.Normalize((0.3337, 0.3064, 0.3171), <br/>                         (0.2672, 0.2564, 0.2629))<br/>]) </span><span id="b49f" class="kl km hu kh b fv kr ko l kp kq">validation_data_transforms = transforms.Compose([      <br/>    transforms.Resize((224, 224)),      <br/>    transforms.ToTensor(),    <br/>    transforms.Normalize((0.3337, 0.3064, 0.3171), <br/>                         (0.2672, 0.2564, 0.2629))<br/>])</span></pre><p id="7a2c" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">请注意，我没有对验证图像执行随机转换。我们在训练期间执行变换，以创建训练图像的不同随机变化。这有助于增加我们的训练集大小，从而帮助我们对抗过度拟合。我们不想让我们的模型在验证过程中更难对验证图像进行分类。</p><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff kz"><img src="../Images/42936bca66e83308623c33e164e50fda.png" data-original-src="https://miro.medium.com/v2/resize:fit:636/format:webp/1*Q2m9UOvZmDzz6YEOvfDOOA.png"/></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">Training accuracy using ResNet18 with data augmentation.</figcaption></figure><figure class="jr js jt ju fq jv fe ff paragraph-image"><div class="fe ff la"><img src="../Images/482a09ff33fee922fe7d637f69ed3c8a.png" data-original-src="https://miro.medium.com/v2/resize:fit:628/format:webp/1*wFvl2qMVMZJTq37e0IasTw.png"/></div><figcaption class="kc kd fg fe ff ke kf bd b be z ek">Validation accuracy using ResNet18 with data augmentation.</figcaption></figure><p id="5276" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">验证准确率再次达到98%，尽管这一次它能够获得更多正确分类的图像。该模型能够从3870个交通标志中正确分类出3818个。为了获得提交的最终模型，我组合了训练集和验证集，以获得更多的训练数据。我加载了能够正确分类3818幅图像的模型的模型参数，并训练了3个以上的时期。提交这个最终模型给了我0.99283分。不算太坏。</p><p id="edc7" class="pw-post-body-paragraph ir is hu it b iu iv iw ix iy iz ja jb jc jd je jf jg jh ji jj jk jl jm jn jo hn dt translated">包含模型和运行训练的脚本的存储库可以在<a class="ae jp" href="https://github.com/AaronCCWong/german-traffic-sign-recognition" rel="noopener ugc nofollow" target="_blank">https://github . com/AaronCCWong/german-traffic-sign-recognition</a>找到。</p></div></div>    
</body>
</html>