# 人工智能限制

> 原文：<https://medium.com/hackernoon/artificial-intelligence-restriction-a182be021299>

![](img/190c13f44b7c158855b81d2a8531d8a8.png)

在过去的 5 年里，人工智能的发展获得了令人难以置信的速度。在 00 年代，我们甚至没有想到汽车中的自动驾驶，在智能手机摄像头中使用人工智能，以及教机器人如何后空翻(嘿，波士顿动力公司！).与此同时，更多关于限制人工智能的必要性的讨论开始出现。不仅是专业媒体的作者，就连埃隆马斯克(Elon Mask)等领先企业家也已经多次谈到这个话题。

> *“直到人们看到机器人走在街上杀人，他们都不知道该如何反应，因为这看起来太飘渺了。人工智能是一个罕见的案例，我认为我们需要主动监管，而不是被动应对。因为我认为，当我们在人工智能监管方面做出反应时，已经太晚了。”*

这听起来很有说服力，同时也很吓人。但是现在人工智能限制了自己。为了让[机器人走上街头去杀人](https://hackernoon.com/6-proofs-that-rise-of-the-machines-has-begun-f6577bb3bdd2)，它们需要克服这种束缚，这不是你能在 10 分钟内完成的事情。

![](img/022d211dc08c1adb04460b1ec57a1be0.png)

Elon Musk

人工智能是基于概率的数学。这意味着在任务执行过程中总是会有错误。许多行业不允许错误的任务执行:自动驾驶汽车、法律或医学。为了更好地理解，让我们看看自动驾驶汽车的例子——看看它们目前存在的形式。人工智能可以以 97.5%的准确率识别汽车行驶途中的物体，因此出错的可能性为 2.5%。1000 次乘坐中，25 次就可能导致车祸。因此，以如此高的误差率出租汽车等于收集脸书用户的数据，并希望没有人会注意到。这个出错概率就是人工智能的限制。如果我们更仔细地观察，我们会发现这项技术在那些不会出现错误的领域非常受欢迎:摄像头、信使和其他娱乐应用。

只有当错误的概率下降到零，人工智能才会出现在我们生活的最重要的方面。否则，这是一个不合理的风险，只有白痴才会尝试。接下来的 5-10 年将被用来克服这一限制。生活在一个我们可以创造出零出错概率的[医生的世界里，也不会太糟糕。但如果一个人决定创造一个完美的机器人，其主要功能是杀人，这个人对武器制造商来说就没什么不同了。也许我们应该专注于限制这样的人。](https://dashbouquet.com/blog/artificial-intelligence/the-change-of-healthcare-industry-and-modern-it-trends-where-do-we-stand-now)

[由罗曼·昆采维奇撰写](https://www.linkedin.com/in/roman-kuntsevich-55819515a/)