# 我们能诚实地对待道德吗？

> 原文：<https://medium.com/hackernoon/can-we-be-honest-about-ethics-ecf5840b6e07>

## 大多数道德错误来自于无法预见后果，而不是无法分辨对错。

![](img/a81a1294d02cfa8831994dd71c63c75b.png)

Data science is today roughly where medicine was in the 1900s. We can do so much, but there’s still so much we don’t know. Our thinking about ethics should acknowledge that.

想象你需要手术。你如何阻止你的医生切下并卖掉你的一个肾(或者做一些同样不道德的事情)？你似乎可以得到三种保证:

1.  有一个适当的法律体系，严厉惩罚医生的不道德行为，并有一个监管体系作为后盾，可以依靠该体系持续检测并向法律体系报告该行为。
2.  找到曾与该医生一起工作或接受过该医生手术的人，并获得他们对他或她的职业道德的评估。
3.  相信医生的话。

在我观察和参与关于创建数据科学道德规范的讨论时，我发现人们普遍承认，至少对于数据科学来说，选项#1 目前不存在，并且可能在很长一段时间内都不会存在，也许永远都不会存在。让我吃惊的是，在没有这个选项的情况下，解决数据科学伦理问题的努力似乎压倒性地集中在选项 3 的变体上。这篇文章简要地阐述了为什么第三种选择不仅不切实际，而且不道德，更简单地说，为什么我认为第二种选择是我们所有人首先应该做的。

## **空谈是廉价的**

“数据实践宣言”(datapractices.org)由 Data for Good Exchange 制作，由 Data for Democracy 和彭博赞助，由前美国首席数据科学家 DJ Patil 推动，目前由 data.world 维护。我毫不避讳地指出，我对文件有[重大的道德担忧。](https://towardsdatascience.com/an-ethical-code-cant-be-about-ethics-66acaea6f16f)

总结一下我的批评:《宣言》要求我们通过相信道德实践者的话来识别他们。你所要做的就是在文件上签字。无成本的美德信号会产生系统性风险:因为不道德的从业者肯定会毫不犹豫地声称他们的行为符合道德，而道德的从业者可以在一开始就不做任何这种声称的情况下符合道德，任何廉价言论的奖励----无论多小----都会为个体从业者建立自己的声誉创造途径，并从实际做好工作之外的其他事情中受益。一个没有成本的道德准则会使识别道德从业者变得更难，而不是更容易。

该宣言犯下了文件本身应该解决的道德违规类型:其创造者和签署者支持最低限度的可行产品，而没有充分考虑该产品可能对下游造成的伤害。该文件的创建者没有因创建和推广它而招致任何风险，因此该产品未能达到其自身的道德标准也就不足为奇了。这说明了纳西姆·塔勒布在游戏中的[皮肤原则:](/incerto/how-to-be-rational-about-rationality-432e96dd4d1a)

*“装饰性的信念和……付诸行动的信念是有区别的。他们在语言上没有区别，除了真正的区别在于冒险，有一些处于危险中的东西，一些万一出错可能会失去的东西。……你真正‘相信’某件事的程度只能通过你愿意为此承担的风险来体现。”*

## **我们不会通过修正道德来修正道德**

偷窃和出售某人的器官显然是不道德的——非常不道德。但是，大多数用来证明数据科学道德规范的必要性的问题，并不是那种偷肾的问题。据我们所知， [COMPAS 算法](https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm)的创造者并没有故意设计这个东西来囚禁贫穷的少数民族。亚马逊并没有有意设计其[算法，只向富裕的白人邮政编码提供当天送达](https://www.bloomberg.com/graphics/2016-amazon-same-day/)。一个[虐童检测算法](https://www.wired.com/story/excerpt-from-automating-inequality/)的设计者并没有故意把贫穷和疏忽混为一谈。换句话说，虽然上述所有例子都因其道德后果而令人担忧，但这些后果本身是由于能力的失败而产生的，而不是道德的失败。

这些都是不经意间损害你的肾脏却没有意识到的问题。《数据实践宣言》中列举的所有原则都无法阻止这些有缺陷的算法得到应用。如果那些工具的创造者意识到他们已经在产品中建立了系统化的偏见，他们会在部署之前改变他们的产品。了解合理的道德原则，甚至全心全意地相信这些原则，并不会让你自动意识到一个糟糕的设计选择。伦理问题没有伦理解决方案。简直就是找错了对象。

## **成本比原则更重要**

在这篇文章的开始，我列出了解决道德风险的三个选择。法律选项#1 的一个变体解决的是能力风险:它被称为保险。那是处理这个问题的一种昂贵而复杂的方法。不言而喻，如果有什么不同的话，第三个廉价讨论选项是一种比评估道德更荒谬的能力评估方式。

剩下第二个选择——对从业者进行公开评估。这种选择是减轻能力风险和道德风险的有效方法，当且仅当我们让人们为特定类型的事情担保时——这些事情会给个体从业者带来更多的成本，而从业者会得到更多的回报。

请记住，廉价谈论道德准则的问题是，它使道德和不道德的从业者看起来完全一样:他们都可以签署文件，都宣传他们签署了文件，都明智地谈论原则。这种影响可以通过一个要求定期采取昂贵行动的准则来抵消。证明你遵守道德准则的证据不应该是你的签名。应该是你的简历。

最初的希波克拉底誓言的一个主要特点是要求医生教任何真心想学这门手艺的人。如果有人声称遵守准则，你没有必要问他们“你是一个有道德的医生吗？”。你可以问他们“你上次教别人做生意是什么时候？”这是一个有效的过滤器的原因是因为希波克拉底誓言不是教师的准则。这是医生的代码。这意味着你必须腾出时间和空间去教导他人，即使是在履行你的日常职业职责的时候。

几乎原始希波克拉底誓言的每一部分都是这种对从业者直接成本的列举。宣誓的人承诺在履行职业职责的过程中不会获得额外的好处。利用患者分享的非医疗信息或在患者家庭中发展副业联系的医生没有遵守誓言。要明确的是:这些事情本身没有任何问题，就像不教书本身没有任何问题一样。成本很重要，因为只有真正有能力的医生——那些对自己的职业足够了解和关心，以至于非常擅长自己工作的医生——才会愿意不断牺牲自己的时间，拒绝别人提供的附带福利。

你必须特别能干，才能自愿承担个人成本。这些个人成本阻止了那些仅仅为了获得附带利益而假装有能力的人。换句话说，道德准则也是一种评估能力的方法，是对有意不道德行为和无意不道德行为的有效过滤。事实上，在缺乏法律、监管和保险基础设施的情况下，这是唯一有效的过滤器。唯一的费用是由个体从业者直接支付的。

## **有意义的道德准则是可能的**

道德不是一个可以解决的问题，但它是一个可以管理的风险。没有一套原则，即使是健全的法律和监管基础设施，也不能确保道德结果。我们的目标应该是确保算法设计决策是由有能力、有道德的个人做出的——最好是由这样的个人组成的团体做出。如果我们提高了能力，我们就提高了道德。大多数道德错误来自于无法预见后果，而不是无法分辨对错。

有效的道德规范不需要——事实上，可能不应该——关注道德问题。最重要的是结果，而不是我们用来实现这些结果的工具。只要道德准则规定了个体从业者可以通过自愿承担“不必要的”成本和风险来证明自己能力的方式，它就会淘汰能力较低和道德较差的人。这就是我们应该建立的清单。这种产品将会产生一个更加道德的职业。

我不知道那份名单应该是什么样的。值得一提的是，我个人认为在最初的希波克拉底誓言中发现的两个规定可以很容易地适用于另一个职业:

*   你必须教书。如果有人要求帮助学习与职业相关的技能，你至少要给他们详细的指导，告诉他们如何找到资源，大部分时间你必须实际教他们(教他们是一项明确的工作职责，你可以分配时间，但这不算)。
*   你必须宣传你的无知。如果你被要求，比如说，构建或训练一个你以前从未使用过的算法，你必须明确地告诉所有直接的利益相关者，你会边做边学；如果这是一个全新的能力领域(比如说，设计一个你以前从未做过的数据库架构)，你需要明确地尝试让拥有该产品的人雇佣更有能力的人来做这件事，只有在他们拒绝的情况下才会去做。

那些是昂贵的规定。就教书而言，这是一种机会成本，因为你花了时间去帮助别人，而这些时间本可以用在你的核心职责上。在广告无知的情况下，这是一个更直接的成本:我知道承认无知有多可怕，有时甚至有风险。这种风险使它成为一个好的道德准则。

我认为职业道德准则可能是有用的，甚至是重要的。我认为建立一个健全的、可执行的道德准则是可能的。但是到目前为止提供的产品并不是正确的方向——事实上，它们正在把我们从我们需要的地方带走。如果我们真的想要解决职业中的道德问题，我们需要把皮肤放在游戏中。如果做不到这一点，问题就会恶化。