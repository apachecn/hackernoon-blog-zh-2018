# 选择正确的机器学习算法

> 原文：<https://medium.com/hackernoon/choosing-the-right-machine-learning-algorithm-68126944ce1f>

机器学习既是艺术又是科学。当你看机器学习算法时，没有一个解决方案或一种方法适合所有人。有几个因素会影响你选择机器学习算法的决定。

有些问题非常具体，需要独特的方法。例如，如果你看看推荐系统，它是一种非常常见的机器学习算法，它解决了一种非常特殊的问题。而其他一些问题是非常开放的，需要一种试错的方法。监督学习、分类和回归等。非常开放。它们可以用于异常检测，也可以用于建立更通用的预测模型。

此外，我们在选择机器学习算法时做出的一些决定与算法的优化或技术方面关系不大，而与商业决策关系更大。下面我们来看看一些可以帮助你缩小机器学习算法搜索范围的因素。

# 数据科学过程

在你开始研究不同的 ML 算法之前，你需要对你的数据、你的问题和你的限制有一个清晰的了解。

## 了解您的数据

我们拥有的数据类型和种类在决定使用哪种算法时起着关键作用。一些算法可以处理较小的样本集，而其他算法需要大量的样本。某些算法处理某些类型的数据。例如，朴素贝叶斯对分类输入很有效，但对缺失数据一点也不敏感。

因此，您必须:

**了解你的数据**

1.  查看汇总统计和可视化

*   百分位数可以帮助确定大多数数据的范围
*   平均值和中位数可以描述集中趋势
*   相关性可以表明强关系

2.将数据可视化

*   箱线图可以识别异常值
*   密度图和直方图显示了数据的分布
*   散点图可以描述二元关系

**清理你的数据**

1.  处理缺失值。缺失数据对某些模型的影响比对其他模型的影响更大。即使对于处理缺失数据的模型，它们也可能对缺失数据很敏感(某些变量的缺失数据可能导致糟糕的预测)
2.  选择如何处理异常值

*   离群值在多维数据中非常常见。
*   有些模型对异常值不太敏感。通常树模型对异常值的存在不太敏感。然而，回归模型，或任何试图使用方程的模型，肯定会受到异常值的影响。
*   异常值可能是错误数据收集的结果，也可能是合理的极端值。

3.数据需要汇总吗

**扩充你的数据**

1.  特征工程是从原始数据到可用于建模的数据的过程。它有多种用途:

*   使模型更容易解释(如宁滨)
*   捕捉更复杂的关系(如 NNs)
*   减少数据冗余和维数(例如 PCA)
*   重新调整变量(例如标准化或规范化)

2.不同的模型可能有不同的特征工程要求。有些内置了功能工程。

## 将问题分类

下一步是对问题进行分类。这是一个两步过程。

1.  按输入分类:

*   如果你有带标签的数据，这是一个监督学习的问题。
*   如果你有未标注的数据，想找结构，那就是一个无监督的学习问题。
*   如果你想通过与环境的交互来优化一个目标函数，这就是一个强化学习问题。

2.按输出分类。

*   如果你的模型的输出是一个数字，这是一个回归问题。
*   如果你的模型的输出是一个类，这是一个分类问题。
*   如果模型的输出是一组输入组，这就是聚类问题。
*   你想检测异常吗？那是异常检测

## 了解你的限制

*   您的数据存储容量是多少？根据系统的存储容量，您可能无法存储千兆字节的分类/回归模型或千兆字节的数据来进行集群化。例如，嵌入式系统就是这种情况。
*   预测一定要快吗？在实时应用中，尽可能快地进行预测显然非常重要。例如，在自动驾驶中，重要的是路标的分类要尽可能快，以避免事故。
*   学习一定要快吗？在某些情况下，快速训练模型是必要的:有时，您需要用不同的数据集快速更新您的模型。

## 查找可用的算法

现在，您已经清楚地了解了自己所处的位置，您可以使用您所掌握的工具来识别适用且实用的算法。影响模型选择的一些因素有:

*   模型是否满足业务目标
*   模型需要多少预处理
*   模型有多精确
*   这个模型的解释力有多强
*   模型有多快:建立模型需要多长时间，模型做预测需要多长时间。
*   模型的可伸缩性如何

影响算法选择的一个重要标准是模型复杂性。一般来说，较复杂的模型是:

*   它依赖于更多的特征来学习和预测(例如，使用两个特征对十个特征来预测目标)
*   它依赖于更复杂的特征工程(例如，使用多项式、相互作用或主成分)
*   它有更多的计算开销(例如，单个决策树与 100 棵树的随机森林相比)。

除此之外，基于参数的数量或一些超参数的选择，相同的机器学习算法可以变得更加复杂。举个例子，

*   一个回归模型可以有更多的特征，或者多项式项和交互项。
*   决策树可以有或多或少的深度。

使相同的算法更复杂会增加过度拟合的机会。

![](img/417ae4e751763bfd58ae933fba26c00a.png)

([克服生产就绪机器学习工作流程的障碍](https://cdn.oreillystatic.com/en/assets/1/event/105/Overcoming%20the%20Barriers%20to%20Production-Ready%20Machine-Learning%20Workflows%20Presentation%201.pdf)

# 常用的机器学习算法

## 线性回归

这些可能是机器学习中最简单的算法。例如，当您想要计算一些与输出为类别的分类相比较的连续值时，可以使用回归算法。因此，每当你被告知要预测某个当前正在运行的进程的未来值时，你可以使用回归算法。但是，如果要素是冗余的，即存在多重共线性，则线性回归是不稳定的

可以使用线性回归的一些例子有:

*   是时候去另一个地方了
*   预测下个月特定产品的销售
*   血液酒精含量对协调性的影响
*   预测每月礼品卡销售额并提高年度收入预测

## 逻辑回归

逻辑回归执行二元分类，因此标签输出是二元的。它采用特征的线性组合，并对其应用非线性函数(sigmoid ),因此它是神经网络的一个非常小的实例。

逻辑回归提供了许多正则化模型的方法，您不必像在朴素贝叶斯中那样担心要素的相关性。你也有一个很好的概率解释，你可以很容易地更新你的模型来接受新的数据，不像决策树或支持向量机。如果您想要一个概率框架，或者如果您希望在将来收到更多的训练数据，并希望能够快速合并到您的模型中，请使用它。逻辑回归也可以帮助你理解预测背后的影响因素，而不仅仅是一种黑箱方法。

逻辑回归可用于以下情况:

*   预测客户流失
*   信用评分和欺诈检测
*   衡量营销活动的有效性

## 决策树

单独的树很少被使用，但是在与许多其他树的组合中，它们构建了非常有效的算法，例如随机森林或梯度树提升。

决策树很容易处理特征交互，并且它们是非参数化的，因此您不必担心离群值或数据是否是线性可分的。一个缺点是，它们不支持在线学习，所以当新的例子出现时，你必须重建你的树。另一个缺点是它们很容易过度适应，但这正是像随机森林(或增强树)这样的集合方法的用武之地。决策树也会占用大量内存(您拥有的功能越多，您的决策树就可能越深越大)

树是帮助你在几个行动方案中做出选择的绝佳工具。

*   投资决策
*   客户流失
*   银行贷款拖欠者
*   构建与购买决策
*   销售线索资格

## k 均值

有时你不知道任何标签，你的目标是根据对象的特征分配标签。这被称为集群化任务。例如，当有一大群用户，并且您希望根据一些共同的属性将他们分成特定的组时，可以使用聚类算法。

如果有像这样的问题，这是如何组织或分组或集中在特定群体等。在你的问题陈述中，你应该选择聚类。

最大的缺点是 K-Means 需要提前知道你的数据中会有多少个聚类，所以这可能需要大量的试验来“猜测”最佳的 K 个聚类数来定义。

## 主成分分析

主成分分析提供了降维。有时，您有各种各样的功能，可能彼此之间高度相关，模型很容易在大量数据上过度拟合。然后，可以应用 PCA。

PCA 成功的关键之一是除了低维样本表示之外，它还提供了变量的同步低维表示。同步的样本和变量表示提供了一种直观地找到代表一组样本特征的变量的方法。

## 支持向量机

支持向量机(SVM)是一种受监督的机器学习技术，广泛用于模式识别和分类问题-当您的数据正好有两个类别时。

高精度，良好的关于过拟合的理论保证，以及适当的内核，它们可以很好地工作，即使你的数据在基本特征空间中不是线性可分的。在非常高维的空间是标准的文本分类问题中特别流行。然而，支持向量机占用大量内存，很难解释，也很难调优。

SVM 可用于现实世界的应用，例如:

*   检测患有糖尿病等常见疾病的人
*   手写字符识别
*   文本分类—按主题分类的新闻文章
*   股票市场价格预测

## 朴素贝叶斯

这是一种基于贝叶斯定理的分类技术，非常容易构建，对于非常大的数据集特别有用。除了简单之外，朴素贝叶斯被认为比高度复杂的分类方法更好。当 CPU 和内存资源是一个限制因素时，朴素贝叶斯也是一个不错的选择。

朴素贝叶斯是超级简单的，你只是做一堆计数。如果 NB 条件独立性假设实际上成立，朴素贝叶斯分类器将比像逻辑回归这样的判别模型收敛得更快，因此您需要更少的训练数据。即使 NB 假设不成立，NB 分类器在实践中仍然经常做得很好。如果想要快速简单且性能良好的东西，这是一个很好的选择。它的主要缺点是无法学习特征之间的交互。

朴素贝叶斯可用于现实应用中，例如:

*   情感分析和文本分类
*   像网飞、亚马逊这样的推荐系统
*   将电子邮件标记为垃圾邮件或非垃圾邮件
*   人脸识别

## 随机森林

随机森林是决策树的集合。它可以解决大型数据集的回归和分类问题。它还有助于从成千上万的输入变量中识别出最重要的变量。随机森林高度可扩展到任意数量的维度，并且通常具有相当可接受的性能。最后，还有遗传算法，它可以很好地扩展到任何维度和任何数据，而对数据本身的了解很少，最少和最简单的实现是微生物遗传算法。然而，对于随机森林，学习可能很慢(取决于参数化),并且不可能迭代地改进生成的模型

随机森林可用于现实应用中，例如:

*   预测患者的高风险
*   预测生产中的零件故障
*   预测贷款违约者

## 神经网络

神经网络接受神经元之间连接的权重。权重是平衡的，在学习数据点之后学习数据点。当训练了所有的权重时，如果出现新输入数据点的回归，则可以利用神经网络来预测类别或数量。使用神经网络，可以训练极其复杂的模型，并且可以将它们用作一种黑盒，而无需在训练模型之前完成不可预测的复杂特征工程。与“深度方法”相结合，甚至可以获得更多不可预测的模型，以实现新的可能性。例如，最近，利用深度神经网络极大地增强了物体识别。应用于无监督的学习任务，如特征提取，深度学习也可以在更少的人工干预下从原始图像或语音中提取特征。

另一方面，神经网络是很难澄清的，参数化是非常令人难以置信的。它们也非常消耗资源和内存。

# Scikit 备忘单

Scikit learning 提供了一个非常深入且解释清楚的流程图来帮助你选择正确的算法，我觉得非常方便。

![](img/b47b8cd2ff79766d4990c6d9b8a2a1d5.png)

([http://sci kit-learn . org/stable/tutorial/machine _ learning _ map/index . html](http://scikit-learn.org/stable/tutorial/machine_learning_map/index.html))

# 结论

一般来说，你可以利用以上几点来筛选出几个算法，但是很难一开始就知道哪种算法效果最好。迭代工作通常是最好的。在您确定为潜在好方法的 ML 算法中，将您的数据投入其中，并行或串行运行它们，最后评估算法的性能以选择最佳算法。

最后，为现实生活中的问题开发正确的解决方案很少只是一个应用数学问题。它需要了解业务需求、规则和法规、利益相关者的关注点以及大量的专业知识。在解决机器问题时，能够结合和平衡这些是至关重要的；能做到这一点的人，才能创造最大的价值。