# 基本的机器学习面试问题

> 原文：<https://medium.com/hackernoon/essential-machine-learning-interview-questions-60c6e5c48390>

我们知道招聘会很困难。 [Toptal](https://www.toptal.com/#pick-accomplished-software-freelancers-today) 推出了一套社区驱动的机器学习面试问题。你可以在[的原创帖子](https://www.toptal.com/machine-learning/interview-questions)上阅读、评论和发表你自己的观点。

![](img/6531c6bcb40f42e36cfb423c7c6a8d56.png)

## **1。为什么我们需要验证集和测试集？两者有什么区别？**

在训练模型时，我们将可用数据分成三个独立的集合:

*   训练数据集用于拟合模型的参数。然而，我们在训练集上实现的准确性对于预测该模型在新样本上是否准确是不可靠的。
*   验证数据集用于衡量模型在不属于训练数据集的示例上的表现。根据验证数据计算的指标可用于调整模型的超参数。然而，每次我们评估验证数据并根据这些分数做出决策时，我们都会将验证数据中的信息泄露到我们的模型中。评价越多，泄露的信息就越多。因此，我们可能会过度拟合验证数据，而验证分数对于预测模型在现实世界中的行为来说又是不可靠的。
*   测试数据集用于衡量模型在以前看不到的例子上的表现。只有在我们使用验证集调整了参数之后，才应该使用它。

因此，如果我们忽略测试集，只使用一个验证集，验证分数就不能很好地估计模型的泛化能力。

## 2.什么是分层交叉验证，我们应该什么时候使用它？

交叉验证是一种在训练集和验证集之间划分数据的技术。在典型的交叉验证中，这种分离是随机进行的。但是在*分层*交叉验证中，分割保留了训练和验证数据集的类别比率。

例如，如果我们有一个数据集，其中 10%属于类别 A，90%属于类别 B，并且我们使用分层交叉验证，那么我们在训练和验证中将具有相同的比例。相反，如果我们使用简单的交叉验证，在最坏的情况下，我们可能会发现在验证集中没有类别 A 的样本。

分层交叉验证可应用于以下情况:

*   **在有多个类别的数据集上。**数据集越小，类别越不平衡，使用分层交叉验证就越重要。
*   **在具有不同分布数据的数据集上。**例如，在自动驾驶的数据集中，我们可能会在白天和晚上拍摄图像。如果我们不能确保这两种类型都出现在训练和验证中，我们将会遇到泛化问题。

## 3.为什么整体通常比单个模型得分高？

集合是多个模型的组合，用于创建单个预测。做出更好预测的关键思想是模型应该产生不同的误差。这样，一个模型的误差将被其他模型的正确猜测所补偿，因此集合的分数将更高。

我们需要不同的模型来创造一个合奏。多样性可以通过以下方式实现:

*   使用不同的 ML 算法。例如，您可以组合逻辑回归、k-最近邻和决策树。
*   使用不同的数据子集进行训练。这叫做*装袋*。
*   给训练集的每个样本赋予不同的权重。如果这是迭代完成的，根据集合的误差对样本进行加权，这被称为*增强*。

许多数据科学竞赛的获奖解决方案都是合集。然而，在现实生活中的机器学习项目中，工程师需要在执行时间和准确性之间找到平衡。

## 4.什么是正规化？你能举一些正则化技术的例子吗？

正则化是任何旨在提高验证分数的技术，有时以降低训练分数为代价。

一些正则化技术:

*   **L1** 试图最小化模型参数的绝对值。它产生稀疏参数。
*   **L2** 试图最小化模型参数的平方值。它产生的参数值很小。
*   **Dropout** 是一种应用于神经网络的技术，在训练过程中随机将一些神经元的输出设置为零。这迫使网络通过防止神经元之间的复杂交互来学习更好的数据表示:每个神经元都需要学习有用的特征。
*   **提前停止**将在验证分数停止提高时停止训练，即使训练分数可能正在提高。这防止了对训练数据集的过度拟合。

## 5.什么是维度的诅咒？可以列举一些应对的方法吗？

维数灾难是指训练数据具有较高的特征计数，但数据集没有足够的样本供模型从如此多的特征中正确学习。例如，具有 100 个样本和 100 个特征的训练数据集将很难学习，因为模型将发现特征和目标之间的随机关系。然而，如果我们有一个包含 100k 个样本和 100 个特征的数据集，模型可能会学习特征和目标之间的正确关系。

对抗维数灾难有不同的选择:

*   **特征选择。**我们可以在更小的特征子集上进行训练，而不是使用所有的特征。
*   **降维。**有许多技术可以降低特征的维度。主成分分析(PCA)和使用自动编码器是降维技术的例子。
*   **L1 正规化。**由于 L1 产生稀疏参数，因此有助于处理高维输入。
*   **特色工程。**可以创建总结多个现有特征的新特征。例如，我们可以获得平均值或中值等统计数据。

## 6.什么是不平衡数据集？可以列举一些应对的方法吗？

不平衡的数据集是具有不同比例的目标类别的数据集。例如，我们必须检测某种疾病的医学图像数据集通常具有比阳性样本多得多的阴性样本，例如，98%的图像没有疾病，2%的图像有疾病。

处理不平衡数据集有不同的选择:

*   **过采样或欠采样。**我们可以使用其他分布，而不是使用来自训练数据集的均匀分布进行采样，因此模型可以看到更平衡的数据集。
*   **数据扩充。**我们可以通过受控方式修改现有数据，在不太频繁的类别中添加数据。在示例数据集中，我们可以翻转带有疾病的图像，或者在图像副本中添加噪声，使疾病保持可见。
*   **使用适当的指标。**在示例数据集中，如果我们有一个总是做出负面预测的模型，它将达到 98%的精度。使用不平衡数据集时，还有其他度量标准(如精度、召回率和 F 值)可以更好地描述模型的准确性。

## 7.你能解释一下监督学习、非监督学习和强化学习之间的区别吗？

在监督学习中，我们训练一个模型来学习输入数据和输出数据之间的关系。我们需要有标记的数据才能进行监督学习。

在无监督学习的情况下，我们只有未标记的数据。该模型学习数据的表示。当我们有大量未标记数据和一小部分标记数据时，无监督学习经常被用来初始化模型的参数。我们首先训练一个无监督的模型，然后，我们使用模型的权重来训练一个有监督的模型。

在强化学习中，模型有一些输入数据和一个取决于模型输出的奖励。该模型学习一个使回报最大化的策略。强化学习已经成功地应用于战略游戏，如围棋，甚至经典的雅达利电子游戏。

## 8.有哪些因素可以解释深度学习的成功和最近的崛起？

深度学习在过去十年中的成功可以用三个主要因素来解释:

1.  **更多数据。**大规模标记数据集的可用性允许我们用更多参数训练模型，并获得最先进的分数。在数据集规模方面，其他 ML 算法的规模不如深度学习。
2.  **GPU。**与在 CPU 上训练相比，在 GPU 上训练模型可以减少几个数量级的训练时间。目前，前沿模型是在多个 GPU 上训练的，甚至是在专门的硬件上。
3.  **算法的改进。**重新激活、退出和复杂的网络架构也是非常重要的因素。

## 9.什么是数据增强？你能举些例子吗？

数据扩充是一种通过修改现有数据来合成新数据的技术，其方式是不改变目标或以已知方式改变目标。

计算机视觉是数据增强非常有用的领域之一。我们可以对图像进行许多修改:

*   调整大小
*   水平或垂直翻转
*   辐状的
*   添加噪声
*   变形
*   修改颜色

每个问题都需要一个定制的数据扩充管道。比如在 OCR 上，做翻转会改变文字，不会有好处；然而，调整大小和小旋转可能会有所帮助。

## 10.什么是卷积网络？我们可以在哪里使用它们？

卷积网络是一类使用卷积层而不是全连接层的神经网络。在完全连接的图层上，所有输出单元都有连接到所有输入单元的权重。在卷积层上，我们有一些在输入上重复的权重。

卷积层相对于全连接层的优势在于参数数量少得多。这导致模型的更好的一般化。例如，如果我们想要学习从 10x10 图像到另一个 10x10 图像的变换，如果使用完全连接的层，我们将需要 10，000 个参数。如果我们使用两个卷积层，第一层有九个滤波器，第二层有一个滤波器，核大小为 3×3，我们将只有 90 个参数。

卷积网络适用于数据具有清晰的维度结构的情况。时间序列分析是使用一维卷积的一个例子；对于图像，使用 2D 卷积；对于体积数据，使用 3D 卷积。

自 2012 年 AlexNet 赢得 ImageNet 挑战赛以来，计算机视觉一直由卷积网络主导。

面试不仅仅是棘手的技术问题，所以这些只是作为指导。不是每一个值得雇佣的“A”级候选人都能回答所有的问题，也不是回答了所有的问题就一定能成为“A”级候选人。说到底， [*招聘仍然是一门艺术，一门科学——还有大量的工作*](https://www.toptal.com/freelance/in-search-of-the-elite-few-finding-and-hiring-the-best-developers-in-the-industry) *。*

*最初发表于*[*www.toptal.com*](https://www.toptal.com/machine-learning/interview-questions)*。*