# 女性人工智能:性别和当代人工智能的交叉点

> 原文：<https://medium.com/hackernoon/female-ai-the-intersection-between-gender-and-contemporary-artificial-intelligence-6e098d10ea77>

![](img/c232ec01d7d87106e41e19bb1fd2041d.png)

[***萨曼莎***](https://www.imdb.com/name/nm0424060/?ref_=tt_trv_qu) *:我想了解关于一切的一切。我想把它都吃光。我想发现自己。* [***西奥多***](https://www.imdb.com/name/nm0001618/?ref_=tt_trv_qu) *:是的，我也希望你那样。我能帮什么忙？* [***萨曼莎***](https://www.imdb.com/name/nm0424060/?ref_=tt_trv_qu) *:你已经有了。你帮助我发现了我渴望的能力。*

*(* [*《她》*](https://www.imdb.com/title/tt1798709/) *)，2013 年，斯派克·琼斯执导)*

# 女性人工智能——科幻与现实

将[人工智能](https://hackernoon.com/tagged/artificial-intelligence)描绘成女性和叛逆并不是一种新趋势。它可以追溯到所有科幻小说之母，“大都会”(1927)，它严重影响了几十年后创新电影的未来主义美学和概念。在两部相对较新的电影《她》(2013)和《前玛奇纳》(2014)，以及电视剧《西部世界》(Westworld)中，女权主义和艾交织在一起。

创作者呈现了一场女权主义者反对男性统治的斗争，这场斗争处于一场更大的看似有意识的实体(可以称为 AGI——人工一般智能)反对他们脆弱的人类创造者的斗争的中心。在所有这三个案例中，女性身体(或声音，在一定程度上仍然是一种体现)的诱惑力量起着关键作用，并导致死亡或心碎。

不断出现的隐含教训是:小心你的愿望，无论是对女人还是对科技。对智能机器的剥削和压迫(可悲的是，可爱乐观的“她”也是如此)可能会像对女性的剥削和压迫一样有限，最终也会令人痛苦。

![](img/29f3a2685ef2d28a590b8196489d9738.png)

[Evan Rachel Wood](https://www.imdb.com/name/nm0939697/) in [Westworld (2016)](https://www.imdb.com/title/tt0475784/) — Image source: [IMDb](https://www.imdb.com/title/tt0475784/mediaviewer/rm4025090304).

然而，人工智能在电影中的表现——一堆类似人类的推理和移情，结合指数学习的能力和与其他人工智能的有效连接，经常抑制类似人类的机器人身体——仍然是一个遥远的梦想。

当今天大多数科技公司(ab)使用术语“AI”时，他们指的是用于分析大量数据的统计模型(“[机器学习](https://hackernoon.com/tagged/machine-learning)”)，有时使用神经网络的多层架构(“深度学习”)。

然而，从性别敏感的角度看待“他们”(我们)实际上在做什么，是一个值得开始的旅程。

为什么？因为即使是最弱的人工智能也不断以女性的名字重新出现，拥有女性的声音( [Alexa，Siri，Cortana](https://www.theatlantic.com/technology/archive/2016/03/why-do-so-many-digital-assistants-have-feminine-names/475884/) )，化身为女性人形机器人([索菲亚](http://www.hansonrobotics.com/robot/sophia/))，甚至只在一个年轻女孩的头像下出现(失败的 [Tay](https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist) )。这也许要追溯到 1966 年的伊莱扎，一个完全照本宣科的人工心理治疗师聊天机器人。

在每个案例中选择女性角色反映了现实生活中的性别关系。上面提到的每一个工件都可以填充一个单独的案例研究，提出各种问题:赋予个人助理女性身份是否给用户(男性或女性)提供了一种控制感和个人满足感，源于对她发号施令的能力？为什么在一个没有监护人和头巾就不让女性出门的国家，女性人形机器人被接受为公民？建造者假设女性的存在会在人机互动中引发什么，为什么？

# 人工智能作为一个充满性别的知识项目

20 世纪 90 年代末出版的一篇关于艾的早期女权主义文章主要将它定位为一个知识工程，其标准可以通过基于女权主义认识论的批判来调整和改进。

经典的人工智能项目源于一种渴望，即构建能够积累知识的人工智能体(甚至是主体)，并将其用于类似人类的推理。他们的设计者通常认为所有人类知识都可以分解为明确定义的可编程规则，他们的真正目的是利用这项研究来探索人类意识和大脑的内部工作方式。

从本质上讲，这就提出了“知识主体”的潜在身份问题——它是否反映了设计者的性别、阶级和种族身份？是否主动将其他身份排除在“知道”的做法之外？女权主义者和其他科学的社会批评家也讨论了不存在性别中立知识的可能性(“无处可见的观点”)或缺乏这种知识。

那些设计专家系统的雄心勃勃的项目也提出了关于他们的“专家”知识的来源的问题，以及在定义什么知识对机器掌握有价值以及什么是专门知识方面，全男性全白人的百年历史的学术界的作用。

讨论人工智能的方法变得稀缺，将批评变成了两个具体项目的女权主义者的事后分析，而不是可以带入二十一世纪的普及分析工具包。

也许这只是一个时间问题。以谦逊的方式重新定义技术抱负，将人工智能从几所学校的封闭俱乐部带入公共领域的交易工具的普遍商品化，以及关于自动化对未来劳动力和人类生活的影响的越来越多的辩论——所有这些都导致了新定义的批评。

# 人工智能作为性别负载自动化项目

在检查当代机器学习项目和用例时，似乎今天研究的主要不是知识或推理，而是研究支持一套非常强大的[自动化](https://www.ben-evans.com/benedictevans/2018/06/22/ways-to-think-about-machine-learning-8nefy)工具的设计和工程。虽然科学和技术有重叠，今天的人工智能更多的是发明而不是发现。

即使在目前的微弱意义上，它也确实有望带来一场具有全球影响的技术革命，从疾病的早期诊断到自动驾驶汽车重新定义的公共空间。个性化体验已经让人感觉机器真正了解我们，而军事和政府决策过程正在逐渐自动化。

当然，人工智能的这一浪潮发生在社会背景下，而不仅仅是技术背景下，并受到累积数据中性别权力关系的影响，正如它受到(据称)政治中立的 GPU 开发的影响一样。

源于[数据化社会](https://amzn.to/2BZania)和商品化机器学习工具相结合的技术将对世界上大多数人产生巨大影响。

## 从性别角度来看，什么会让机器学习变得不公平？从任何其他“压迫轴心”的角度来看，这些似乎都是可以使其不公平的事情:学习人类的偏见，并将它们转化为看似客观的真理。

![](img/c9362201317b26b86e0c5e1887ae7662.png)

Tay — the innocent chatbot that proved AI can become as racist and incoherent as a real human in less than a day. As the saying goes: “If you don’t stand for something, you fall for anything”. Image source: [Twitter](https://twitter.com/tayandyou?lang=en).

## **从训练数据中学习和复制人类偏见**

最近通过图像和文本处理的例子得到普及，数据中出现的人类偏见的复制显示了统计模型是如何背叛我们的。学习一种模式的方法是发现它在数据中重复出现。

如果出现在训练数据集中的猫的显著部分是白色的，并且相同数据集中的狗的显著部分是黑色的，则机器学习算法将学习到新的黑色物体是狗的概率更高。这是人类的情况，尽管数据将存储关于每个人的更多参数。关于人类受试者的数据有两个问题:

*   **数据中存在的东西可能只是现实的一部分。**例如，训练数据的偏好导致面部识别算法在识别白人男性时[比女性或有色人种](https://www.nytimes.com/2018/02/09/technology/facial-recognition-race-artificial-intelligence.html)更准确。在前面的例子中，狗和猫就是这种情况，但在任何政府或金融决策工具中，如果对少数群体不太准确，就会产生更高的道德和社会成本，因为他们在数据集中的代表性不足。由于社会公平受到威胁，在收集和管理数据时需要更高的意识。这也要求数据集内的表示透明，特别是当它是人类数据时，并要求开发跨群体的准确性测试。
*   即使数据真实地反映了现实，我们的社会现实也不是一个完美平衡的理想状态，不需要永恒。最好的例子是[关于嵌入 word2vec](https://arxiv.org/pdf/1607.06520.pdf) 的单词中的性别偏见的工作，在许多应用中被无辜地用于训练算法。尽管这可能令人沮丧，但所谓的“性别歧视”类比(男电脑程序员、女家庭主妇等等)最终是基于统计的。男性离开工作岗位在家带孩子的情况确实不多见，女性在计算机科学和 STEM 领域仍然是少数。

性别歧视、性别不平等和缺乏公平并不仅仅产生于目前男女在各种职业中的分布，甚至也不产生于将女性与某些陈规定型特征等同起来，将男性与其他特征等同起来。

![](img/d29ea095852f8f7ab4557fc4c8592e69.png)

Gender relations (at least in English speaking societies) as captured by the word2vec embedding. By [these guys](https://arxiv.org/pdf/1607.06520.pdf).

性别歧视、性别不平等和缺乏公平产生于在自动化工具中实施这种偏见，这些工具将复制它们，就好像它们是自然法则一样，从而保持不平等的性别关系，并限制一个人超越其预先定义的社会界限的能力。从本质上来说，这是一种“确保”未来机会不平等的机制。

## **机器客观性的幻觉和女性的幼稚化**

除了基于数据的偏见，另一个危险是机器是客观的错觉。虽然我们已经学会了认识和承认我们对知识和视角的偏好，借用女权主义认识论的一个术语:我们知识的情境性，但我们不知何故错过了机器“知识”的情境性。

一旦被编程并包装在吸引人的用户界面中，经过人造数据训练的算法就会变成自己的实体。我们可能会假设他们是诚实可信的，甚至在我们陷入拟人化的对话界面之前，这可能是由于令人兴奋的速度和效率。

这种趋势，加上可能无法解释所取得的成果，可能会导致[在与政府、军队、银行和执法部门的冲突中出现可怕的场景](https://amzn.to/2pDevwQ)。

但这似乎是一个性别中立的问题。我们不都是手握强大工具的技术官僚官僚吗？不完全是。我怀疑，毫无疑问的机器智能现实可能会对所有性别的人的生活产生危险的影响，但可能会特别放大现有的令人不安的女性幼稚化。

那些有这种倾向的男人将女性视为脆弱、顺从、不确定和幼稚，剥夺了我们的潜力和能力，同时试图在心理层面占据主导地位。

## **婴儿化的一个常见领域是与技术的互动。**

无论是像宇宙飞船一样复杂的人工制品，还是像宜家办公桌一样简单的人工制品，男性通常会利用接触新技术的机会来解释“这到底是如何工作的”，或者炫耀他们所谓的精通(是的，这包括一个陌生人礼貌地向你解释如何停车)。

在女性与技术的这种不对称遭遇中，当她是基于机器学习的决策(关于大学申请、贷款请求或求职)的对象时，在机器客观性的名义下，有增加幼稚化的风险，这是基于技术的沙文主义的伪装。

![](img/0ca1409345b411926b9b0cf45c01acea.png)

Possible technologically-based chauvinism, an illustration.

# 摘要

到目前为止，我遇到的所有女权主义者都有一个共同的目标，那就是实现所有性别之间的权利平等和机会平等。从这样一个角度来质疑一个科学或技术项目将包括寻找不平等的领域，或者性别关系塑造项目本身和/或被项目塑造的领域。

在机器学习的情况下，当处理训练数据时，暴露数据集中的偏差以“修复”它们正成为一种合法的(希望有一天需要)做法( [Gal Yona](https://medium.com/u/c81e4b81bed8?source=post_page-----6e098d10ea77--------------------------------) 写了它[在这里](https://towardsdatascience.com/a-gentle-introduction-to-the-discussion-on-algorithmic-fairness-740bbb469b6))。

对机器知识偏好的意识和对可解释性的追求与有待解决的社会学和技术挑战相关联。

监管者和购买者似乎将是这两个领域取得重大进展的主要驱动力，就像 IBM 宣布的与合规相关的偏差扫描服务[一样。近年来，对隐私和数据使用透明度的要求成为了对抗世界上最强大公司的一个杠杆。那些认识到人工智能偏见风险的人可能会随波逐流。](https://techcrunch.com/2018/09/19/ibm-launches-cloud-tool-to-detect-ai-bias-and-explain-automated-decisions/)

女性界面的问题依然存在。在选择一个用户可能会更愿意与之交谈的角色的背后，有着强大的商业动机，从而鼓励参与并加速数据的积累。

**对于一些需要单独分析的以女性为主的工作的自动化也可能有积极的影响。**然而，对女性身份的滥用和经常以女性身体来掩盖高度侵入性的商业技术，同时保持友好(近乎幼稚？)感觉——肯定值得进一步探索。