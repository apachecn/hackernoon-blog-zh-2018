# 用 Hinglish 处理令人不快的推文

> 原文：<https://medium.com/hackernoon/fighting-for-acceptance-on-social-media-tackling-offensive-tweets-in-hinglish-ad10e0eef2b9>

## 打击社交媒体上的仇恨言论:

我有幸在 ACL'18 和 EMNLP'18 这两个顶级 NLP 会议上展示了我在用[代码](https://hackernoon.com/tagged/code)转换印地语-英语进行攻击性文本分类方面的工作。根据我收到的大量反馈，我能够提高的外联和意识，以及我能够在社交媒体上参与解决心理健康问题的人数，我决定更深入地研究这项工作的动机和方法。

我们的团队非常幸运地为我们的论文获得了资助，我们很高兴能够获得这个平台，不仅可以学习，还可以将我们在这些论坛中学到的一切带回我们的社区。写这篇文章的动机和我为什么写我的其他博客文章或发表演讲是一样的；我想回馈社区，我想通过利用人工智能和人工智能对社会有益的方面，向学生介绍如何使网络成为一个更受欢迎、开放和安全的地方。

论文可以在 ACL 选集中找到:

1.  http://www.aclweb.org/anthology/W18-3504
2.  【http://www.aclweb.org/anthology/W18-5118 

# **对问题的深入研究**

社交媒体上攻击性内容的猖獗使用对一个进步的社会具有破坏性，因为它往往会助长虐待、暴力和混乱，并在不同层面上严重影响个人。具体来说，在印度次大陆，由于廉价的数据，互联网用户的数量正在迅速上升。随着这种增长，社交媒体上的仇恨言论、攻击性和辱骂性帖子的问题也随之而来。社交媒体充斥着此类攻击性内容，根据歧视的严重程度和目标，这些内容可被广泛归类为辱骂和仇恨诱导

**仇恨言论 vs 辱骂言论:有区别吗？**

> 仇恨言论是基于某些关键属性，如宗教、种族、性取向、性别、意识形态背景、精神和身体残疾，冒犯一个人或一个群体的行为。
> 
> 辱骂性言语是攻击性的言语，目标模糊，意图轻微，意在伤害接受者的感情。

# 欣格里什:什么和为什么？

**什么是 Hinglish？**

Hinglish 是在线攻击性极高的一个主要贡献者，这种攻击性由印地语口语形成，但用罗马字体而不是梵文字体书写。英语是一种基于发音的双语语言，没有固定的语法规则。Hinglish 扩展了它的语法设置，从本地的印地语伴随着过多的污点，俚语和由于地区影响的语音变化。

**hing lish 是常用来保证攻击性文本分类研究的吗？**

大多数社交媒体平台会在以下情况下删除此类攻击性内容:(I)有人手动举报或(ii)攻击性内容分类器自动检测到它们。然而，人们经常使用这种代码转换语言在社交媒体上写攻击性内容，使得英语训练的分类器不能自动检测它们，这就需要一种能够从代码转换语言中自动检测攻击性内容的有效分类器。2015 年，印度在社会敌对指数中排名第四，指数值为 8.7，满分为 10 分，这使得过滤 Hinglish 中极高的攻击性在线内容势在必行。

# 挑战

Hinglish 有以下特点:

1.它由印地语(Indic)语言中的单词组成，但是用罗马字体而不是标准的梵文字体书写。

2.它是许多基于发音的伪语言之一，由社交媒体用户为了便于交流而自然创建。

3.它没有固定的语法规则，而是借用了当地印地语的语法设置，并用罗马字母以及过多的蔑称、俚语和因地区影响而产生的语音变化来赞美它。

因此，这种代码转换语言在由于外来文字而导致的显式单词的随机拼写变化以及由于在不同上下文环境中对单词的各种解释而产生的复合歧义方面呈现出挑战性的局限性。

在处理 Hinglish 时，另一个值得考虑的挑战是 Hinglish 用户相对于全球活跃用户总数的人口统计差异。这造成了严重的限制，因为 Hinglish 语言的 tweet 数据只是所生成的大量 tweet 中的一小部分，需要使用选择性的方法来自动处理这些 tweet。

# 公式化问题

1.  创建一个由 tweets 组成的数据集，以识别 Hinglish 语言中的攻击性、辱骂性和仇恨性言论。
2.  确定一组不同的特征，以建立一个强大的分类器。
3.  基于特征选择的模型开发和具有迁移学习的深度学习方法的探索。

在下一篇文章中，我将深入讨论每个子问题的技术方面。

# 数据:收集和注释

**热门数据集**

HOT 是一个手动标注的数据集，它是使用 Twitter 流 API3 通过选择包含 3 个以上 Hinglish 单词的推文创建的。这些推文是在 2017 年 11 月至 2018 年 2 月的 4 个月间隔期间收集的。通过施加地理位置限制来挖掘推文，使得仅源自印度次大陆的推文成为语料库的一部分。收集的推文语料库最初有 25667 条推文，这些推文被过滤掉，以删除仅包含 URL、仅包含图像和视频、少于 3 个单词、非英语和非英语脚本以及重复的推文。

![](img/2b218928927f693f17582e717dc94222.png)

T-SNE plot of the HOT dataset

**热标注**

热门推文的注释是由三个在自然语言处理研究方面有足够背景的注释者完成的。如果这些推文满足一个或多个条件，它们就会被贴上仇恨言论的标签:(一)推文使用性别歧视或种族诽谤来针对少数群体，(二)有损尊严的定型观念，或(三)支持#ReligiousSc*m 等有问题的标签。

![](img/af370ba7b103cd136e77e7ff740df1d3.png)

Examples of tweets in the HOT dataset

# 方法学

**预处理**

预处理经常被忽视，但它是 NLP 问题中最关键的步骤之一。从数据源获得的推文通过以下预处理管道进行传输，目的是将它们转换为语义特征向量。

1.  第一个预处理步骤是删除标点符号、URL、用户提及{@mentions}和数字{ 0–9 }。
2.  散列标签和表情符号被它们的文本对应物适当地转换，同时将所有推文转换成小写字母。
3.  停用词移除，然后使用 http://www.cfilt.iitb.ac.in/~hdict/webinterface_user/[将 Hinglish tweet 中的每个单词音译和翻译成相应的英语单词。](http://www.cfilt.iitb.ac.in/~hdict/webinterface_user/)
4.  创建单词嵌入层。

**MIMCT 型号**

MIMCT 模型具有由两个主要组件组成的分离架构:

1.  主要和次要输入。
2.  CNN-LSTM 双通道神经网络。

![](img/cfd123d65a4a2e2be2be46f1bf9ef14f.png)

MIMCT Model

**这个模型一定要这么复杂吗？**

您可能在想，一定有更简单的模型可以解决这个问题。这里发生了很多事情，虽然本文对此进行了更正式的描述，但我将尝试用最简单的方式来描述。

除了常规的嵌入输入之外，还需要附加的分层上下文特征，以便补充文本数据的整体分类。这些特征还关注常规词典语料库中可能不存在的情感和定制的滥用。这有助于克服分类任务中的严重瓶颈，并且可能是基线和基本迁移学习方法中滥用和仇恨诱导类的高错误分类的主要原因之一。作为二次输入添加到 MIMCT 模型的多种模式有:

1.  情绪得分:正面/中性/负面
2.  LIWC 特征:真实性、心理状态等的生成性标签。
3.  亵渎向量:Hinglish 中特定坏词的存在。

**通过 CNN 和 LSTMs 转移学习**

应用迁移学习的建议受到这样一个事实的启发，即尽管有一个小规模的数据集，但它以减少的存储和计算成本提供了相对的性能提高(Bengio，2012)。在 EOT 上预先训练的深度学习模型学习英语推文的低级特征。初始卷积层的权重被冻结，而最后几层保持可训练，使得当模型在热数据集上被重新训练时，它学习提取对应于翻译的英语语言中的语法变化的高级特征。

**深入建筑**

CNN:卷积 1D 层(滤波器大小=15，内核大小=3) →卷积 1D(滤波器大小=12，内核大小=3) →卷积 1D(滤波器大小=10，内核大小=3) →下降(0.2) →平坦层→密集层(64 个单位，激活= 'relu') →密集层(3 个单位，激活= 'softmax ')

LSTM : LSTM 层(h=64，辍学=0.25，经常辍学=0.3) →密集(64 个单位，激活= 'relu') →密集(3 个单位，激活= 'sigmoid ')

# 结果

![](img/835fff83f2291bc0886a79b85a46e435.png)

Results for non-offensive, abusive, hate-inducing tweet classification on EOT, HOT and the HOT dataset with transfer learning (TFL) for Glove, Twitter Word2vec and FastText embeddings

关键要点:

1.  与基线监督分类器的其他配置相比，补充了 TF-IDF 特征的 SVM 给出了峰值性能。
2.  TF-IDF 是在语义上表示 Hinglish 文本的最有效的特征，并且给出了比单词向量包和字符 N-grams 更好的性能。
3.  迁移学习后，模型在 HOT 上的表现显著提高，加强了从英语到英语 tweet 数据的特征正迁移的论点。
4.  虽然情感评分不是很有用，但脏话向量和 LIWC 特征的结合带来了巨大的改进。

![](img/b3a30cd052196cbb65f81e89b7ccc0b0.png)

Results of the MIMCT model with various input features HOT compared to the previous baseline. Primary inputs are enclosed within parentheses, and secondary inputs are enclosed within square brackets.

## **错误分析**

1.  **创造性的单词变形**:人类注释者和分类器错误地将推文“chal bhaag m*mdi ”(英文翻译为“go run m*mdi ”)识别为无害的，而不是引起仇恨的。这里的“m*mdi”是指一个特定的少数民族的一种土著方式，它已经被变形以逃避可能的识别。
2.  **间接仇恨**:推特“Bas kar ch*tiye m***rsa educated”被我们的注释者正确地识别为引发仇恨，但分类器将其识别为辱骂。这是因为将这条推文预处理为“限制它去他妈的宗教学校教育”会导致它失去对特定社区的习俗和传统的上下文参考。
3.  不常用的英语单词:本书目前的形式不涉及不常用的和未知的英语单词。这些可能是由于拼写变化、同音异义词、语法不正确、混合外语、地区方言的影响或由于 146 音译过程的主观性质的疏忽而引起的。
4.  **语码混合词分析**:之前的研究表明，双语语言倾向于偏向于在文本的特定位置对某些词进行语码混合。这方面的语境研究有助于在今后的工作中消除从 Hinglish 到 English 音译的主观问题。
5.  **同质数据上可能的过度拟合**:社交媒体门户上通常呈现的数据往往是嘈杂的，内容经常重复。数据集类别平衡的偏斜以及对深层模型的训练可能导致数据的过度拟合，并可能导致预期结果和真实结果之间的较大差异。我们怀疑这可能是目前实验中固有的，可以通过从异质来源提取数据来模拟现实生活场景来克服。

# 结论和未来工作

我们工作的主要贡献可以总结如下:

1.  构建带注释的 Hinglish 攻击性 Tweet (HOT)数据集
2.  我们确定了迁移学习对分类攻击性英语推文的有用性。
3.  我们建立了一个新的 MIMCT 模型，其性能优于 HOT 上的基线模型。

未来的工作包括:

1.  更优特征子集的特征选择。
2.  基于 GRU 模型的探索。
3.  浅 CNN 堆叠系综研究。