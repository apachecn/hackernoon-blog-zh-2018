# ä½¿ç”¨ RNNs ç”Ÿæˆæ•…äº‹|å¸¦ä»£ç çš„çº¯æ•°å­¦|:

> åŸæ–‡ï¼š<https://medium.com/hackernoon/generate-stories-using-rnns-pure-mathematics-with-code-cb6f1e967b22>

![](img/314cbec63462cef83ca0c67efc2b800e.png)

ä½ å¥½ï¼Œè¯»è€…ï¼

> è¯»è€…æ³¨æ„:
> 
> è¿™ç¯‡æ–‡ç« å‡è®¾ä½ å¯¹æ·±åº¦å­¦ä¹ çš„æ•°å­¦ä¸–ç•Œéå¸¸ç€è¿·ã€‚ä½ æƒ³è¦æ·±å…¥åˆ°æ·±åº¦å­¦ä¹ çš„æ•°å­¦ä¸­å»ï¼Œä»¥äº†è§£åœ¨å¼•æ“ç›–ä¸‹å®é™…å‘ç”Ÿäº†ä»€ä¹ˆã€‚
> 
> **å…³äºè¿™ç¯‡æ–‡ç« çš„ä¸€äº›ä¿¡æ¯:**
> 
> åœ¨æœ¬æ–‡ä¸­ï¼Œæˆ‘ä»¬å°†ä»å¤´å¼€å§‹è®¨è®ºå’Œå®ç° RNNsã€‚ç„¶åï¼Œæˆ‘ä»¬å°†ä½¿ç”¨å®ƒä»¬æ¥ç”Ÿæˆæ–‡æœ¬(å¦‚è¯—æ­Œã€c++ä»£ç )ã€‚åœ¨é˜…è¯»äº† Andrej Karpathy å…³äºâ€œ[é€’å½’ç¥ç»ç½‘ç»œ](http://karpathy.github.io/2015/05/21/rnn-effectiveness/)çš„ä¸åˆç†æœ‰æ•ˆæ€§â€çš„åšå®¢åï¼Œæˆ‘å—åˆ°äº†å†™è¿™ç¯‡æ–‡ç« çš„å¯å‘ã€‚è¿™æ®µä»£ç ç”Ÿæˆçš„æ–‡æœ¬å¹¶ä¸å®Œç¾ï¼Œä½†å®ƒç»™å‡ºäº†æ–‡æœ¬ç”Ÿæˆå®é™…å·¥ä½œæ–¹å¼çš„ç›´è§‰ã€‚æˆ‘ä»¬çš„è¾“å…¥å°†æ˜¯åŒ…å«ä¸€äº›æ–‡æœ¬(å¦‚èå£«æ¯”äºšçš„è¯—)çš„çº¯æ–‡æœ¬æ–‡ä»¶ï¼Œæˆ‘ä»¬çš„ç¨‹åºå°†ç”Ÿæˆç±»ä¼¼äºè¾“å…¥(è¯—)çš„è¾“å‡ºï¼Œè¿™å¯èƒ½æœ‰æ„ä¹‰ï¼Œä¹Ÿå¯èƒ½æ²¡æœ‰æ„ä¹‰ã€‚

è®©æˆ‘ä»¬æ·±å…¥ RNNs çš„æ•°å­¦ä¸–ç•Œã€‚

é‚£ä¹ˆ RNN çš„åŸºæœ¬ç»“æ„æ˜¯ä»€ä¹ˆå‘¢ï¼Ÿ

![](img/0fcac18e55b714cdf609e1ad8774bf8d.png)

Fig 1 :Vanilla RNN

![](img/ce9ed6a2d5d360bb512d44d26069f785.png)

Fig 2: Unrolled Vanilla RNN

ä¸è¦æ‹…å¿ƒä»»ä½•æ¡æ¬¾ã€‚æˆ‘ä»¬å°†é€ä¸€è®¨è®ºå®ƒä»¬ã€‚å®ƒä»¬å¾ˆå®¹æ˜“ç†è§£ã€‚

åœ¨å›¾ 1 ä¸­:

**h(t)**:RNN åœ¨æ—¶é—´ t=t æ—¶çš„éšè—çŠ¶æ€

**fw** :éçº¿æ€§å‡½æ•°(ä¸»è¦æ˜¯ tanh)

**Whh** :éšæœºåˆå§‹åŒ–çš„æƒé‡çŸ©é˜µã€‚å½“æˆ‘ä»¬ä» **h** ç§»åŠ¨åˆ° **h** æ—¶ä½¿ç”¨(éšè—çŠ¶æ€åˆ°å¦ä¸€ä¸ªéšè—çŠ¶æ€)ã€‚

**Wxh** :éšæœºåˆå§‹åŒ–çš„æƒé‡çŸ©é˜µã€‚å½“æˆ‘ä»¬ä»' **x'** ç§»åŠ¨åˆ°' **h'** (éšè—çŠ¶æ€çš„è¾“å…¥)æ—¶ä½¿ç”¨ã€‚

**ä¸ºä»€ä¹ˆ**:å½“æˆ‘ä»¬ä»' **h'** ç§»åŠ¨åˆ°' **y'** å‘ˆç°éšè—çŠ¶æ€è¾“å‡ºæ—¶ï¼Œéšæœºåˆå§‹åŒ–æƒé‡çŸ©é˜µã€‚

**bh(ä¸åœ¨ç…§ç‰‡ä¸­)**:éšæœºåˆå§‹åŒ–çš„åˆ—çŸ©é˜µï¼Œä½œä¸ºåå·®çŸ©é˜µåŠ å…¥ h(t)çš„è®¡ç®—ä¸­ã€‚

**by(ä¸åœ¨ç…§ç‰‡ä¸­)**:éšæœºåˆå§‹åŒ–çš„åˆ—çŸ©é˜µï¼Œä½œä¸ºè®¡ç®— y(t)æ—¶è¦åŠ å…¥çš„åç½®çŸ©é˜µã€‚

**ä»£ç :**

æˆ‘ä»¬ä»å¯¼å…¥æ•°æ®å¼€å§‹:

ä»[è¿™é‡Œ](https://github.com/Manik9/RNNs-from-scratch-)ä¸‹è½½æ•°æ®ã€‚

```
**char_to_ix:** it's a dictionary to assign a unique number to each unique character
**ix_to_char:**it's a dictionary to assign a unique character to each number.
We deal with assigned number of each character and predict number of next character and then use this predicted number to find the next character.
```

*éšè—å¤§å°*:éšè—ç¥ç»å…ƒçš„æ•°é‡

*seq_length* :è¿™æ˜¯æŒ‡æˆ‘ä»¬å¸Œæœ›æˆ‘ä»¬çš„ RNN è®°ä½å¤šå°‘ä¸ªå…ˆå‰çš„ç´§æ¥çš„çŠ¶æ€ã€‚

*lr* :ä»£è¡¨å­¦ä¹ ç‡ã€‚

> **åˆå§‹åŒ–å‚æ•°:**

åˆå§‹åŒ–æˆ‘ä»¬ä¸Šé¢è®¨è®ºçš„å‚æ•°(Whh â€¦â€¦ by)ã€‚

> **å‘å‰ä¼ çƒ:**

ForwardPass.py

xsï¼Œysï¼Œhsï¼Œps éƒ½æ˜¯å­—å…¸ã€‚

**xs[t]** :åœ¨æ—¶é—´(character) t=tï¼Œæˆ‘ä»¬ä½¿ç”¨ç‹¬çƒ­ç¼–ç æ¥è¡¨ç¤ºå­—ç¬¦ï¼Œå³é™¤äº†ä¸€ä¸ªå…ƒç´ ä¹‹å¤–ï¼Œç‹¬çƒ­å‘é‡çš„æ‰€æœ‰å…ƒç´ éƒ½æ˜¯é›¶ï¼Œå¹¶ä¸”æˆ‘ä»¬ä½¿ç”¨ char_to_ix å­—å…¸æ¥æ‰¾åˆ°è¯¥å…ƒç´ (å­—ç¬¦)çš„ä½ç½®ã€‚ç¤ºä¾‹:å‡è®¾æˆ‘ä»¬çš„æ•°æ®ä¸ºâ€œabcdefâ€ã€‚æˆ‘ä»¬é€šè¿‡ä½¿ç”¨ç‹¬çƒ­ç¼–ç å°†â€œaâ€è¡¨ç¤ºä¸º

```
this is what we are doing in 25th,26th line in the code above.
a=[[1], 
   [0],
   [0],
   [0],
   [0],
   [0]] 
```

**ys[t]** :åœ¨æ—¶é—´(character) t=tï¼Œæˆ‘ä»¬å­˜å‚¨é‚£ä¸ª RNN å•å…ƒæ ¼çš„æœ€ç»ˆè¾“å‡ºã€‚

**hsã€tã€‘**:åœ¨æ—¶é—´(character)t=tï¼Œæˆ‘ä»¬å­˜å‚¨å½“å‰ RNN å•å…ƒæ ¼çš„éšè—çŠ¶æ€ã€‚

**PSã€tã€‘**:åœ¨æ—¶é—´(å­—ç¬¦)t=tï¼Œæˆ‘ä»¬å­˜å‚¨æ¯ä¸ªå­—ç¬¦å‡ºç°çš„æ¦‚ç‡ã€‚

æ­£å¦‚ä½ åœ¨ä¸Šé¢çš„ä»£ç ä¸­çœ‹åˆ°çš„ï¼Œæˆ‘ä»¬å®ç°äº†ç®€å•çš„è®¡ç®—ï¼Œå¦‚å›¾ 1 æ‰€ç¤ºçš„ xs[t]ï¼Œys[t]ï¼Œhs[t]ï¼Œps[t]ã€‚

æœ€åï¼Œæˆ‘ä»¬è®¡ç®— softmax æŸå¤±ã€‚

![](img/9e96d7a8233ffed3671634f57506eb0a.png)

Forward Pass

> **å‘åä¼ çƒ**

dWxh:å¯¼æ•° w.r.t çŸ©é˜µ Wxhã€‚æˆ‘ä»¬å°†ç”¨å®ƒæ¥ä¿®æ­£æˆ‘ä»¬çš„ Wxh çŸ©é˜µã€‚ä»¥åŠç±»ä¼¼çš„ dWhhï¼ŒdWhyï¼Œdbhï¼Œdbyï¼Œdhnextã€‚

ä¸ºäº†è¿”å›åˆ° y:æˆ‘ä»¬ä»æ­£ç¡®çš„ä¸‹ä¸€ä¸ªå­—ç¬¦çš„å‡ºç°æ¦‚ç‡ä¸­å‡å» 1ï¼Œå› ä¸º:

![](img/0458929130753e6f0c63c9fdb402d76d.png)

stanford CS231N notes

```
Now:
To calculate:
**dy**: ps[t]-1**dWhy** += : dyâ€¢hs[t].T
**dh** += Why.Tâ€¢dy + dhnext**dby** += dy (As matrix multiplication term becomes zero in   derivative )#backprop in hs[t] now:
**dhraw** adds derivative w.r.t tanh(derivative of tanh is 1-tanh^2)
dhraw= (1-hs[t]^2)*dhdbh += dhraw (because derivative matrix multiplication terms is zero w.r.t dbh)
dWhx += (dhrawâ€¢xs[t].T)
dWhh += (dhrawâ€¢hs[t-1])
finally:
dhnext += (Whh.Tâ€¢dhraw)
```

ä¸€åˆ‡éƒ½å‡†å¤‡å¥½äº†:

## **è¯¥è¿è¡Œç¨‹åºäº†:DeepLearning Studio**

rnn åœ¨è®¡ç®—ä¸Šéå¸¸æ˜‚è´µã€‚ä¸ºäº†è®­ç»ƒæˆ‘ä»¬çš„ç¨‹åºï¼Œæˆ‘ä½¿ç”¨äº† Deep Cognition çš„**æ·±åº¦å­¦ä¹ å·¥ä½œå®¤**ã€‚å®ƒæä¾›äº†é¢„è£…çš„æ·±åº¦å­¦ä¹ æ¡†æ¶ï¼Œå¦‚ Tensorflow-gpu/cpuã€keras-gpu/cpuã€py torchâ€¦ç­‰ç­‰ã€‚æŸ¥çœ‹[**è¿™é‡Œ**](https://deepcognition.ai/) ã€‚

![](img/f309cadaf171bda7a941d1dbfb19cdeb.png)![](img/289ef4f5e5caadca3e2e09fd0491771a.png)

click on Notebooks and youâ€™re ready to code! âœ‹

[](https://deepcognition.ai/) [## æ·±åº¦è®¤çŸ¥â€”â€”ä»Šå¤©å°±æˆä¸ºä¸€ä¸ªäººå·¥æ™ºèƒ½é©±åŠ¨çš„ç»„ç»‡

### æ— éœ€ç¼–ç å³å¯è®¾è®¡ã€è®­ç»ƒå’Œéƒ¨ç½²æ·±åº¦å­¦ä¹ æ¨¡å‹ã€‚æ·±åº¦å­¦ä¹ å·¥ä½œå®¤ç®€åŒ–å¹¶åŠ é€Ÿäº†â€¦

deepcognition.ai](https://deepcognition.ai/) 

mbhï¼Œmby æ˜¯ Adagrad optimiser çš„å†…å­˜å˜é‡ã€‚

![](img/db042448bafdfbd99fb0ca4b327d1622.png)

For line number 7â€“11\. Here one-step = seq_length.

æœ€åï¼Œæ ¹æ®ä¸åŒå‚æ•°(Whyâ€¦h(t))çš„æŸå¤±å‡½æ•°è®¡ç®—æŸå¤±ï¼Œå¹¶ä»ç›¸åº”å‚æ•°ä¸­å‡å»æŸå¤±ã€‚

```
line number 5-6 is the way we Adagrad works.
Like in normal gradient descent we do:
theta= theta-lr*grad
1e-8 is used to prevent DivisionByZero exception.
```

> **åŸ¹è®­ç»“æœ:**

![](img/8b99b7be840df8add13e2214f80d450a.png)

```
At epoch zero:Generated text
**loss=106.56699692603289
iteration:0**QZBipoe.M
prbâ€™gxc]QXECCYâ€œf);wqEnJAVV-Dn-
Fl-tXTFTNI[ ?Jpziâ€BPMâ€™TxJlhNyFamgIj)wvxJDwBgGbF!Dâ€œFâ€˜bU;[)KXrT km*;xwYZIx-
AX
dDl_zk(QlW(KolSenbudmX.yq
H-(uPUl-B:mj]oâ€™E-ZTjzH)USf:!
sCiTkTMcmgUY)rCj
ZaL*rhWVpS----
**---------------------------------------------------** l was  beginning begiginning to Alice walicegininn to geteginninato giteginniito geteginninn to geteginninatg gegeginninasto get beginninnninnigw to gicleaaaa  was ginniicg benning to get a wen----
**loss=11.115271278781561
iteration:66200**
```

å®ƒå¼€å§‹å­¦ä¹ åƒâ€œå¼€å§‹ï¼Œçˆ±ä¸½ä¸ï¼Œæ›¾ç»ï¼Œå»ï¼Œå»â€¦â€¦â€è¿™æ ·çš„å•è¯ã€‚ä¸€ç‚¹éƒ½ä¸å®Œç¾ã€‚ä½†å®ƒç»™äººä¸€ç§ç›´è§‰ï¼Œå³ç»™å®šä¸€äº›æ ·æœ¬æ•°æ®ï¼Œæˆ‘ä»¬å¯ä»¥ç”Ÿæˆé€‚å½“çš„æ–‡æœ¬ã€‚LSTMs çš„æ€§èƒ½æ¯” RNNs å¥½å¾—å¤šã€‚LSTMs æ˜¯å…·æœ‰ 3-4 ä¸ªé—¨çš„ RNNs çš„æ‰©å±•ã€‚è¯·åŠ¡å¿…æŸ¥çœ‹æˆ‘åœ¨ LSTMs ä¸Šçš„æ–‡ç« 

[](https://hackernoon.com/understanding-architecture-of-lstm-cell-from-scratch-with-code-8da40f0b71f4) [## ç”¨ä»£ç ä»é›¶å¼€å§‹ç†è§£ LSTM ç»†èƒçš„ç»“æ„ã€‚

### åœ¨æ•°æ®åºåˆ—å¾ˆé‡è¦çš„æƒ…å†µä¸‹ï¼ŒåŒ…æ‹¬ CNN åœ¨å†…çš„æ™®é€šç¥ç»ç½‘ç»œè¡¨ç°ä¸ä½³ã€‚æ¯”å¦‚è¯´â€¦

hackernoon.com](https://hackernoon.com/understanding-architecture-of-lstm-cell-from-scratch-with-code-8da40f0b71f4) 

åœ¨**[**github repo**](https://github.com/Manik9/RNNs-from-scratch-)**ä¸Šè®¿é—®å¸¦æœ‰æ•°æ®é›†çš„å®Œæ•´ä»£ç ã€‚****

**æ­å–œè¯»è€…ï¼Œç°åœ¨ä½ å·²ç»æ·±å…¥äº†è§£äº† RNNs(ç®€å•çº¿æ€§ä»£æ•°)çš„æ•°å­¦çŸ¥è¯†ã€‚**

**æ„Ÿè°¢æ‚¨æŠ½å‡ºå®è´µçš„æ—¶é—´é˜…è¯»æˆ‘çš„æ–‡ç« ã€‚å¦‚æœä½ çœŸçš„å–œæ¬¢å®ƒï¼Œè¯·åˆ†äº«å¹¶é¼“æŒğŸ‘ã€‚**

**åœ¨[åª’ä½“](/@maniksoni653)å’Œ [LinkedIn](https://www.linkedin.com/in/maniksoni) ä¸Šå…³æ³¨æˆ‘ã€‚**

**å¿«ä¹æ·±åº¦å­¦ä¹ ã€‚**

**[](/@maniksoni653) [## é©¬å°¼å…‹ç´¢å°¼åŸ¹å…»åŸº

### é˜…è¯»åª’ä»‹ä¸Šçš„ Manik Soni çš„ä½œå“ã€‚æœºå™¨å­¦ä¹ ç ”ç©¶å‘˜ã€‚æ¯å¤©ï¼ŒManik Soni å’Œæˆåƒä¸Šä¸‡çš„å…¶ä»–äººâ€¦

medium.com](/@maniksoni653) [](https://www.linkedin.com/in/maniksoni) [## Manik Soni -æœºå™¨å­¦ä¹ ç ”ç©¶å‘˜-è‡ªé›‡| LinkedIn

### æŸ¥çœ‹ Manik Soni åœ¨å…¨çƒæœ€å¤§çš„èŒä¸šç¤¾åŒº LinkedIn ä¸Šçš„ä¸ªäººèµ„æ–™ã€‚Manik æœ‰ 2 ä»½å·¥ä½œåˆ—åœ¨ä»–ä»¬çš„â€¦

www.linkedin.com](https://www.linkedin.com/in/maniksoni)**