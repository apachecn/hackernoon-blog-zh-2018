# 如何为 50 万人创建一个金融市场💸。第二部分(技术)

> 原文：<https://medium.com/hackernoon/how-to-create-a-financial-marketplace-for-500-000-people-part-ii-technical-4d2456d9768d>

![](img/0dddac48f1e9586d6644c2e2723bdad3.png)

本文分为两部分:

*   [第一部分:非技术性](/@amozgovoy/how-to-create-a-financial-marketplace-for-500-000-people-part-i-non-technical-78ab893b1a65)
*   第二部分:技术

如果你对生态系统背后的决策和想法感兴趣，请查看本文第一部分[。同时，故事继续定义核心架构。](/@amozgovoy/how-to-create-a-financial-marketplace-for-500-000-people-part-i-non-technical-78ab893b1a65)

现代金融科技银行是一个拥有银行牌照、核心平台、KYC、CRM、API 和一些核心产品的市场。金融科技银行直接提供的产品可能仅限于资金持有、银行账户、卡和支付钱包。

然而，我们的任务并不典型。起初，我们的主要目标是设计和构建一个能够横向扩展的金融平台，能够与多个外部服务提供商集成，拥有一个开放的 API 系统，并且足够模块化，能够扩展到多个产品线和功能。

这就是为什么从平台的基本原则开始非常重要。

# 标准 API 定义

我们需要能够拥有一个可以在所有渠道中使用的单一规范 API 定义，或者允许我们至少验证客户端的正确性。

有必要标准化 [gRPC](http://www.grpc.io/) 来定义服务 API，标准化“逻辑”数据中心内部的 gRPC，然后使用 [grpc-gateway](https://github.com/grpc-ecosystem/Grpc-gateway) 来创建客户端可以调用的 REST 适配器。适配器的这个组件将涵盖所有客户端功能。

# 横向可扩展，运营成本最低

我们不希望在过度开发的系统上花费额外的资金来应对负载，我们也不希望额外的容量成为负担。一切都应该水平缩放。

因此，我们希望将所有内容都转换成 Kubernetes，并将所有服务容器化，这将使我们能够应对负载，提高效率。

我们仍然需要将 Bigtable 标准化为我们的永久存储，因为它的性能成本很高。

# 记录

所有代码都必须有标准的日志记录方式和日志搜索支持。这是至关重要的。

所有的日志行都被转换成 JSON 格式的标准输出，然后使用 EFK 堆栈([elastic search](https://www.notion.so/humaniq/Backend-Infrastructure-overview-rus-22c9eb00448c4bbeaa143e7c4ed5f49d#932524524fab44bb9ce4a0ffacc8cabb)+[fluent d](http://www.fluentd.org/)+[Kibana](https://www.elastic.co/products/kibana))进行连接。

# 韵律学

我们需要一种单一的标准方式来呈现指示板的指示器和警告。

因为我们已经标准化了 Go for development，所以使用 [expvars](https://golang.org/pkg/expvar/) 公开任何度量是有意义的，然后可以清除 [Datadog](https: //www.datadoghq .com /) 或 [Prometheus](https://prometheus.io/) 。额外的好处是，因为我们标准化了 gRPC，所以很容易确保所有 gRPC 服务都设置了一组标准的度量标准，比如对 RPC 端点的响应时间的百分比。

开发人员也可以使用相同的方法轻松地识别附加的、特定于服务的指示器。

# API 网关

网关应用应该是唯一向公众公开的服务。它应该执行以下标准:

*   网关应该能够水平扩展。因此，不应该存在任何应用程序状态；
*   网关必须能够异步组合请求和调用微服务；
*   网关必须能够限制一段时间内的请求数量；
*   网关必须能够验证认证令牌的真实性。*传统上，建议 API 网关执行认证，底层微服务执行对其资源的授权，但我们将采用何种认证方法有待讨论；*
*   网关必须能够自动从微服务导入可用资源。首先，我们将选择 Swagger 格式，这是当今世界上最流行的格式；
*   网关必须能够改变(改变)微服务的回复；
*   网关必须能够与 gRPC 适配器(grpc-gateway)的 REST 对话
*   最后:网关应该完美地直接从 Docker 镜像运行，并通过环境变量进行配置。我们不需要任何额外的存储库、删除脚本等等。

# GCP 堆栈

在选择我们的云服务提供商时，我们决定使用谷歌云平台。我们受到三个主要因素的驱动:隔离、性能和成本，以及开箱即用的 Kubernetes。

## *隔离*

我们知道我们想尝试更先进的地理商店和其他技术，并认为我们肯定会在早期遇到困难。在这种情况下，确保不影响其他服务的最好方法是创建一个新的、完全独立的服务。

## *性能&成本*

有一个存储和提供大量地理标记和聚合数据的计划，我们需要一个低成本、持久的存储，它非常适合这个用例。这就是 Google Bigtable 真正闪光的地方，它让迁移对我们更有吸引力。例如，您可以支持默认的 3 节点集群，该集群支持大约 30，000 个 QPS，每月价格约为 1，500 美元，包括存储。由于容量是在集群级别而不是在表级别调配的，因此您不必担心过度调配特定于用例的表而浪费资金。

## 库伯内特斯

这个很简单。在写这篇文章的时候，AWS 已经提供了“开箱即用”的 Kubernetes 服务，所以这个要点相对没用。然而，在设计平台的时候，这是决策制定的关键原因之一。

这是 GCP 堆栈的高级概述。所有与区块链相关的数据都被排除在范围之外，也不在这里讨论。而以集中方式存储的所有数据都属于当前堆栈。

![](img/7fc18f289a1cedd65b7f52b9295367be.png)

# 整体还是微服务？

在这种特定情况下，最有效的方法是使用微服务。这个决定是基于创建一组核心服务和控制依赖指数的尝试。

![](img/d35c39dce99debe88a58d268c39cd79f.png)

Number of services running on the platform (besides network layers)

关于微服务的简要说明。微服务是独立构建的系统，每个都在自己的进程中运行，经常与 REST API 通信。它们代表应用程序的不同部分，可以单独部署，每个部分都可以用任何语言编写。

通过处理单块系统的问题，你可以很容易地看到微服务是如何成为任何先进软件的需求的。

如果你想更深入地了解这种架构风格中的关键概念，我强烈推荐你阅读《T2》微服务(詹姆斯·刘易斯)和《单片微服务》的[。](https://dev.otto.de/2015/09/30/on-monoliths-and-microservices/)

# 库伯内特斯

Kubernetes 的设计初衷是成为使用容器构建、管理和编排分布式应用程序的理想平台。它包括用于复制和服务发现的原语，作为其核心的一部分(这些是通过 Mesos 中的框架添加的，需要一些知识来正确配置)，Kubernetes 的愿景是开发一个系统，允许企业以最高的效率、安全性和易用性管理可扩展的应用程序部署。

就个人而言，我喜欢将 Kubernetes 描述为“一种特殊的云操作系统”——这是一种允许开发人员将任意数量的机器视为一台非常强大的机器的操作系统。在我看来，K8s 对于云就像 Linux 或者 Windows 对于电脑一样。

就像操作系统为开发人员提供了一个来自组成计算机的硬件的抽象层一样，K8s 为开发人员提供了一个来自组成云的计算机的抽象层。

你对这种比较想得越多，你就会发现更多的相似之处。例如，操作系统的主要目的之一是调度进程，以便它们可以在单台机器上高效地共享硬件资源——类似地，K8s 的主要目的之一是调度容器，以便它们可以在云(可能由多台机器组成)上高效地共享计算资源。

一旦你认为 K8s 是一个“云操作系统”,商业机会就开始实现了。我们不再只是谈论一个提高部署效率的系统，而是谈论一个用于构建云原生应用的全新平台。

# 混合平台

## 它是如何工作的？

混合系统中有三层区块链:以太坊主网、主内部区块链和特定国家的区块链。每个内部区块链都是以太坊协议的修改版，交易费用和排放为零。在它们里面有一个代币，作为主要的货币，就像以太网一样。

请注意，在内部区块链上没有发生发射，因为这些都是从“主钱包”中已经存在的最大可用令牌供应开始的。当令牌离开网络时，它们被发送到第二个“清算钱包”，实际上是“烧掉”或删除它们。

系统必须处理三种关键情况:当用户创建帐户时；当令牌从生态系统发送到外部世界时；最后，当令牌从外部世界发送到混合生态系统时。

## 创建用户帐户

![](img/206785be74222ac87ed50009512159b7.png)

当用户注册一个新账户时，服务负责通过区块链 API 创建两个相同的钱包，重复使用相同的私钥。这样，一个用户在 ETH Mainnet 和私有链上都有完全相同的地址。这些信息随后被返回给 Tapatybe 服务(负责保存用户身份)并与账户绑定。

作为响应，TokenRef 服务被调用，它在 ETH Mainnet wallet(通过调用合同并铸造令牌)和私有链上执行所需的发射:此时，令牌从主/清算 wallet 传输到用户的内部 wallet。

## **从内部到外部的交易**

![](img/4a5bbf067a60b6393a1de0e78b147f49.png)

当用户发起交易时，有两种可能的情况:要么钱包属于网络，要么它属于以太网。

当事务开始时，调用一个服务来确定目的地址是否存在于数据库中。如果有，它只是将交易代理给内部链的区块链 API。如果地址确实是外部的，那么事务被添加到一个队列中，由第二个服务拾取。

然后，该服务将事务代理到 ETH Mainnet，这是从中转地址广播的。一旦完成，它就会调用区块链 API 来创建一个交易，该交易会在用户的内部余额上“刻录”令牌，并将它们发送到清算钱包。

## **从外部到内部的交易**

![](img/9d12cc7210d15ca295097c0f59ddc7a9.png)

鉴于外部交易可能随时到来，区块链服务必须“监听”所有钱包的传入交易。每当检测到新的交易时，第二个服务启动从用户的 mainnet 地址到 Transit Wallet 的资金转移，将交易分组以尽可能降低成本。

然后调用第三个服务，该服务命令内部区块链 API 将令牌从主钱包分发到用户的内部余额。

## **混合系统如何实现可扩展性？**

私有区块链是并行工作的，这意味着我们可以根据需要添加任意多的它们来增加以太坊的 TPS。当然，区块链间业务的存在意味着一些效率损失，但这只是整个交易池的一小部分。

# 在应用程序中共享联系人

如果服务使用的标识符已经列在典型的联系人卡片中(电话号码或电子邮件)，则很容易快速显示用户的哪些联系人也注册了该服务，并立即向该用户提供社交功能。这意味着，如果朋友们已经把对方作为联系人，他们就不必在服务上“发现”对方。

问题是，计算注册用户和设备联系人交集的最简单方法是将地址簿中的所有联系人上传到服务，对它们进行索引，反向索引，将交集发送给客户端，并在这些联系人中的任何一个后来注册时通知客户端。

# 布隆过滤器和加密的布隆过滤器

有一整个研究领域致力于解决类似这样的问题，被称为“私人信息检索”(PIR)。最简单的 PIR 形式是服务器向客户端发送注册用户的完整列表，然后客户端可以在本地查询。基本上，如果客户机拥有整个数据库的副本，它就不会将其数据库查询泄露给服务器。

我们可以通过在 bloom 过滤器中传输注册用户的列表来提高网络效率，bloom 过滤器的误报率较低。为了避免泄露所有注册用户的列表，甚至可以通过以下方式使用“加密布隆过滤器”构建一个“对称 PIR”系统:

1.  服务器生成一个保密的 RSA 密钥对。
2.  服务器不是将每个用户放入[布隆过滤器](https://en.wikipedia.org/wiki/Bloom_filter)，而是将每个用户的 RSA 签名放入布隆过滤器。
3.  客户端请求 bloom filter，它包含每个注册用户的 RSA 签名。
4.  当客户端希望查询本地 bloom 过滤器时，它根据 David Chaum 的[盲签名方案](https://en.wikipedia.org/wiki/Blind_signature)构建一个“盲”查询。
5.  客户端将隐蔽的查询发送到服务器。
6.  服务器对隐蔽查询进行签名，并将其发送回客户端。
7.  客户端[解开查询](https://en.wikipedia.org/wiki/Blind_signature)以揭示它希望查询的联系人的服务器 RSA 签名。
8.  然后，客户端检查其本地布隆过滤器中的该值。

也可以压缩布隆过滤器的“更新”。服务器只需要计算客户端拥有的版本和更新版本的异或，然后通过 [LZMA](https://en.wikipedia.org/wiki/Lempel%E2%80%93Ziv%E2%80%93Markov_chain_algorithm) 运行(输入将大部分为零)，并将压缩的 diff 传输到客户端。

# 面部识别系统

面部识别在平台的两个地方使用:

*   在注册和认证期间
*   在钱包中执行交易时的附加验证期间

## 服务认证

所有 API 方法都需要简单的基于令牌的 HTTP 认证。为了进行身份验证，您应该将 world“Token”和一个密钥放入 Authorization HTTP 头中，用空格隔开:

`Authorization: Token yfT8ftheVqnDLS3Q0yCiTH3E8YY_cm4p`

## 常见对象类型

**人脸
代表一张人脸。请注意，一张照片上可能有几个人。同一个人的不同照片也被认为是不同的面孔。**

*   `"id" (number)`:服务生成的人脸的唯一标识符。
*   `"timestamp" (string)`:脸对象创建时间为 ISO8601 字符串。
*   `"photo_hash" (string)`:原照片的哈希。请注意，相同的照片将始终具有相同的哈希，而不同的照片肯定会具有不同的哈希。不要解释这个值，也不要对用于哈希计算的特定哈希函数做出假设。
*   `"x1" (number)`:原始照片上人脸边框左上角的 x 坐标。
*   `"y1" (number)`:原始照片上人脸边框左上角的 y 坐标。
*   `"x2" (number)`:原始照片上人脸边框右下角的 x 坐标。
*   `"y2" (number)`:原始照片上人脸边框右下角的 y 坐标。
*   `"meta" (string)`:元数据字符串，可以用来存储与人脸相关的任何信息。
*   `"galleries" (string[])`:有这个面的图库名数组。
*   `"photo" (string)`:用于创建面部对象的照片的文件名的 URL。
*   `"thumbnail" (string)`:存储在服务缓存中的脸部缩略图的 URL。

## 方法

**创建人脸** 处理上传的图像或提供的 URL，检测人脸并将检测到的人脸添加到可搜索的数据集中。如果照片上有多个面孔，默认情况下只会添加最大的面孔。

或者，您可以添加一个自定义的字符串元，例如名称或 ID，它唯一地标识一个人。多个面对象可能具有相同的元。我们建议您不要将相同的元分配给不同的人。因此，当使用人名作为元时，要确保所有的名字都是唯一的。

此方法的示例响应代码如下所示:

```
{
  "results": [
    {
      "age": 40,
      "emotions": [
        "neutral",
        "surprised"
      ],
      "galleries": [
        "default",
        "ppl"
      ],
      "gender": "male",
      "id": 2333,
      "meta": "Sam Berry",
      "photo_hash": "dc7ac54590729669ca869a18d92cd05e",
      "timestamp": "2016-06-13T11:06:42.075754",
      "x1": 225,
      "x2": 307,
      "y1": 345,
      "y2": 428
    }
  ]
}
```

**检测人脸** 该方法在提供的图像上检测人脸。您可以将图像文件作为多部分/表单数据上传，或者提供一个 URL，API 将使用它来获取图像。

此方法的示例响应代码如下所示:

```
{
  "faces": [
    {
      "age": 36,
      "emotions": [
        "neutral",
        "happy"
      ],
      "gender": "female",
      "x1": 236,
      "x2": 311,
      "y1": 345,
      "y2": 419
    }
  ],
  "orientation": 1
}
```

**验证人脸** 该方法验证两张人脸属于同一个人，或者测量两张人脸之间的相似度。您可以通过设置`threshold`参数在这两种模式之间进行选择。

在这种情况下，当需要二进制决策时，用户可以为`threshold`参数传递一个值。我们为`threshold` : `strict`、`medium`和`low`提供了 3 个预设值，前者旨在最小化错误接受率，而后者更宽松一些。客户端也可以通过固定的阈值来覆盖这些预设值。

此方法的示例响应代码如下所示:

```
{
  "results": [
    {
      "bbox1": {
        "x1": 610,
        "x2": 796,
        "y1": 157,
        "y2": 342
      },
      "bbox2": {
        "x1": 584,
        "x2": 807,
        "y1": 163,
        "y2": 386
      },
      "confidence": 0.9222600758075714,
      "verified": true
    }
  ],
  "verified": true
}
```

# 基础设施的当前外观

自该应用推出以来，对基础设施的需求增加了**十倍**，跨节点使用 **96Gb** 内存，并达到每秒**数百兆字节**的峰值流量。基础设施能够有效应对负载，平均 SLA 为**99.4%**。所有构建和更新都是使用连续交付系统自动推出的，该系统允许服务的透明升级。

我们目前的堆栈基于以下技术和语言:Java(native Android 应用程序)+原生 Android 库、GoLang、Python、PostgreSQL、MySQL、RabbitMQ、Redis、MongoDb、Kubernetes、Docker、Tensorflow(用于基于 AI 的助手 bot ML)、Google Cloud、Sentry、Grafana、各种分析 SDK(Firebase 和其他)、BigQuery、Apache Zeppelin、用于实时通信的 MQTT 协议、用于 web 服务的 Node.js。

开发团队使用 scrum 方法，每周进行 sprints，包括后端和前端开发人员，一名 DevOps 工程师，一名数据科学家，一名报告和事件工程师，一名区块链开发人员，QA 工程师和一名管理员/scrum-master。在 2018 年 6 月之前，使用双周冲刺，随后减少以加快对不断变化的环境的响应。所有版本都包括在人工冒烟测试中，并且在需要时，包括完整的回归测试，以确保服务的正常运行。

![](img/ba59fd79cd1d8b4a40acd72e7432e379.png)

This is what 500,000 users are supported by

# 进一步发展基础设施

## 总体改进

*   聊天对象在 Google 存储上被移动到静态
*   拒绝用于服务的大量数据库实例
*   自动列出保管库
*   展示所有服务的资源限制，包括基础设施
*   头盔模板、部署脚本等的一致性。
*   面向云基础设施的 Terraform
*   一个命名空间中的所有业务服务
*   为域保留 IP 地址

## 可靠性

*   生产环境的集群版本和操作系统更新
*   基础设施数据服务转移到云
*   向 rabbitMQ、Redis 和入口控制器的云解决方案过渡
*   服务应该能够在多个副本中工作
*   处理故障点
*   为事故做准备，恢复计划
*   压力测试
*   包括检查包含大量信息的数据库
*   高可用性模式下的保险存储
*   多地区或多区域生产集群

## 其他改进

*   收集有关服务行为的指标，需要支持服务。
*   具有业务指标和延迟、自动 SLI 计算的控制面板
*   过渡到新的日志收集和汇总系统

## 持续集成部署交付

*   发布和回滚的自动化
*   过程可测量性
*   加速构建和发布
*   按需创建环境(看看 GKE 阿尔法集群)。
*   测试自动化
*   淡黄色，蓝绿色