# 我不会画画，但来见见我的机器人

> 原文：<https://medium.com/hackernoon/i-cant-paint-but-meet-my-robot-f167a60b2635>

![](img/35761b7454786b77ef7740a42de86302.png)

## 我是如何设计出一幅令人满意的画的。

![](img/52e45c669a8d9180888c9b183d5540d6.png)

“028749_0001_08”, my submission to Robotart 2018\. 20cm x 20cm, gouache on watercolor paper.

上图是我提交给 [Robotart 2018](https://robotart.org) 比赛的实物画。它是由[人工智能](https://hackernoon.com/tagged/artificial-intelligence)创造的，由一个机器人手臂绘制，由我创造和/或训练的一组计算机程序和人工智能生成。我对结果很满意，如果[能在比赛](https://robotart.org/projects/028749_0001_08/)中投票，我将不胜感激。

几年前，我第一次听说了 Robotart.org。当时，我正在尝试使用一个机器人或者某种形式的软件来帮助我绘画。在几乎 40 年的完全非艺术经历后，我对艺术产生了兴趣，并一直在参加一些在线课程，自学如何绘画。结果比我预期的要好，但是远远低于我想要的。作为一名终身程序员，我想:如果有一种方法可以提高我的软件成果，我想尝试一下。

![](img/c3b4c9f502e299df614455978622f8f2.png)

A hand-made painting I did in 2015\. Let’s just say… I’m not very good.

大约九个月前，我获得了墨尔本(澳大利亚)的一个机器人实验室，并抓住了这个机会，目标是参加 2018 年机器人艺术大会。

我这个项目的目标是回答两个问题:我能使用机器人来创作我会自豪地展示的作品吗？机器人能帮助我实现创作目标吗？根据我的第一个结果，这两个问题的答案都是肯定的。

# 内容

## 来源:人工智能生成的图像
目的地:机器人指令
旅程:物理现实
现实:最终绘画

# 来源:人工智能生成的图像

![](img/f941c055d24567005bf6e997cbc2b763.png)

“028749_0001_08”, the image that became the painting.

直到最近，我的计划是将一幅基于照片的肖像列入“重新诠释的艺术品”类别。但是在玩了过去几年中创建的一些令人惊叹的人工智能图像生成算法之后，我决定通过使用人工智能从头创建一个图像来尝试“原创艺术品”类别。

要绘制的源图像是由深度卷积生成对抗网络(DCGAN)创建的，其架构基于亚历克·拉德福德、卢克·梅茨和苏密·钦塔拉 2015 年的论文“[使用深度卷积生成对抗网络的无监督表示学习](https://arxiv.org/abs/1511.06434)”。我使用了来自 Github 的 [Tensorlayer 实现。“028749_0001_08”是我的网络为该图像自动生成的名称。抱歉图像太小，但网络只能创建 64x64 像素的图像！](https://github.com/tensorlayer/dcgan)

我训练网络生成我想要的风格的肖像。我通过在几千幅我喜欢的男性和女性画像上训练它来做到这一点。当我改进训练过程时，我选择、过滤、手工编辑并扩充它们。最终的训练集是增强后的大约 100，000 幅训练图像。经过数周的准备和反复试验，最终的训练和图像生成在机器学习云服务器(AWS p2.xlarge 实例)上花费了大约 7 天时间。

玩 DCGAN 很有趣，但有时也令人沮丧。观察训练集的变化如何影响输出是很有趣的，但也很难理解为什么一个特定的训练过的网络优于另一个。由于我的训练集很小，我遇到了许多所谓的“GAN 模式崩溃”的实例，其中网络的生成器端“弄清楚”如何生成通过鉴别器测试的几个原型图像。他们会陷入正反馈循环，导致奇怪的结果:

![](img/b67bd4efa8818fb8b58116c0e6cefccf.png)

This set of images was from a state of GAN collapse. Scary stuff.

以及直接伪造的情况，在这种情况下，生成器从鉴别器中推断出如此多的东西，以至于它学会了如何创建伪造品:

![](img/fcefd5f5aeb74d4980525c17151b0d47.png)

DCGAN-generated image in mode collapse.

![](img/bb9efb1a7a4cbd8384bdcb3262aafa05.png)

“The Twins” by Boris Grigoriev (1922), part of the training set.

经过多次反复试验，我得到了一些不错的结果，但它们是从堆积如山的垃圾中筛选出来的。我确信更大的训练集和更好的网络参数微调会产生更好的结果。

在看到它产生如上所述的“伪造品”后，我编写了一个程序来检测是否有任何图像与训练集中的图像相似，以确保我不只是看到一个崩溃的 GAN 反刍它从鉴别器的反馈中推断的项目。028749_0001_08 的伪造分数很低，我通过手动扫描训练集中的每个图像进行了复查。伪造匹配分数最高且看起来最相似的图像是:

![](img/59c7b1ae7162d6ba915a616156522f02.png)

*“Rainer Maria Rilke”* by Paula Modersohn-Becker (1906)

![](img/88dbb00d4f7f0dd33d3d0284734c9080.png)

“Portrait De Leopold Zborowski” by
Amedeo Modigliani (1917)

有相似之处——面部毛发、衣领、兹博罗夫斯基的发际线、绘画纹理。我当然认为莫迪里阿尼的 Leopold Zborowski 肖像对这项工作有重大的“影响”——我喜欢这些肖像，在训练集中有几幅——但制作的作品似乎与训练集中的任何图像都很独立。

我还创建了几十个额外的鉴别器神经网络，训练它们根据主题和格式识别绘画，以及识别我可能喜欢的绘画。这些网络在大约 20，000 幅绘画上进行了训练，我在 6 个月的时间里对这些绘画进行了人工分类(这是我的电视时间活动)。鉴别器网络建立在卡伦·西蒙扬和安德鲁·齐泽曼的 VGG 网络之上，每个网络训练他们的顶层大约两天。

DCGAN 网络在几天的时间里产生了成千上万的图像。为了加快筛选过程，为这个项目选择一幅图像，并尽可能多地将决策权下放给人工智能，我使用鉴别器网络来过滤 DCGAN 的输出，只向我显示它识别为肖像和我可能喜欢的风格的绘画。其中，少数图片符合我对这个项目的理想参数。

我个人选择 028749_0001_08 是因为它的独特性、框架、与任何训练集绘画的不同以及配色方案。基于人工智能的过滤步骤在很大程度上对这个项目没有意义——我最终观看了几乎所有产生的图像，并真正照看了这个过程——但在处理大型输出集时，我将继续使用辅助人工智能来帮助分类的想法。

这个 GAN 的输出只是一个 64x64 像素的图像。就是这样。与其说这是一幅画，不如说是一幅缩略图，但我被这个特别的结果吸引住了:

![](img/f941c055d24567005bf6e997cbc2b763.png)

“028749_0001_08”, the image the GAN generated that was the subject of the painting.

下一步是我打算训练另一系列神经网络(基于 2017 年菲利普·伊索拉、、周廷辉和阿列克谢·a·埃夫罗斯(Alexei A. Efros)的论文“[用条件对抗网络进行图像到图像的翻译](https://arxiv.org/abs/1611.07004)”)能够向绘画风格的图像添加细节，允许它们在增加细节的同时增加尺寸，使用网络填充的“想象的细节”。我最终放弃了这个项目的这一步，因为网络在我选择的风格的肖像上表现不佳，但我打算在未来使用这种方法制作更大规模的实物作品。

这个网络在我正在处理的风景上产生了一些有趣的结果，但在我从 GAN 得到的肖像上却没有这么多:

![](img/f5d542e63b14e2c0ddc47c699ff52982.png)

A source landscape generated by another DCGAN instance I trained on landscapes.

![](img/d3f9be530623902db9348b16cc97ab74.png)

“ENHANCE.” A trained AI upscale of the above image, filling in imagined details.

![](img/31f4ca657fbd9403bd72adc413a2bb97.png)

An AI upscale of 028749_0001_08\. Better than most it produced in this particular run, but not really what I was going for and certainly not true to the source.

![](img/824fc1484c9681bad3d4777f157f1159.png)

One of the rejected DCGAN portraits, upscaled below.

![](img/4696c58ac896748fba5564bf5432425f.png)

Above portrait, AI upscaled. I like this image, but it is objectively frightening.

我认为细节高档的方法是有前途的，我对制作大型绘画非常感兴趣，所以我把它放在工具箱里。但是这个项目没有成功。我会在未来用更多的训练数据和更多的训练时间再试一次。

## 开始/堆栈根

在第 11 个小时，我确实花了一些时间在最近的 GAN 网络上，特别是[begin](https://arxiv.org/abs/1703.10717)和 [StackGAN](https://arxiv.org/pdf/1612.03242v1.pdf) 。使用正确的训练集，它们都可以呈现有趣的结果，但是考虑到我的训练集很小并且时间有限，我遇到了两个问题。

BEGAN 按照设计给出了很好的平滑结果，但在给定我的训练集和学习参数的情况下，几乎立即导致 GAN 崩溃:

![](img/ff67c8e04a603f4035c1ff193c2d2a99.png)

BEGAN results after 73,000 steps

StackGAN 的训练速度慢得令人难以置信，在一整天的训练后，他的输出是这样的:

![](img/9fbc19ca38f9531a4920b76c535299d1.png)

StackGAN didn’t get off the ground, due to time constraints.

也许我做错了什么？在离比赛截止日期不到两周的时候，我和他们两个都搞砸了，而且考虑到我的时间限制，过早地放弃了他们。我认为在合适的训练环境和训练时间下，它们看起来都很有趣，但是我不得不开始画画。我将在未来重新访问它们，但它们没有满足我对这个项目的时间限制。

## 深梦/神经风格

我玩了一下 DeepDream 和 Neural Style，马上就为了这个项目拒绝了他们。它们非常适合制作看起来像绘画的基于计算机的图像，但我希望这一步通过使用实际的颜料来实现。

# 目的地:机器人指令

从 2017 年 7 月开始，我在机器人手臂上工作的头几个月，是为了熟悉它的功能，并验证我可以让它产生有点像人类的笔触。我还不想开始摆弄颜料，所以我用[Winsor&Newton brush markers](http://www.winsornewton.com/au/shop/graphic-markers/brushmarker)进行了实验，使用起来真的很有趣。它们是带有画笔风格笔尖的艺术记号笔，是测试画笔笔触的理想选择，无需担心颜料混合。

最初我没有做出什么了不起的东西，但是我非常自信我可以用画笔得到有用的结果。

An early test run using BrushMarkers, September 2017.

Final test run using BrushMarkers, March 2018.

![](img/3d12b42a73f894056273737ff2a73cad.png)

Final product of the above test run. Some good ideas, some bad ideas in here.

我工作真的很忙，提交截止日期悄悄逼近我，到 2018 年 3 月，我甚至还没有开始使用真正的画笔。我想要一条捷径。我计划通过使用[水彩笔](https://www.jasco.com.au/products/art-craft-materials/brushes/jasart-aqua-brush/jasart-aqua-pen)来回避颜料混合的问题，水彩笔是一种带有内置颜料容器的画笔。我决定只用 8 种预混合色(比赛限制)来解决，并用它们来绘画。

这并不奏效。一点也不。我的测试结果很差，我甚至在离开实验室之前就把它们扔掉了。水刷需要太多的水，我要去的，结果并不好。我确信我可以用不同的媒介得到更好的结果，但是基于我的手工测试和我已经建立的设计，我在这一点上致力于水粉。

My failed attempt using Aqua Brushes. Way too much water on the page, and the strokes didn’t layer as effectively as I had hoped.

因此，在最后期限前几周，我咬紧牙关，决定用传统的笔刷和颜料用传统的方式来完成。我几乎没有时间在实验室测试这个，所以大部分工作都是理论性的，并且是在家里完成的。

在试图绘制 028749_0001_08 之前的最后一步，使用我一直在研究的算法，图像被转换成 ABB 机器人指令的最终完整系列。它将输入图像转换为基于调色板的一系列笔触指令。这幅图像的调色板是为机器人可以在少量步骤中混合的颜色选择的，同时保持一致的配色方案。

![](img/f8c7eda9caec37e4eb8b4e8b65283bb2.png)

The target image for the image-to-brush-stroke algorithm after upscaling, smoothing, and color reduction.

图像到笔刷程序是我对这个项目唯一的“从零开始”的技术贡献；所有其他基于人工智能的步骤在很大程度上是基于过去几年中已经存在的论文和代码。在过去的两年里，编写和测试从图像到笔画的过程消耗了我数百个小时的时间，并且仍然是一项进行中的工作。

在整个项目过程中，对源图像所做的唯一编辑就是在这一步，并且都是纯机械的:放大 DCGAN 生成的图像，减少颜色以匹配调色板近似值，以及机械平滑图像以提高生成的笔触的平滑度。

我的过程依赖于从 ABB RAPID 指令(机器人手臂的编程语言)，到图像，到执行计划，再回到 RAPID 的往返翻译。

我从捕捉黑色水粉笔画开始，基于一组对 ABB 手臂的快速指令:

![](img/fd730cb35f23b10f1a0c4133d47e70fb.png)

The RAPID code that created the test strokes.

![](img/9520210647d258041cad71dab16c3c25.png)

The resulting captured strokes. A few failures in here that I had to drop from the training set.

我在 Photoshop 中剪切了这些，为笔画生成器创建了一个训练集。这些，连同颜料混合指令，是图像到颜料算法的输入；它基本上使用了上述笔画的版本来构成这幅画。我最初的计划是使用更多的潜在笔画，但是时间再次战胜了我。

我最初的计划(在截止日期前 12 天制定)是从奶油色开始，逐渐混合成深棕色，然后对剩余的颜色使用调色板混合。这是一个不错的想法，但由于时间限制，现实世界中的机器人测试对此一无所知。

这一步我犯了大错；由于我设置混合指令的方式，我在手动混合中使用的比例与我最终从机器人那里获得的比例相差甚远，而且(正如你在最后的延时镜头中看到的那样)我不得不在最后一刻进行几次调整来解决这个问题。

![](img/4f8c39bda65727fd7602683df9818e62.png)

Some paint mixing notes. This test was done manually, not with the robot arm, which caused a lot of problems in production.

我的规划程序接受一个输入图像，一组带有执行顺序的可混合颜色，并尝试使用机械臂指令绘制图像。它使用一个有机的试错过程，考虑许多潜在的笔触，并根据与目标图像的匹配程度选择每一种笔触。

代码试图做一些人会做的画布上的混合和融合，但由于时间限制，我没有把这个想法发挥到我想要的程度。

AI 绘画算法的最终输出是一组近似的笔触，以及机器人手臂的调色板混合指令:第一次尝试 6000 笔，最终绘画 4000 笔。在我的家用电脑上，使用我的图像到画笔笔画代码渲染指令集花了 8 个小时。

![](img/a9b6d09888beee9e060757972c162c2e.png)

Initial output of the image-to-brush-stroke code.

![](img/075570187db128f4d57eb5d7c1793078.png)

Translation of the initial output to RAPID instructions that were fed to the ABB arm.

# 旅程:物理现实

我在两个晚上做了第一次生产:4 月 5 日星期四和 4 月 9 日星期一。我打算用这些来产生最终的结果，因为我无法保证 4 月 9 日之后的实验室时间。

4 月 5 日进展顺利。我几乎立刻意识到我的调色说明对青色太重了，而对棕色太轻了。我还意识到机器人走得太慢了，我使用了太多的笔画:在三个小时的绘画中，只执行了 1800 个笔画，而初始设置为 6000 个笔画！我处于恐慌状态。

Beginning of first night of painting, April 5\. The arm is moving slowly and the paint mixing was not great.

当我 4 月 9 日回到实验室时，我了解到 ABB 有一种生产模式，这种模式使它比我几个月前运行的速度快得多，所以我尝试了一下。速度很快，笔画看起来更“人性化”，但在第一次运行时，我还犯了很多其他错误:我将水粉稀释得太多，以至于在页面上出血，我指示手臂过于依赖燃烧的棕色来进行颜色混合，并且涉及到太多的层。

Beginning of second night, April 9\. The arm is going much faster thanks to being in “automatic” mode.

这实际上是我第一次用真正的油漆进行测试，但我打算这是我的最后一次。我本来要提交那幅画的，但是一件令人高兴的意外发生了。我有一个单行的错误，在我从罐混合到调色板混合的过渡中，导致画笔在表面上移动得太低。我实际上已经测试过了，但是没有注意到画笔的笔尖碰到了页面的表面。在制作过程中，我在画的表面画了一条长长的棕色线条。一场灾难！

![](img/098759078ca16e4db505e2c61bdd3353.png)

So much wrong with the first attempt: terrible color mixing, overwatered paint, and that software bug that resulted in a long brown line coming out of 028749_0001_08’s mouth.

# 现实:最后一幅画

幸运的是，我在 4 月 10 日星期二，也就是提交截止日期前三天，得到了一些最后的实验时间。我调整了图像到笔画生成器以获得更有效的笔画，这使得笔画数从第一次运行的 6000 下降到了 4000 下。我还重新设计了颜料的混合方式，希望能产生更有趣的颜色。

![](img/049f16ae64de705827ca51cf75ac5959.png)

Visualization of the final execution plan for the robotic arm.

那天早上上班前我开始了最后的笔画渲染，在我到实验室前几分钟就完成了。

最后的生产发生在那个晚上。它花了 2.5 小时的设置和测试，以及 3 个多小时的绘画。在油漆过程中没有休息，但我不得不停下来几次，对油漆混合说明做一些最后的修改。

我的最后一分钟的颜料混合方法导致了很多与来源的偏差，但也导致了更多的颜色变化。有些是故意的，有些不是。最终产品的许多元素都是随着最后期限的临近而耗尽时间的直接结果，也是我的代码的意想不到的后果，但是我把它们当作快乐的意外。

![](img/2549add8eedbefc8e9a0aa9e243025ca.png)

Animated visualization of the robot execution plan, with the final product.

我喜欢“有机不准确性”,因为它可以产生意想不到的结果。如果你只是想让机器人像打印机一样工作，那么用机器人做实体绘画有什么意义呢？

与前两次相比，最后一次测试进行得更加顺利:

Footage from the final run on April 10\. What a difference a day makes.

这是延时拍摄的整个最终制作过程，并附有解说:

Full unedited timelapse of the whole production run, about 3 hours.

晚上结束时，我筋疲力尽，但很高兴我创作了一幅符合我想要创作的画。我用两只保护性的手把它带回家，就像它是圣杯一样。

这是最终产品的特写，展示了机器人制作的纹理。在我提交画作后，我用蜡手工完成了表面，给水粉一些光泽和深度。我提交了无蜡版本的比赛，因为完成不是由机器人应用。

我使用的颜料是 [Winsor & Newton Designers 水粉](http://www.winsornewton.com/au/shop/water-colour/designers-gouache)，使用未混合的颜色洋红、光谱黄、钴青绿色和棕色，每一种都混合了少量的水。除了这些原色，我手动预混合了一个单一的基础奶油颜色，使用锌白色，光谱黄色和燃烧棕色，这是在视频中的五个源颜料罐的第一个。所有其他颜色都是由机器人混合的。

这幅画是在 300gsm 热压机 [Fabriano 工作室的水彩画纸上](https://fabriano.com/en/)的帆布拉伸板上完成的。我用了一把刷子——一把 1 号 Winsor &牛顿长柄圆形 Galeria 刷子。

这是一个爱的劳动，哇，这是一个劳动！我总共花了大约 500 个小时进行开发和测试，才完成了我的第一幅真正的机器人画。我很希望能有一个宠物机器人，每天为我画一幅新画，但我担心这一天可能会比我开始这个项目时所希望的更远。

我对这幅画很满意，它满足了我第一个机器人绘画项目的所有目标。不幸的是，在墨尔本使用机器人系统是非常有限的，所以我在这样的项目上工作的能力是非常有限的。如果你碰巧知道在墨尔本有谁可以在晚上和周末定期使用 ABB 式的机器人手臂，我很乐意介绍给你！

我想继续研究人工智能生成的绘画，但我的下一个计划是训练人工智能从我这里获取更明确的指令和概念，并将它们转化为实物绘画，同时我们随着时间的推移发展一种风格。

至于“这是艺术吗？”——我认为在这样的问题中使用“艺术”这个词几乎太过了。具体到这个项目，虽然它确实实现了我的一些创造性目标，但我更多地把它作为一个技术概念验证，而不是个人表达。但是我会自豪地在我的家里展示这幅画，带着一种自豪感和成就感，这对我来说很有效。

![](img/31baf9a43329d2d075fb3f80dab06ba0.png)

A cartoon from around 100 years ago, in the photography vs painting debate. (Source: Library of Congress collection)

当然，关于新的颠覆性技术能否用于艺术的争论并不新鲜。例如，阅读一百多年前艺术界围绕摄影展开的辩论，让我希望有一天公众会完全接受机器人和人工智能，将其作为另一种可以用于人类表达的工具——我认为这是不可避免的。

如果你读到这里，谢谢你，并请[在比赛中投票](https://robotart.org/projects/028749_0001_08/)！竞争仍然很隐蔽——去年只有大约 3000 名选民登记——所以你的投票真的很重要！

我要衷心感谢 Loren Adams、Tom Frauenfelder、Ryan 彭宁斯、谢勒、Hans 以及墨尔本设计学院私人实验室的整个团队，没有他们的支持和鼓励，这个项目就不会发生。感谢米开朗基罗，不知疲倦的 ABB IRB 120，他的手最终创造了这件作品。我还要感谢[调色板](http://palette.com)的 Paul Peng、Djordje Dikic 和 Rocky Liang，他们对色彩的奉献是这个项目的灵感来源。感谢 Cameron Leeson、Li Xia、Ryan Begley、Joseph Purdam、Rayyan Roslan、Steven Kounnas、Trent Clews de-Castella、Alex Handley、Maxine Lee、Abena 奥福里、Heath Evans 和我的兄弟 Jon，他们以各种资源极大地帮助了我。感谢[埃克斯雷艺术与工艺](https://www.eckersleys.com.au/)和[墨尔本艺术家用品](https://melbourneartsupplies.com.au/)的工作人员回答了我的许多问题。最后，感谢我亲爱的伴侣 Mannie 和我的整个家庭，感谢他们的支持，感谢他们在相当长的一段时间里忍受我对机器人艺术的咆哮。这很有趣，我很高兴我做到了。感谢 Robotart.org 举办这个比赛，我希望它将成为未来人类和非人类之间激烈辩论的一部分！