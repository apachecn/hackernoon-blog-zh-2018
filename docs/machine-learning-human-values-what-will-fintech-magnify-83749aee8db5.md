# 机器学习，人类价值观:FinTech 会放大什么？

> 原文：<https://medium.com/hackernoon/machine-learning-human-values-what-will-fintech-magnify-83749aee8db5>

Sankaet Pathak 是我最喜欢谈论金融服务创新的人之一。他创办的公司 [SynapseFI](https://synapsefi.com/) ，在促成银行和金融科技初创公司之间的合作方面发挥着重要作用。从最近的这次谈话中，我对人工智能带来的道德风险有了更深刻的理解，对行为数据科学的见解，以及对我们可以使用这些工具和技术来创造我们想要生活的金融世界的谨慎乐观。

![](img/8b2e5b250245b2829874b267b7dfcd2b.png)

**DM:你在 Synapse 想做什么——无论是现在还是将来？**

史迪芬:我们正努力确保每一个银行产品都变成一个应用编程接口。金融领域的大部分创新已经放缓，因为银行要么无法支持金融科技公司，要么它们自己无法创新以满足美国人的真正需求。

每位顾客的成本需要降低。如果我们能够创建一家拥有完全自动化后台的银行，那么你在银行账户中保留 100 美元还是 10 万美元都没有关系。无论持有多少存款，每个人都将是好客户。

**DM:您认为当今金融服务技术中存在哪些道德风险？它们能被减轻或者怎样减轻？**

标准普尔:我们在金融领域面临的所有道德问题都很容易克服。现在有几件事我们应该非常关注:无论银行家认为一个好的贷款候选人是什么样的，贷款实践都存在固有的偏见，有些问题，以及今天的银行业是如何为支出而优化的。

当你开始自动化贷款业务，甚至信用卡发行业务时，很容易产生偏见。自动化并不总是意味着解放。我们必须确保在制造这些产品的时候，我们做出有意识的选择来对抗这些习惯，而不仅仅是接受现状。

其次，我们在银行业所做的一切都集中在信用卡上。银行业经过了超级优化，能够销售这种花钱得到钱的产品。我们必须改变银行业的一些模式。

在你看来，道德规范是机器可读的吗？随着人工智能在金融服务领域变得越来越普遍，人类今天应该扮演什么样的角色？

史迪芬:在我看来，人类将会参与这些过程和决策，但这确实需要我们更多地发挥道德力量。我担心很多公司会说:*我们向这个黑盒提出了一个问题，它给了我们答案，不管答案是什么，它都是最终的答案，我们会跟着它走。*

一个著名的例子是优步的激增定价(也许现在随着领导层的改变，这种情况将会改变)。当某种灾难发生时，优步最初的反应大多是:*哦，好吧，系统不知道，因此它设定了激增定价，所以它是激增定价。*

这些是不可接受的答案。

你需要交叉验证团队中的人不断查看任何机器学习模型的结果，以弄清楚:这是预期的结果吗？你还需要在种族、民族、性别、地点等方面寻找相似之处。我们是否因为共同元素的存在而拒绝消费者，或行为不端，或虐待一些消费者？如果是这样的话，我们需要回去重新思考我们如何自动化这种决策。

有个新东西叫进化算法，类似于强化学习。我认为随着时间的推移，进化算法可以卸载一些道德决策，但它们还没有出现。

**DM:当你说“我们”的时候，这是一个公司一个公司的问题吗，还是这个行业需要在工作组或导师的指导下更广泛地合作才能真正做出改变？**

史迪芬:首先，也是最重要的，消费者意识非常关键。越多的消费者意识到数据科学或认知科学在哪里被使用，如果他们不同意某些做法，他们可以选择不支持某家公司。是最近成功的一个大工具。我们需要鼓励越来越多的意识来建立一个反馈回路:公司必须自我修复。如果没有，消费者就不会使用它们。

接下来是监管监督。在监管不同数据科学模型和实践在银行业不同方面的应用方面，CFPB 可以做得很好。

为了实现这一点，我认为数据科学的工作需要在开源环境中完成——开放人工智能已经做了很多。这将有助于在监管机构工作的人了解如何使用这些技术，这样他们就可以开始建立一些监管基础设施。

然后很多都归结到公司本身。公司必须意识到道德不仅仅是一件感觉良好的事情，它会降低你的业务风险。关心你如何影响你的最终客户、你的员工和你的供应商是很重要的。我们已经看到公司最近内爆，因为他们没有展示他们的道德力量。我还认为，一家以使命为导向的公司更有可能雇佣更多有才华的人，他们会非常努力地为公司工作。

**DM:新组织如何与拥有数十年数据的现有组织竞争？**

SP:在过去的一年半时间里，合成数据生成变得非常重要——出于某种原因，没有多少人在谈论它。在 Synapse 的情况下，我们可以综合大量的政府 ID 数据，以便能够训练不同的系统来验证政府 ID。我们必须担心闪光灯、照明条件、磨损、方向和相机的角度。对于自动驾驶汽车，你必须能够在呈现之前合成不同的光线条件、雾和所有这些场景。这需要使用一点点真实数据，然后生成大量合成数据。

不仅仅是小公司可以从合成数据生成中受益，就连大公司也在使用它来构建他们目前没有数据的技术。据我所知，谷歌剪辑的大部分训练都是在合成数据上进行的。

**DM:金融服务行业的人还应该更多地谈论哪些与数据相关的问题？**

SP:行为科学，产品和服务如何调整人们的情绪并最终调整他们的行为是重要的数据科学工作。我觉得我们在这件事上太天真了。我们已经说过了，*开发出一个人们会反复使用的产品本身就是一件好事*。这并不明显，因为很多这样的东西会引发多巴胺，让我们上瘾。

当人们开始喜欢我们在脸书上的帖子时，这让我们感觉很好，脸书展示这一点的方式，它向你发送通知的方式，无限卷轴——所有这些都在你的大脑中分泌多巴胺。银行业做着类似的事情，却没有意识到这一点。信用卡强化了相信消费是好事而不是坏事的行为，因为如果你不消费，你就不会得到现金回报。我不想对信用卡持过于消极的态度，但我觉得它是一种掠夺性产品，监管者还没有真正搞清楚这一点。

信用卡可以很容易地翻转过来，你可以问:*我们怎样才能改变消费者的行为，让人们更愿意存钱而不是花钱？Synapse 将推出一种信用卡——希望在今年——坚持现金返还奖励，但在储蓄活动而不是消费活动中给予人们。事实上，交换是你赚钱的方式。这里的区别在于，当顾客存钱时，你就把它给他们，而不是当他们刷卡时。然后，你可以围绕他们如何将支出和储蓄联系起来，慢慢调整他们的行为。*

公司需要考虑他们在应用程序中构建的挂钩类型，以及从长远来看这些挂钩会如何影响社会中的人们。我们不能假装不知道这个研究领域。我们不能说，哦，当你说“多巴胺”时，我们不知道你在说什么我们知道它对人的影响。现在的问题是:我们如何能做更多的研究，并找出我们如何能使用多巴胺以积极的方式改善人们的生活？

**DM:就机器从我们身上学到什么或什么被编入算法而言，我们现在所处的这个关口有多重要？**

标准普尔:人类今天所做的任何有偏见的事情，或者对人们的财务生活产生不利影响的事情，都是以如此分散的方式发生的，以至于很难在高层次上量化。如果你将所有这些自动化，那么所有这些偏见都会被放大。例如，当信贷员写贷款时，他们很可能在某种程度上考虑借款人的服装、年龄、性别和种族。当我们坐下来和他们交谈时，我们只是在大脑中有意识或无意识地计算。现在，如果你着手建立一个面部识别系统，并将其作为承保流程的一部分，你并没有缓解这个问题，而是让它变得更加糟糕。现在不是成千上万的代理人试图为某人担保贷款。更确切地说，这是一个大代理人，无论这个大代理人有什么样的偏见，都会影响到很多人。

这不是假设，我们已经看到脸书是如何被利用的。随着我们将这些事情自动化，并以前所未有的规模进行数字化运营，我们必须非常非常谨慎地对待我们如何使用数据以及系统存在何种漏洞。十年来，我们没有意识到脸书是多么脆弱。我们必须在早期非常积极主动。

**DM:谢谢你和我们谈话，Sankaet！**

*注释:为了清晰和篇幅，对话经过编辑。*