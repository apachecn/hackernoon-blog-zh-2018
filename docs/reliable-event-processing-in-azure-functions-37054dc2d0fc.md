# Azure 函数中的可靠事件处理

> 原文：<https://medium.com/hackernoon/reliable-event-processing-in-azure-functions-37054dc2d0fc>

## 如何避免错过一条信息

事件处理是[无服务器](https://hackernoon.com/tagged/serverless)和 [Azure](https://hackernoon.com/tagged/azure) 功能中最常见的场景之一。几周前，我写了一篇关于[如何用函数按顺序处理事件的文章，在这篇博客中，我想概述一下如何创建一个可靠的消息处理器，从而避免丢失任何消息。老实说，这个博客可以很容易地分成两三部分，但我决定把它们都放在一篇文章里。它很长，但从基础一直到高级模式，如断路器和异常过滤器。虽然这些示例是用 C#编写的，但所有模式都可以跨任何语言工作(除非另有明确说明)。](/@jeffhollan/in-order-event-processing-with-azure-functions-bb661eb55428)

# 分布式系统中事件流的挑战

想象一个系统以恒定的速率发送事件——假设每秒 100 个事件。从 Azure Functions 消费这些事件很容易设置，几分钟内你就可以有多个并行实例每秒处理这 100 个事件。但是，如果事件发布者发送了一个损坏的事件呢？或者您的实例在执行过程中出了问题并崩溃了？还是某个下游系统下线了？如何在保持应用程序整体完整性和吞吐量的同时处理这些问题？

有了队列，可靠的消息传递变得更加自然。在 Azure 函数中，当您触发队列消息时，该函数可以在队列消息上创建一个“锁”，尝试进行处理，如果失败，则“释放”该锁，以便另一个实例可以获得它并重试。这种往复一直持续到成功，或者经过多次尝试(默认为 4 次)后，消息被添加到病毒队列中。虽然在这个重试周期中可能有一个队列消息，但这并不妨碍其他并行执行继续将剩余的消息出队，因此总体吞吐量在很大程度上不受一个坏消息的影响。然而，存储队列不能保证有序，并且没有针对事件中心等服务的高吞吐量进行优化。

对于像 Azure Event Hubs 这样的事件流，没有锁的概念。为了实现高吞吐量、多消费者群体和可重放性，像事件中心这样的服务在消费事件时读起来更像磁带机。每个分区的流中都有一个“偏移”指针，您可以向前或向后读取。在读取事件流时，如果遇到故障并决定将指针保持在同一个位置，它会阻止对该分区的进一步处理，直到指针前进。换句话说，如果每秒钟仍有 100 个事件进来，而 Azure Functions 在试图处理单个坏事件时停止将指针移动到新事件，这些事件将开始堆积。不久之后，你就会有大量的事件积压，而且还在不断增加。

![](img/61257577bcdf730cc2d349f3d9de2a1f.png)

Handle exceptions — while not holding up the line

给定这个偏移量和消费者行为，**函数将继续在流上前进指针，而不管执行是成功还是失败**。这意味着您的系统和功能需要意识到并结构化来处理这些行为。

# Azure 函数如何使用事件中心事件

Azure Functions 事件中心触发器的行为如下:

1.  为事件中心的每个分区创建一个指针，并保存在 Azure 存储中(如果你仔细查看，可以在你的存储帐户中看到这一点)
2.  当接收到新的 Event Hub 消息时(默认情况下是一批消息)，主机将尝试用该批消息触发该功能
3.  **如果函数完成执行**(有或无异常)，指针前进并在存储器中设置检查点
4.  如果某些东西阻止函数执行完成，主机将无法使指针前进，并且在随后的检查中，将再次接收到相同的消息(来自前一个检查点)
5.  重复步骤 2–4

这里有一些重要的事情需要注意。第一个是**如果你有未处理的异常，你可能会丢失消息**——因为即使导致异常的执行也会使指针前进。第二，作为分布式系统的标准，函数保证至少一次交付。您的代码和相关系统可能需要考虑这样一个事实，即相同的消息可能会被接收两次。下面的例子展示了这两种行为，以及如何围绕这些行为进行编码:

对于这些测试，我做了以下工作——我发布了 100，000 条要按顺序处理的消息(每个分区键)。在处理每条消息的过程中，我会将它记录到 Redis 缓存中，以验证和可视化顺序和可靠性。对于第一个测试，我这样写，每 100 条消息抛出一个异常，没有任何异常处理。

当我在这个示例中推送 100，000 条消息时，我在 Redis 中看到了以下内容:

![](img/8dbc0f9b7daff77e815d068096d9e1d2.png)

你会注意到我错过了 100-112 之间的一大块消息。这里发生了什么？在某个时候，我的一个函数实例得到了这个分区键的一批消息。这个特定的批处理以 112 结束，但是在消息 100 处抛出了我的异常。这中止了执行，但是函数主机继续前进并读取下一批。从技术上讲，这些消息仍然保存在事件中心，但是我需要手动重新获取 100–112 来重新处理。

# 添加尝试捕捉

对此最简单的解决方法是在我的代码中添加一个简单的“try/catch”块。现在，如果抛出一个异常，我可以在同一个执行中捕获它，并在指针前进之前处理它。[当我在上面的代码示例中添加一个 catch 并重新运行测试时，我看到所有 100，000 条消息都按顺序排列。](https://github.com/jeffhollan/functions-csharp-eventhub-ordered-processing/blob/6e16b23c967dd677559687e7ee325baa8a1301f0/OrderedEventHubs/EventHubTrigger.cs#L29-L33)

![](img/33355972d54c7648b0c6d4dec47fce13.png)

> **最佳实践:**所有事件中心函数都需要有一个 catch 块

在这个示例中，我使用 catch 尝试在 Redis 中进行额外的插入，但是您可以想象其他可行的选项，比如发送通知，或者将事件输出到“有害”队列或事件中心以供以后处理。

# 重试机制和策略

出现的一些异常可能是暂时的。也就是说，如果几分钟后再次尝试操作，一些“打嗝”或其他问题可能会消失。在上一节中，我在 catch 块中进行了一次重试——但是我只重试了 1 次，如果重试失败或者抛出了自己的异常，我就不走运了，仍然会丢失事件 100–112。有许多工具可以帮助定义更健壮的重试策略，这些工具仍然允许您保持处理顺序。

在我的测试中，我使用了一个名为 [Polly](https://github.com/App-vNext/Polly) 的 C#错误处理库。这允许我定义简单和高级的重试策略，如“尝试插入此消息 3 次(重试之间可能有延迟)”。如果所有重试的最终结果都是失败，请向队列中添加一条消息，以便我可以继续处理该流，并在以后处理损坏或未处理的消息。

In this code I append the message to Redis cache with the location in code that creates the entry

以及由此产生的 Redis:

![](img/47b00899183675ba8c427aedfe7153d1.png)

当使用更高级的异常捕获和重试策略时，值得注意的是，对于预编译的 C#类库，有一个预览功能可以在函数中编写“异常过滤器”。这使您能够编写一个方法，只要在函数执行过程中引发未处理的异常，该方法就会执行。详情和样品可在本帖中找到。

# 非异常错误或问题

我们已经讨论了代码遇到异常时可能发生的异常，但是如果函数实例在执行过程中出现问题或失败，该怎么办呢？

![](img/5d565db46f6f4ce92c9b0d729a255972.png)

如前所述——如果一个函数没有完成执行，偏移指针就永远不会前进，所以当一个新的实例开始拉消息时，相同的消息将再次处理。为了模拟这种情况，在处理 100，000 条消息的过程中，我手动停止、启动和重启了我的功能应用程序。这里是一些结果(左)。你会注意到，虽然我处理了所有的东西，而且一切正常，但是有些消息被处理了不止一次(在 700 之后，我重新处理了 601+)。总的来说，这是一件好事，因为它给了我至少一次的保证，但这意味着我的代码可能需要某种程度的幂等性。

# 断路器和停止线路

上述模式和行为有助于重试并尽最大努力处理任何事件。虽然这里或那里的一些故障可能是可以接受的，但如果发生了大量故障，并且我想在系统达到健康状态之前停止触发新事件，该怎么办呢？这通常是通过“断路器”模式实现的，在这种模式下，您可以断开事件流程的电路，稍后再继续。

Polly(我用于重试的库)支持一些断路器功能。然而，当跨越分布式短暂函数工作时，这些模式就不那么容易翻译了，因为电路跨越了多个无状态实例。有一些关于如何在 Polly 中解决这个问题的有趣讨论，但同时我手动实现了它。在事件过程中，断路器需要两部分:

1.  跨所有实例共享状态，以跟踪和监控电路的健康状况
2.  可以管理电路状态(开路或闭路)的主进程

出于我的目的，我将 Redis 缓存用于#1，将 Azure Logic 应用用于#2。有许多其他的服务可以满足这两个需求，但是我发现这两个效果很好。

## 跨实例的失败阈值

因为我可能同时有多个实例处理事件，所以我需要共享外部状态来监控电路的健康状况。我想要的规则是“如果所有实例在 30 秒内有超过 100 个最终失败，则断开电路并停止触发新消息。”

没有深入细节([所有这些样本都在 GitHub](https://github.com/jeffhollan/functions-csharp-eventhub-ordered-processing) 中)，我使用 Redis 中的 TTL 和 sorted set 特性来获得最近 30 秒内失败次数的滚动窗口。每当我添加一个新的失败时，我都会检查滚动窗口以查看是否超过了阈值(在过去的 30 秒内超过了 100)，如果是，我会向 Azure Event Grid 发出一个事件。[相关 Redis 代码在此](https://github.com/jeffhollan/functions-csharp-eventhub-ordered-processing/blob/3d8153cdbb3be772cd7a3ee89882cb677ec8672c/OrderedEventHubs/EventHubTrigger.cs#L61-L99)如有兴趣。这允许我检测和发送事件并断开电路。

## 使用逻辑应用程序管理电路状态

我使用 Azure Logic 应用程序来管理电路状态，因为连接器和状态编排是一个天然的组合。在检测到我需要断开电路之后，我触发一个工作流(事件网格触发器)。第一步是停止 Azure 函数(使用 Azure 资源连接器)，并发送包含一些响应选项的通知电子邮件。然后，我可以调查电路的健康状况，当情况看起来正常时，我可以响应“启动”电路。这将恢复工作流，该工作流随后将启动该功能，并且将从最后一个事件中心检查点开始处理消息。

![](img/fce347a041150d874dd98df792edae91.png)

The email I receive from Logic Apps after stopping the function. I can press either button and resume circuit when ready.

大约 15 分钟前，我发送了 100，000 条消息，并设置第 100 条消息失败。I 中大约有 5，000 条消息达到了失败阈值，因此向事件网格发出了一个事件。我的 Azure Logic App 瞬间火了，停了功能，给我发了邮件(上图)。如果我现在查看 Redis 中的当前状态，我会看到许多分区的部分处理如下:

![](img/942da770bcbac9abfaba6aa59167e48e.png)

Bottom of the list — processed the first 200 messages for this partition key and was halted by Logic Apps

单击电子邮件重启电路后，运行相同的 Redis 查询，我可以看到函数从最后一个事件中心检查点继续运行。没有消息丢失，一切都按顺序处理，并且我能够通过我的逻辑应用程序管理状态来中断电路，只要我需要。

![](img/ee6099ba97fbd85260025d09522e0843.png)

Waited for 17 minutes before I sent approval to re-connect the circuit

希望这篇博客有助于概述一些使用 Azure 函数可靠处理消息流的模式和最佳实践。有了这种理解，您应该能够利用功能的动态规模和消费定价，而不必牺牲可靠性。

我包含了一个到 GitHub repo 的链接，该链接指向这个示例的不同支点的每个分支:[https://GitHub . com/jeffhollan/functions-cs harp-eventhub-ordered-processing](https://github.com/jeffhollan/functions-csharp-eventhub-ordered-processing)。如有任何问题，欢迎通过 Twitter @jeffhollan 联系我。