# 当人工智能接管时，我们将会问的问题

> 原文：<https://medium.com/hackernoon/the-questions-were-going-to-be-asking-after-artificial-intelligence-takes-over-c4f00caf04e9>

## 对未来几年可能主宰我们工作记忆的经济和社会难题的概述。

## **机器学习及其重要性**

[人工智能](https://hackernoon.com/tagged/artificial-intelligence) (AI)是机器能够以我们人类认为“智能”的方式执行任务的更广泛的概念。机器学习(ML)是人工智能的一个子集，指的是机器使用数据做出*智能*决策的想法——即它们不一定是由程序做出的决策。

今天，人工智能的发展速度比以往任何时候都快。简单的谷歌搜索列出了人工智能威胁要颠覆的各种行业——金融、教育、科学、法律……一个人工智能系统在国际象棋和围棋上击败了一位大师。IBM 设计的人工智能系统 Watson 击败了两位 Jeopardy 冠军。

![](img/943a641a8ca8f1223eaf322b21b4c704.png)

这些超级复杂的技术的成就和里程碑是 Techcrunch 和 Quartz 文章的头条，被学者、[技术爱好者和寻找“下一件大事”的风投们搜罗。但是，当多年的逐步改进、开发、测试和创新成本降低策略将这些技术推向主流消费者和企业可负担的领域时，会发生什么呢？如果公司可以通过对人工智能系统进行一次性投资来降低可变劳动力成本，成为他们的会计、网站管理员、内容创作者、设计师和销售人员，会怎么样？](https://hackernoon.com/tagged/technology)

对经济会有什么影响？我们所知的社会学框架和系统？这个世界？这篇文章探讨了人工智能系统的经济和社会含义，以及法律和经济机构的未来问题可能会是什么样子。

## 短期影响:经济

从历史上看，技术一直被用作企业家颠覆特定行业的工具。我们越接近指数增长曲线上越陡峭的垂直位置，我们创造的技术就越强大。技术越强大，行业内和行业间经济崩溃的速度就越快。随着时间的推移，技术变得越来越强大，这种不断的、我们称之为颠覆性的全行业经济变革也许有一天会导致整个经济系统的大规模内爆。

考虑一个具体的例子:设备和数字服务越来越普遍，取代了物体和物理位置。GPS 是一张地图；您的智能手机、便携式相机、娱乐系统和规划器。Kindles 和电子阅读器是书店和书籍，而谷歌是一个巨大的全球图书馆。诚然，技术取代物体已经有一段时间了。但是很快，它就会开始取代人。

> 软件正在吞噬世界，很快，它也会开始吞噬我们。

事实上，它已经发生了。我们已经走过了组装汽车和包装盒子的工业流水线——今天的机器是*驾驶*汽车，*设计*盒子。他们已经开始学习如何编写和创建自己的应用程序。

企业正在迅速转变模式以适应这些变化。Panera Bread 决定用机器取代全球所有的收银员；百思买的[克洛伊](https://www.businessinsider.com/companies-that-use-robots-instead-of-humans-2016-2#best-buys-chloe--sifts-through-music-movies-and-games-bringing-customers-what-they-want-4)是一个机器人手臂，它通过从适当的货架上找到并交付物品来响应消费者的电影请求。

最近的一项研究发现，美国经济中每增加一个机器人就会减少 5.6 名工人的就业。事实上，根据技术的加速回报和指数增长定律，专业化的智能系统将在 10 年内主导各行业，让世界上大部分人失业。

![](img/5a6b2188e0ffe4427132f29823372c94.png)

如果家庭不再为企业提供劳动力和其他生产要素，商业周期会是一个可靠的模型吗？如果没有收入流入家庭，收入循环流动模式就不复存在，因为大多数人没有工作。货币主义和凯恩斯主义是在上世纪 50 年代之前，在完全不同的技术背景下发展起来的。经济体系尽管是普遍的，却没有能力应对前所未有的、迫在眉睫的技术进步可能带来的巨大动荡。

> 如果我们不及时更新我们的系统，它们就会崩溃。

除非我们在情报系统融入主流社会之前设计出一个替代系统*，否则政府将难以支持大量失业工人，并将不得不分配宝贵的资源来提供旨在使工人在“更新”的世界中能够就业的培训项目。*

## **长期影响:社会、伦理&整合**

本节探讨了与人工*一般*智能(AGI)发展相关的问题。AGI 不仅仅是专门用于一系列狭窄的任务——它们是具有世界知识或常识的系统，有能力执行更高级的精神功能——像人类一样。这对世界意味着什么？

考虑电车问题的一个变种。一辆自动驾驶汽车必须决定是否撞上两个过马路的孩子，并拯救车里的车主；或者为了救孩子撞到树上，撞死了主人。从功利主义的角度来看，拯救两个孩子而不是一个主人是最理想的。但是，你会以社会美德的名义，买一辆被设计成在一些无关的情况下杀死你的车吗？

那么，如果自动驾驶汽车被编程为不惜一切代价拯救其主人，但突然使用其自学的逻辑框架做出决定，即*超越其程序员的*，选择撞车以拯救儿童，那会怎样？作为一名消费者，你会为一个数据驱动的 AGI 付费吗？它结合了自我设计的逻辑框架和程序员的隐含偏见，作为如何以及何时杀死你的衡量标准。

![](img/c4c7cc6dc85ef86145506688c1fc1315.png)

以刑事司法系统为例。如果一个 AGI 犯了罪，谁将被追究责任——创造它的程序员，还是批准它的公司？还是首先允许这种 AGIs 工业发展的国家的政府？或者，AGI 本身应该受到惩罚，因为它是思考、理性和推理的。的确，如果是‘会思考’的生物，难道不应该‘受到法律的惩罚’吗？

如果我们真的让 AGI 承担责任。解决的办法是把它囚禁起来吗？人类惩教机构的目的是纠正社会越轨行为，并确保未来的越轨行为不再发生。如果通过*对其重新编程*，并完全避免进入刑事司法系统的过程，就可以简单地阻止 AGI 未来犯下类似性质罪行的能力，会怎么样？从逻辑上讲，这是合理的。如果一个机器人犯了一个错误，你修复这个错误，然后发布包含错误修复的新版本。那么，也许应该*而不是*因谋杀被监禁。

但是有一个可供选择的角度需要考虑:如果它被赋予了与人类相同的社会自由，难道它不应该受制于相同的社会契约，从而为了社会监管的目的而将同等程度的控制权交给国家吗？按照这种推理，它确实应该被监禁。

然而，AGI 人(很可能)在认知上与人类不同；它的社会功能的某些方面可以归因于这些认知差异吗？将人类发展的社会框架推广到 AGI 人口中是不公正和不公平的。当在人类中进行行为研究时，跨文化差异是必须考虑的，特别是因为文化差异表明社会规范的差异，因此，文化不同的人群之间可接受的行为差异。同样，不同的“认知规范”可能会对行为产生影响，因此在评价社会行为时必须加以考虑。

我们将如何量化机器人是否在和人类一样的智力水平上工作？如果我们在生物结构和认知功能上与他们不同，这就很难评估了；我们作为一个物种的评价很可能受制于人类沙文主义。

想想当人类意识到他们并不孤独时，他们将面临的心理压力——因为一般智力在他们的日常生活中变得越来越普遍。随着我们越来越依赖我们创造的机器，我们会变得更弱吗？

![](img/eeb6d6f96adbc10ca6664a3c1ff50453.png)

## 我们能做些什么呢？

如今，只有政治当局有权对新技术的发展施加监管约束。只有当我们激起足够的公愤，促使监管发生变化时，这种情况才会发生。这需要时间，以及一系列的叫醒电话。

但在此之前，创新者、创造者有责任退一步思考。停止编写代码，停止测试算法，停止计算神经网络的权重，直到他们能够回答与他们正在帮助实现的新实体相关的伦理和哲学问题。

如果你想继续对话，请给我发邮件到 arm4pk@virginia.edu。