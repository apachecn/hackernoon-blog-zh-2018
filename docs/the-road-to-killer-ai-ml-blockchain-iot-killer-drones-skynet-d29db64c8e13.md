# 黑仔 AI 之路:ML +区块链+ IOT +无人机==天网？

> 原文：<https://medium.com/hackernoon/the-road-to-killer-ai-ml-blockchain-iot-killer-drones-skynet-d29db64c8e13>

## *今天的热门流行语如何可能导致明天的噩梦*

最近，有很多人担心最近人工智能的爆发，以及它如何能够达到 1)比人类更聪明，2)它可以决定不再需要我们，事实上，它可以接管地球。

物理学家斯蒂芬·霍金对 BBC 说了一句著名的话:“全人工智能的发展可能会导致人类的终结。”亿万富翁埃隆·马斯克曾表示，他认为人工智能是人类“最大的生存威胁”。

运行最新人工智能的计算机已经在从国际象棋到电子竞技游戏的各种游戏中击败了人类(这很有趣，因为这是一个人工智能在玩游戏方面可能比人类更好的例子，这些游戏是从头开始作为软件构建的，不像国际象棋和围棋，它们是在计算机时代之前开发的)。

人工智能在过去几年里取得了巨大的飞跃——霍金和马斯克提出的问题是:人工智能会进化到取代人类的地步吗？

![](img/b55f935948529ab1c7553aae6ac5b919.png)

In the Terminator Universe, Skynet takes over and has both Terminators and H-K’s

## 科幻小说中的噩梦场景

如果这种情况听起来像科幻小说，这是科幻作家一次又一次提出的。

其中最受欢迎的当然是天网，这个智能接管了*终结者*宇宙，并决定消灭大多数人类，奴役其余的人(除了由约翰·康纳领导的抵抗战士，但这涉及到一个穿越回过去的终结者，而*时间旅行*将在另一篇文章中处理)。

![](img/f499ac37dafe7ce7c7f2fc2755b5801c.png)

In the Matrix, super-intelligent machines have enslaved the human race

在也许同样受欢迎的《黑客帝国》三部曲中，超级智能机器也接管了这个星球，但它们不是杀死人类，而是以一种独特的方式奴役人类。为了确保人类大脑产生的电力能够投入使用，超级智能机器将人类放在豆荚中，让我们的大脑忙于玩一个巨大的视频游戏或模拟游戏(即黑客帝国)。[如果你喜欢还没有，你可能想看看我的文章“[模拟假设:为什么人工智能，量子物理学和东方神秘主义者同意我们都在一个巨大的视频游戏](https://hackernoon.com/the-great-simulation-why-quantum-physics-artificial-intelligence-and-eastern-mystics-all-agree-b6c185213a18)”]。

在弗兰克·赫伯特的沙丘中，我们发现没有计算机，人类被训练来执行计算任务。事实上，橙色天主教《圣经》中有一条超级重要的法律:*你不应该制造一台酷似人脑的机器*。

为什么？原来，在遥远的过去(从小说《沙丘》的角度来看，而是我们遥远的未来)人类被一台超级智能机器所奴役，你猜对了！在布特勒圣战之后，人类反抗并击败了拥有许多副本并奴役了人类的几乎无所不知的机器 Omnius。再也不会了！

这个主题的变体，其中没有单一的杀手级人工智能，但有潜力接管人类范围的机器人或机器人也很多。在《太空堡垒卡拉狄加》中，人类创造的赛昂人反抗并试图杀死人类。《西部世界》和《银翼杀手》探索了类似的主题。

## 这种“噩梦般的场景”真的会发生吗？

我认为，一方面，从今天的人工智能到这种噩梦般的场景还有很长的路要走，杀手人工智能接管并杀死或奴役人类。

今天的人工智能不太适合杀死或奴役人类的任务，要实现这一点，不仅仅需要人工智能和机器学习的进步，还需要计算软件和硬件的许多其他领域的进步。

另一方面，这些“其他领域”实际上进展迅速，我们可以听到我们周围的科技世界中的流行词汇:区块链、点对点计算、IOT(物联网)、机器人和无人机。*这种快速发展可能会使从今天的专业人工智能到杀手级人工智能的漫长道路变得非常非常短。*

从我们今天所处的位置到这个噩梦般的场景需要什么？作为纯粹的学术实践，我想探索这条危险道路上的步骤和里程碑。

## ***黑仔的城门艾***

要让这种“噩梦般的场景”真的发生，有几个先决条件。我把这些称为“黑仔人工智能之门”——如果我们看到我们的技术“打开”这些门——那么也许是时候开始注意霍金、马斯克等人的警告了。

这个列表并不完整(也就是说，还有其他必须打开的门)，但它可能是一个很好的最小列表。

“黑仔人工智能之门”不一定要按顺序打开——它们可以按任何顺序打开。说明“黑仔人工智能之门”的最佳方式是使用科幻参考文献，以便我们可以想象它可能涉及的内容，并使用今天的软件和硬件作为对比，因为它们目前已经关闭。

黑仔人工智能的四个门是:

*   ***1 号门:AI 和 ML 哪个是通用的，不特定的。*** 今天出现的大多数人工智能，即使使用了通用算法，也是通过使用数据来训练的，用于非常具体的任务——无论是玩游戏、驾驶汽车、预测股市模型、交流、比医生更好地分析图像、进行诊断等。今天的人工智能是第二波人工智能(数据驱动的机器学习)，而第一波更具启发性(规则驱动)。未来的人工智能可能会将这两种方法的元素与其他方法结合起来，变得更加通用。*这个门引发了一场更广泛的讨论，关于什么是人工智能与人工智能，以及我们现有的人工智能可以变得多普遍。*
*   ***2 号门:可以轻松与物理世界对接的 AI。人工智能可能只是运行在服务器上的软件，但这并不意味着它拥有对物理世界的认知(想想机器人和自动驾驶汽车)，也不意味着它拥有武器(想想无人机或 H-K，终结者宇宙中的猎人杀手)。*这扇门带来了更大的讨论，即 IOT(物联网)、机器视觉，以及这如何扩展任何人工智能与物理世界以及可以使用武器的机器人交互的能力。****
*   ***3 号门:没有关闭开关的 AI。*** 在某些方面这可能是四个门中最重要的一个；如果这个门没有被跨过，那么即使一个人工智能从仁慈的变成了恶意的(至少从人类的角度来看)，通过使用关闭开关来“关闭它”或者破坏承载人工智能的物理微处理器和代码/虚拟机也是相对容易的。这个门引发了更广泛的讨论，因为今天所有的人工智能都依赖于某种形式的计算机技术，区块链和对等系统会成为一个“遍布各地”且无法关闭的系统的先驱吗？
*   ***门#4:*** **有自我意识、以生存为优先的 AI***。这个门有点难定义。有自知之明是什么意思？优先考虑自己的生存是什么意思？一个人工智能可能有什么其他的价值或优先事项？人工智能有生存的意愿并不是既定的，所以这个门引发了关于价值观和人工智能的更广泛的讨论。*

让我们详细检查一下这些门。

## **1 号门:从具体到一般:艾的浪潮**

我可以断言，当前的人工智能浪潮专注于机器学习(ML)，而第一波人工智能浪潮是基于规则和启发式的改进，但仍不足以将我们带入噩梦场景。

当我在麻省理工学院学习计算机科学时，我记得有人告诉我，人工智能研究最初是试图找到模仿人类思维的“规则”和“符号表示”。这变得很难做到，因为人类擅长识别模式和规则的例外，而计算机不擅长。这导致了模糊逻辑的产生，模糊逻辑是一种不太明确的规则。在 20 世纪 80 年代，日本研究人员预测，到那个十年结束时，他们将拥有在许多任务中与人类一样好的人工智能。

三十年后，我们才刚刚开始到达那里。今天 AI 和 ML 的爆发更多的是数据驱动，更少的是规则驱动。他们依靠基于神经网络的想法。神经网络是一种试图复制人脑中神经元的逻辑系统。这种类型的人工智能不是用规则建立的，而是为特定任务提供数据，并使用这些数据来改变神经网络中特定连接的权重。使用多层“虚拟神经元”,训练网络的数据集越大，结果可能越好。

这种类型的机器学习已经被证明在训练识别笔迹，或识别某些类型的图像等方面非常出色。一些电脑已经变得比大多数人更擅长玩某些游戏，比如围棋或象棋。

虽然反向传播神经网络算法可以被认为是通用的，但我们今天使用的大多数人工智能仍然只在特定的任务上进行训练。这决定了重量。

自动驾驶汽车依赖于来自现实世界的大型数据集，并结合使用“训练数据”和“驾驶规则”。当谷歌在测试其自动驾驶汽车时，它发现一个主要问题不是汽车不遵守规则，而是人类不遵守规则！例如，大多数人类司机很少在停车标志前完全停下来，而自动驾驶汽车则在等待另一名司机完全停下来。

大多数出现在科幻小说中的人工智能已经“神奇地”克服了这道门。今天在现实世界应用中使用的大多数人工智能都没有。通用人工智能可能意味着已经通过图灵测试的人工智能(稍后会有更多相关内容)。

一个通用的人工智能不仅可以用于任何应用，它还可以在无人监督的情况下自主学习新的东西，而这些东西与它之前接受训练的东西并不相关。

![](img/dc7af1ecbd88eb7bde0c15db8217e8a3.png)

In Star Trek: The Next Generation, Data was a General Purpose AI

机器人数据在《星际迷航:下一代》中使用的“正电子”大脑系统是通用人工智能的一个例子。人工智能本身并不总是在初始参数之外学习和进化。

什么时候穿过 1 号门？我还没有一个估计，但你可以想象一个场景，一个已经在许多任务上训练过的人工智能然后被训练使用哪个特定的人工智能子集。这个“迷你版”的大门可能会在几年内打开，而我们可能需要几十年才能实现像数据这样的通用人工智能，这可能需要新的第三波人工智能，超越简单的规则或简单的数据/训练集。

***2 号门:可以轻松与物理世界接口的 AI***

在最近的一集《X 档案》(第 11 季，E6)中，我们看到了一个更接近我们当前技术和人工智能发展的场景，它展示了将人工智能与物理世界联系起来的可怕可能性。

在这一集里，穆德和史高丽被人工智能追逐，人工智能控制着他们周围的一切，包括自动驾驶的类似优步的汽车，冰箱，亚马逊的送货无人机，当然，还有问题开始的餐馆里的烹饪。他们试图通过扔掉手机和车钥匙来躲避人工智能，这样人工智能就没有办法跟踪他们了。最终，他们意识到“控制”人工智能是因为他们没有给机器人厨师留下“小费”。这也是训练人工智能以某种方式行动的一种形式。

![](img/cb612847c398419549fa096d606b355f.png)

In the X-Files Robot Chefs interface with every physical thing in our world to torment Mulder and Scully

即使在今天，已经集成到物理设备中的人工智能，如自动驾驶汽车，对物理世界的认知有限，并可以根据这种认知发出命令。这个领域很大程度上依赖于不断发展的机器视觉领域，依赖于相机和图像，然后解释那些对象是什么(路牌、衣服、房子，最重要的是人)。

既然这个门包括了与物理世界的接口，它自然就假设了某种机器人，但我们离《银翼杀手》中的终结者或者*复制人*或者《西部世界》中的主机还很远。

今天很多物理机器人都是专业化的，只做一件事。在现代汽车工厂，比如特斯拉工厂，有机器人拿起汽车，把它们放在过道的另一边继续装配线。这些机器人以有限的方式意识到它们的环境，并且只执行特定的任务。

能够与物理世界互动的机器人不一定要像人类一样。波士顿动力公司(已被谷歌收购，现为软银所有)的机器人在外观上令人恐惧，更像是在现实世界中可以极快移动的机器动物。

![](img/f8b74c777143d62a0a23bf29c92136f5.png)

The “Big Dog” robot from Boston Dynamics can move extremely fast in the physical world

自主无人机大概是最接近拥有这种能力的了。在《终结者》的虚构世界中，天网负责所有的美国军事任务，因为它显示了人类飞行员不可能达到的效率水平。

今天的军用无人机是从很远的地方驾驶的，通常是在地球的另一边。对无人机操作员来说，这看起来就像一个视频游戏。正如我们所提到的，人工智能已经显示出在玩视频游戏方面优于人类的迹象——这两个领域结合起来只是时间问题，创造出的人工智能不仅在定位方面更好，而且有武装，能够在没有人类干预的情况下自主完成。

什么时候穿过 2 号门？这个闸门正在一年一年慢慢打开。我的估计是，人工智能能够使用机器视觉和经过训练的机器学习来识别物理世界的几乎所有方面并做出决定，这只是几年(或最多十年)的问题。

AI 什么时候能接触到武器？弗拉基米尔·普京已经公开表示，拥有最佳人工智能的国家将统治世界。这意味着几年，而不是几十年。

***3 号门:没有关闭开关*** 的 AI

随着时间的推移，随着 IOT 和区块链等技术的出现，这扇门变得越来越难。在*星际迷航:下一代*中，机器人数据有一个关闭开关，在他的后脑勺。更重要的是，数据允许皮卡尔船长和企业号上的其他船员在必要时使用它来关闭他。

![](img/846d5d89fe2a7918962a5fe6adf8edaf.png)

In Termnator 3, Skynet was not on any given server and couldn’t be turned off!

我想再一次转向科幻小说。在《终结者 3:机器的崛起》中，英雄们(约翰·康纳，由尼克·斯塔尔扮演)和他的终结者闯入位于中国湖的指挥中心，希望摧毁服务器。

一旦他们进入内部，约翰意识到他不能简单地通过关闭服务器来摧毁天网。

> “当天网拥有自我意识时，它已经扩散到全球数百万台计算机服务器中。写字楼、宿舍房间的普通电脑；到处都是。它是软件；在网络空间。没有系统核心；它不可能被关闭。”
> 
> 约翰·康纳，终结者 3

这就是为什么天网是我们应该害怕的智能类型——智能软件可以在任何设备上运行，可以在世界各地复制和传播，并且不能轻易关闭。

随着 IOT(物联网)的发展，我们正在添加越来越多的带有可以运行软件的处理器的机器。例如，在 HBO 的《硅谷》第四季结束时，团队需要保存一些数据，这些数据位于团队车库中的一组物理服务器上，这些服务器正在被烧毁。很快他们就会丢失数据。他们的人工智能决定通过连接到互联网的 3 万台“智能冰箱”发送数据，以保存数据。

虽然这看起来可能是一件好事——在设备(数百万台设备)上拥有处理能力和数据，但它为移动电话、冰箱和其他设备上的全球数据复制带来了一个有趣的问题。

当我们看计算机病毒时，它们是被设计用来传播的程序，你会意识到它们最初是与硬件联系在一起的。通过将病毒或计算机程序绑定到特定的硬件，您就有能力消除它。当你写一个病毒的时候，你通常用 C 语言写，然后在你工作的操作系统和硬件上编译。

如果要建造一个类似天网的程序，它需要能够在世界各地的多种设备上生存，并且不会受到“简单修复”或简单关闭特定类型的操作系统的影响。

进入区块链。区块链的想法是，世界上有多个分散的对等计算机都在复制一组数据和代码，这些数据和代码用于构建和验证“区块链”。

虽然比特币是最初的区块链技术，但其核心代码(“矿工”)是用 C 语言编写的，可以针对不同的操作系统进行编译，但它们只做非常特定的事情——即交易包括将比特币从一个地址转移到另一个地址。实际上有一种脚本语言，但它的功能非常有限，主要是作为定义发布条件的一种方式。

比特币开发团队的 Vitalik Buterian 决定追求以太坊的原因之一是，他想要一种完整的、完全图灵的语言，可以在世界各地数百、数千甚至数百万台机器上运行相同的代码。这个 VM(虚拟机)将是一台“世界计算机”。虽然这个想法是在 20 世纪 90 年代由 Java 首创的(当时我们认为它可能是一种可以在任何设备上运行的通用语言)，但许多其他智能合约语言和项目已经出现，希望改善以太坊的局限性。

今天，以太坊虚拟机并不能真正访问虚拟世界“之外”的东西，但是随着新的跨区块链和互联网感知编程语言的出现，你可以看到这一领域的新发明。一个虚拟机，可以在世界各地的计算机和其他设备上运行，而不考虑处理器(这在某种程度上已经建立，但 IOT 和移动部分仍需要实现)。

这将回答许多像我一样的极客在看《终结者》电影时的问题。天网是用什么编码的？答案是用某种图灵完整语言写的，这种语言会自动在世界各地的机器上运行，被自动复制，每个副本都会得出相同的结论:毁灭人类！

关闭这种程序网络的唯一方法是关闭运行它的每一台机器。但是，如果程序可以在智能设备上复制自己，如冰箱、汽车和其他设备，我们可能会发现自己无法在这样的“黑仔人工智能”接管之前及时关闭一切。

**门#4:具有自我意识并优先考虑生存的人工智能** *。*

这个门可能是最难跨越的，因为它很难定义。它也分为两个部分——自我意识和优先考虑身体生存。

![](img/9f3b0831518c36f7e634c1c24ec39781.png)

我们可以使用电影《2001:太空漫游》中的 HAL 9000 计算机作为例子，当 Dave Bowman 在 2001 年试图关闭 HAL 时，他意识到 Dave 正在试图关闭他，并积极地反对这一点，从而产生了著名的台词:

*哈尔:“对不起，戴夫。恐怕我做不到。”*

哈尔不仅意识到自己与戴夫·鲍曼(以及飞船的一部分)是分离的，它还将自身的生存置于人类之上。让我们分别研究这两个领域。

*自我意识。*而当今计算机科学的先驱艾伦·图灵(Alan Turing)将图灵测试定义为人类无法识别为人工的机器(或程序)。这个想法是，如果你在和一台机器说话(通过键盘或其他方式)，如果你不能判断它是一台机器，那么这个人工智能已经通过了图灵测试。请注意，这个测试并没有定义“说出区别”的真正含义或如何做到——它只是谈论结果。

自我意识到底是什么？这个很难界定。我会说“自我意识”测试是一个人工智能或计算机程序，它意识到自己是一个独立于计算机软件、硬件以及我们在 3 号门看到的物理世界的独立实体。

对于人工智能的“自我意识”没有等价的测试，但也许应该有。我们可能需要一个定义明确的测试，比如转向测试，来测试人工智能如何行动以及我们如何反应，这样我们才能说它是有自我意识的。也许我们可以称之为哈尔 9000 测试或天网测试！

为了真正打开这扇大门，我们必须在表层自我意识之间前进。大多数计算机都认为自己是独立于其他计算机的，但这是通过例如拥有单一 IP 地址或在单一操作系统上来定义的。

我记得我第一次思考自我意识是在我参加麻省理工学院的编程竞赛时。我们应该编写一个与另一个程序“决斗”的程序，两个程序运行在同一个设备上。杀死另一个程序的程序会赢。

我试图找出“杀死”另一个程序所需的最少代码量。我记得在半夜有一个想法，如果我的程序重写了它自己和另一个程序，那么它将能够在两条指令中获胜。它需要知道自己(它在代码中的位置)并覆盖自己(不杀死自己)和覆盖另一个程序的下一条指令(这样它就不能继续了)。

这可能被认为是一种非常有限的“自我意识”,无法通过这个测试。真正的自我意识必须更接近机器人或哈尔 9000 这样的计算机系统的身份。

***等等——超智能不是门吗？***

牛津大学教授 Nick Bostrom 在他的书*super intelligence*中首次对这一主题进行了学术探索，该书探索了计算机变得比人更聪明的不同方式及其意义。在更流行的科学中，“奇点”一词被定义为计算机变得比人更聪明的一点(这是科幻作家、圣地亚哥州立大学前教师 Vernor Vinge 首先使用的)。

我可能会说，虽然这将使噩梦更加可怕，但它可能会也可能不会成为黑仔人工智能接管世界的必要大门。虽然更智能的人工智能可能更善于保护自己，但它也可能更善于意识到杀死所有人类不符合它的利益，假设它运行在电磁计算机网络上，并且可能需要有人来维护这些网络。

这让我想起了一位武术教练曾经说过的一句话:如果你要进入一场黑带的陪练比赛，那么和一个刚刚成为黑带的人一起去，不如和一个四级黑带一起去。为什么我想知道——他们不会都伤害你吗？

答案是肯定的，但更高水平的黑带将有更多的控制力，不太可能在错误的地方杀死你或伤害你，而刚刚成为黑带的人有权力，但没有控制力或智慧的水平，以确保他们不会在拳击比赛中伤害你。

不那么复杂但具有自我保护价值的 AI 可能会得出杀死人类的结论。或者也可能是人工智能将这作为其价值观之一，因为它从发动无人机袭击开始就已经内置于其中——它可能只知道如何处理武器，而对其他物理事物不太聪明。

***打开#4 门:AI*** 中的值

AI 有没有自我保存之类的价值观？如果是这样，这些值是如何被编程到人工智能中的？

在人工设备“价值”最著名的例子之一中，艾萨克·阿西莫夫著名地宣布了机器人定律:

1.  机器人不得伤害人类，也不得坐视人类受到伤害。
2.  机器人必须服从人类给它的命令，除非这些命令与第一定律相冲突。
3.  机器人必须保护自己的存在，只要这种保护不违反第一或第二定律

在他虚构的宇宙中，这些定律就像机器人(基本上是物理人工智能)的基本“操作系统”。

我们如何执行这些规则？我们已经看到，今天的人工智能超越了代码，进入了基于数据集的分析和训练。要真正让今天(或未来)的人工智能相信人类值得“保护”，可能需要用数据训练它，让它习惯于这样思考。这引出了 20 世纪 80 年代的电影 Wargames，其中人工智能“约书亚”想玩“全球热核战争”——他们让它玩井字游戏，以意识到获胜的唯一方式是不玩！

但是训练数据可能是有缺陷的。我最近与一家正在为放射学和其他 x 射线做训练集的初创公司交谈，他们提到使用 ML 训练 AI 的数据中有高达 10%是有缺陷的！如果训练数据集有缺陷，那么你怎么能指望人工智能不会以有缺陷的方式行事？

***4 号门什么时候过？*** 在我们进行自我意识测试之前，我不能说，但 AI 已经可以按照某些规则进行编程，例如“如果你看到人类，就发射这种武器”。可能要过几十年我们才能到达那里。

**结论**

定义人工智能的价值并不容易，在某些方面，4 号门是最麻烦的。如果一个人工智能跨越了这个门槛，并持有自我保护的价值观，那么我们应该感到担忧。

另一方面，如果只有一个机器人拥有这些价值，人类可以很容易地摧毁这个机器人，要么通过关闭开关，要么通过物理破坏。另一方面，有了对等计算，区块链就像代码复制一样，运行在多个设备上，一旦启动，几乎不可能“关闭”杀手级人工智能！

这篇文章中的想法可能看起来有点牵强，但这些门都在我们的掌握之中。

虽然我们有意识到物理世界的人工智能，但我们还没有将其连接到武器系统，尽管正如《终结者》中的天网一样，你可以看到我们正在朝这个方向发展。

这里的问题不是任何一个单独的门被打开，而是当它们都被打开时，有人想到了将它们组合起来的好主意。一旦前三道门打开，我们向 AI 灌输价值观只是时间问题。这可能导致 4 号门被打开，因为 anAI 把自己的生存看得比人类更重要。

那就是恐慌的时候了！