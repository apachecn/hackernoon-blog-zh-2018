# 拆箱谷歌人工智能的 7 个新原则

> 原文：<https://medium.com/hackernoon/unboxing-googles-7-new-principles-on-artificial-intelligence-1b5f77d6eeb2>

多少次听说人工智能(AI)是人类最大的威胁？一些人认为，谷歌上个月宣布推出 Duplex 时，让我们离黑暗的未来更近了一步。Duplex 是谷歌数字助理的一项新功能，它可以代表你打电话预约小企业。你可以在这里看到它的作用:

争议的根源在于，这位助理成功地伪装成了一个真实的人，从未向通话的另一方透露其真实身份。许多技术专家想知道这是否是一种道德行为，或者是否有必要隐藏声音的数字本质。

![](img/78b422f53bbf3e9e6c63e3f6a976166b.png)

上个月，谷歌还受到了另一个敏感话题的批评:该公司参与了五角大楼的一个项目，该项目使用人工智能来解释视频图像，并可用于提高无人机袭击的针对性。数千名员工签署了一封信，抗议该计划并要求改变:

> “我们认为谷歌不应该卷入战争。因此，我们要求取消 Maven 项目，并要求谷歌起草、公布并执行一项明确的政策，声明谷歌及其承包商都不会开发战争技术。”

围绕人工智能的“明确政策”是一个大胆的要求，因为没有一个大玩家曾经这样做过，而且理由充分。这是一项如此强大的新技术，以至于我们还不清楚我们将在生活中的多少领域注入它，也很难围绕未知制定规则。Google Duplex 是一个很好的例子，这是一项 10 年前我们会认为“神奇”的技术发展，今天让许多人感到害怕。

无论如何，桑德尔·皮帅不仅满足了这一要求，还进一步创造了 7 条原则，作为人工智能的行业驱动力之一，该公司将推广和执行这些原则。以下是对它们的一些评论:

**1。对社会有益**

多年来，我们一直在处理舒适的边界，在非常专注的领域创造越来越智能的实体。人工智能现在能够以对用户透明的方式在不同的领域之间切换。例如，在家里拥有一个知道你习惯的 AI 非常方便，尤其是当你的家电连接到同一个网络时。当同样的人工智能也知道你在家以外的习惯，比如你最喜欢的餐馆，你的朋友，你的日历等。，它对你生活的影响会变得很可怕。正是这种便利让我们走出了舒适区。

这是最重要的原则，因为它屈从于“尊重文化、社会和法律规范”。这是一个宽泛的原则，但它旨在通过让人工智能适应我们的时代，并让它与我们的社会习俗同步进化，来缓解这种不舒服的感觉。

**2。避免产生或强化不公平的偏见**

如果我们允许，人工智能会变成种族主义者。这方面的一个很好的例子发生在 2016 年 3 月，当时微软推出了一个具有 Twitter 界面和[的人工智能，不到一天人们就教会了它我们人性中最糟糕的一面](https://www.theverge.com/2016/3/24/11297050/tay-microsoft-chatbot-racist)。人工智能通过实例学习，因此确保安全措施到位以避免这种情况是至关重要的。我们的孩子将在一个越来越多地由人工智能辅助的世界中成长，因此我们需要在这个系统暴露于互联网巨魔和其他不良玩家之前对其进行教育。

**3。进行安全制造和测试**

这一点与前一点是一致的。事实上，微软对 Tai 惨败的回应是将其撤下，[承认对 ai 测试场景类型的疏忽。在设计人工智能时，安全应该是首要考虑的因素之一。](https://blogs.microsoft.com/blog/2016/03/25/learning-tays-introduction/)

**4。对人们负责**

谷歌 Duplex 受到的最大批评是，在不让其他人知道的情况下模仿真人是否道德。我很高兴这个原则只是说“技术将受到适当的人类指导和控制”，因为它没有低估未来构建类似人类的人工智能的可能性。

代表我们打电话的人工智能必须听起来尽可能像人类，因为这是确保与另一边的人顺利互动的最佳方式。设计类似人类的人工智能时，应考虑到尊重、耐心和同理心，但也要考虑到人类的监测和控制能力。

**5。纳入隐私设计原则**

当 AI 创造的便利与我们的个人感受或私人数据相交时，一个新的担忧就显现出来了:我们的个人数据可能会被用来对付我们。[剑桥分析公司(Cambridge Analytica)的事件](https://geekonrecord.com/2018/03/25/fixing-facebooks-privacy-problem/)，个人数据与未经授权的第三方共享，损害了用户对技术的信任，从而放大了问题。

谷歌在这个原则上没有使用很多词语，可能是因为在不直接影响他们的商业模式的情况下，这是最难澄清的一个原则。然而，它代表了十年来最大的技术挑战，即在放弃隐私和获得合理回报之间找到平衡。提供“适当的透明度和对数据使用的控制”是正确的缓解措施，但当人工智能知道我们生活中最隐私的细节时，这不会让我们不那么不舒服。

**6。坚持科学卓越的高标准**

以开放的方式构建未来的人工智能系统是保持任何公司诚实的最佳方式。提供“让更多人开发有用的人工智能应用的教育材料、最佳实践和研究”是一项伟大的承诺，因为它可以更快地暴露问题，并帮助更快地找到解决方案。

**7。供符合这些原则的用途使用**

最后一条原则是概述谷歌承诺不追求的应用的一个章节的前身，这并非偶然。许多人害怕人工智能，只是因为他们想象如果一个有缺陷和不可控的系统有能力对人类行为做出判断，会出现什么问题。

谷歌承诺不会建造可能造成身体伤害的人工智能，不会推动“违反国际公认准则”的监控，也不会违反任何类型的法律/人权。

这些原则是一个宝贵的开端，也是一次值得称赞的尝试，旨在建立将推动我们走向未来的规则。但这还不够，还应该有适当的监管来保护消费者。我们正处于涉及人工智能的漫长旅程的边缘，这将改变我们，我们需要向前推进，并确保适当的指导方针到位。自我调节不可能是我们在人工智能上看到的唯一控制类型。为了我们的未来，我们需要推动科技行业向最高标准发展。

你可以在这里阅读谷歌的原则。

你喜欢这篇文章吗？ [**订阅**](https://geekonrecord.com/subscribe/) **通过邮件获取新帖。**

*图片来自坎特伯雷大学*

*原载于 2018 年 6 月 9 日*[*geekonrecord.com*](https://geekonrecord.com/2018/06/09/unboxing-googles-7-new-principles-on-artificial-intelligence/)*。*