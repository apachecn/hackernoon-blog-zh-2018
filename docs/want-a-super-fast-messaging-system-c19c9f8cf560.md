# 想要一个超快的信息系统？

> 原文：<https://medium.com/hackernoon/want-a-super-fast-messaging-system-c19c9f8cf560>

## 设计和构建快速系统的终极指南。

![](img/f2ea1069b011b597c0d92fb79c3a9221.png)

如今有许多技术将数字系统、服务和设备联系在一起。你可能会想到 HTTP 和消息系统，比如 NATS、T2、gRPC 或 T4 的卡夫卡。这些系统的速度和性能对于效率和规模至关重要。速度和效率也可以导致系统在负载下的可预测和确定性的行为，我相信这是更可取的。好的表现是好的，可预测的表现是伟大的！

那么，你将如何设计和构建一个具有高性能和可伸缩性的系统呢？

消息系统被设计成跨不同的网络传输(例如，TCP/IP、UDP、WebSockets、蓝牙、LoRa)传递消息。它们可以有代理或服务器组件，或者客户端可以直接相互对话。我的大部分历史都与基于服务器的系统有关，在这种系统中，客户机与服务器对话，服务器将消息分发给一个或多个接收者。尽管有些人可能更喜欢系统直接从一个客户端与另一个客户端进行对话，但我觉得服务器/代理方法更好，因为服务器易于运行和操作，可以很好地集群，因此可以在任何地方运行，并且具有弹性和良好的性能。我将参考 [NATS 项目](https://nats.io)来讲述这些主题，我创建这个项目是为了充当 [CloudFoundry](https://www.cloudfoundry.org/) 的控制平面，CloudFoundry 是我在 VMWare 创建的一个项目。

# **每个 IO 调用的消息。**

这是第一步，也是最重要的一步。在用户空间和内核空间之间移动代价很高。如果您为发送或接收的每个消息调用内核，这将会降低您的性能。我总是测量每个 IO 调用在入口和出口收到多少消息。对于入口来说，这要简单一些，因为你可以预先分配缓冲区，进行我称之为盲读的操作。在一次调用中尽可能多地读取内核为您提供的内容。通常，这不会影响入站消息的延迟。需要注意的是，要让这些缓冲区的大小动态地增长和收缩，以匹配流量，否则，当您扩展到大量连接时，会浪费内存。

对于出口，或者说将消息发送出去，这变成了吞吐量和延迟之间的平衡游戏。将消息从消息服务器中取出是非常重要的。我通常通过让一个单独的线程或协程实际执行内核的 IO 调用来解决这个问题。这允许用户空间将多个消息结合在一起，再次尝试最大化每个 IO 调用的消息。我不希望这种内部缓冲不受检查，因此用户空间会达到一个极限，它会故意占用 IO 调用的所有权，实际上可能会减慢上游的速度，并避免内部缓冲导致的大量内存消耗。如果有人跟不上，迅速失败并切断他们，否则你将冒着一个坏苹果损害其他人的服务的风险。还应该测量 IO 线程或协程的信令和交换成本，以实现吞吐量和延迟之间的良好平衡。您还应该衡量合并缓冲区与使用分散和聚集语义(writev，如果支持的话)对性能的影响。

有相当多有趣的工作正在进行，通过像 [dpdk](https://www.dpdk.org/) 和其他仅用户空间的网络来消除从用户空间到内核空间的跳跃。我更感兴趣的是通过像 [eBPF](https://lwn.net/Articles/740157/) 这样的机制将处理下推到内核中，或者甚至推到像 NIC 卡这样的网络元素上的能力。

# **消息路由**

在支持多种消息模式(如 pub/sub 或 1:N、请求/回复和负载平衡动态队列)的消息传递系统中，从性能角度来看，消息的路由变得非常重要。在主题和/或话题功能丰富并涉及多个级别和通配符支持的系统中，将入站主题映射到一组接收者可能变得不简单。此外，如果主题空间的变化率很高，在没有正确架构的情况下，这将对分布性能产生不利影响。在我的职业生涯中，我可能在这个问题上花费了最多的时间，我确信我仍然没有完全正确。在 NATS，主题由以“.”分隔的标记组成或者点。对于发布者，所有主题都必须是文字，但是，订阅可以使用通配符将不同的发布主题组合到一个订阅者回调/处理流中。在 NATS，我们有一个令牌或部分通配符' * '，以及一个终端完整通配符" > "。例如，我可以订阅“ *foo.bar.*”，这将作为消息发送到“foo.bar.baz* ”或“ *foo.bar.22* ”，而不是“*foo . bar”*。如果我订阅了" *foo。> "* 在 NATS，那么任何发布到" *foo.1 "、"* foo.bar.baz "等都可以。有关通配符的更多信息，请参见我们的 NATS.io 文档中关于基于主题的寻址的内容。

NATS 的主题经销商的后台存储是修改的 [Patricia 树或 Radix 树](https://en.wikipedia.org/wiki/Radix_tree)。唐纳德·r·莫里森在 1968 年从维基百科上首次描述了他所谓的“帕特里夏树”；[【4】](https://en.wikipedia.org/wiki/Radix_tree#cite_note-4)名字来源于[的缩写](https://en.wikipedia.org/wiki/Acronym) **PATRICIA** ，代表“*检索以字母数字编码的信息的实用算法*”。当主题层次结构有许多叶节点时，这种结构可以很好地节省空间。TIBCO 与 Rendezvous(和 EMS)和金融领域(想想股票报价分布)的早期工作表明，一般的树形结构可能非常适合。例如，对于像"*foo . bar . baz .[1–1，000，000]"* 这样的主题空间，只有 1M 的叶节点是不同的，并且将共享 *foo* 和 *bar* 的公共节点。在现代计算机体系结构中，可预测的数据访问和缓存友好性更为重要，带链接的树结构并不流行，但仍然非常有效。我在 NATS 使用的结构使用链接和哈希表，所以是一个组合。您给它一个主题，它会返回一个普通订户和队列订户的结果列表。对于 NATS，它们被不同地处理，所以结果集将它们分开。虽然有效，但如果这是我们使用的唯一数据结构，NATS 的性能将远远不如它在这个部门中的性能。许多线程/协程可以访问这个结构。使用读/写锁是有帮助的，在某些方面也是原子性的，我确实在 Patricia 树前面的数据结构中内置了一种 L2 缓存。一个以前的同事认为我们应该重做这个结构，使其无锁，并使用原子和 CAS。理论上，这看起来总是很吸引人，但是很少会产生你期望的结果。相反，我试图实现的类似于处理器和缓存的工作方式，在最好的情况下，每个入口处理器都有一个无锁和无竞争的数据结构来处理大部分消息分发。当然，缓存失效在这里很重要，对于入口处理的 L2 共享缓存和 L1 独立缓存都是如此。对于 L2，我们尝试变得更加智能，并使用更小的缓存行来进行无效处理。这些都是在传统的锁定方案下完成的。对于独立的 L1，我对主题分发商的世代 ID 进行原子检查。如果它已经被改变了，我不会试图太聪明，我只是吹走整个 L1 缓存，让它从共享的 L2 或后备树本身重新填充。对于单个入站流，现代硬件上的 NATS 服务器每秒可以处理大约 2000 万条消息，这还算不错。而这只是其中的一个流！但是，同样，如果分发服务器的更改率增加并导致更多缓存失效，这将开始受到影响。如果我有一些空闲时间，我可能会回到这个问题上，但现在我对适度变化的主题空间的吞吐量相当满意。

# 协议分析器

这是我的第三条，但仍然很重要。NATS 是基于文本的协议，许多人会认为只有二进制协议才能表现良好。我设计并实现了这两者。在我看来，基于文本的协议不会影响性能，但是协议解析器需要高效。最初的 NATS 服务器编写得非常快，让 [CloudFoundry](https://en.wikipedia.org/wiki/Cloud_Foundry) 用作系统的控制平面。我用 Ruby 写的原版，虽然今天的[版](https://github.com/nats-io/gnatsd)是用 [Go](https://golang.org/) 写的。虽然我仍然热爱 C，但我怀疑我在未来的工作中会用到它。从一开始，Go 就一直是我选择的网络基础设施语言。

![](img/b9e49b9b97f70b0e7e11e3cd9e2881ae.png)

虽然 NATS 现在相当复杂，我也不打算像我把它从 Ruby 转移到 Go 时那样用另一种语言重写服务器，但 Rust 吸引了我的眼球，我也像其他人一样关注着它。布莱恩·坎特里尔的文章很值得一读。我最感兴趣的是 WebAssembly，但那是另外一篇文章了。

回到协议解析器，Ruby 中最初的解析器是使用正则表达式编写的。这并不是因为我懒，而是因为与使用 Ruby 本身遍历输入流相比，Ruby 中的 RegEx 非常快。当然，当我们转向像 Go 这样的编译语言时，这种性能优势不再明显。NATS 服务器的协议解析器是一个接近零分配的手动解析器，可以处理拆分缓冲区、大消息、文本到整数的转换，性能非常好。在 Go 的早期，文本转换工具的性能并不是很好，所以你仍然会看到很多我们自己手工编写的例程来将文本转换成数字，等等。为了了解 Go 早期的一些性能挑战，请随意观看我在丹佛第一届 GopherCon 上的演示。它详细介绍了这篇文章中提出的许多关键性能领域。Golang 多年来在地图和垃圾收集等基础数据结构的性能方面创造了奇迹。它背后有一个不可思议的团队。这对我们来说是一个极好的选择。

# 可量测性

最后但同样重要的是可伸缩性，即规模化的性能。了解您是否有性能问题或可伸缩性问题非常重要。如果您的系统对于单个用户很慢，或者在本例中对于单个客户端连接很慢，那么您就遇到了性能问题。如果您的系统对于单个客户端连接来说很快，但是对于大量连接来说就慢下来了，那么您的系统就存在可伸缩性问题。当我们讨论消息路由和主题分发器中的多个缓存层以避免大规模争用时，我们已经看到了这种暗示。现代硬件上的 NATS 服务器有许多高消息速率连接，可以处理近 100 兆条消息/秒。如果您考虑独立的消息流，其中没有交叉，我们应该尽可能接近线性扩展，直到达到 CPU/内核数量。实际上，这很困难，因为我们开始反复研究缓存和锁定结构来强制同步。在上面的例子中，共享一个主题空间和数据结构来路由消息会严重损害我们的可伸缩性，即使订阅的更新率很低。如果硬件有资源，我集中精力确保它们可以并发和并行运行的领域如下。

1.  连接入口处理。这是协议解析器。就每个连接的处理而言，它们应该是独立的。
2.  消息路由。这一点已经讨论过了，但我们已经在这部分架构上投入了太多的精力，以使其能够运行和扩展。
3.  消息出口。这也应该能够大规模运行，即使当多个入口源合并成单个出口流时。

我在 2011 年做了一个关于可扩展和可用的成功模式的演讲。如果你有时间，这是一个很好的补充，值得一试。

[![](img/9d991761e35d78e3ebbd13766ee17429.png)](https://www.slideshare.net/derekcollison/scalable-and-available-patterns-for-success-7196090)

[https://www.slideshare.net/derekcollison/scalable-and-available-patterns-for-success-7196090](https://www.slideshare.net/derekcollison/scalable-and-available-patterns-for-success-7196090)

# 结论

如果你已经做到了这一步，恭喜你！我从事这项工作已经将近 30 年了，但我仍然从设计和构建简单快捷的系统中获得巨大的乐趣！我希望上面的一些讨论要点可以帮助您设计和构建一个快速高效的基于网络的服务。

*如果您喜欢，请点击💚所以其他人会在媒体上看到这个。*

推特: [@derekcollison](https://twitter.com/derekcollison)